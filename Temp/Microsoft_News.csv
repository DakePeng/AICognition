affiliation,postLink,researchLink,title,text
Microsoft_News,https://blogs.microsoft.com/blog/2024/04/17/manufacturing-for-tomorrow-microsoft-announces-new-industrial-ai-innovations-from-the-cloud-to-the-factory-floor/,,Manufacturing for tomorrow: Microsoft announces new industrial AI innovations from the cloud to the factory floor,"After years of uncertainty from supply chain disruption and increased customer expectations, to changes in consumer demand and workforce shortages, manufacturing remains one of the most resilient and complex industries. Today, we are witnessing the manufacturing industry enter a transformative era, fueled by AI and new AI-powered industrial solutions. This AI-driven shift is prompting many organizations to fundamentally alter their business models and re-evaluate how to address industry-wide challenges like data siloes from disparate data estates and legacy products, supply chain visibility issues, labor shortages, and the need for upskilling employees, among others. AI is more than just an automation tool, it’s a catalyst for innovation, efficiency and sustainability. AI innovation creates an opportunity to help manufacturers enhance time-to-value, bolster operations resilience, optimize factory and production costs and produce repeatable outcomes.

Ahead of Hannover Messe, one of the world’s largest manufacturing innovation events, Microsoft is announcing new AI and data solutions for manufacturers to help unlock innovation, enable intelligent factories, optimize operations and enhance employee productivity. The manufacturing industry has been incredibly resilient over the last decade and the infusion of new AI solutions signifies a critical transformation in this vital industry.

Unlock innovation and fuel the next generation of intelligent factories with data and AI

Manufacturing is one of the most data-intensive industries, generating an average of 1.9 petabytes worldwide every year, according to McKinsey Global Institute. And most of this data goes unused, leaving many valuable insights untapped. According to Gartner® Research, “Generative AI will transform the manufacturing industry to a level previously not available, by providing new insights and recommendations based on data and actionable information.”[1] In this era of AI, the importance of data continues to grow as organizations realize they are only scratching the surface of what’s possible.

To help customers leverage their data and insights, today, we are announcing the private preview of manufacturing data solutions in Microsoft Fabric, and copilot template for factory operations on Azure AI. These solutions help manufacturers unify their operational technology and information technology (IT) data estate and accelerate and scale data transformation for AI in Fabric, our end-to-end analytics SaaS-based platform. Copilot template for factory operations helps manufacturers to create their own copilots for front-line workers utilizing the unified data. Front-line employees can use natural language to query the data for knowledge discovery, training, issue resolution, asset maintenance and more. For example, if a factory plant manager wants to understand why a machine is breaking, they can query the copilot to get insights and resolve the issue in just days, instead of weeks.

As part of our private preview, Intertape Polymer Group (IPG) uses Sight Machine’s Manufacturing Data Platform to continuously transform data generated by its factory equipment into a robust data foundation for analyzing and modeling its machines, production processes and finished products. IPG is now using Sight Machine’s Factory CoPilot, a generative AI platform with an intuitive natural language chat interface, powered by the Microsoft Cloud for Manufacturing and the copilot template for factory operations on Azure AI. This tool facilitates the team’s ability to rapidly gather insights and direct work on production lines which previously operated like black boxes. Instead of working through manual spreadsheets and inaccessible data, all teammates including production, engineering, procurement and finance have better information to drive decisions on products and processes throughout the plant improving yield and reducing inventory levels.

Also in private preview, Bridgestone is partnering with Avanade to confront production challenges head-on, focusing on critical issues related to production disruptions and scheduling inefficiencies, like yield loss, which can escalate into quality issues. As a private preview customer collaborating with Avanade, Bridgestone aims to harness the power of manufacturing data solutions in Fabric and the copilot template for factory operations. Their goal is to implement a natural language query system that enables front-line workers, with different levels of experience, with insights that lead to faster issue resolution. The team is excited to establish a centralized system that efficiently gathers and presents critical information from various sources and facilitates informed decision-making and enhances operational agility across Bridgestone’s production ecosystem.

Creating more resilient operations and supply chains

A robust data strategy must span from cloud to the shop floor to enable the level of scale and integration that will help manufacturers accelerate industrial transformation across all operations. However, gathering OT data and integrating the data into multiple solutions is not an easy task for manufacturers. Production is complex, and their sensors, machines and systems are highly varied. Each site is unique and ensuring the right data is being shared with the right person at the right time is onerous and costly. Unfortunately, these scale and integration hurdles also block the enterprise from scaling AI solutions across every shop floor or gaining global visibility across all their sites.

With this in mind, Microsoft recently launched the adaptive cloud approach, including Azure IoT Operations. Our adaptive cloud is a framework to modernize edge infrastructure across operations, like factories, to take advantage of a modern, composable and connected architecture for your applications. Our adaptive cloud approach creates the level of scale needed to repeat AI solutions across production lines and sites. Putting the adaptive cloud approach into practice, Azure IoT Operations leverages open standards and works with Microsoft Fabric to create a common data foundation for IT and OT collaboration. To find out more about our adaptive cloud approach and Azure IoT Operations, visit our Azure Blog.

Looking to increase global operational efficiency, Microsoft’s customer Electrolux Group, developed a single platform to build, deploy and manage several key manufacturing use cases. Their platform’s goal is to capture all manufacturing data, contextualize it and make it available for real time decision-making across all levels of the organization within a scalable infrastructure. To enable this, Electrolux Group is adopting a full stack solution from Microsoft that leverages the adaptive cloud approach, including Azure IoT Operations. Using this approach, Electrolux Group is looking to reduce overhead from multiple vendors, a consistent and simple way to deploy and manage multiple use cases at a site, and then the ability to scale those solutions to multiple sites with simple and consistent fleet management.

Supply chain disruption is not new; however, its complexity and the rate of change are outpacing organizations’ ability to address issues. Manufacturers are under pressure to prevent and minimize disruptions, and as a result, almost 90% of supply chain professionals plan to invest in ways to make their supply chains more resilient. To support our customers, we’re announcing the upcoming preview of a traceability add-in for Dynamics 365 Supply Chain Management that will allow businesses to increase visibility into their product genealogy through the different steps of the supply chain. Traceability will also help businesses track events and attributes throughout supply chain processes and will provide an interface to query and analyze data.

Empowering front-line workers with AI tools to improve productivity,and job satisfaction

To enable intelligent factory operations, an empowered and connected workforce is key. According to the latest Work Trend Index, 63% of front-line workers do repetitive or menial tasks that take time away from more meaningful work. Additionally, 80% of front-line workers think AI will augment their ability to find the right information and the answers they need. From the office to the factory floor to the field, we are building solutions to address the unique challenges manufacturers face — by helping streamline front-line operations, enhance communication and collaboration, improve employee experience and strengthen security across shared devices.

Today we’re introducing new capabilities for Copilot in Dynamics 365 Field Service that help service managers and technicians efficiently find information, resolve issues while keeping customers updated at every step, and help summarize their work. Generally available, field service managers can interact with Copilot to find pertinent information about work orders using natural language in their flow of work in the Dynamics 365 Field Service web app. Additionally, available in public preview, front-line workers can configure and customize the fields Copilot uses to generate summaries within Dynamics 365 Field Service.

To further streamline collaboration among field service managers, technicians, and remote experts, Dynamics 365 Field Service users with the Field Service app in Teams can now share links to work orders that automatically expand to provide key details. This capability is generally available starting today. Should technicians need additional assistance from remote experts to resolve issues, they can simply access Dynamics 365 Remote Assist capabilities in the flow of work in Microsoft Teams with anchored spatial annotations even if the camera moves.

Microsoft ecosystem and partnerships in the era of AI



These new industry innovations in data and AI are strengthened through the Microsoft Cloud for Manufacturing, which enables organizations to accelerate their data and AI journey by augmenting the Microsoft Cloud with industry-relevant data solutions, application templates and AI services. The Microsoft Cloud for Manufacturing brings the best of Microsoft and our partners to jointly accelerate the digital transformation in manufacturing.

Microsoft is a trusted co-innovation partner committed to working with enterprises to unlock the true potential of AI solutions and transform the industry.​ Our offerings can also be customized by an unmatched global ecosystem of trusted partners. This year, we’re proud to have the following valued partners demonstrate at our Hannover Messe booth: Accenture, Annata, Ansys, Avanade, AVEVA, Blue Yonder, Bosch, CapGemini, Cognite, Connected Cars DK, DSA, HERE Technologies, Hexagon, Netstar, NVIDIA, o9 Solutions, PTC, Rockwell Automation, SAP, Syntax, Sight Machine, Siemens, SymphonyAI, Tata Consultancy Services (TCS), Threedy, ToolsGroup and Tulip Interfaces.

We look forward to seeing you at the Microsoft Booth in Hall 17 Stand G06, where you can join guided tours, and speak with manufacturing and industrial experts from around the world.

_____

[1] Gartner®, GenAI use-case prism for manufacturing, By Ellen Eichhorn, Sohard Aggarwal, July 2023. GARTNER is a registered trademark and service mark of Gartner, Inc. and/or its affiliates in the U.S. and internationally and is used herein with permission. All rights reserved.

Tags: AI, Copilot for Dynamics 365, Generative AI"
Microsoft_News,https://www.microsoft.com/en-us/worklab/our-year-with-copilot-what-microsoft-has-learned-about-ai-at-work/,,A Year with Copilot: What Microsoft Learned About AI at Work,"Who should get AI first? We prioritized functions that would drive ROI fastest.

How We Did It

“Every company will have a slightly different approach,” says Nathalie D’Hers, Corporate Vice President of Microsoft Digital, who oversaw the internal rollout to our more than 200,000 employees. “In our case, we zeroed in first on the roles that we knew would gain a lot of benefit.”

It made sense for sales to get first access: After all, they need to know the product inside and out to communicate its value to customers. But beyond that, we found that salespeople are uniquely positioned to benefit from Copilot, whether it’s cutting down on email triage to prioritize leads or gathering relevant info ahead of a client meeting. In early results, our salespeople saved 90 minutes of time per week; 83 percent of them felt they were more productive; and 67 percent said they were able to parlay the time savings into more time with customers.

Next came customer service and support. Nine months ago, they rolled out Copilot to their more than 40,000 support professionals at once, so they could get the entire organization familiar with the technology fast. They had four objectives: reduce time to expertise for agents, streamline access to knowledge, reduce repetitive administrative tasks (to allow people to focus more on customer support, their key priority), and reduce the high volume of inquiries that come in every day.

It’s been a year of learning, but we have started to discover what Copilot can unlock for individual employees and companies as a whole. Most days, it can feel like we’re on a rocket ship. More specifically, like we’re riding on the rocket ship as we’re building it. —Jared Spataro, Microsoft Corporate Vice President of AI at Work

The investment has paid off. According to a study last year from our Chief Economist’s office of nearly 10,000 Microsoft support agents, several teams saw, on average, a 12 percent reduction in case handling time and a 10 percent boost in case resolution.

And once HR got access, the department retooled an AI-powered employee resource called Ask HR, which expedited the response time for more complex questions about benefits, payroll, and other HR topics. With HR service advisors using Copilot, employees now get faster and more accurate answers to questions that previously might have taken several days to compile and respond to.

“Our HR service professionals are able to handle employee inquiries more efficiently,” says Kathleen Hogan, Microsoft Executive Vice President and Chief People Officer. “So far we are seeing a 26 percent reduction in initial response time thanks to Copilot.”

From there, we used what we learned from those early adopters to help guide the rollout to the rest of our company.

How You Can Do It Too

Put Copilot where it’s most useful. Whatever department or role you’re targeting, clearly identifying goals before a rollout helps leaders and employees determine from the start what’s working and what’s not. It also helps set appropriate benchmarks for success, whether that’s response times or more effective meetings or other metrics. For guidance, look to our Copilot Scenario Library, which includes suggested use cases and key performance indicators to help orgs determine how Copilot can help.

Go for easy wins too. As you’re going after function-level transformation, use AI to improve simple tasks as well. Gaining confidence and ability early on (for example, asking Copilot to recap a meeting) helps users maintain a healthy growth mindset when they hit the inevitable road bumps.

Give it to entire teams. Rolling out Copilot to entire teams at once—even if they’re small ones—is crucial in promoting peer-to-peer learning: It encourages sharing and learning among the group members, multiplying the impact of the technology. It also allows organizations to see patterns to help identify what’s working (or what’s not).

Make sure to track the impact. To understand how AI is transforming workplace behavior, you’ll need a way to measure its usage. A platform like our Copilot Dashboard can help you plan and measure the impact."
Microsoft_News,https://azure.microsoft.com/en-us/blog/ai-study-guide-the-no-cost-tools-from-microsoft-to-jump-start-your-generative-ai-journey/,,AI study guide: The no-cost tools from Microsoft to jump start your generative AI journey,"The world of AI is constantly changing. Every day it seems there are new ways we can work with generative AI and large language models. It can be hard to know where to start your own learning journey when it comes to AI. Microsoft has put together several resources to help you get started. Whether you are ready to build your own copilot or you’re at the very beginning of your learning journey, read on to find the best and free resources from Microsoft on generative AI training.

Let’s go!

Azure AI Build intelligent apps at enterprise scale with the Azure AI portfolio Lean more

Azure AI fundamentals

If you’re just starting out in the world of AI, I highly recommend Microsoft’s Azure AI Fundamentals course. It includes hands on exercises, covers Azure AI Services, and dives into the world of generative AI. You can either take the full course in one sitting or break it up and complete a few modules a day.

Learning path: Azure AI fundamentals

Course highlight: Fundamentals of generative AI module

Azure AI engineer

For those who are more advanced in AI knowledge, or are perhaps software engineers, this learning path is for you. This path will guide you through building AI infused applications that leverage Azure AI Services, Azure AI Search, and Open AI.

Course highlight: Get started with Azure OpenAI Service module

Let’s get building with Azure AI Studio

Imagine a collaborative workshop where you can build AI apps, test pre-trained models, and deploy your creations to the cloud, all without getting lost in mountains of code. In our newest learning path, you will learn how to build generative AI applications like custom copilots that use language models to provide value to your users.

Learning path: Create custom copilots with Azure AI Studio (preview)

Course highlight: Build a RAG-based copilot solution with your own data using Azure AI Studio (preview) module

Dive deep into generative AI with Azure OpenAI Service

If you have some familiarity with Azure and experience programming with C# or Python, you can dive right into the Microsoft comprehensive generative AI training.

Learning path: Develop generative AI solutions with Azure OpenAI Service

Course highlight: Implement Retrieval Augmented Generation (RAG) with Azure OpenAI Service module

Cloud Skills Challenges

Microsoft Azure’s Cloud Skills Challenges are free and interactive events that provide access to our tailored skilling resources for specific solution areas. Each 30-day accelerated learning experience helps users get trained in Microsoft AI. The program offers learning modules, virtual training days, and even a virtual leaderboard to compete head-to-head with your peers in the industry. Learn more about Cloud Skills Challenges here, then check out these challenges to put your AI skills to the test.

Invest in App Innovation to Stay Ahead of the Curve Learn more

Challenges 1-3 will help you prepare for Microsoft AI Applied Skills, scenario-based credentials. Challenges 4 and 5 will help you prepare for Microsoft Azure AI Certifications, with the potential of a 50% exam discount on your certification of choice1.

Challenge #1: Generative AI with Azure OpenAI

In about 18 hours, you’ll learn how to train models to generate original content based on natural language input. You should already have familiarity with Azure and experience programming with C# or Python. Begin now!

Challenge #2: Azure AI Language

Build a natural language processing solution with Azure AI Language. In about 20 hours, you’ll learn how to use language models to interpret the semantic meaning of written or spoken language. You should already have familiarity with the Azure portal and experience programming with C# or Python. Begin now!

Challenge #3: Azure AI Document Intelligence

Show off your smarts with Azure AI Document Intelligence Solutions. In about 21 hours, you’ll learn how to use natural language processing (NLP) solutions to interpret the meaning of written or spoken language. You should already have familiarity with the Azure portal and C# or Python programming. Begin now!

Challenge #4: Azure AI Fundamentals

Build a robust understanding of machine learning and AI principles, covering computer vision, natural language processing, and conversational AI. Tailored for both technical and non-technical backgrounds, this learning adventure guides you through creating no-code predictive models, delving into conversational AI, and more—all in just about 10 hours.

Complete the challenge within 30 days and you’ll be eligible for 50% off the cost of a Microsoft Certification exam. Earning your Azure AI Fundamentals certification can supply the foundation you need to build your career and demonstrate your knowledge of common AI and machine learning workloads—and what Azure services can solve for them. Begin now!

Challenge #5: Azure AI Engineer

Go beyond theory to build the future. This challenge equips you with practical skills for managing and leveraging Microsoft Azure’s Cognitive Services. Learn everything from secure resource provisioning to real-time performance monitoring. You’ll be crafting cutting-edge AI solutions in no time, all while preparing for Exam AI-102 and your Azure AI Engineer Associate certification. Dive into interactive tutorials, hands-on labs, and real-world scenarios. Complete the challenge within 30 days and you’ll be eligible for 50% off the cost of a Microsoft Certification exam2. Begin now!

Finally, our free Microsoft AI Virtual Training Days are a great way to immerse yourself in free one or two-day training sessions. We have three great options for Azure AI training:

Azure AI Fundamentals Generative AI Fundamentals Building Generative Apps with Azure OpenAI Service

Start your AI learning today

For any and all AI-related learning opportunities, check out the Microsoft Learn AI Hub including tailored AI training guidance. You can also follow our Azure AI and Machine Learning Tech Community Blogs for monthly study guides."
Microsoft_News,https://blogs.microsoft.com/blog/2024/04/15/microsoft-and-g42-partner-to-accelerate-ai-innovation-in-uae-and-beyond/,,Microsoft and G42 partner to accelerate AI innovation in UAE and beyond,"Strategic partnership highlights:

Expansion of partnership between Microsoft and G42 to deliver advanced AI solutions with Microsoft Azure across various industries and markets.

Microsoft will invest $1.5 billion in G42 for a minority stake in G42 and join its board of directors.

Companies will support the establishment of a $1 billion fund for developers to boost AI skills in the United Arab Emirates (UAE) and broader region.

Expanded strategic partnership:

Today, we announced a strategic investment in G42, a leading AI company in the UAE, to co-innovate and deliver advanced AI solutions with Microsoft Azure for various industries and markets across the Middle East, Central Asia and Africa.

Microsoft will invest $1.5 billion in G42 for a minority stake in the company with Brad Smith, Microsoft Vice Chair and President, joining G42’s board of directors — strengthening the long-standing collaboration and mutual synergies between the two companies. With the breadth of the Microsoft Cloud and its differentiated AI capabilities, the deal significantly advances G42’s strategy of delivering generative AI and next-generation infrastructure and services for a range of customers across financial services, healthcare, energy, government and education.

The commercial partnership is backed by assurances to the U.S. and UAE governments through a first-of- its-kind binding agreement to apply world-class best practices to ensure the secure, trusted, and responsible development and deployment of AI. Microsoft and G42 will work closely together to elevate the security and compliance framework of their joint international infrastructure. Both companies will move forward with a commitment to comply with U.S. and international trade, security, responsible AI, and business integrity laws and regulations. The work on these topics is governed by a detailed Intergovernmental Assurance Agreement between G42 and Microsoft that was developed in close consultation with both the UAE and U.S. governments.

Foundational to the partnership is G42’s trust and commitment in Microsoft’s cloud platform. G42 will expand its existing commitment to deploying Microsoft Cloud offerings, demonstrating confidence in Microsoft as its preferred partner to enhance services and deliver value-added solutions to its customers. With the partnership, G42’s data platform and other essential technology infrastructure will migrate to Microsoft Azure to benefit from industry-leading performance, scalability and security capabilities. Migrating to Azure will also support AI product development that allows G42 to create services that can scale to achieve faster delivery times for its customers globally. Together, we look forward to accelerating AI transformation in emerging markets and advancing equitable growth in AI globally.

Building on our technical co-innovation

G42 brings an excellent track record as a leader actively driving global progress and accessibility in AI technologies, and Microsoft and G42 have worked closely together to help optimize Cloud and AI solutions for the Middle East.

Last year, G42 was one of the first partners to commit to implementing Microsoft Cloud for Sovereignty offering to UAE-based organizations. G42 is helping public sector and regulated industries to use new platform capabilities for securing sensitive data, providing access to the latest cloud and AI features available on Azure public cloud, and ensuring they comply with local privacy and regulatory requirements. G42’s deep understanding of UAE sovereignty requirements and technical capabilities are central to customizing Microsoft Cloud for Sovereignty to help address customer’s specific needs.

Microsoft also announced that Jais, G42’s Arabic Large Language Model (LLM), will be available in the Azure AI Model Catalog. This model represents a significant advancement for the Arabic world in AI, offering over 400 million Arabic speakers the opportunity to explore the potential of generative AI. Jais is the world’s first Arabic LLM developed by G42 in collaboration with Cerebras, Mohamed bin Zayed University of Artificial Intelligence (MBZUAI), and Med42 LLM, a generative AI model to streamline medical reporting. The expanded partnership with Microsoft will help accelerate the adoption of G42’s groundbreaking AI products and services, such as Jais, making them available through Microsoft Azure.

Announced in March of this year, First Abu Dhabi Bank (FAB), the UAE’s largest bank, will collaborate with Core42, a subsidiary of G42, to accelerate its digital transformation journey leveraging Microsoft Azure trusted cloud platform for enterprises. FAB will move its datacenter and workload to Azure, enabling the bank to use Core42’s sovereign controls platform, which is built on Azure and ensures the highest standards of data sovereignty and compliance with UAE regulations.

One of the leading examples of precision medicine in action is the collaboration between G42 subsidiary M42, a global health care company, the Broad Institute of MIT and Harvard, Microsoft, and the International Center for Genetic Disease (ICGD). The partners are using Terra, a scalable and secure platform for biomedical research, to enable data sharing and analysis across different institutions and countries. Terra, powered by Microsoft Azure, allows researchers to access and analyze anonymized genomic data from the Emirati Genome Program, which has completed over 500,000 whole genome sequences to date. By applying AI technologies to this rich data source, the collaborators aim to advance clinical genomic research and disease prevention, as well as support precision medicine and life science strategies globally.

Accelerating access to digital innovation in UAE and the region

Along with providing advanced AI capabilities, the partnership will benefit regions beyond the UAE in ways that will improve how enterprises experience cloud computing. By bringing expanded low latency datacenter infrastructure to emerging markets, Microsoft and G42 will help accelerate digital transformation across key industries in those regions. This will provide countries across the Middle East, Central Asia and Africa with expanded access to services and technologies that will allow them to address the most challenging business concerns while ensuring the highest standards of security and privacy.

Furthermore, the partnership will also support the development of a skilled and diverse AI workforce and talent pool that will drive innovation and competitiveness for the UAE and broader region with the investment of $1 billion in a fund for developers.

Tags: AI, Microsoft Azure"
Microsoft_News,https://news.microsoft.com/source/features/digital-transformation/how-ai-can-help-cancer-patients-receive-personalized-and-precise-treatment-faster/,,How AI can help cancer patients receive personalized and precise treatment faster,"During a typical 15- to 20-minute clinic visit with patients, oncologist Dr. Rom Leidner opens around 20 different files on his computer. They are pieces of a puzzle, creating a picture of the patient’s cancer – blood-test results, weight trends, radiology images, microbiology, pathology, cardiology, electronic messages from other doctors, electronic messages from patients, text pages from nurses and clinic staff, prescriptions, chemotherapy orders, insurance forms.

For some files, he has to log in to specialized software for access. And after reviewing all that, he can actually examine the patient and discuss their cancer care. To keep to his schedule for seeing patients, Dr. Leidner and many doctors resort to spending their weekends copying and pasting all this information into medical charts ahead of time.

Dr. Rom Leidner. (Courtesy of Providence)

“The last hope of our profession may well be AI-assisted curation of information streams that converge in the exam room,” says Dr. Leidner, a medical oncologist specializing in hematology at Providence Cancer Institute Franz Clinic in Portland, Oregon.

Providence, a 51-hospital healthcare organization serving seven western states in the U.S., is working to do just that, developing research prototype AI tools to sort through growing mountains of patient data, in time-of-flight, to improve therapies and to advance the treatment of cancer, which accounts for nearly one in six deaths worldwide.

More refined lab tests, scans and genetic analyses can help promote a better understanding of each patient’s case, resulting in personalized therapies that adapt treatment and medication to each patient’s genetic biomarkers. Assessing all that information is an unfathomably huge task.

“It’s a fortunate convergence in the last two years, that just as we’re approaching a bottleneck with hyper-plexed cellular and molecular data from clinical trials that will exceed human capacity to readily analyze, we appear to be at the doorstep of a transformative technology capable of handling the data streams we foresee in next-gen medical science,” Dr. Leidner says.

Providence is working with Microsoft on prototype AI tools to improve care for cancer patients, accelerate progress in understanding cancer and perhaps find treatments or cures. The project is part of Microsoft’s commitment to apply generative AI to precision health.

Hoifung Poon, Ph.D. (Courtesy of Microsoft)

“Our research collaboration at Providence is bearing fruits in end-to-end real-world applications toward precision medicine. The underlying technological advances can empower clinical practitioners and researchers to unlock more and more high-value applications for improving patient care and accelerating biomedical discovery,” says Hoifung Poon, Ph.D., general manager of Health Futures at Microsoft Research, who has been collaborating with Providence on these prototype AI tools.

Patient information exists in a variety of formats – electronic medical records (EMRs), imaging scans, genomics and all manner of lab tests. The same information might be noted using different terms or different formats and the core information requires synthesizing a large amount of unstructured data. This is just the kind of job AI can do well – summarize unstructured data in text form.

For cancer patients who have exhausted the first line of treatments, a clinical trial, in which new treatments are tested, can offer a best last hope. The hard part is finding one. The percentage of U.S. cancer patients participating in a trial is in the single digits, yet, ironically, lack of enrollment is a key reason clinical trials fail.

This problem has nothing to do with a scarcity of clinical trials. In fact, the number of registered clinical trials (for all treatments, globally), increased 59-fold between 2000 and 2021, according to the World Health Organization. In the U.S., the number of registered studies grew 289-fold in that same period.

Instead, one of the biggest hurdles to clinical trial enrollment is data. Again, the issue isn’t scarcity but the opposite – mountains of records.

“A patient’s performance status, location of the cancer, blood counts, critical organ function such as heart, liver and kidneys, and numerous other criteria must all be carefully assessed for every potential patient, in every clinical study,” says Dr. Leidner, who is running a clinical trial of gene-modified TCR-transduced T-cell adoptive therapy targeting KRAS neoantigen. This is a kind of immunotherapy in which a patient’s own T-cells are engineered to specifically recognize and eradicate cancer cells with mutations in the KRAS gene associated with cancer.

As if the medical puzzle pieces weren’t challenging enough to fit together, basic logistical information may also be missing from patient records. “It may be surprising, but identifying a patient’s oncologist or other specialists that have been involved isn’t necessarily straightforward. This kind of information should be readily organized in the patient record, but in reality it’s often fragmented or absent,” Dr. Leidner says.

Where AI shines

The challenge isn’t just multiple varieties of information for each patient, but also fragmentation in EMR formats from one clinic or healthcare system to another. AI, however, can summarize this information quickly. Most importantly, it doesn’t require information to be formatted – it can vacuum up lab results, doctors’ notes and digitized scans as they are. It also can figure out that two different terms refer to the same thing, because it can work with natural language.

“AI is very useful in going through the databases of research trials, gathering multiple trial eligibility criteria and matching that to each individual patient by culling that information from the digital medical record,” Dr. Leidner says. “As a clinician, there simply aren’t enough hours in the day to sift through the trials matching process and still see patients.”

One thing that will become less important in clinical research is the site of origin of a patient’s cancer or the morphologic categorization – “this is quite a difficult thing for even the medical profession to grasp,” Dr. Leidner says. In some advanced clinical trials, “it’s more a question of ‘do they have the right immune system and the right gene mutation rather than which type of cancer?’”

Genetic testing of cancers is now routine, but HLA typing (for human leukocyte antigen, a set of genes that regulate the immune system), while routine for organ transplants, isn’t yet common in oncology. Providence has made HLA typing standard for cancer patients to enable personalized medicine and to be able to quickly find trials that offer a potential match.

Dr. Carlo Bifulco. (Courtesy of Providence)

Personalized medicine in oncology “is based on the presence or absence of genomic alterations. Each therapy is specific for those alterations, and those can be very rare,” says Dr. Carlo Bifulco, chief medical officer of Providence Genomics, a division of Providence that is using AI to transform health care.

Think of all these pieces as pixels in a photograph. In a low-resolution image, it might be possible to guess what kind of bird is in a photo, but with high resolution, it’s easier to recognize the species thanks to specific details.

Treating cancer by the organ where it occurs, such as lung cancer, is a low-resolution analogy. By increasing the resolution, it becomes clear that one patient’s cancer is driven by a set of genetic aberrancies and another patient’s is driven by a different set – they are different even though they are both lung cancer.

Biomarkers are not the end of the story. Other attributes, such as overall health, tolerance to cancer drugs, age and a patient’s other health problems further sharpen the resolution. Such high-resolution, holistic representation is called “patient embedding.” To find enough patients with similar patient embedding for a new treatment undergoing clinical trial requires starting from a huge pool of patients.

Providence Cancer Institute Franz Clinic is using AI to better match patients with clinical trials and to research new treatments. (Courtesy of Providence)

The National Institutes of Health maintains a voluntary database of clinical trials, “but it only has a rudimentary search interface,” Poon says. In the U.S. alone, there are two million new cancer patients every year. Meanwhile, at any given moment, there are thousands of active trials.

“Today’s manual process is hopelessly non-scalable,” he adds. “Our dream is to structure all medical information and create a high-fidelity patient embedding to automatically match against trials continuously, thus enabling just-in-time clinical trial matching and democratizing this very important source of high-quality health care. As a research team, it has been exciting to work with Providence. Developing prototype AI tools using the principles of responsible AI like fairness, privacy and security, and reliability and safety is important when we look to improve patient outcomes in the future.”

With the latest advances in generative AI and the promising initial proof point at Providence, one can already imagine creating a population-scale dashboard for clinical researchers to find potential trial candidates in real time.

While AI untangles the logistics of clinical trial matching, it could have an even bigger role in medical discovery. “We are looking for ever more and new ways to understand the biology of cancer, and through that, to discover ways we can eradicate cancer,” Dr. Leidner says.

The goal is to develop computer models that can take the enormous amounts of data generated in clinical trials and real-world data to spot a trend and then prove that the therapy caused the trend. “Today, from one biopsy, we’re getting gigabytes of data at the cellular and molecular level,” Dr. Leidner says. “There can be tens of thousands of variables from every patient visit on a clinical trial.

These datasets are simply beyond human capacity to analyze. Given the scale, it would conceivably require scores of Ph.D.’s, working for years, to complete the analysis of one clinical trial.”

The promise of multimodal machine learning

Providence and Microsoft are working together on multimodal machine learning, trained on diverse data generated and managed by Providence – text, images or genomics and, in the future, spatial biology, proteomics (the study of proteins in our bodies), transcriptomics (the study of the body’s RNA) and epigenomics (the study of the regulatory superstructure of the genome).

“We put together very complex data sources, which may be images, genomic datasets or just text, and there are gigantic data streams which can benefit from this approach,” Dr. Bifulco says. “The technique is matching solutions already. We have it already facing oncologists, research nurses and pathologists and we use it every day.”

This demo shows how the AI tool helps doctors efficiently comb through clinical trial criteria for a patient. (Courtesy of Providence)

The progress is remarkable on several levels. The diagnostic machines that are generating such huge amounts of data didn’t exist a couple of years ago. AI has also improved in that time – the joint Providence and Microsoft research team is exploring the cutting edge of foundation models and going further to bridge the competency gap in precision health. Oncology may be the tip of the spear, but exponentially expanding data streams, converging at every visit to the doctor’s office, will eventually impact all areas of medicine.

The AI prototypes for Providence were trained on such holistic, multimodal patient data. Microsoft helped Providence process legacy radiology images – more than two million studies with 600 million images. All computation was conducted within Providence’s private tenant and approved by the Providence Institutional Review Board (IRB), adhering to appropriate standards of privacy and compliance.1

Microsoft also helped Providence digitize all cancer pathology slides (100,000-plus whole-slide images) as ultra-high-resolution images to become another research AI training set. The joint team has since made great strides in pretraining powerful biomedical large multimodal models (LMMs) from such large-scale, multimodal, real-world data.

“The resulting multimodal patient embedding can serve as a digital twin for the patient and enable patient-like-me reasoning at scale,” Poon says. “Such population-level real-world evidence can improve patient care by identifying what works and accelerate biomedical discovery by pinpointing where and how it doesn’t work.”

Many pieces of the puzzle, or pixels that would increase resolution of the picture, are still missing – or they exist as data that isn’t being analyzed.

“All the other things that we are still not capturing are influencing and impacting the outcomes of the patient,” Dr. Bifulco says. “Currently in the experimental setting, you’re limited by the computational aspects. AI can play a major role.”

1Providence IRB protocols #2019000204 and 2019000206.

Top photo: More complex medical tests are generating enormous amounts of data. AI is helping analyze that data much faster – and time is of the essence for patients with cancer. (Photo by sinology/Getty Images)"
Microsoft_News,https://www.microsoft.com/en-us/industry/blog/media-and-entertainment/2024/04/11/microsoft-at-the-2024-nab-show-reimagining-media-with-data-and-ai/,,Microsoft at the 2024 NAB Show: Reimagining media with data and AI,"NAB Show stands as a transformative crossroads, where the past, present, and future of media converge. Since its inception in 1923, the National Association of Broadcasters’ flagship event has been a cornerstone of the industry, uniquely blending content and technology.

Today, we are witnessing an extraordinary evolution, where AI is revolutionizing every aspect of content creation, distribution, viewer engagement, and monetization. The show serves as a powerful stage to witness firsthand the profound impact of AI on the industry. At Microsoft, we are bringing these elements to life across our platform and ecosystem. Attendees will see that we have moved beyond hype and are deploying this technology at scale powered by data and the Microsoft Cloud.

This is an era defined by tech intensity, characterized by personalized content delivery, on-demand streaming services, data-driven advertising, and a shift towards immersive and interactive experiences. We are committed to empowering our customers to navigate these changes successfully. Whether you’re a content creator, broadcaster, ad agency, or streaming platform, adapting to the expectations of a global, tech-savvy audience is imperative. This shift presents both challenges and opportunities, and at Microsoft, we stand ready with our partners in this dynamic landscape.

Our industry-specific solutions are designed to enhance production efficiency and cost-effectiveness, while our advanced analytics unlock valuable insights. We are redefining the video editing process to drive audience engagement and amplify personalization.

As AI catalyzes one of the most profound transformations in the industry’s history, I am personally thrilled to invite you to join us in redefining the future of creativity, content, and experiences.

Microsoft for media and entertainment Transform the future of creativity, content, and digital experiences Get started

Join Microsoft at 2024 NAB Show to see how we are reimaging media

Microsoft empowers media organizations to achieve more through a trusted and secure platform supported by a comprehensive partner ecosystem. Join us at our booth (W2657) to see how data and AI are reimagining the media landscape.

Empower content creators and distributors

Elevate the viewer experience

Microsoft AI solutions Learn more

Experience your AI assistant at work with Microsoft Copilot for Microsoft 365, where AI helps automate and personalize the content creation process, offering a new way to work.

Captivate your audience with Microsoft Azure PlayFab tools for engaging content that automatically adapts to viewer preferences and behavior.

Reimagine monetization strategies

Maximize revenue with insights that help reach a broader audience, as demonstrated by YOBI with the power of Azure Databricks.

Optimize ad revenue by expanding reach of advertisers through precision targeting and personalization with Copilot in Microsoft Dynamics 365 Customer Insights and Microsoft Fabric.

Come see the future of interactive TV

Come visit the Capitalize Zone (W2149) to experience Beat the BUZZR®️. Beat the BUZZR®️ takes the future of interactive TV to the next level by showcasing its dynamic interactivity using content from Fremantle’s BUZZR®️ television network, a treasure trove of pop culture and game show classics, such as Family Feud, To Tell The Truth, and Supermarket Sweep. Leveraging the collaborative strengths of Microsoft, NVIDIA, and an extensive partner ecosystem.

Beat the BUZZR®️ not only invigorates these classic programs with interactive elements like quizzes, trivia, and personalized insights but also opens the door to innovative monetization strategies for content owners. This platform serves as a testament to how the intelligent use of data and AI can revolutionize both audience engagement and revenue generation. Dive deep into your favorite episodes and see how Beat the BUZZR®️ is crafting new possibilities for content monetization, making every interaction an opportunity to captivate and capitalize.

At the heart of this transformation is a coalition of esteemed partners:

Prime Focus Technologies breathes new life into archival content, employing their CLEAR AI to deepen and enrich metadata, unlocking a treasure trove of interactive potential.

breathes new life into archival content, employing their CLEAR AI to deepen and enrich metadata, unlocking a treasure trove of interactive potential. MediaKind revolutionizes the broadcasting experience, making dynamic ad placements and seamless content delivery a reality, ensuring each moment resonates with crystal clarity.

revolutionizes the broadcasting experience, making dynamic ad placements and seamless content delivery a reality, ensuring each moment resonates with crystal clarity. Alice & Smith stretches the bounds of fan interaction with XR Server, making the leap from passive observation to active, immersive participation.

stretches the bounds of fan interaction with XR Server, making the leap from passive observation to active, immersive participation. Microsoft Advertising redefines the advertising landscape, integrating interactive, real-time content that speaks directly to viewers’ interests and passions.

redefines the advertising landscape, integrating interactive, real-time content that speaks directly to viewers’ interests and passions. SymphonyAI’s Revedia delivers a masterclass in analytics, turning raw data into a goldmine of insights, enhancing content strategy, and fine-tuning monetization models.

Revedia delivers a masterclass in analytics, turning raw data into a goldmine of insights, enhancing content strategy, and fine-tuning monetization models. UIC Digital elevates the user experience, melding intuitive design with captivating aesthetics while integrating all systems and components seamlessly to ensure the user journey is as engaging as the content itself.

Each partner demonstration in the NAB Capitalize Zone is a portal to understanding how these contributions not only support the Beat the BUZZR®️ experience but also contribute to new revenue models and engagement strategies in the media landscape.

Hear from Microsoft and industry expertise in the sessions

In addition to catching us at our booth, you can hear from Microsoft in a variety of ways. Below are the different sessions you’ll be able to find Microsoft at.

Keynote session

AI in Media and Entertainment—Hear from Paige Johnson, Microsoft’s Vice President of Media Industry, and other industry leaders in a conversation around the applications of AI in Hollywood and the benefits and pitfalls of its growing use in productions and development.

Microsoft sessions

Microsoft’s commitment to the media and entertainment industry

Microsoft enables media organizations to achieve more through a trusted and secure platform built to empower content creators and distributors, enhance the viewer experience, and reimagine monetization strategies. More information can be found on Microsoft media and entertainment industry solutions."
Microsoft_News,https://www.microsoft.com/en-us/microsoft-365/blog/2024/04/11/enabling-your-ai-transformation-journey-with-microsoft-viva/,,Enabling your AI transformation journey with Microsoft Viva,"A year into working with Microsoft Copilot, we’ve learned a lot from our customers about how people are using AI at work. We’ve also learned from our own company-wide rollout to more than 200,000 employees—what’s working, where there are challenges, and what early behaviors can teach us about broader impacts to adoption and establishment of new work patterns. One of the biggest takeaways is that AI reinvention is a whole new way of working that involves both software and culture. It’s a cultural shift. Microsoft Viva empowers leaders and organizations to make that shift. We’re excited to announce new capabilities to help drive enterprise-wide adoption of Copilot, including the general availability of Microsoft Copilot Dashboard and Microsoft Copilot Academy, powered by Viva, which will be available to all Copilot for Microsoft 365 customers.

Microsoft Viva Empower and engage your workforce with next-generation AI and insights in Microsoft Viva. Discover more

Microsoft Copilot Dashboard is now generally available

The Microsoft Copilot Dashboard is an out of the box report designed for business leaders to easily understand the impact of Copilot for Microsoft 365 by providing privacy-protected insights across every stage of your AI transformation journey. Building on the initial release at Microsoft Ignite, which included readiness and usage data across Microsoft 365 apps, this release offers additional pivots that combine Copilot usage metrics with organizational context and collaboration data, enabling deeper views of adoption and impact. Copilot customers will have the flexibility to filter by attributes like department, teams, or roles, understand differences between groups, and compare those same measures between users and non-users. Viva Insights customers can use analyst workbench capabilities to dive deeper with custom reports, including incorporating data from other relevant sources. And for a limited time only, Copilot for Microsoft 365 customers will be eligible to access Viva Insights at no additional cost.

We are also excited to announce that starting in 2024 Q3, the Copilot Dashboard will be available to all Copilot for Microsoft 365 customers at no additional cost and will not require a Viva license. You can access the dashboard in the Viva Insights app in Microsoft Teams or via the web app. Select the “Copilot Dashboard” option from the left navigation menu and start exploring results from your organization. Additionally, Copilot for Microsoft 365 customers will be eligible for a promotional offer that will provide access to all of Viva Insights, including Copilot Dashboard, as well as access to advanced insights and manager and leader insights. Contact your account team to learn more about how you can take advantage of this offer.

In addition to having the right data-driven insights, successful AI reinvention often requires a change management strategy that includes arming employees with the right knowledge, developing clear and consistent communications, and understanding employee feedback to address any gaps or challenges. Microsoft Viva helps you develop employee skills, drive awareness, foster champions, and dig deeper into the impact of Copilot across your organization.

Enable employees with AI knowledge and skills

Our Work Trend Index showed that 82% of leaders said their employees will need new skills to be prepared for the growth of AI. I’m excited to announce the general availability of Microsoft Copilot Academy, where we’ve centralized those learning experiences for your organization to supercharge their Copilot skills. Copilot Academy is available in Viva Learning and starting in 2024 Q3, it will be available to all Copilot for Microsoft 365 customers at no additional cost and will not require a Viva license.

The Copilot Academy includes curated learning paths designed by Microsoft experts to help your employees discover, learn about, and use Copilot experiences effectively. The initial release features a combination of standard generative-AI learning content (such as “Intro to prompts”) and a series of learning paths specific to Copilot for Microsoft 365 (such as “Summarize email threads with Copilot in Outlook”). We will continue to enhance Copilot Academy in the coming months, including hands-on experiences hosted by Copilot Lab in our next release.

Copilot Academy is available in Viva Learning, your central hub for learning, so it’s easy for users to access, discover, and share within the Microsoft 365 tools they’re already using. It is preloaded and requires no admin setup or configuration, so your Microsoft 365 admins can focus on helping drive Copilot adoption. Check out our setup documentation to get started, and stay tuned for updates on content, experience, and feature enhancements coming soon. Additionally, to help our customers develop a skillset related to AI tool usage—like prompt engineering—we’ve developed a set of learning content available on Copilot Lab and Microsoft Learn that you can access today.

Build excitement and momentum around Copilot

Getting the word out, often and early, about new technologies like AI is key to successful change management. With Viva Amplify, an internal communications platform, you can elevate your Copilot messaging and energize employees by reaching them in the channels they use most often—email, SharePoint, Microsoft Teams, and Viva Engage. And we’ve designed the new Copilot Deployment Kit in Viva Amplify specifically to help you launch Copilot campaigns with ease. Your corporate communications team, your change team, or your early champions can use pre-built campaign templates to drive awareness, and help employees learn what it can do for them. It comes with pre-drafted content, videos, guides, and publications that can easily be customized and sent to help users learn about Copilot. And in the reporting tab, you have rich campaign analytics to understand engagement and where to make improvements.

Grow the Copilot conversation through community

Fostering leadership communications and AI champions in your organization can also help accelerate Copilot adoption. Viva Engage can enable leaders and community champions to share strategy, learnings, and experiences broadly with their organization. In the coming weeks, Viva Engage will add built-in capabilities to help you accelerate adoption, where admins can enable a new custom-made Copilot community with one click that launches an onboarding checklist, recommends pre-seeded content and conversation starters, and supports dynamic community membership based your organization’s existing Copilot licensing allotment.

Corporate communicators or community managers can build campaigns for Copilot based on what people are talking about, so the conversation remains relevant and reaches the right people. As people post comments, Copilot can help draft responses and provide analytics around engagement, trending topics, reach, and sentiment. And people can use Answers in Viva to ask questions and find Copilot knowledge and resources around the organization. The new Intelligent Importer—now generally available—makes it easy to generate and add your own question-and-answer for this community to support commonly asked questions.

And lastly, new network analytics include detailed engagement metrics and theme extraction to show what’s trending and what’s top of mind for employees across all communities.

Gain a deeper understanding of AI readiness, adoption, and impact

Innovative companies and early adopters keep up with their Copilot deployment by engaging employees through the journey, that includes continuously seeking employee feedback and making the right adjustments to manage a successful rollout. In addition to using Viva to measure organizational-wide employee engagement on your AI transformation strategy, we’re introducing new research-backed Microsoft Copilot Impact survey templates in Viva Glint and Viva Pulse designed to gauge sentiment on how Copilot is impacting employees while benchmarking those insights against industry research. The survey results will integrate directly with the Copilot Dashboard so that talent and business leaders can see the data in a unified view. Questions will include:

Quality: Copilot helps improve the quality of my work or output.

Effort: Using Copilot helps me spend less mental effort or mundane or repetitive steps.

Speed: Copilot allows me to complete tasks faster.

Productivity: When using Copilot, I am more productive.

By combining workplace collaboration and behavioral insights with employee survey data, Microsoft customer, dentsu, one of the top creative media companies in the world, was able to see the direct value and productivity impact of Copilot on its workforce.

“Our recent analysis shows employees are saving at least 15 minutes, if not 30 minutes a day by using Copilot. We are seeing a noticeable shift in how they are using the technology, spending less on meetings, emails, calls, or chats, using the time they get back to focus on deep work without interruptions and to invest in their teams.” —Kate Slade, Director of Emerging Technology Enablement at dentsu

Start using Microsoft Viva to help you drive Copilot adoption today

We invite you to discover the full capabilities of Microsoft Viva and the Copilot Dashboard as we prepare for the future of work together. Reach out to your Microsoft account team to get started today.

To learn more about Microsoft Viva and how it can help you on our AI transformation journey, download our Copilot Success Kit, which includes a detailed overview on how to use each Viva app to accelerate Copilot adoption and engagement. Also, sign up for our upcoming webinar series to hear how our customers are using Viva to drive Copilot adoption and measurement.

For the latest research insights on the future of work and generative AI, visit WorkLab."
Microsoft_News,https://www.microsoft.com/en-us/industry/blog/healthcare/2024/04/10/beyond-himss24-microsoft-partners-redefine-healthcare-with-ai-solutions/,,Beyond HIMSS24: Microsoft partners redefine healthcare with AI solutions,"After the excitement of HIMSS24, healthcare organizations are harnessing AI momentum leveraging our partner network to bring transformative healthcare solutions to market. Our presence at the event revolved around the theme ‘shaping a healthier future.’ With that goal in mind, we focused on our partners’ innovative use of data and AI solutions in three key areas: solving care continuum challenges, modernizing data estates to unlock powerful insights, and accelerating essential cloud migration and security initiatives.

The latest AI innovations from Microsoft Cloud for Healthcare, with our partners, empower patients, providers, payors, and life sciences organizations:

Patients can access personalized care.

can access personalized care. Providers can deliver more efficient and effective care through advanced data analytics.

can deliver more efficient and effective care through advanced data analytics. Payors gain insights to improve operational efficiency and enhance patient outcomes.

gain insights to improve operational efficiency and enhance patient outcomes. Life sciences organizations accelerate research and drug development processes.

Some specific examples of our investments include healthcare data solutions in Microsoft Fabric, which enables healthcare organizations to unify and centralize their data for scalable analytics and AI workloads. Additionally, we’ve invested in a new certified software designation for Solutions Partners in healthcare, and other industries, as part of the Microsoft Cloud for AI Cloud Partner Program. These designations certify that our partner solutions are optimally built on Microsoft Industry Clouds to deliver their solutions.

Together, we’re seizing the remarkable opportunity that AI presents in healthcare, propelling the industry towards a transformative future.

Microsoft Cloud for Healthcare Improve healthcare experiences with AI-powered solutions Explore capabilities

Microsoft at HIMSS24

We were proud to showcase the remarkable work of our featured partners at HIMSS24. Teladoc Health shared how they are enabling connected care through virtual care solutions from inpatient to home—bridging virtual and in-patient care and at-home condition management. TCS showcased how they’re reducing the time it takes to respond to health authorities for regulatory submissions with AI, while providing an intelligent dashboard for real-time feedback to deepen patient understanding. Other partners we featured at the event throughout the week included Sectra, Hitachi Solutions, Accenture-Avanade, Quisitive, and HITRUST.

Additionally, 10 groundbreaking startups joined us, including BeekeeperAI, Mapped, and Pangaea Data. Partners such as CDW, Nordic, Kyndryl, BDO, and Vervint, demonstrated the significance of data and AI in the Electronic Health Record (EHR) on Microsoft Azure by guiding attendees on secure cloud migration, emphasizing high-quality care delivery that prioritizes patient needs. Each partner is reshaping the healthcare landscape by integrating enhanced solutions with Microsoft Azure OpenAI Service, Microsoft Copilot for Azure, and Microsoft Fabric. Our collaborations are deeply aligned to our focus of creating connected experiences, empowering the workforce, and unlocking the value of data across the healthcare landscape.

Partners leveraging AI to fuel innovation in healthcare

From revolutionizing patient engagement to streamlining clinical documentation and advancing drug discovery, partners are harnessing generative AI applications to help solve seemingly insurmountable challenges in healthcare.

To boost clinician productivity and provide better patient services, Accenture-Avanade are utilizing generative AI capabilities powered by Microsoft Copilot for patient medical history summarization, patient response drafting, and intelligent search. CitiusTech’s Smart Search leverages Azure OpenAI Service and Azure Cognitive Search to provide patients with round-the-clock query assistance and personalized responses, reducing the dependency on doctors—ultimately driving better patient satisfaction.

Additionally, Cognizant is infusing generative AI into healthcare administration to enhance productivity and efficiency for payers and providers, ensuring timely responses and improved patient care using Azure OpenAI Service and Semantic Kernel within the TriZetto® user interface.

“At Cognizant, we’re working closely with clients to understand and implement generative AI into their organizations, helping them unlock and expand value across the enterprise. Through this collaboration with Microsoft, we have infused generative AI capabilities into our TriZetto® platform, making it easier for healthcare organizations to realize the full potential of this groundbreaking technology.” —Surya Gummadi, Executive Vice President and President, Cognizant Americas

In imaging and clinical documentation, Sectra’s Azure-optimized software as a service solution, Sectra OneCloud, revolutionizes enterprise imaging with scalability, security, and diagnostic capabilities to enhance care delivery and optimize clinical processes.

Several partners are also leveraging Fabric—an end-to-end, unified analytics platform that brings together data and AI—to modernize data estates and unlock powerful insights. For example, Hitachi Solutions is enhancing predictive care management, reducing operational costs, and strengthening data security and privacy with Lumada Empower Data Platform and Discern Health. Quisitive is uncovering actionable insights and driving greater efficiency with the development of MazikCare Copilot, which utilizes AI for care coordination, denial management, and gap assessments.

To better protect and govern data, HITRUST is establishing a foundation of privacy and security that enables the operationalization of responsible AI and establishes AI assurance and risk management. Commvault is providing powerful defense against threats by leveraging AI-driven automation and generative AI through their copilot, enabling seamless business continuity.

“At Commvault, our collaboration with Microsoft Cloud for Healthcare is at the forefront of providing robust defenses for the healthcare sector. By integrating AI and automation we’re not just improving the resilience of healthcare organizations, we’re transforming how they anticipate and neutralize threats.” —Anna Griffin, Chief Marketing Officer, Commvault

Other powerful partnerships with organizations like GE Healthcare, Sophia Genetics, Andor Health, and Volpara are bringing innovations to customers and we’re proud to announce new advances alongside them.

And finally, we’ve recently announced a healthcare collaboration with NVIDIA that will harness the immense power of the cloud and cutting-edge AI to accelerate healthcare innovation. And we’ve partnered with Truveta to advance medical research with a groundbreaking solution that leverages AI to analyze patient data, helping to save lives.

We’re deeply committed to advancing together with our partner community, fueling new use cases and exploring impactful generative AI scenarios to deliver efficient care. Join us on this journey.

Learn more about healthcare solutions from Microsoft

To learn more about Microsoft Cloud for Healthcare and our work with key partners:"
Microsoft_News,https://www.microsoft.com/en-us/worklab/podcast/all-leaders-can-learn-from-how-ai-is-revolutionizing-medicine/,,All Leaders Can Learn from How AI is Revolutionizing Medicine,"MOLLY WOOD: Today I’m talking to Peter Lee, President of Microsoft Research, about what business leaders across industries can learn from the way that AI is transforming medicine and life sciences. He delivers a report from the front lines on the technological innovations that are transforming every aspect of medicine, from research to diagnosis to security and privacy, and even the fundamental way that doctors and patients communicate with each other. AI innovations are helping to evolve a healthcare system that is less siloed, less confusing, more thorough, more efficient, more secure, and even more empathetic. And if similar transformations aren’t happening in your industry yet, rest assured, they will be soon. Here’s my conversation with Peter.

[Music]

MOLLY WOOD: Let’s start with your shift three and a half years ago, when Microsoft CEO Satya Nadella asked you to rethink the company’s healthcare strategy. I want to ask you when AI sort of entered and became a major focus of what was already a pretty big strategy shift into healthcare, right?

PETER LEE: Right. Satya first asked me to take a new look at healthcare way back in 2016, and I was actually pretty confused by that. I was wondering, why is he punishing me? [Laughter]

MOLLY WOOD: It’s not considered like a fun field to try to transform.

PETER LEE: It isn’t, but I think Satya really saw the future and was understanding, you know, Microsoft is in literally every single healthcare organization on the planet. Everything from Kaiser Permanente and the UnitedHealth Group, all the way to a one-nurse clinic in Nairobi, Kenya, and everything in between. You know, his point was, the future is going to be a lot about AI and about the cloud and about health data, and are we doing enough there? And so that was the assignment. I joked that it was a little bit like him dropping me and some of my team into the middle of the Pacific Ocean and asking us to find land, because you just don’t know which way to swim. It took a little bit of time to kind of understand, what is it about Microsoft that gives us a right to participate here? What are the differentiated new things that we could offer? And the way that we ask that question is, If Microsoft were to disappear today, in what ways would the world of healthcare be harmed or held back? When ChatGPT was released in November of 2022, three days after the release I got emails from some clinician friends of mine around the world saying, wow, Peter, this is great stuff. And I’m using it in my clinic to do such and such a thing.

MOLLY WOOD: Immediately.

PETER LEE: Immediately. And so that really motivated us to try to study and also educate the world of medicine as quickly as possible, what this new technology is.

MOLLY WOOD: I mean, healthcare is universal. We’ve all interacted in one way or another, and it can be really personal and emotional, but it can also be super bureaucratic and complicated. What’s the potential you see for AI to improve the whole experience?

PETER LEE: Well, I think everyone who has contact with the healthcare system has moments of confusion and frustration. If you live and work in the United States, for example, and you have health insurance from your employer, let’s say, and you get some treatment of some kind, a few weeks later you’ll get something in the mail called an Explanation of Benefits form, an EOB, and that’s totally mysterious. At least for me, you know, I look at those things. I have no idea. Is this a bill? Um, you know, what’s being explained here? You have these weird codes, they’re called CPT codes. You shouldn’t feel bad about not being able to decode those things because I’ve actually interacted with quite a few C-suite executives in major American health insurance companies. And I’ve learned that they can’t even parse these things. And so a simple thing is when you get something like that, or maybe you get lab test results from a physical exam, you can show those things to GPT-4 or to Microsoft Copilot, and just say, take a look at this, explain this to me. So that’s really empowering. Last year, my father passed away after a long illness. And it was a struggle for me and my two sisters to look after his care because we all lived several hundred miles away from my father. And there were moments when the stresses of that would cause the relationships between me and my two sisters to fray. And what I’ve learned over the last few years is that so many people in our world go through this. And so the ability to give all the lab test results, all the notes, to GPT-4, explain the situation and explain that we’re going to have a 15-minute phone conversation with Dr. K, and then just ask the question, What would be the best two or three things to ask? What’s the best use of this time? The ability of that interaction to kind of bring the temperature down and really preserve family harmony and give us a way to feel empowered in interacting with a complex healthcare system is something that was very meaningful.

MOLLY WOOD: First, I’m so sorry to hear about your father.

PETER LEE: Oh, thank you. It was really his time and also, you know, he passed peacefully and with family around, so all of that was great.

MOLLY WOOD: I mean, those situations are so trying for families, and it’s really profound to think about technology helping to make experiences like that a little bit easier. It’s interesting how meaningful an increase in empathy can be in those situations, and you found that introducing AI into medicine actually can introduce more empathy. Was that surprising to you?

PETER LEE: You know, as a techie, I was guilty of thinking, when you think about medicine and healthcare, of immediately zooming in on AI. Diagnosis. So a technologist, traditionally, when they think about healthcare, will think, Oh, can we make an AI system look at radiological images? Can we get an AI system to pass the US medical licensing exam? All those things are good and important, but there’s so much more to healthcare. A big part of healthcare is the relationship between the doctor or nurse and the patient. Just a doctor being able to maintain eye contact and be present with the patient during an encounter instead of typing at a laptop, it matters a whole lot. A doctor being reminded by an AI system, oh, your patient is about to make her very first trip ever to France next month. Maybe it’s good to put an extra line in your email to her to wish her the best. Those extra little human touches. And so there are two things involved in making that possible. One is doing what I call reverse prompting. We always think about the human being prompting the AI system and then the AI system reacting, but the AI system can oftentimes prompt the human. But the other is just giving more time to doctors, to nurses, making them more productive. And so just the aid of an AI system that can say, listen to the doctor-patient conversation and unload most of the time and labor involved in, say, writing the clinical encounter note. These things, they add up and they really matter a lot for that human connection between doctor and patient.

MOLLY WOOD: You said something a bit counterintuitive, in a way, at a conference recently about how that time that’s freed up that should allow doctors and nurses to do the work, you know, not offload the technical work to AI, and that AI can, as you just pointed out, actually be the more empathetic communicator.

PETER LEE: Yeah, I have a colleague, he’s a neuroradiologist, Greg Moore, and he had a friend, a vibrant, very successful friend, and she unfortunately got diagnosed with pancreatic cancer. And using Greg’s connections, he got her into the specialist clinic, at Mayo Clinic, really one of the top places for that particular kind of cancer. And being the go-getter that she was, she was insisting on a cutting-edge immunotherapy. But these specialists, these are the very best people on the planet in treating this type of cancer, were dead certain that that was the wrong approach, that they needed to start with a particular chemotherapy. The patient was insistent in disagreeing, and so there was a conflict that eventually led the specialist to come back to Greg and say, We’re having a problem interacting with this patient, can you talk to her? Greg, not knowing what to say to this absolutely desperate patient, consulted with GPT-4. GPT-4, interestingly, came to the same conclusion as the specialist. And they had this conversation, GPT-4 and Greg, on how to talk to the patient. At the end of that interaction, Greg, in a weirdness about AI today, thanked GPT-4. And GPT-4 said, you’re welcome, Greg, but let me ask, how are you doing? Are you holding up okay? And are you getting all the support that you need?

MOLLY WOOD: Whoa.

PETER LEE: Again, it’s in this idea of reverse prompting that just got Greg to just take a step back and reflect on his own mental state and on his own psyche and ability to cope with the situation of such a close friend in such a desperate situation. That’s very extreme, but there are lots of smaller things as well. The largest manufacturer of electronic health record systems is Epic, and Epic has been rapidly integrating GPT-4 and GPT-3.5 into various applications in their EHR system. And they’ve been then working with academic medical centers to do controlled studies to see if it works well, if it’s not making lots of mistakes, patient satisfaction, doctor satisfaction, and so on.

One of the things that they’re finding is that when GPT-4 writes the after-visit summary email to a patient, the patients are consistently rating those notes as more human than the notes written by the doctors themselves.

MOLLY WOOD: Wow.

PETER LEE: And of course, it’s not the case that they’re more human. They’re written by a machine. But when you’re a busy doctor, you might not just take the time to, say, congratulate your patient on becoming a grandparent. Those extra little touches, it just shows that somebody remembers and cares. It can just make so much of a difference in the connection between doctor and patient.

MOLLY WOOD: I mean, that’s fascinating and kind of heartbreaking that AI clearly learned from the data it was trained on that empathy is a key part of medicine, but our medical professionals are so overtaxed that they can’t take the time to do it. I also love this kind of reverse prompt idea, like AI as an assistant taking some of the load off so medical professionals can get back to fundamentals, which are about care.

PETER LEE: Well, it’s such an important point because right now there is this crisis in the US, but there have been numerous studies that show over 40 percent of a clinician’s day, on average, is spent on clerical work, documentation, and note-taking. I really love my primary care physician, but every time I see her, her back is turned to me. She’s sitting there at a computer, typing while she’s talking to me. And the reason she’s doing that is she has a life. What I mean by that is if she didn’t take the time to write those notes during the encounter with me, she’d have to take that work home with her. That’s called, in the profession, pajama time. Some doctors don’t want to do that while they’re with their patients and they take that work home and jump in bed with a laptop and spend two hours doing that documentation and clerical work. And so what if AI could reduce that by half or by 80 percent? So much more would be possible.

MOLLY WOOD: You speak about this topic globally, and I’m curious about how your findings apply to doctors and nurses across the world. Is it just in the US that we have, you know, burnout and clerical loads that are untenable? How do you find that this technology is translating to doctors in other parts of the world?

PETER LEE: It is a global issue. However, it is worth emphasizing just how extreme the problem is in the United States. Over the next five years, there is projected to be several-hundred-thousand-nurse shortage in the US healthcare system. And then if you go to the UK, the National Health Service, it is not unusual outside of London to have a multi-month wait if you need to see someone for primary care. There are huge parts of Africa where people still might live an entire lifetime never seeing a doctor. And then in China, the caseloads on primary care physicians in China is now approaching 80 patients per day.

MOLLY WOOD: Whoa.

PETER LEE: For a single primary care physician. And the kind of burnout and, in some cases, violence fueled by just frustration that people have. It really makes headline news in that country. We also have something called the “silver tsunami” that is coming. There are demographic changes where the aging population is reaching a point where there will not be enough young healthcare workers to care for an aging population. And so all of these things are about to really become extreme issues. And all of that leads to fewer and fewer bright young people wanting to enter into the profession. Now, the US healthcare system is reacting—for example, there’s a whole slew of new medical schools that have sprung up. In fact, I’m on the board of directors of a new medical school, Kaiser Permanente School of Medicine. But that’s just one of a dozen new medical schools that have sprung up in the US just in the past three years, in an attempt to produce more doctors and nurses. The fundamental root cause is, can we make being a doctor, being a nurse, the kind of satisfying profession that allows people to connect with their personal desires to help people as opposed to do paperwork? Can we create that situation that will motivate people? And that is the most important problem for us as technologists to work on. Yes, it’ll be great for us to solve genomics with AI, to solve cancer with AI, to have better radiological imaging techniques with AI. All of that is great. But at the end of the day, if the one thing that we can accomplish is to have AI make a dent in this kind of workforce shortage and then day-to-day worker satisfaction in healthcare, we’ll have really done the world a great service.

MOLLY WOOD: Healthcare is obviously such a unique industry and it presents its own set of challenges. But you can imagine that these are also lessons that extend into other industries. I wonder, in your learnings, what is your message about the way that leaders across industries should implement AI in this way to bring more time and potentially more empathy?

PETER LEE: This is going to sound funny, but the way I explain it is that generative AI, that a large language model, is not a computer. You could substitute any type of information worker for this, but let’s imagine you’re a nurse. Your mental model of a computer is a computer is a machine that does perfect calculation and has perfect memory recall. So, if you ask a computer to come up—let’s say you do a web search, it’s going to come up with precise answers. If you ask a computer to do some calculations, it’s going to come up with a precise answer. The thing that’s odd about a large language model is it’s similar to the human brain in being very faulty with memory and very faulty with calculation. And so, it will make mistakes. If you ask it to do a big pile of arithmetic, it’ll get it wrong in ways very similar to the way a human being would get it wrong. The thing that is so important for people to realize is that this is now a new type of machine, a new type of tool, that doesn’t have that perfect calculation or perfect memory capability. There’s a professor at the Wharton School at University of Pennsylvania, Ethan Mollick, who really puts it nicely. He says it’s better to think of a large language model as an eager and tireless intern, and so if you are a doctor, it can be dangerous to use the large language model as though it’s a computer. It’s much better to treat it like an intern. And the answers you get from it, you have to assess and you have to think about in the same way as you would from your intern. And it’s high stakes, particularly in the world of medicine. If you don’t understand this, you can end up hurting someone. And so, as I’ve gone around to healthcare organizations around the world over the past year, I always start with that lesson.

MOLLY WOOD: Yeah, that is a very different mindset. And actually seems like an important one for using these tools in any industry. So what’s your general advice to leaders for how to use AI in a way that really taps into those strengths?

PETER LEE: The way to start, of course, is to be very hands-on with these systems. And the easiest way for a human being to be hands-on is to do it through a chat interface. And you can just talk to it. There’s another stage where, if you have a whole bunch of data, you can ask the system, Can you figure out how best to structure this data and prepare it for analysis and machine learning? That’s another thing that’s rising in tremendous importance. A great project in Microsoft Research involves clinical trials matching. So, right now, when there are potential new therapies and new drugs, new diagnostic techniques that are proposed by medical researchers, they have to go through a validation process. Part of the validation process involves standing up what’s called a clinical trial to kind of test under circumstances, whether let’s say some new therapy is both safe and works well. A sad thing is that over half of clinical trials that are stood up fail to recruit enough participants. And this holds back the advancement of medical science by huge amounts. It’s really a sad thing. And part of the problem is that when you look at clinical trials documents, they’re incredibly complicated things to read. And they’re highly unstructured text documents. What we’re learning is that a large language model like GPT-4 can read all those clinical trials documents and put them in a structured database that allows tools to better match up patients with those trials. It just opens up the possibilities that we’ll be able to accelerate the advancement of medical science by doing that. And so each one of these stages, you know, where you just start with the raw large language model, then you give the large language model access to tools, and then you use the large language model to make sense of all that data out in the world. Those three stages, I think, is a natural progression.

MOLLY WOOD: And again, we should say those stages are applicable to almost any industry. It’s really sort of that mindset of thinking about it and sort of understanding what you should adopt for and what you shouldn’t.

PETER LEE: Oh, yeah, absolutely. I mean, transportation, retail, manufacturing, law, finance, you name it. These same ideas apply across the board.

MOLLY WOOD: When you hear reluctance to engage with some of these tools, what’s your sort of go-to response?

PETER LEE: I just try to show empathy. You know, when folks first showed what we now called GPT-4 to me and explained to me what it could do, I was super skeptical. Like, give me a break. And then I passed from skepticism to annoyance because I saw some of my Microsoft Research colleagues getting what I felt was duped by this stuff. And then I got sort of upset because it became clear that my boss, Kevin Scott, and his boss, Satya Nadella, were going to make a big bet on this technology. So I thought, what? This is crazy. And then, with my own personal investigations, I got into the phase of amazement. Because it was true. These things that OpenAI was claiming about this thing were actually true. They were happening. That led to a period of intensity where you try to figure out, okay, so what is this going to mean? How can we use it? Then you get into a period of concern because you start to encounter problems like hallucination, issues with bias, transparency, and so on. And then you realize this is a real technology that’s going to change everything. And so I share my own journey because I’ve seen so many other people go through the same journey. And I’ve seen whole organizations and businesses step through these things. And so what I tell people is, you need to have patience. Everyone needs to go through this. And you need to understand this is a process that people have to go through because it’s just very challenging to believe that this technology can even exist.

MOLLY WOOD: And then finally, in the medical field in particular, is there something, is there a moonshot that you think you really want this technology to take on?

PETER LEE: You know, when I think about what is the most important thing to accomplish, there is a concept in medicine called real-world evidence, RWE. The dream there is, what if every healthcare experience that every patient has could feed directly into the advancement of medical knowledge and science. And so here’s my favorite example from the pandemic. In the first year of the pandemic, some doctors around the world were randomly discovering that if they had a very sick COVID patient in respiratory distress that they could sometimes avoid having to intubate that patient by having the patient stay prone for 12 hours, stay on their stomachs for 12 hours, and they would start to share that knowledge actually on social media. And so other doctors started to do the same thing, but it was very random and ad hoc. A few months later, a network of medical research institutions around the world banded together and formed a clinical trial, a clinical study, to study this. And a year and a half later, they determined that, yes, for some patients in severe respiratory distress that this worked. That year-and-a-half gap is something that, first off, leads to thousands of patients being intubated when maybe they didn’t need to be and some of those patients dying needlessly. What if we had systems that could observe every single experience in every single medical encounter that patients had? And that feeds in directly into the storehouse of medical knowledge. That’s the dream of real-world evidence. And when I see what AI is becoming today, I cannot escape the feeling that some aspects of that dream of RWE are actually within our grasp. And that’s where I’d like to see the world lead to.

MOLLY WOOD: Peter Lee is President of Microsoft Research. Thank you so much for the time. This is phenomenal.

PETER LEE: Thank you, Molly. It’s been great to chat.

MOLLY WOOD: If you’ve got a question or a comment, please drop us an email at worklab@microsoft.com. And check out Microsoft’s Work Trend Indexes and the WorkLab digital publication, where you’ll find all of our episodes along with thoughtful stories that explore how business leaders are thriving in today’s new world of work. You can find all of it at microsoft.com/WorkLab. As for this podcast, please rate us, review us, and follow us wherever you listen. It helps us out a ton. The WorkLab podcast is a place for experts to share their insights and opinions. As students of the future of work, Microsoft values inputs from a diverse set of voices. That said, the opinions and findings of our guests are their own, and they may not necessarily reflect Microsoft’s own research or positions. WorkLab is produced by Microsoft with Godfrey Dadich Partners and Reasonable Volume. I’m your host, Molly Wood. Sharon Kallander and Matthew Duncan produced this podcast. Jessica Voelker is the WorkLab editor."
Microsoft_News,https://news.microsoft.com/apac/2024/04/10/microsoft-to-invest-us2-9-billion-in-ai-and-cloud-infrastructure-in-japan-while-boosting-the-nations-skills-research-and-cybersecurity/,,"Microsoft to invest US$2.9 billion in AI and cloud infrastructure in Japan while boosting the nation’s skills, research and cybersecurity","Microsoft to invest US$2.9 billion in AI and cloud infrastructure in Japan while boosting the nation’s skills, research and cybersecurity

Washington D.C., April 9 ET, 2024 – Today, Microsoft announced it will invest US$2.9 billion over the next two years to increase its hyperscale cloud computing and AI infrastructure in Japan. It will also expand its digital skilling programs with the goal of providing AI skilling to more than 3 million people over the next three years, open its first Microsoft Research Asia lab in Japan, and deepen its cybersecurity collaboration with the Government of Japan.

These investments aim to support Japan’s key pillar to tackle deflation and stimulate the economy by expanding the infrastructure, skilled talent, and security required to accelerate Japan’s digital transformation and adoption of AI. The announcement coincides with Japanese Prime Minister Fumio Kishida’s state visit to the United States, where he was joined by Microsoft Vice Chair and President Brad Smith, and Microsoft Japan President Miki Tsusaka.

Expanding Japan’s AI and cloud infrastructure capacity

The US$2.9 billion commitment is Microsoft’s single largest investment in its 46-year history in Japan, also the site of its first international office. It effectively doubles the company’s existing financial commitment to expand its AI and cloud infrastructure across Japan.

This significant enhancement in digital capacity will enable Microsoft to provide more advanced computing resources in Japan, including the latest graphics processing units (GPUs), which are crucial for speeding up AI workloads. It builds on Microsoft’s support for the Generative AI Accelerator Challenge (GENIAC), a program led by the Ministry of Economy, Trade and Industry which helps innovative startups and established enterprises develop foundation models as a core technology of generative AI in Japan.

Building Japan’s AI capability by training 3 million people

Microsoft will also invest in training 3 million full-time and part-time workers across Japan over the next three years, giving them the skills they need to build and work with AI technologies. This investment will be delivered through programs focused on assisting organizations and society at large, including women in general and also with a focus on developers and students.

Microsoft will expand its Code; Without Barriers program to Japan and provide dedicated training for women looking to participate in AI-enabled work. It will also provide free and widely accessible content on AI, cybersecurity, and digital skills in partnership with the United Nations Institute for Training and Research (UNITAR).

Nurturing advanced AI professionals who can drive further AI integration, Microsoft will offer courses and reference architectures for AI developers and technology companies in Japan. These will be augmented by Microsoft’s AI coding assistant, GitHub Copilot. The company will also support startups with resources through the Microsoft for Startups Founders Hub and help implement AI-centric programs in vocational high schools.

To advance the societal benefits offered by AI through companies of all sizes, governments, and public entities – including the Tokyo Metropolitan Government – Microsoft will continue with established programs that support the widespread adoption and application of AI tools. Furthermore, Microsoft provides support in developing customers’ internal AI policies, including data management and security to ensure its responsible and safe use.

Opening Japan’s first Microsoft Research Asia lab in Tokyo

Microsoft Research Asia is extending its research leadership in the Asia-Pacific region with the opening of a lab in Tokyo.

The new lab will have a unique focus on areas including embodied AI and robotics, societal AI and wellbeing, and scientific discovery that align with Japan’s socioeconomic priorities. Its establishment reflects Microsoft’s long-term commitment to Japan and its belief in the nation’s potential to lead the world in innovation.

Microsoft Research is a division of Microsoft that pursues bold ideas and technical breakthroughs in AI, while building on a legacy of foundational computer science advances. As its fundamental research arm in the Asia-Pacific region, Microsoft Research Asia has collaborated with Japanese academia for more than two decades which have been instrumental in propelling cross-disciplinary research and fostering talent.

To foster enhanced research collaboration, Microsoft will provide US$10 million resource grants over the next five years to both The University of Tokyo and to the Partnership on Artificial Intelligence Research between Keio University and Carnegie Mellon University.

Partnering to strengthen Japan’s cybersecurity defenses

Microsoft will collaborate with Japan’s Cabinet Secretariat to strengthen cybersecurity resilience for the government, business, and society, as the nation enhances its cybersecurity approach under the government’s updated National Security Strategy.

The collaboration will build on the services Microsoft provides to protect thousands of Japanese organizations every day. It will focus on areas such as information sharing, talent development, and technology solutions, with Microsoft to provide its expertise and advanced cloud and AI-driven security services as part of joint efforts to tackle cybersecurity threats.

Leadership statements

Fumio Kishida, Prime Minister of Japan

“As economic activities in the digital space increase, it is important for the Japanese industry as a whole to work with global companies like Microsoft that are equipped with a set of digital infrastructure. We appreciate Microsoft’s announcement of its new investment in Japan. Microsoft has made significant contributions to the social implementation of generative AI in Japan through various initiatives, and we look forward to further collaboration. We also look forward to deepening our cooperation in the field of cybersecurity.”

Brad Smith, Vice Chair and President, Microsoft

“Today’s announcement represents Microsoft’s most significant investment in Japan since we set roots here in 1978. These investments in digital infrastructure, AI skills, cybersecurity, and AI research are essential ingredients for Japan to build a robust AI Economy.”

Ken Saito, Minister of Economy, Trade and Industry

“As digital investments increase around the world, we welcome Microsoft’s announcement of new investment in Japan and look forward to its future contribution to promoting Japan’s digital industries, including AI. Ministry of Economy, Trade and Industry will continue to work with Microsoft, a world leader in the digital field, to create both innovation and discipline.”

Takuya Hirai, Chairperson, Headquarters for the Promotion of a Digital Society, Policy Research Council, Member of the House of the Representatives

“The adoption of digital tools is essential for addressing Japan’s societal challenges of an aging population and the pursuit of economic growth and regional revitalization. Microsoft’s investment contributes significantly in advancing Japan’s AI capabilities, particularly in infrastructure and talent development. I wholeheartedly welcome this initiative and look forward to the leadership role Microsoft can play in promoting collaboration between Japan and the United States, as well as across public and private sectors.”

Miki Tsusaka, President, Microsoft Japan

“We are honored to contribute to Japan and its future with our largest investment to date, technology and knowledge. In collaboration with our partners, Microsoft Japan is fully committed to supporting the people and organizations of Japan to solve social problems and achieve more.”

Yuriko Koike, Governor of Tokyo Metropolitan

“The Tokyo Metropolitan Government and Microsoft entered into a partnership last year and have been empowering Japan’s workforce with digital skills. Today’s announcement by Microsoft, which includes programs to encourage women to embrace AI and provide AI skilling to three million people, is a significant step for Japan to lead in the age of digitalization. The Tokyo Metropolitan Government pioneered the use of generative AI to make our offices more efficient and improve the quality of services provided to our citizens. We will continue to embrace cutting-edge technology and lead Japan’s digital transformation with unwavering dedication.”

Chisa Mikami, Head of Hiroshima Office, UNITAR

“Through the collaboration between UNITAR and Microsoft, we will strive to democratize access to AI education, ensuring that knowledge is freely available to all. Together, we pave the way for advanced AI professionals, foster innovation in startups, and promote responsible AI practices across industries and sectors. With collective effort, we harness the transformative power of AI for the betterment of society.”

Kevin Scott, Chief Technology Officer and Executive Vice President of AI, Microsoft

“The impact that AI is poised to create over the coming years has the potential to generate unprecedented societal benefit for the entire world. The steps we are taking today to empower Japanese citizens through AI technologies and programs—whether job training and skilling, improvements to infrastructure capacity, or new research investments—will in the aggregate help accelerate this process of beneficial innovation. We’re particularly excited for Microsoft Research’s global footprint to further expand into Japan, extending the ability for our world-class research efforts to both contribute to and benefit from local diversity of thought and talent.”

Teruo Fujii, President, The University of Tokyo

“The University of Tokyo is committed to contributing to the realization of a better society through research and education focused on cutting-edge technologies such as artificial intelligence. To maximize the benefits of those technologies and promote innovation while minimizing risks, it is essential to collaborate with partners who share our objectives. With the establishment of Microsoft Research Asia’s new lab in Tokyo, we enter an exciting new phase in our more than two decades of partnership with Microsoft. We look forward to working together to further advance our research community and spearhead the development of outstanding human resources as we continue our journey together.”

Tags: AI, Japan"
Microsoft_News,https://www.microsoft.com/en-us/industry/blog/financial-services/2024/04/09/ai-for-social-impact-3-ways-financial-services-can-influence-global-challenges/,,AI for social impact: 3 ways financial services influence global challenges,"In virtually every customer conversation I have these days, I am inspired by the innovation that generative AI has ignited in the financial services industry. There’s no shortage of creative ideas and impactful use cases for business transformation—with exciting new capabilities to cut costs, boost efficiencies, enhance productivity, and deliver better customer support.

What is equally if not more important, however, is the power of AI to help solve some of the world’s most challenging social problems. This resonates with the work we’re doing with Microsoft Cloud for Financial Services, where we strive to not only empower customers but also help improve the world broadly through responsible AI and cloud computing.

Microsoft Cloud for Financial Services Unlock business value and deepen customer relationships. Discover more

It’s clear that generative AI opens new doors to create greater value for customers, the benefits of which are already dramatic across industries. In the unique case of financial services, generative AI also opens opportunities to address global problems that have long challenged almost every segment of society.

Three areas of financial services impact

In January, I had the opportunity to participate in the World Economic Forum’s annual meeting in Davos, Switzerland. Naturally, AI was a big topic of conversation, and what was most encouraging to me were the discussions and examples of its potential to impact major social challenges. In the context of social good, I see three key areas where this can happen:

1. Equity and inclusion

I see advanced and generative AI holding tremendous potential to create more inclusive and personalized financial products and experiences for a broader population. This could include the latest natural language capabilities in chatbots, integrating screen reading and narration capabilities like Seeing AI into your banking products for the blind and low vision community, and offering speech-to-text functionality for those with hearing impairments. A powerful example of the transformative potential of AI in coding is the story of Anton Mirhorodchenko, a Ukrainian software developer living with cerebral palsy. By using GitHub Copilot, he dramatically simplified his workflow and improved his productivity and outlook.

2. Poverty and stability

Financial inclusion is also key to stability, as technological innovations unlock new opportunities for data-driven financial tools that can empower a broader range of underserved communities to achieve financial independence. There’s a lot of exciting fintech innovation in this area. For example, CWallet, a fintech company specializing in digital wallet services, is empowering migrant workers in Qatar to access financial services with Microsoft Azure. There are other important fintech initiatives underway in places like Latin America and Kenya using AI and digital innovations to improve lives, reduce poverty, expand access to financial services and credit, and narrow the financial inclusion gap.

And it’s exciting to see how other organizations across industries are already innovating with Azure OpenAI Service to enable inclusive growth with technology. For example, as part of our new ADVANTA(I)GE INDIA initiative and AI skilling efforts, Indian social impact organization, Karya, is using Azure OpenAI to help make technology accessible in under-resourced languages and to more inclusive data—with work that also provides rural citizens with training, fair wages, and education about financial tools to make best use of their earnings.

3. Environment

We all recognize the critical importance of addressing climate change, and this is already an important topic in financial services. But I believe we are just scratching the surface on AI’s potential to tackle common risks and opportunities for environmental, social, and governance (ESG) and sustainability efforts in FSI due to slow manual processes, siloed data, data quality issues, lack of insights, and reporting. Generative AI advancements can aid in synthesizing structured and unstructured data, creating ESG insights and recommendations, and reporting out to stakeholders. I’m also excited to see examples from financial leaders like Emirates NBD transforming sustainability measurement capabilities with Microsoft Sustainability Manager.

When it comes to achieving these ambitions—and countless others where AI can make a major difference—success requires more than just cutting-edge technology. Microsoft believes that meaningful innovation can only happen when organizations also embrace a set of enabling principles that focus on ethics and human factors.

The critical role of responsible AI

The excitement around this next wave of AI is undeniable, but we must wield it responsibly to avoid perpetuating biases or excluding segments of society. At Microsoft, we are committed to helping our customers use our AI products responsibly, sharing our learnings, and building trust-based partnerships.

Microsoft Responsible AI standard Learn the requirements

To help financial services organizations realize AI’s potential, Microsoft has published the Responsible AI Standard, developed an Impact Assessments template, and created transparency documents for customers using our Azure OpenAI Service and products like the new Bing to share what we’ve learned. The Microsoft open-source Fairlearn toolkit can also help financial services organizations ensure their AI systems are equitable by identifying biases in data. When our partner EY put it to the test with real-world mortgage adjudication data, it improved the fairness of loan decisions, narrowing gender disparities from 7% to less than 0.5%. From Davos, you can also watch my panel discussion on the responsible deployment of AI in financial services.

How inclusive design and diversity unlock potential

Inclusive design hinges on the vast spectrum of human diversity, gleaning insights from varied perspectives. Microsoft champions design principles that recognize exclusion, learn from diversity, and create universally beneficial solutions. Technology that is designed in this way means better access, less friction, and greater emotional connection with more people.

Our commitment to helping others shift to inclusive solutions is found in our Microsoft Inclusive Design toolkit. The tools create large-scale solutions, such as digital experiences that are more responsive and less biased, and cities that are more accessible. In the financial sector, this translates into products and services designed to meet the needs of as many individuals as possible, regardless of their abilities or circumstances.

Likewise, diversity is a proven catalyst for innovation among technology teams. Studies show that greater diversity can help teams focus more on facts, process those facts more carefully, and generate more creativity and innovation.1 Ethnically and gender-diverse management teams are more likely to financially outperform in their industry, and companies with more women in leadership positions tend to be more profitable.2 So, for technology to be truly inclusive, it needs to be built by teams that reflect the diversity of its users.

A mission of empowerment through AI

My transition from the banking industry to Microsoft was driven by the potential for meaningful technological innovation that could create a positive change. Despite the challenges we face, my outlook remains optimistic. I hope this blog has set some ideas in motion for you, and I invite everyone to become involved in efforts to use AI in ways that benefit society broadly.

The Microsoft mission is to empower every individual and organization on the planet to achieve more, and we do that by building technology that we believe will change the world. To accomplish that, we know that we must embrace a set of important responsibilities. Trust, reliability, safety, privacy, security, inclusiveness, transparency, and accountability—these are the foundational principles that have guided our leadership in AI over the past decade. Along with our partners and many other global stakeholders, we invite you to join us on the important journey ahead.

To learn more about our commitment to trustworthy AI and to find further resources, please visit our Empowering responsible AI practices website.

1Diversity wins. How inclusion matters. McKinsey & Company, May 2020.

2Why Diverse Teams Are Smarter. David Rock and Heidi Grant, Harvard Business Review, Nov 4, 2016."
Microsoft_News,https://startups.microsoft.com/blog/partnering-with-alt-capital-to-support-early-stage-b2b-ai-startups/,,Partnering with Alt Capital to Support Early-Stage B2B AI Startups,"Microsoft for Startups Founders Hub brings people, knowledge and benefits together to help founders at every stage solve startup challenges. Sign up in minutes with no funding required.

At Microsoft, we understand the incredible potential of AI and the vital role that startups play in shaping and becoming the companies of the future. Today, we’re excited to announce our support of Alt Capital’s Generate Program that will offer startups in their new accelerator (launching in May) the opportunity to innovate and grow with access to cutting edge AI tools on the Microsoft platform.

What sets Alt Capital apart is its dedicated focus on B2B solutions—a field where Microsoft’s expertise can truly add value. This partnership presents an exceptional opportunity for us to further empower startups specializing in B2B AI solutions, fueling innovation, and fostering growth in this important sector.

“We’re thrilled to be partnering with Microsoft on the new Generate program. Of course, it’s great to bring the additional financial resources to Generate companies, but more importantly we’re excited for the expertise, network, and distribution they represent as a global leader in both AI and B2B software,” Jack Altman, Alt Capital, Former CEO, Lattice.

Applications are now open for the Alt Capital Generate program, where selected participants will receive:

A $250,000 investment, uncapped (MFN SAFE.)

Free Azure AI infrastructure along with up to $350,000 in Microsoft Azure credits including preferred access to high-end GPU virtual machine clusters and Microsoft Go-To-Market support.

The opportunity to learn from a stellar lineup of advisors and visiting partners.

Networking and development opportunities, including customer development events, a hiring day connecting startups with top talent, and an investor day to facilitate connections with high-quality investors.

The deadline to apply is May 5th, 2024, and the program is scheduled to commence on May 27th.

In November, Microsoft for Startups announced the availability of Azure AI infrastructure for high-end GPU virtual machine clusters for use in training and running large language models and other deep learning models. Since we made these resources available, we’ve expanded access to Y Combinator, M12, AI Grant Fund, Alchemist Accelerator, Conviction, The House Fund, Open AI Startup Fund, Neo, AI investor Elad Gil, and today, Alt Capital.

We recognize the challenges that early-stage startups face in building the necessary technical infrastructure for AI development. These hurdles, including securing computing resources and establishing scalable architecture, can be both costly and complex. By providing access to cutting-edge technology and infrastructure, we aim to accelerate the development of the next generation of groundbreaking companies, drive positive change, and shape the future of AI.

Tags: Alt Capital, Startup Accelerator"
Microsoft_News,https://www.microsoft.com/en-us/worklab/when-it-comes-to-ai-do-not-build-islands-of-intelligence/,,"When It Comes to AI, Don’t Build 'Islands of Intelligence'","When people discover a new work hack, they can be tempted to keep it to themselves. Maybe they subconsciously want to gatekeep it, or maybe they mean to share it with colleagues but forget. Over time, this creates “islands of intelligence.” And while being on an island is great for a relaxing vacation, at work these private knowledge bases can hinder learning and development across the organization—which is why it’s crucial for leaders to promote (and reward) sharing and collaboration.

We’re living through a unique moment where people across industries are all exploring the AI toolbox at the same time, says A.J. Brush, a Partner Group Product Manager at Microsoft who spends much of her time studying the most effective ways to talk to Microsoft Copilot. For her, the best part of learning isn’t improving her own work—it’s sharing with her colleagues. “There’s something magical about giving other people the same amount of delight,” she says.

For leaders who want to get the most out of AI, it’s important to build bridges between individual islands, with everyone sharing what they learn. Here’s how:

Keep a running list

Brush keeps a record of questions and conversation starters that are recommended to her by colleagues. One of those prompts: start the day by asking Copilot to summarize all communications since the evening before. Another tip: Before meeting with a colleague, get up to speed by asking Copilot to surface the latest interactions with them, organized by emails, chats, and files. A running list keeps your latest tips top of mind—and makes it easy to share them with others.

Create a forum for sharing great prompts

Brush and her colleagues regularly share success stories and new prompts to try in a Microsoft Teams channel and an internal weekly newsletter. Think about which forum feels most conducive to sharing for your team: It could be a collaborative OneNote or Excel sheet, or a callout at the start of a standing meeting. The format is not as important as giving your team the opportunity to share their own best prompts, Brush says: “It feels good to help your colleagues discover ways to free up time for deep work.”

Consult Copilot Lab

Copilot Lab is a repository for people to share their best prompts with co-workers and exchange advice about talking with AI. It’s a place to experiment and learn iteratively—and it can also pick you up from a productivity lull if you’re in need of inspiration. And as AI spreads across your organization and reaches more people, it can help employees who are just getting started. “When you show up to use something new, one of the challenges is that you don’t know what’s possible,” Brush says. “Can I ask about my email? Can I ask about meetings? This gives you a starting point.”

Be a role model for your team

Leaders are uniquely positioned to show their teams that there is no shame in learning. By publicly sharing which prompts yield both good and not-so-good results and creating space for employees to chat about their experiences working with Copilot, leaders become champions of AI. “I spend a lot of time showing colleagues that they can pretty much ask AI for anything,” Brush says. If she has a question, she reasons that others are probably wondering about it too.

“People react to what others do, not always what they say,” Brush says. “When people see their leaders using the same tools and sharing what they’ve learned, they get excited to do the same.” It’s not about telling people what to do. It’s about filling in your team’s awareness gaps by building bridges between islands—making knowledge accessible across your organization and building your collective brainpower."
Microsoft_News,https://azure.microsoft.com/en-us/blog/announcing-updates-to-azure-ai-search-to-help-organizations-build-and-scale-generative-ai-applications/,,Announcing updates to Azure AI Search to help organizations build and scale generative AI applications,"Share Announcing updates to Azure AI Search to help organizations build and scale generative AI applications on LinkedIn

Share Announcing updates to Azure AI Search to help organizations build and scale generative AI applications on X

Share Announcing updates to Azure AI Search to help organizations build and scale generative AI applications on Facebook

Today we are announcing significant changes to Azure AI Search in support for customers building production ready generative AI applications. Azure AI Search has drastically increased storage capacity and vector index size at no additional cost, so customers can run retrieval augmented generation (RAG) at any scale, without having to compromise cost or performance.

In this post, we will walk through how customers:

Can achieve more scalability at a lower cost with today’s changes.

Trust Azure AI Search to handle their large RAG workloads.

Apply advanced search strategies to navigate complex data to innovate in ways previously unimaginable.

Azure AI Search Deliver accurate, hyper-personalized responses in your generative AI applications Try today

Announcing more scalability and performance at a lower cost with Azure AI Search

Azure AI Search has significantly raised vector and storage capacity, offering customers greater scalability, high performance, and more data per dollar.

The amount of capacity and compute available has increased for Azure AI Search’s Basic and Standard tiers, in select regions.

Here’s what this means.

Users will now see up to a:

11x increase in vector index size .

. 6x increase in total storage .

. 2x improvement in indexing and query throughput.

With these changes, customers can deliver high quality experiences for every user and interaction, at any scale. Customers can scale their generative AI applications to a multi-billion vector index in a single search instance, without compromising speed and performance.

Supporting large RAG-based applications with a trusted enterprise retrieval system

Over half of Fortune 500 companies trust Azure AI Search to manage their mission critical enterprise search and generative AI applications. OpenAI, Otto Group, KPMG, and PETRONAS use Azure AI Search to support retrieval augmented generation (RAG) workloads.

When OpenAI announced their RAG-powered “GPTs” and the Assistant API at OpenAI DevDay 2023, OpenAI needed to ensure their retrieval system was capable of handling unprecedented demand and scale. OpenAI turned to Azure AI Search for its capacity to support their large, internet-scale RAG workloads.

Azure AI Search now supports RAG capabilities for ChatGPT, GPTs, and the Assistant API, and provides search functionality to products like the GPT Store. Any time someone searches in or adds a file to one of these products, Azure AI Search is the retrieval system that makes it happen.

ChatGPT alone, as of November 2023, receives 100 million weekly visitors, with over 2 million developers building with its API. Within two months of announcing custom GPTs, 3 million GPTs were created. These are massive numbers, with users spanning across the globe. Truly RAG at scale.

Building better applications with a modern, advanced retrieval system

Teams in professional services, healthcare, and telecommunications have recognized that in order to build a generative AI application that performs as its designed, using only one search practice like vector search, simply doesn’t work.

Different retrieval techniques perform better for different use cases. High quality retrieval systems combine multiple techniques to cover the variety of scenarios that any given application tends to see.

Azure AI Search can enable applications to apply a variety of approaches right out of the box, including hybrid retrieval and semantic reranking, enabling developers to achieve objectives faster and more effectively.

Telus Health uses advanced RAG to deliver a customer care application

Telus Health, headquartered in Canada, is at the forefront of providing technology-driven solutions and services to employers, individuals, healthcare practitioners, and insurers. The organization introduced a customer support platform, designed to answer user inquiries about specific health plans, and offer guidance for navigating their website. The initial implementation, which relied solely on vector search, fell short in addressing all requirements within a unified system. Because of this, Telus Health turned to Azure AI Search, known for its innovative, comprehensive set of search technologies.

The Guide Team at Telus Health was instrumental in designing their search strategy and leveraging AI Search effectively to enhance the platform. By expanding their retrieval strategy, and implementing hybrid search with semantic reranking, Telus Health enabled the system to efficiently handle both questions around client specific documents and using the organization’s website. This strategic enhancement, supported by Azure AI Search, has significantly improved the platform’s accuracy and responsiveness, and showcases Telus Health’s commitment to delivering exceptional customer support.

NIQ Brandbank empowers brands to optimize their online presence with multi-vector retrieval

NIQ Brandbank supports Fast-Moving Consumer Goods (FMCG) brands with solutions to deliver rich, relevant content and imagery for their digital shelf, in order to outshine their competitors.

NIQ Brandbank’s solution Content Health+ empowers brands to optimize their online presence with data-driven, actionable guidance and information to show how their product content stacks up against market rivals.

With their simple, user-friendly format, the application helps brands improve product placement across retailer search results, boost sales and elevate their online presence.

Content Health+ pulls from research completed by a NIQ Data Impact team, to identify what product attributes influence organic placement on the digital shelf. On the backend, the application searches this research stored in both images and text, using multi-vector search, and surfaces the most relevant results with search reranking. This functionality provides quality recommendations for what content attributes a brand should focus on to improve their performance and bottom line.

For this application to perform as designed, Content Health+ was built using hybrid multi-vector search and semantic ranking. For ecommerce and recommendation applications, more ideas and opportunities are realized by combining various retrieval methods.

“Azure AI Search allows us to use hybrid multi-vector search, using text and image embeddings with semantic ranking to promote the most semantically relevant products to the top. From production ready automatic data ingestion from Azure data sources to integration with Azure Machine Learning, Azure AI Search is exactly what we needed to make the Content Health+ application a reality.” —Gabriel Harris PhD, Principal Data Scientist

Learn more about Azure AI Search

With these announcements today, we are making it easier for the AI systems to retrieve information at scale. Customers can innovate with confidence with state-of-the-art retrieval technology in Azure AI Search and an enterprise-ready foundation.

For more on RAG and Azure AI Search:"
Microsoft_News,https://news.microsoft.com/2024/04/04/cloud-software-group-and-microsoft-sign-eight-year-strategic-partnership-to-bring-joint-cloud-solutions-and-generative-ai-to-more-than-100-million-people/,,Cloud Software Group and Microsoft sign eight-year strategic partnership to bring joint cloud solutions and generative AI to more than 100 million people,"Cloud Software Group and Microsoft sign eight-year strategic partnership to bring joint cloud solutions and generative AI to more than 100 million people

FORT LAUDERDALE, Fla., and REDMOND, Wash. — April 4, 2024 — Today, Cloud Software Group Inc. and Microsoft Corp. announced they are deepening their collaboration through an eight-year strategic partnership agreement. The agreement will strengthen the go-to-market collaboration for the Citrix® virtual application and desktop platform and support the development of new cloud and AI solutions with an integrated product roadmap. Additionally, Cloud Software Group will make a $1.65 billion commitment to the Microsoft cloud and its generative AI capabilities.

The agreement will invigorate one of the industry’s most durable alliances between Citrix, a business unit of Cloud Software Group, and Microsoft. Under the partnership, Citrix is the preferred Microsoft Global Azure Partner solution for Enterprise Desktop as a Service when collaborating with joint Azure customers. The companies will jointly support customer success and offer tailored solutions, expert guidance, and support to accelerate customers’ cloud journeys. Additionally, Citrix will leverage Microsoft Azure as its preferred cloud solution, providing Citrix customers with the comprehensive benefits of the Citrix platform, complemented by Azure Virtual Desktop and Windows 365. Further, the collaboration will create deeper paths to modern procurement options through Azure Marketplace, where customers can easily evaluate, expand, or renew Citrix solutions.

“As organizations embrace flexible work models, the need to empower employees with secure, innovative solutions for enhanced productivity becomes imperative,” said Sridhar Mullapudi, General Manager at Citrix. “The partnership between Citrix and Microsoft epitomizes the ‘Better Together’ relationship, combining both companies’ strengths to deliver unmatched value and innovation to our customers.”

“The simplification of our new Universal and Cloud Platform licensing, which brings together all of our capabilities, including NetScaler, will make our joint solutions with Microsoft much easier for customers to consume and deploy,” said Hector Lima, Chief Revenue Officer at Citrix.

The agreement will also accelerate productivity and new innovations in AI. Cloud Software Group’s engineering organizations are deploying GitHub Copilot to all their engineers with the goal of increasing developer productivity by over 20% — thus accelerating the pace of R&D across the organization. Also, Spotfire, a Cloud Software Group business unit, recently announced a new Spotfire Copilot™ extension built on Microsoft Azure OpenAI service. The Copilot assistant is embedded directly within Spotfire to help customers get more done with their data faster.

To increase collaboration and productivity, Cloud Software Group will transition all its employees to Microsoft 365. This will empower field teams with best-in-class productivity and AI tools to enable a new wave of joint go-to-market activities.

“Our strategic partnership with Cloud Software Group is built on a shared vision for customer success through cloud and AI technology adoption. Together, we will enhance the customer experience with integrated solutions and go-to-market support for its Citrix business unit,” said Judson Althoff, Executive Vice President and Chief Commercial Officer at Microsoft. “With Microsoft 365 as its collaboration platform and Microsoft Azure as its preferred cloud solution, Citrix is well positioned to deliver transformative solutions for our mutual customers at scale.”

“We are excited to see the expanded partnership between Microsoft and Citrix and the ways in which it will help advance our own transformation journey,” Providence Chief Technology Officer Wasif Jamal said.

About Cloud Software Group

Cloud Software Group provides the modern enterprise with mission-critical software. Composed of TIBCO, Citrix, NetScaler, and other business units, Cloud Software Group helps more than 100 million users around the globe evolve, compete, and succeed across private, public, managed, and sovereign cloud environments. To learn how to leverage Cloud Software Group’s solutions for and across data, automation, insight, and collaboration, visit https://www.cloud.com/.

About Citrix

Citrix, a business unit of Cloud Software Group, provides a secure app and desktop delivery platform that companies of all sizes can use to enable secure flexible work. With Citrix, employees can work where and how they prefer, and IT can be confident their information and devices remain safe. Click here to learn more about Citrix solutions and the value they can provide.

About Microsoft

Microsoft (Nasdaq “MSFT” @microsoft) enables digital transformation for the era of an intelligent cloud and an intelligent edge. Its mission is to empower every person and every organization on the planet to achieve more.

###

Citrix, NetScaler and the Citrix logo are trademarks or registered trademarks of Cloud Software Group Inc. and/or its subsidiaries in the United States and/or other countries. All other product and company names and marks mentioned in this document are the property of their respective owners and are mentioned for identification.

For more information, press only:

Microsoft Media Relations, WE Communications for Microsoft, (425) 638-7777, [email protected]

David Rodriguez, Cloud Software Group, [email protected]

Note to editors: For more information, news and perspectives from Microsoft, please visit Microsoft Source at http://news.microsoft.com/source. Web links, telephone numbers and titles were correct at time of publication but may have changed. For additional assistance, journalists and analysts may contact Microsoft’s Rapid Response Team or other appropriate contacts listed at https://news.microsoft.com/microsoft-public-relations-contacts."
Microsoft_News,https://news.microsoft.com/source/features/digital-transformation/innovation-novel-program-helps-microsoft-customers-create-solutions-once-thought-unreachable/,,‘Innovation happens here’: A novel program helps Microsoft customers create solutions they once thought unreachable,"To understand a bakery, you need to see the ovens. To appreciate the products, you must meet the people behind the dough.

But to truly know the operation? You’ve got to eat the cookies.

That’s the recipe Judson Althoff followed recently to gain a firsthand view of the business goals and tech ambitions at Grupo Bimbo, the world’s largest baking company and a Microsoft customer.

Althoff, executive vice president and chief commercial officer at Microsoft, traveled to Grupo Bimbo’s oldest factory in Mexico – “a museum piece” packed with vintage equipment, as one Grupo Bimbo executive described. After a digital upgrade, however, the facility is now a financial dynamo.

Judson Althoff, standing fifth from the left in the group, meets with associates at a Grupo Bimbo bakery. (Photo courtesy of Grupo Bimbo.)

On the factory floor in Guadalajara, Althoff popped on a hair net. He toured the mixers, slicers and conveyor belts. He paused to chat with associates and managers. And he sampled an assortment of breads and sweet treats fresh from the ovens. Company leaders took note.

“To become true partners to our customers and help them drive pragmatic innovation, we need to deeply understand their day-to-day business and the unique challenges they are facing,” Althoff said of the visit. “Through firsthand experience, we were able to bring the best of Microsoft to help Grupo Bimbo reimagine its operations.”

“That was important,” says Juan Pajón, Grupo Bimbo’s global senior vice president of business technology. “The only way you really understand what is happening is by talking to the person on the line, understanding their problems, their concerns, their ideas. True innovation happens here.”

Althoff, center, chats with Grupo Bimbo’s Juan Pajón, left, and Jorge Zarate. Zarate is the company’s global senior vice president of operations and engineering. (Photo courtesy of Grupo Bimbo.)

Yet it was bigger than one delicious moment. Althoff’s visit arose from a long-term, customized collaboration between Grupo Bimbo and Microsoft – a new breed of partnership devised by Microsoft called the CEO Co-Innovation program or COIN.

Several times each year, Microsoft Chairman and CEO Satya Nadella and some of his senior leaders pair up with the chief executive officer and several top execs at a selected customer company. Together, they explore and define new solutions or product features that are visionary yet also relatively market ready.

COIN conversations are tailored to each customer’s business opportunities. But what really makes these gatherings different: The topic of tech doesn’t even enter the discussion until everyone understands what the customer is trying to achieve – and why.

Each COIN engagement spans four to six months, ultimately blending a small group of engineers, developers and industry experts from each company who craft solution concepts that can eventually bring those ideas to life. COIN sessions may be held in person, via Microsoft Teams or both.

COIN kicked off in 2018. Since then, nearly 40 Microsoft customers have leveraged the unique program to build and launch their innovations – from using data to ensure better outcomes for hospital patients to creating an autonomous method to transport people.

At its heart, COIN seeks to help customers accelerate their aspirations through the spirit of co-creation. What it’s not, however, is a Microsoft sales tool. There’s no contract to be signed, no commercial numbers to hit. The focus is squarely on customers’ business needs and helping them meet those needs more quickly, rather than only pitching Microsoft tech.

A Grupo Bimbo associate kneads dough at a company factory. (Photo courtesy of Grupo Bimbo)

“This is a marrying of engineering and business, and it’s beautiful,” says Deb Cupp, president of Microsoft Americas. Cupp was one of the executives responsible for creating the COIN concept and remains a frequent COIN participant.

“The experience has been remarkable, watching customers come to the table, having conversations in a safe space with an opportunity to just dream about what is possible.”

The freedom to hold free-flowing chats around novel business ideas was a revelation for some customers, particularly those that typically applied a more rigid approach to digital modernization, Cupp says.

Deb Cupp.

“I think we’ve opened their eyes. We’ve created an environment that helped them feel like innovation is safer than it might have felt before. I think we’ve helped them see it’s OK to create and ideate. It’s been fun to watch.”

And as generative AI evolves, selected companies can engage with Microsoft executives via COIN to explore how AI can help transform operations, enhance both customer and employee experiences, and bend the curve on innovation, says Cindy Rose, chief operating officer for global enterprise sales at Microsoft and the executive in charge of COIN today.

For a peek inside the program, three customers agreed to share their COIN experiences: What solution they envisioned during their collaboration, what they eventually built and what they learned.

The Company: Amadeus

Travel technology. Headquartered in Madrid, Spain.

COIN participation: November 2021 to March 2022.

The idea: Seize a new moment in business travel.

In late 2021, nearly a year after COVID-19 vaccines became available, many U.S. and European companies began reinstituting employee trips. During 2022, the rate of business travel doubled in those regions. In 2023, companies reported that their domestic and international travel had reached at least 70% of their pre-pandemic levels, according to a global survey.

The revival was on. But an emerging reality accompanied the resurgence: Business travel would undergo more scrutiny compared to the pre-pandemic years.

During their initial COIN meetings, executives from Amadeus and Microsoft discussed how employers would now need to justify the value of their trips – and the environmental impacts they generated. Those meetings included Wolfgang Krips, senior vice president of corporate strategy at Amadeus.

Wolfgang Krips. Photo courtesy of Amadeus.

The group saw an opportunity: A smarter way to manage costs and the carbon. Unlike personal travel, business trips often involve groups of employees who head to the same city for a single event.

“What happens if we can get away from the traditional way of individually booking travel, inputting expenses and getting reimbursed?” Krips recalls asking. “What if we go into a model in which we plan the trip together, aligning on the flight and hotel and sharing ground transportation?”

The process: Both teams quickly realized they had a secure platform readily available to meet their vision. They would integrate Amadeus’ Cytric Easy, a travel and expense tool, into the Microsoft 365 suite, which includes Teams.

Engineers from each company worked on the integration. Business reps explored monetization and mapped out a market plan. Eventually, Microsoft employees tested the solution.

“By (Microsoft) becoming early adopters, it helped us solidify our solution,” Krips says “We immediately received feedback on what the issues were. We learned a lot.”

The collaborations with Microsoft also helped “opened doors” within the market by connecting several Microsoft customers to the Amadeus team, Krips says.

Travelers move through an airport. (Photo courtesy of Amadeus)

Such discussions are the bedrock of COIN – a program fueled by Microsoft’s transformation from a transactional software licensing company a decade ago to a company that today invests in customer success and business outcomes, says Rose, the Microsoft COO for global enterprise sales.

“We’ve learned over the years to actively listen, to be curious about what our customers are experiencing,” Rose says. “COIN is not about selling Microsoft products. We’re here to prioritize the challenges and opportunities our customers are facing and support them on every step of their unique transformation journeys.”

Cindy Rose.

For example, people will soon be able to tap the generative AI capabilities in Microsoft 365 and use natural language prompts to complete their travel bookings.

The creation: Cytric Easy embedded in Microsoft 365, enabling businesses to plan and book travel and track travel expenses.

The COIN takeaway: “Everyone participates at an eye-to-eye level,” Krips says. “This is not the classic (sales-oriented deal) of: OK, I signed up for your cloud program, now you need to deliver it for us. No, this squeezes the best out of us both.”

The Company: Equinor

Energy. Headquartered in Stavanger, Norway.

COIN participation: August 2021 to January 2022.

The idea: Devise a faster and easier way to design offshore wind farms.

You may be familiar with the sight of immense white turbines at sea, each secured by underwater foundations, their blades spinning amid offshore breezes. Average wind speeds tend to be higher over the water than on land, enabling these farms to generate more electricity.

But the upfront work to analyze potential windfarm locations can be arduous. Engineers must make numerous assessments: What platform and turbine size are needed? What are the wind and wave patterns? How should you lay out the wind farm? How much electricity will it produce? Is it worth the cost?

“So we asked: Why don’t we digitize and automate that entire early phase? Why don’t we do digital simulations?” recalls Alvin Shaffer, head of partnerships, ecosystems and intelligence at Equinor.

The process: Engineers from Equinor and Microsoft partnered to accelerate development of a digital platform capable of managing numerous design iterations, ultimately automating the site-assessment process.

“The ocean of data you need to be able to analyze this stuff is significant,” Shaffer says. “You need a platform to be able to orchestrate and handle all of that work.”

For their build, the group relied on several Microsoft technologies, including Azure Digital Twins, which create virtual models of the physical world, and Azure IoT, which connects, monitors and controls IoT devices.

As is typical of a COIN engagement, conversations also took place between Nadella and Equinor CEO Anders Opedal and among senior leaders from both companies.

Alvin Shaffer. Photo courtesy of Equinor.

“To be able to be on a call with Satya, to hear his questions, engagement and suggestions, that was pretty impressive,” Shaffer says. “You don’t typically see that at the CEO level when two companies come together.

“His excitement helped me push (the development) from my side,” he added.

The creation: Digital wind farms.

Assessments and design changes that once took weeks can now be done with the click of a button, Shaffer says.

The COIN takeaway: “There’s something special about two companies being willing to put money on the table, then co-innovating to find a commercial opportunity,” Shaffer says. “That takes a bit of time, but we found it. I personally want more of this.”

For Microsoft, there’s also deep value in a joint process that offers better understanding – in real time – of a customer’s priorities and pressures, Cupp says.

“We learn how we can show up differently and create the space that allows a customer to accomplish these innovations – not just with us, but with themselves too,” Cupp says.

The Company: Grupo Bimbo

Baked goods. Headquartered in Mexico City.

COIN participation: February 2021 to June 2021.

The idea: The year before Althoff donned a hairnet and toured the Grupo Bimbo bakery in Guadalajara, the nearly 80-year-old company mulled an important business riddle.

How can we put real-time data in the hands of our salespeople – give them true business intel to execute more sales and have more strategic conversations when they meet with the retailers who sell our products?

A Grupo Bimbo delivery truck. (Photo courtesy of Grupo Bimbo)

For seven decades, the company’s model for distributing and delivering its baked goods to retail sellers largely depended on the experience of Grupo Bimbo’s salespeople and their ability to network with those retail customers, says the company’s senior VP Pajón.

But the salespeople lacked vital customer sales histories. What they needed was a tool that could show recent sales metrics for Grupo Bimbo goods at specific stores.

Juan Pajón. Photo courtesy of Grupo Bimbo.

The process: During their COIN sessions the Microsoft and Grupo Bimbo teams developed an AI-powered tool that provides data on past sales.

“We’re putting that history into their hands, helping the salesperson not only rely on their experience, but also suggesting some insights that maybe, as humans, we cannot see.”

At the same time, Microsoft executives like Cupp and Althoff engaged with Grupo senior leaders “not only for tactical and operational conversions, but also to make sure we were moving in the right direction,” Pajón says. “We had so many visits from Judson to our bakeries. They listened to us. They understood where we wanted to go.”

The creation: The sales tool was dubbed Ben, inspired by “Star Wars” character Obi Wan Kenobi or Ben Kenobi.

Jose Antonio Parra. (Photo courtesy of Grupo Bimbo)

“We wanted that Ben Kenobi spirit – the force is with you, driving the sales representative in the moment of truth,” says Jose Antonio Parra, vice president of global digital transformation, data and analytics at Grupo Bimbo. “The idea is to empower, to bring something more to the person at the forefront.”

The COIN takeaway: “In terms of our exposure to the top management at Microsoft, this is beyond a business relationship,” Parra says. “It is closer to a friendship where we talk about business.”

Customers interested in learning more about COIN or applying to participate should reach out to their primary Microsoft contact.

At top: A photo of a wind turbine, courtesy of Equinor."
Microsoft_News,https://news.microsoft.com/source/latam/features/ai/cemex-technical-xpert-copilot/?lang=en,,Cemex creates a copilot to cement its foundation with customers,"When multinational building materials company Cemex recognized the need for an AI tool to enhance the agility of their sales force and enable them to tailor solutions to their customers’ needs in a matter of minutes, they also understood that efficient human collaboration within the company was crucial to the success of their plan.

The result of this combination was a sales copilot called Technical Xpert, an AI-assistant running on Microsoft Azure OpenAI Service with GPT 4.0 and found as a chat window in Teams.

Spurred by a need in Mexico operations and supported by Central technology area to create an AI-powered tool that would increase efficiencies in the sales of its products, and even change the way the company offers holistic solutions to its customers, Noel Martínez Pérez and Alan Cortez joined forces to build a solution that would help the sales team quickly navigate Cemex’s vast array of products, from traditional concretes and cement to its new suite of sustainable construction materials.

“I think we are in a time when we need to integrate all these types of tools into our daily processes, because although it is something that has been working well for a long time, I think that with this we can take it to the next level,” says Cortez, head of commercial information at Cemex Mexico. “And that’s exactly what we’re looking for, to think out of the box and to be able to evolve our processes.”

“Many times, hard data provides us with information that, as data scientists, we believe is insightful,” says Martínez, a data scientist for Cemex. “But those hard data, those hard numbers, don’t always reflect what the customer needs.” Which is why the synergies between both departments were crucial to come up with the right copilot.

Over the development period of the AI tool, Martínez and Cortez went back and forth, testing different elements and accentuating several features to provide the best possible product.

Alan Cortez and Noel Martinez Perez used their skill sets in sales and data science to collaborate on the Technical Xpert tool for Cemex. Image by Octavio Hoyos.

“The kinds of details that the bot should look at, I think, come out of that synergy between Alan and our team, where they tell us, which functionalities of the bot would be useful, and based on those user recommendations, we programmed and deployed the tool to do just that” Martínez says. “We polished the tool until it was ready.”

The outcome of these efforts, alongside their partnership with Microsoft, is a solution that aligns with Cemex’s digital transformation efforts. Technical Xpert is a copilot embedded that allows Cemex’s sales agents to use AI to pull up all pertinent product information – almost like an instantaneous online brochure – and provide the best possible materials for customers in a fraction of the time.

The tool recently launched in Mexico, and sales agents are beginning to incorporate it into their engagement with customers, with game-changing results.

“This new tool is sending us information much faster, so we can have the conversations with customers and at the same time asking, internally, technical questions: What can I offer to this customer based on what he’s requiring from me?” says Cristhian Alday, a Cemex commercial advisor located in La Paz, Baja California. “For me, reaching this type of information in the past would take me to knock at least on four people’s doors and the response time would have been maybe, I don’t know, in an hour. And here it is in nine seconds.”

Cemex relies on a network of sales agents throughout Mexico to provide potential customers with the solutions that work best for a particular project. But with so many different choices now available, even the most knowledgeable agents could get stuck in their attempts to recommend roller-compacted concrete or masonry mortar cement.

Fausto Sosa, vice president of information technology at Cemex, oversaw the development of Technical Xpert. Image by Cemex.

“Sometimes it is very hard for the sales force to know all the different ranges of products and the correct technical characteristics for them,” says Fausto Sosa, vice president of information technology at Cemex. “We are constantly releasing new products that are more sustainable and with different characteristics. So, it becomes a little complex to understand all the details.”

That led to Cemex Mexico president suggestion of building a tool to help the sales force become more agile and effective in its recommendations.

“He wanted to have a sales force with relevant information because they are not in offices, they are in the field,” says José Luis de Apodaca, global data science director for Cemex. “It’s a role that usually doesn’t sit at a desk and go over dashboards. So, we needed a very efficient and available tool.”

As part of that change, Cemex looked to Microsoft and the power of AI for help. How could it create a nimble, knowledgeable tool that empowered its sales agents to make the most valuable and efficient product recommendations for its customers? With each large construction project, sales agents needed to put together a full set of materials required, also providing options to account for environmental factors, ground composition and cost.

For the Microsoft team involved in helping create the copilot, the challenge was ensuring that Cemex had an architecture that both met their needs and was highly secure. The back and forth ensured that the design accounted for all variables and could be flexible as new products entered Cemex’s system.

This customized copilot had to be built and trained with the correct information over four months. That required giving the tool hundreds of pages of documents and manuals with information on the myriad products Cemex offers to customers. It also had to be easy to update, since new developments in materials would allow sales agents to have the latest products available to suggest to customers."
Microsoft_News,https://www.microsoft.com/en-us/microsoft-365/blog/2024/04/02/bringing-the-latest-capabilities-to-copilot-for-microsoft-365-customers/,,Bringing the latest capabilities to Copilot for Microsoft 365 customers,"With Microsoft Copilot, we are bringing the power of generative AI to everyone across work and life. And with Copilot for Microsoft 365, we are committed to making sure our commercial customers have access to the very best generative AI models and capabilities from Microsoft.

Today we are announcing two important updates for users of Copilot for Microsoft 365. First, we are bringing priority access to the GPT-4 Turbo model to work with both web and work data. We will also be removing limits on the number and length of conversations while increasing file uploads. Second, later this month we are bringing expanded image generation capabilities in Microsoft Designer to users of Copilot for Microsoft 365, including priority access during peak times.

Copilot for Microsoft 365 Discover Copilot features that work alongside you Get started

Priority access to GPT-4 Turbo and unlimited conversations

Starting today, all licensed commercial customers will have priority access to GPT-4 Turbo in Copilot for Microsoft 365. As part of this change, we are removing the limits on the total number of chats per day and the number of turns per conversation, along with additional updates.

Together, these changes mean that customers will receive faster, more comprehensive responses whether they are using Copilot in the web context or in the work context.

In the web context, Copilot users get the power of the latest foundation models grounded in the latest public information from the web. The web context includes commercial data protection, meaning Microsoft doesn’t retain your prompts or responses, doesn’t have eyes on your prompts or responses, and doesn’t use your chat data to train the underlying foundation models—ensuring a more secure alternative to using other public generative AI services.

The work context lets you go even further by grounding in your work data––that’s your calendar, emails, chats, documents, meetings, contacts, and more––so you get contextually accurate responses. Copilot can help you quickly scan your email for important messages to prioritize, help you get ready for key meetings by pulling information from across your work, and help you ideate on the best path forward. The work context also benefits from enterprise-grade data protection, going further to ensure that your data remains within the Microsoft 365 service boundary.

Expanded image generation capabilities in Microsoft Designer

Starting next month, we’ll increase the number of image generation boosts per day from 15 to 100. Powered by the DALL-E 3 model, Microsoft Designer image generation allows users to create custom images from text descriptions, transforming written ideas into visual art. Users will be able to initiate up to 100 rapid image generation requests daily, significantly reducing waiting times for image creation and unlocking new productivity.

Harnessing the full power of Copilot

We are learning alongside our customers that AI is so much more than a new technology. It is a new way of work that gives organizations the opportunity to completely reinvent their business—rewiring everything from core processes and workflows to hiring and training the workforce of the future.

These new capabilities will be initially available in copilot.microsoft.com, followed by the Copilot mobile app, in Windows, and in Edge, as well as the places where users can access the work context directly, like in Microsoft 365. Additional details about these changes are available on the Copilot for Microsoft 365 documentation page.

Next steps

Learn more about Microsoft Copilot and visit the Copilot for work site for actionable guidance on how you can start transforming work with Copilot today. For the latest research insights on the future of work and generative AI, visit WorkLab."
Microsoft_News,https://blogs.microsoft.com/?p=52561702,,Sustainable by design: Advancing the sustainability of AI,"During the past year, the pace of AI adoption has accelerated significantly, ushering in groundbreaking advances, discoveries and solutions with the potential to help address humanity’s biggest problems. We see this as a massive platform shift, akin to the printing press, which was not just an invention, but a technology that shaped a new economy. Alongside the incredible promise and benefits of AI, we recognize the resource intensity of these applications and the need to address the environmental impact from every angle.

In line with our commitment to responsible AI and our ambitious sustainability commitments, we’re determined to tackle this challenge so the world can harness the full benefits of AI. There are three areas where we’re deeply invested and increasing our focus. The first is optimizing datacenter energy and water efficiency. The second is advancing low-carbon materials, creating global markets to help advance sustainability across industries. And the third is improving the energy efficiency of AI and cloud services, empowering our customers and partners with tools for collective progress.

1. Optimizing datacenter energy and water efficiency

Over the past decade, our quest to innovate across every part of our cloud infrastructure to deliver more sustainable cloud services has led to many changes across how we design, build and operate our datacenters. As we continue this work, two of the biggest challenges we’re addressing are energy management and water intensity.

Energy management

The energy intensity of advanced cloud and AI services has driven us to accelerate our efforts to drive efficiencies and energy reductions. In addition, we have expanded our support to grow the availability of renewable energy, both for our own operations and for the communities in which we operate.

To continue driving improvements in datacenter energy management, we work to reduce peak power, safely harvest unused power, increase server density in existing datacenters through intelligent utilization and power-aware virtual machine allocation, and drive efficiency all the way to our chips and code.

With recognition of the need to continue bringing more renewable energy online, we currently have more than 135 renewables projects in our power purchase agreement (PPA) portfolio globally, a powerful mechanism to support the global energy transition. In the way we design, build and operate our datacenters, we’re focused on the path to 100% zero-carbon electricity 100% of the time.

We’re also working on solutions that enable datacenters to provide energy back to the grid to contribute to local energy supply during times of high demand. For example, in Ireland we built batteries into wind turbines for a wind energy project to capture energy when the turbines over-perform and deliver that energy to the local grid. In Denmark, excess heat created in a Microsoft datacenter will provide heat to the local community, producing enough heat to warm around 6,000 local homes. Both are examples of our work to use our data centers as a source of electricity to relieve pressure on local electric grids.

Water intensity

Currently, many datacenters rely on water for two reasons: directly for cooling, and indirectly for electricity generation. Although at a global scale total water consumption by datacenters is relatively small, weighing in about 0.1% of national water use in the U.S.1 we recognize the impact of datacenter operations on water-stressed areas, and are working to reduce this impact and design solutions that advance our progress on the road to water positive.

We take a holistic approach to water reduction across our business, from design to efficiency, looking for immediate opportunities through operational usage and, in the longer term, through design innovation to reduce, recycle and repurpose water. We’ve found success in using direct air instead of water to cool datacenters, harvesting rainwater, and procuring reclaimed water from utilities to reduce our dependence on fresh water. For example, in our Sweden datacenters, we will use a process called free cooling, a simple, cost-effective method that results in a 30% reduction in energy costs and 90% less water usage than standard systems.

2. Advancing low-carbon materials

For our future datacenters and to help drive progress industry-wide, another way we can advance progress is by helping to accelerate markets for low-carbon building materials. As a sector, building materials such as steel and cement are currently some of the highest contributors to the carbon cost of new construction, together producing an estimated 13.5% of global carbon emissions.2

Innovations in green steel3 and lower-carbon cement are rapidly emerging, however, these markets are still nascent and need significant investment to scale up and bring supply online.

With our $1 billion Climate Innovation Fund, we’re investing to hasten the development and deployment of new climate innovations, especially for underfunded sectors and supply-constrained markets like lower-carbon building materials. For example, we are investing in solutions such as H2 Green Steel to expand market supply of near-zero carbon steel4 which can deliver up to 95% lower CO2 emissions than conventional steel. We are also evaluating use of near-zero carbon steel in our own building materials and equipment supply chains.

Similarly, we’re working to broaden availability of low-carbon concrete and other construction materials through commercial projects and collaboration with the largest datacenter companies in the world. In Washington state, our pilot program utilizes concrete alternatives like biogenic limestone and fly ash and slag with the goal of lowering the embodied carbon in concrete by more than 50% compared to traditional concrete mixes. With these investments, we aim to facilitate the commercialization of materials that can make an outsized impact on carbon reduction, for our own construction and the broader industry.

3. Improving energy efficiency of AI and cloud services

Reducing the energy needed to power AI and cloud services up front is another critical component of the solution. We’re working to support developers and IT professionals with tools to optimize models and code, exploring ways to reduce the energy requirements of AI, and harnessing the power of these advanced technologies to drive energy breakthroughs.

As a founding member of the Green Software Foundation, we collaborate with other industry-leading organizations to help grow the field of green software engineering, contribute to standards for the industry and work together to reduce the carbon emissions of software. Across our cloud services, we’re working to ensure IT professionals have the information they need to better understand and reduce the carbon emissions associated with their cloud usage.

As AI scenarios increase in complexity, we’re empowering developers to build and optimize AI models that can achieve similar outcomes while requiring fewer resources. Over the past few months, we’ve released a suite of small language models (SLMs) called “Phi” that achieve remarkable performance on a variety of benchmarks, matching or outperforming models up to 25x larger. Now available in the Azure AI Studio model catalog, Phi-2 offers a compact model for research and development or fine-tuning experimentation on a variety of tasks.

We’ve learned that the complex sustainability challenges we face today are best addressed through multidisciplinary, multi-sector collaboration, and energy breakthroughs are no exception. We recently collaborated with the Department of Energy’s Pacific Northwest National Laboratory (PNNL) using advanced AI models to find new materials that can reduce reliance on traditional battery materials such as lithium. The team screened over 32 million materials, discovered 500,000 stable candidates, and synthesized one promising candidate to a working prototype, shortening a process that can take years to a matter of days.

These highlights provide a glimpse into our work to build and operate cloud services more sustainably, advancing solutions that can reduce the future impact of AI. Our ambitious 2030 targets to become carbon negative, water positive, zero waste and to protect biodiversity require continued innovation across every aspect of our operations, and we’re committed to sharing what we learn along the way. Stay tuned for more on this topic in the months ahead.

Learn more:

To learn more, visit the Microsoft Sustainability website and read the whitepaper Accelerating Sustainability with AI. To learn how we’re integrating AI into our sustainability solutions, watch the digital event This is AI . . . for Sustainability.

Sources in footnotes:

1Data centre water consumption | npj Clean Water (nature.com)

2Cement and steel — nine steps to net zero (nature.com)

3What is green steel and how can it help us reach net zero? | World Economic Forum

4Iron & steel – IEA

Tags: AI, Climate Innovation Fund, sustainability"
Microsoft_News,https://www.microsoft.com/en-us/microsoft-365/blog/2024/03/28/your-new-way-of-working-copilot-for-microsoft-365/,,Your new way of working: Copilot for Microsoft 365,"Small and medium-sized businesses (SMBs) have tremendous vision and passion, and Copilot for Microsoft 365 can help turn dreams into reality. With Copilot for Microsoft 365, you can use the power of AI to reduce the daily grind of running your business—giving you additional time to reach more customers, create new products, and continue to grow your business. Copilot for Microsoft 365 is available for businesses of all sizes, and we recently announced availability on additional plans, such as Microsoft 365 Business Basic. Learn how to get Copilot for Microsoft 365 now.1

Copilot for Microsoft 365 Focus on what matters most with Copilot for Microsoft 365 and the power of AI. Discover more

SMBs are important drivers of economic growth and essential for the well-being of communities both locally and globally. While the specific business challenges may differ, one thing is true—many of you have told us that you are challenged by time-consuming, mundane tasks.2 Copilot for Microsoft 365 can help you save time and enables you to maintain focus on why you started a business in the first place—your vision for your product or service and solving the problems your customers face. And with Copilot for Microsoft 365, you can feel confident in knowing Microsoft has a commitment to responsible, secure AI and the Copilot Copyright Commitment.

Unlock the transformative power of AI

The age of AI is here, and the technology is evolving rapidly. To support businesses and workers, Copilot for Microsoft 365 introduces an entirely new way of working. You can gain a lot from incorporating AI into your work.

There are many options available for those of you who want to tap into the transformative power of AI. To begin your journey, you can start with Copilot to see what is possible when using AI plus the web. However, you can go much further than that and use tools that meet you where you are in the flow of your work while keeping your business safe and secure. To understand how we make this possible with Copilot for Microsoft 365, let’s start with an overview of the capabilities.

It all starts with AI and large language models (or LLMs), which make up the foundational, underlying intelligence for Copilot. LLMs generate responses based on prompts that you create. The models are guided by receiving use-case-specific information through a process we call grounding. When you are using our free version of Copilot, you get the power of AI grounded in the information widely available on the web. But what if you want to receive information more relevant to you and your business—like gathering all the information relevant to helping you prepare a proposal for a customer? Part of the magic of Copilot for Microsoft 365 happens when responses are based on your personalized work information. This is made possible with the Microsoft Graph.

Microsoft graph Learn more

The Microsoft Graph is all of your work content and context that exists throughout your day—like your emails, chats, call transcripts, documents, and more. The quality and relevance of the responses received improve dramatically when AI is reasoning over your information from the Microsoft Graph. For example, you can prompt Copilot for Microsoft 365 to give you the latest updates and information from one of your team members or a summary of business performance and it will return information that is relevant along with references for support. All this can be done with ease in the tools that you use every day.

“Everyone has a favorite way for gathering and using information. Some people use email, some OneNote or something else, but a single app never gives you the whole picture. That’s what’s great about Copilot because it looks at everything across all the Microsoft 365 apps and data and then lets you bring it all together no matter which app you’re using.” —Melissa Lee-Young, Head of Marketing, Generation-e

Microsoft 365 apps Learn more

The Microsoft 365 apps include the tools you use to run your business, such as Microsoft Teams, Outlook, Word, PowerPoint, Excel, and more. You can find so many ways to get more done in less time using Copilot for Microsoft 365 within these apps including:

Keeping tabs on your daily operations by asking Copilot in Microsoft Outlook to summarize long email threads so you’re immediately up to speed with those important conversations.

Partnering with Copilot in Microsoft Word to write and edit job descriptions and customer-facing content as well as summarizing documents so you never have to start with a blank sheet again.

Growing your customers and building your brand by transforming written content into compelling pitch decks and presentations with Copilot in Microsoft PowerPoint.

Staying on top of your business performance or projects by using Copilot in Microsoft Excel (currently in public preview with updates beginning to roll out in June 2024) to filter, format, sort, and edit information, letting you go from raw data to useful insights faster.3

Having Copilot for Microsoft 365 at your side within the flow of work—instead of leveraging an external tool that doesn’t have access to the information most relevant to you—is how workers can reap the benefits of supercharged productivity and creativity that Copilot for Microsoft 365 offers.

Data protection is automatically inherited through your existing Microsoft 365 security, privacy, identity, and compliance policies. Copilot for Microsoft 365 acts on behalf of the individual user, so it can’t access any information that someone does not have permission to see. Your data always stays within your control and is never used to train the models without your permission. This protection of your business data is a key reason why your business information is safer using AI in the confines of Microsoft 365, versus through a free service.

Floww, a fast-growing FinTech company in the United Kingdom has built a financial infrastructure platform for entrepreneurs and investors to supercharge private market growth. Floww is an ecosystem that connects scaling companies with venture capital and investors, based on merit and real data, while also managing all regulatory perimeters.

Floww relies on Copilot for Microsoft 365 to help their employees quickly catch up on meetings and follow discussions to suggest action items. They also use Copilot to get real-time access to quickly pull and synthesize information from multiple sources. Copilot for Microsoft 365 is giving time back to Floww’s employees so they can focus on the most impactful work.

“Because we’re a relatively small team we have to maximize every resource we have. Copilot is already decreasing the time our employees spend on mundane tasks by 10 to 20%, which lets them concentrate on more meaningful work.” —Alex Pilsworth, Chief Technology Officer, Floww

Get Copilot for Microsoft 365 today

If you have Microsoft 365 Business Standard or Microsoft 365 Business Premium, you can purchase Copilot for Microsoft 365 as an add-on and realize this magic for yourself today.4 As we just announced, Microsoft 365 Business Basic customers will also be able to purchase. Of course, if you do not already have these core productivity offerings you can purchase them now and add Copilot for Microsoft 365 to your subscription.

Copilot for Microsoft 365 transforms your everyday work life, easing the burden of rote tasks so you can stay focused on the work that matters. Find out more about Copilot for Microsoft 365 or reach out to a Cloud Solution Partner to learn more.5

You can start taking steps to prepare, understand licensing and technical requirements, familiarize yourself with new capabilities, and get your team ready, too. Copilot for Microsoft 365 introduces a whole new way of working, so visit the Copilot Lab to see prompting in action and learn more about how Copilot works in Microsoft 365 apps. You can also check out our WorkLab for insights and thought leadership on how Copilot is transforming work.

1Copilot for Microsoft 365 may not be available for all markets and languages. To purchase, enterprise customers must have a license for Microsoft 365 E3 or E5 or Office 365 E3 or E5, and business customers must have a license for Microsoft 365 Business Standard or Business Premium or a version of these suites that does not include Microsoft Teams.

2Wakefield Research. (2023). Microsoft study: Small businesses intrigued by AI and the opportunities it brings.

3Copilot in Excel (preview) is currently supported in English (US, GB, AU, CA, IN) and will be supported in Spanish (ES, MX), Japanese, French (FR, CA), German, Portuguese (BR), Italian, and Chinese Simplified starting in March.

4Copilot for Microsoft 365 is currently supported in the following languages: English (US, GB, AU, CA, IN), Spanish (ES, MX), Japanese, French (FR, CA), German, Portuguese (BR), Italian, and Chinese Simplified. We will start rolling out Arabic, Chinese Traditional, Czech, Danish, Dutch, Finnish, Hebrew, Hungarian, Korean, Norwegian, Polish, Portuguese (Portugal), Russian, Swedish, Thai, Turkish, and Ukrainian over March and April. Check the public roadmap and message center to track roll out status.

5More information on how to find your Microsoft 365 partner or reseller."
Microsoft_News,https://www.microsoft.com/en-us/worklab/how-ai-can-help-you-have-a-smarter-more-thoughtful-conversations/,,"AI Can Help You Have Smarter, More Thoughtful Conversations","This article first appeared in the WorkLab newsletter. Get exclusive insights on AI and the future of work by subscribing here.

The ability to clearly articulate what you want and why you need it is not just vitally important to how you interact with other people—it determines the quality of the responses you get from AI as well. It’s an insight Charles Duhigg, bestselling author of multiple productivity books, uncovered while researching his latest release, Supercommunicators: How to Unlock the Secret Language of Connection.

Duhigg recently joined us on the WorkLab podcast to explain why communication is having a moment. Here’s what he told us.

1. Communication is now a technical skill

In the age of AI, forward-looking leaders are already prioritizing communication skills when they hire. “We’re already seeing more and more emphasis on communication ability as something that employers are looking for,” Duhigg says. “The ability to show during an interview that you can communicate and connect well with others is going to tell that interviewer something about how you also interact with technology, and that’s going to be powerful.”

2. Want to get more from AI? Get more conversational!

“The future of tech is going to be more and more like having a conversation and less like using a calculator,” Duhigg says. “I have a 15-year-old son, and if he reads a book that none of his friends are reading, he’ll have a conversation with AI about it. It can be really edifying. Similarly, if you ask AI questions about how it got to an answer, or what other questions it thinks you should ask, it’ll reveal interesting and useful things, and open new avenues of inquiry.” Remember, AI isn’t just a computer spitting out answers; it can be an intellectual partner too.

3. Communicating emotion is a conversational superpower

“If you use emotional language with AI, you can increase its effectiveness,” Duhigg says. “Saying something like, ‘The answer to this will determine whether I get a promotion’ will raise the efficacy of the answer that it delivers.” Why? Duhigg says that AI models may be trained on data that contains emotional language, “so using emotional language helps to identify which parts of that dataset the AI ought to pay attention to.” Great communicators know that offering personal or emotional context helps engage others, whether it’s a person or an AI assistant.

4. Explaining what you need helps you understand what you need

“One of the reasons why conversation is so useful is because not only does it help us understand another person, it helps us understand ourselves.” That goes for conversational interactions with AI as well. “Sometimes we learn things just in what we say to AI, and then sometimes we learn things from what the machine responds with. And then there are times when I don’t even understand what question I want to ask AI, and it ends up helping me understand what I’m trying to get at.” Clearly articulating exactly what you are looking for helps you clarify in your own head what it is that you actually want.

5. AI can even help you upgrade your communication in other contexts

“I talk to researchers who are teaching negotiation skills, and they tell all their students to practice negotiations with AI and pay attention to, What surprises you? What objections do they raise? How do they come back that catches you off guard?” Leaders should absolutely use AI as a sounding board or a stand-in to game out different scenarios or rehearse difficult conversations.

For more productivity and communication insights from Charles Duhigg, check out the WorkLab podcast."
Microsoft_News,https://www.microsoft.com/en-us/worklab/how-business-leaders-are-using-copilot-right-now/,,How Business Leaders Are Using Copilot Right Now,"BBy now it’s clear: AI will transform work for everyone. But some business leaders have moved to the front of the pack. In the past year, people in industries around the world have adopted Copilot for Microsoft 365, testing how it can revolutionize the way they work. The early results show Copilot users spend less time on mundane, energy-sapping tasks and more time on high-level, high-value work, allowing leaders to reimagine their business models and pursue once-impossible bold opportunities. One company even used AI to help develop a product that boosts crop yields.y now it’s clear: AI will transform work for everyone. But some business leaders have moved to the front of the pack. In the past year, people in industries around the world have adopted Copilot for Microsoft 365, testing how it can revolutionize the way they work. The early results show Copilot users spend less time on mundane, energy-sapping tasks and more time on high-level, high-value work, allowing leaders to reimagine their business models and pursue once-impossible bold opportunities. One company even used AI to help develop a product that boosts crop yields.

We asked six early adopters—from advertising executives to accounting experts—how their companies are using Copilot for Microsoft 365 today.



Julie Sweet, Chair & CEO, Accenture

What Accenture Does: Accenture is a global professional services company that creates tangible value at speed and scale by helping businesses, governments, and other organizations build their digital core, optimize their operations, accelerate revenue growth, and enhance citizen services.

Sweet’s Role: In just nine years, she rose from a general counsel role to become the first female CEO in the firm’s 35-year history.

Her Experience With Copilot: Sweet made it her mission for Accenture to become one of the first companies to adopt Copilot; this year, she says, Accenture is set to train 250,000 of its 700,000 workers on AI. “We first of all wanted to unlock the personal productivity for our own people. But every minute of productivity they get they’re using to enable our clients.”

Sweet’s big push has already paid off. “The first users told us they saved at least 30 minutes a day, and sometimes up to three hours,” she says. And, while some companies might just dip a toe in the water with a small pilot program, Accenture dove straight in. “We didn’t start with our most junior people,” she says. “We started with our most senior leaders in the first cohort, including me. Now that’s sometimes counterintuitive. But the real power of AI is reinvention, and in order to reinvent, you have to have leaders who understand the power of it themselves.”

Florian Häse, Research Scientist, Bayer

What Bayer Does: Best known as the creator of aspirin, today it’s one of the largest companies in the world, with core competencies in the life science fields of healthcare and nutrition.



Häse’s Role: Working in the company’s Computational Life Science department, Häse combs through reams of research to support the search for that one molecule that could lead to a new crop protection product to enable plants to thrive and boost yields.



His Experience With Copilot: Bayer Crop Science is focused on finding new ways for farmers to produce more food for the growing world population. To do that, Häse has been using Microsoft Copilot to help pick through research data the company has gathered over the years and even decades. “Not only does it assist me in finding that information, but it also shows how to extract that information from unstructured data sources, whether they’re reports or slide decks,” he says. Copilot also helps him keep up with the latest research, which is essential in a fast-moving field. “It can be quite a challenge to figure out who knows what at which point in time, and getting that contact you need to solve the task at hand,” he says. Before Copilot, he used to spend days and weeks finding that information. “The process has certainly sped up,” he says. “Now you don’t miss out on opportunities to connect with the colleagues you should be talking to.”

James Thomas, Global Head of Technology, Dentsu Creative

What dentsu Does: Global ad agency dentsu connects brand, content, commerce, and experience for some of the world’s largest brands, including Kraft Heinz, Netflix, and T-Mobile.

Thomas’ Role: Thomas is focused on growing dentsu’s Global AI Centre of Excellence (CoE) to help the company harness technology to create innovative, award-winning content for clients. His work used to involve getting input from clients, researching, brainstorming, and “maybe days, weeks, even months later, we’d come back with creative illustrations of the client’s ideas.”

His Experience With Copilot: He says that the process of transforming ideas into images has been reduced from weeks and months to minutes. “We can be ideating, we can have someone in the corner prompting, and by the end of that session, we’ve already got visuals,” Thomas says.

Those visuals lead to quicker, more effective communication with clients—a critical step to keeping clients excited and ensuring that the best new ideas prevail. “The more creative the idea, the harder it is to translate,” he says. “Being able to visualize a lot of these ideas really helps you know if you’re going down the wrong route or the right one. It really gets us where we need to go a lot faster.”

Vicki Holman, Collaboration Platform Owner, Hargreaves Lansdown

What Hargreaves Lansdown Does: The UK-based financial services powerhouse helps 1.6 million customers save, invest, and retire.



Holman’s Role: She’s the point person helping Hargreaves Lansdown with its cloud transformation and ensuring that teams get the most from it.

Her Experience With Copilot: Early users have been discovering new ways to cut hours of drudgery out of their workweeks, from generating first drafts of a PowerPoint presentation by pulling material from an existing Word doc to crafting smarter, clearer emails when the words just won’t come. “The average respondents are saving two to three hours a week,” Holman says. “And 90 percent of them felt they would save even more time over the coming months as the product matures and they get a better understanding of how to use it.”

One of the unexpected advantages of Copilot, Holman says, is the positive impact it’s had on the company’s neurodivergent workers. “I hadn’t anticipated it, but the impact we’ve seen on people who have workplace accessibility needs has been incredible,” she says. Workers who can’t maintain focus through hour-long meetings, she says, can record meetings and listen to them later, or get summaries of what they’ve missed. “There’s the reduction of stress, making it more enjoyable to be at work when you’re not struggling to do your tasks and find the information you need.”

Coskun Cavusoglu, Financial Services Tax AI Go-to-Market Leader, EY Americas

What EY Does: This “Big Four” professional services organization provides assurance, consulting, law, strategy, tax, and transaction services to clients in more than 150 countries.

Cavusoglu’s Role: Utilizing leading-edge technology, he collaborates with clients to boost operational efficiency and help manage risks. He is dedicated to transforming the tax function into a crucial element that helps drive value and foster business growth.

His Experience With Copilot: The EY Global Tax team collaborated with our team at Microsoft to build a Copilot plugin proof of concept on a developer tenant, which Microsoft provided. With it, they can directly ask questions of EY sample data, expediting analyses and report creation. The plugin is intended to redefine the report creation experience for EY Global Tax senior executives.

“When implemented, our senior leaders will be able to query all these databases by effortlessly asking questions in natural language and then generating reports,” Cavusoglu says. “We’re going to be able to have not only productivity gains but insights that are going to be served to us in near real time.”

Anup Purohit, Group CIO, Wipro Limited

What Wipro Does: A leading technology services and consulting company with 245,000 employees across 65 countries, Wipro builds innovative solutions that address clients’ most complex digital transformation needs.

Purohit’s Role: He helms Wipro’s digital transformation journey with an AI-first approach.

His Experience With Copilot: In consulting, people are your business. Purohit says that Copilot has already transformed every aspect of his workday, freeing up time to deliver great results for his clients. “I use it when I wake up to check my calendar—it’s totally reinventing the way I look at my daily schedule,” he says. “I use it to summarize emails, especially if there is a long thread with multiple interactions. It helps me to focus on key actions discussed in calls, and I use it to create follow-on actions for my team within 10 minutes of the call completion. It even helps me plan my business trips and personal holidays.”"
Microsoft_News,https://azure.microsoft.com/en-us/blog/announcing-new-tools-in-azure-ai-to-help-you-build-more-secure-and-trustworthy-generative-ai-applications/,,Announcing new tools in Azure AI to help you build more secure and trustworthy generative AI applications,"In the rapidly evolving landscape of generative AI, business leaders are trying to strike the right balance between innovation and risk management. Prompt injection attacks have emerged as a significant challenge, where malicious actors try to manipulate an AI system into doing something outside its intended purpose, such as producing harmful content or exfiltrating confidential data. In addition to mitigating these security risks, organizations are also concerned about quality and reliability. They want to ensure that their AI systems are not generating errors or adding information that isn’t substantiated in the application’s data sources, which can erode user trust.

To help customers meet these AI quality and safety challenges, we’re announcing new tools now available or coming soon to Azure AI Studio for generative AI app developers:

Prompt Shields to detect and block prompt injection attacks, including a new model for identifying indirect prompt attacks before they impact your model, coming soon and now available in preview in Azure AI Content Safety.

Groundedness detection to detect “hallucinations” in model outputs, coming soon.

Safety system messages to steer your model’s behavior toward safe, responsible outputs, coming soon.

Safety evaluations to assess an application’s vulnerability to jailbreak attacks and to generating content risks, now available in preview.

Risk and safety monitoring to understand what model inputs, outputs, and end users are triggering content filters to inform mitigations, coming soon, and now available in preview in Azure OpenAI Service.

With these additions, Azure AI continues to provide our customers with innovative technologies to safeguard their applications across the generative AI lifecycle.

Safeguard your LLMs against prompt injection attacks with Prompt Shields

Prompt injection attacks, both direct attacks, known as jailbreaks, and indirect attacks, are emerging as significant threats to foundation model safety and security. Successful attacks that bypass an AI system’s safety mitigations can have severe consequences, such as personally identifiable information (PII) and intellectual property (IP) leakage.

To combat these threats, Microsoft has introduced Prompt Shields to detect suspicious inputs in real time and block them before they reach the foundation model. This proactive approach safeguards the integrity of large language model (LLM) systems and user interactions.

Prompt Shield for Jailbreak Attacks: Jailbreak, direct prompt attacks, or user prompt injection attacks, refer to users manipulating prompts to inject harmful inputs into LLMs to distort actions and outputs. An example of a jailbreak command is a ‘DAN’ (Do Anything Now) attack, which can trick the LLM into inappropriate content generation or ignoring system-imposed restrictions. Our Prompt Shield for jailbreak attacks, released this past November as ‘jailbreak risk detection’, detects these attacks by analyzing prompts for malicious instructions and blocks their execution.

Prompt Shield for Indirect Attacks: Indirect prompt injection attacks, although not as well-known as jailbreak attacks, present a unique challenge and threat. In these covert attacks, hackers aim to manipulate AI systems indirectly by altering input data, such as websites, emails, or uploaded documents. This allows hackers to trick the foundation model into performing unauthorized actions without directly tampering with the prompt or LLM. The consequences of which can lead to account takeover, defamatory or harassing content, and other malicious actions. To combat this, we’re introducing a Prompt Shield for indirect attacks, designed to detect and block these hidden attacks to support the security and integrity of your generative AI applications.

Identify LLM Hallucinations with Groundedness detection

‘Hallucinations’ in generative AI refer to instances when a model confidently generates outputs that misalign with common sense or lack grounding data. This issue can manifest in different ways, ranging from minor inaccuracies to starkly false outputs. Identifying hallucinations is crucial for enhancing the quality and trustworthiness of generative AI systems. Today, Microsoft is announcing Groundedness detection, a new feature designed to identify text-based hallucinations. This feature detects ‘ungrounded material’ in text to support the quality of LLM outputs.

Steer your application with an effective safety system message

In addition to adding safety systems like Azure AI Content Safety, prompt engineering is one of the most powerful and popular ways to improve the reliability of a generative AI system. Today, Azure AI enables users to ground foundation models on trusted data sources and build system messages that guide the optimal use of that grounding data and overall behavior (do this, not that). At Microsoft, we have found that even small changes to a system message can have a significant impact on an application’s quality and safety. To help customers build effective system messages, we’ll soon provide safety system message templates directly in the Azure AI Studio and Azure OpenAI Service playgrounds by default. Developed by Microsoft Research to mitigate harmful content generation and misuse, these templates can help developers start building high-quality applications in less time.

Evaluate your LLM application for risks and safety

How do you know if your application and mitigations are working as intended? Today, many organizations lack the resources to stress test their generative AI applications so they can confidently progress from prototype to production. First, it can be challenging to build a high-quality test dataset that reflects a range of new and emerging risks, such as jailbreak attacks. Even with quality data, evaluations can be a complex and manual process, and development teams may find it difficult to interpret the results to inform effective mitigations.

Azure AI Studio provides robust, automated evaluations to help organizations systematically assess and improve their generative AI applications before deploying to production. While we currently support pre-built quality evaluation metrics such as groundedness, relevance, and fluency, today we’re announcing automated evaluations for new risk and safety metrics. These safety evaluations measure an application’s susceptibility to jailbreak attempts and to producing violent, sexual, self-harm-related, and hateful and unfair content. They also provide natural language explanations for evaluation results to help inform appropriate mitigations. Developers can evaluate an application using their own test dataset or simply generate a high-quality test dataset using adversarial prompt templates developed by Microsoft Research. With this capability, Azure AI Studio can also help augment and accelerate manual red-teaming efforts by enabling red teams to generate and automate adversarial prompts at scale.

Monitor your Azure OpenAI Service deployments for risks and safety in production

Monitoring generative AI models in production is an essential part of the AI lifecycle. Today we are pleased to announce risk and safety monitoring in Azure OpenAI Service. Now, developers can visualize the volume, severity, and category of user inputs and model outputs that were blocked by their Azure OpenAI Service content filters and blocklists over time. In addition to content-level monitoring and insights, we are introducing reporting for potential abuse at the user level. Now, enterprise customers have greater visibility into trends where end-users continuously send risky or harmful requests to an Azure OpenAI Service model. If content from a user is flagged as harmful by a customer’s pre-configured content filters or blocklists, the service will use contextual signals to determine whether the user’s behavior qualifies as abuse of the AI system. With these new monitoring capabilities, organizations can better-understand trends in application and user behavior and apply those insights to adjust content filter configurations, blocklists, and overall application design.

Confidently scale the next generation of safe, responsible AI applications

Generative AI can be a force multiplier for every department, company, and industry. Azure AI customers are using this technology to operate more efficiently, improve customer experience, and build new pathways for innovation and growth. At the same time, foundation models introduce new challenges for security and safety that require novel mitigations and continuous learning.

Invest in App Innovation to Stay Ahead of the Curve Learn more

At Microsoft, whether we are working on traditional machine learning or cutting-edge AI technologies, we ground our research, policy, and engineering efforts in our AI principles. We’ve built our Azure AI portfolio to help developers embed critical responsible AI practices directly into the AI development lifecycle. In this way, Azure AI provides a consistent, scalable platform for responsible innovation for our first-party copilots and for the thousands of customers building their own game-changing solutions with Azure AI. We’re excited to continue collaborating with customers and partners on novel ways to mitigate, evaluate, and monitor risks and help every organization realize their goals with generative AI with confidence.

Learn more about today’s announcements"
Microsoft_News,https://www.microsoft.com/en-us/microsoft-365/blog/2024/03/26/ai-powered-collaboration-with-microsoft-teams/,,Announcing new Copilot in Microsoft Teams enhancements,"AI Data Drop: The 11-by-11 Tipping Point Read the research

As we bring Microsoft Copilot to more customers around the world, people are already unlocking its value and learning the power of generative AI at work. Our recent Copilot customer research shows that 11 minutes of time savings is all it takes for most people to feel like AI is useful, and that after 11 weeks—about one business quarter—most users say it improves their work across key areas like productivity and having fewer meetings.

Microsoft Teams is where work happens, and now we’re excited to announce new Copilot in Teams enhancements that will supercharge collaboration and make hybrid meetings even better.

Read on for all the details.

Microsoft Teams Collaborate more effectively with a faster, simpler, smarter, and more flexible Teams. Discover more

Making collaboration smarter

Based on customer feedback, in May, we are enhancing the Copilot in meeting experience. Copilot in meetings will now provide information and insights from the meeting chat in addition to the meeting transcript. When you open Copilot in the meeting chat, you will have a more comprehensive and inclusive view of what was covered in the meeting, whether it was spoken (transcript) or written (chat).

In April, with Copilot in Teams chat compose box, you can prompt Copilot to adjust your message and provide a custom rewritten version. For example, Copilot can adjust your message to add a call to action, or even to make you sound like a pirate. Soon, you will also be able to generate a new message with a prompt by typing just a few words in Teams chat. This will save you time thinking about where to start, and let you adapt and edit messages with ease.

Intelligent call recap brings one of the best meetings AI features to calling. Intelligent call recap can provide AI-powered insights and recaps of your VoIP and Public Switched Telephone Network calls in Teams. This feature will be generally available in June with Teams Premium and Copilot.

Making hybrid meetings better

Hybrid meetings with attendees participating both in-room and remote can be less than ideal. Remote participants often have a hard time knowing who is in the room or who is speaking. Microsoft IntelliFrame helps hybrid meeting attendees to see people in Teams Rooms more clearly, using Cloud AI to identify and capture individual video feeds of each in-room participant. We’ve now made it even easier to ensure your meeting spaces are ready for hybrid work by turning on Intelliframe by default on Teams Rooms devices. More people than ever are now experiencing the power of great hybrid meetings.

The remote experience continues to get better as automatic camera switching for IntelliFrame becomes available later this year. Using AI to determine and select the optimized view of each person in a meeting room, this capability ensures that every remote participant knows who is in the room at all times. It compares multiple video sources, such as individual laptop and room cameras, and ensures the room captures, segments, and presents the best head pose for the benefit of remote participants—for example, choosing laptop video feeds instead of the front of room camera when multiple people are in the same room. If a camera view for someone in the room becomes obstructed, another camera view will be chosen to provide remote participants with a clear view.

Not all Teams Rooms have intelligent speakers, but starting in public preview in April 2024, speaker recognition capabilities for any existing microphone will improve transcript accuracy and Copilot provided meeting insights for Teams Rooms on Windows environments. When you join a meeting from a Teams Room, what you say in the meeting is isolated and attributed to you in the transcript, simply by enrolling your voice and face profiles.

When you need to join a call or meeting in a noisy location, voice isolation, generally available in April 2024, can help ensure that only your voice is heard. Once you complete a short enrollment process, this AI-based advanced noise suppression feature will isolate your voice and eliminate all other background noise—including other people’s voices.

Windows Autopilot for Teams Rooms reduces the time it takes IT admins to deploy Teams Rooms from days to minutes. This new integration with Windows Autopilot and auto-login of Teams Rooms on Windows offers low-friction provisioning that will enable devices to sign in to the account associated with the Autopilot device seamlessly. Additionally, the Microsoft Teams Rooms for Windows app automatically checks for and installs new applications and Windows updates during the initial setup, ensuring devices are protected and up to date on day one. Autopilot for Teams Rooms will be in public preview this week.

Our Bring-Your-Own Device (BYOD) ecosystem is also growing. Shared Display mode is now generally available and ensures that you are in full control of the content you share to a display. Support for intelligent speakers in BYOD spaces will allow in-person meeting participants to attribute speech to individual attendees. This feature will enter public preview later this year.

Finally, BYOD IT Management now gives IT admins the power to easily discover, inventory, and generate insights about BYOD peripherals, and will be generally available in April 2024.

Expanding Teams Phone and customer-facing role capabilities

Teams Phone gives you a reliable and simple way to connect, no matter where you are. As of April 1, 2024, we’re updating our Teams Phone financially-backed service level agreement to 99.999% uptime. Additionally, we’re continuing to expand survivable calling capabilities made possible with the Survivable Branch Appliance capabilities. Starting next quarter, Teams Phone will support call transfer, forwarding, and incoming calls from call queues or auto attendants in the event of a network outage.

To make it easier to communicate on the go, Teams Phone Mobile gives you a single number across both Teams and your mobile device native dialer. We are excited to announce that several new partners including AT&T, Odido, Virgin Media O2, and Vodafone UK will begin offering Teams Phone Mobile later this year.

As more customers standardize on Teams Phone, we’re adding additional capabilities for customer-facing work. The new Queues app creates a workspace for both supervisors and employees engaging with customer calls. When a call comes into the queue, users are notified and assigned with the options to accept or transfer the call. Supervisors can add users to different queues, supervise queues, manage workloads, monitor performance, and train team members to better engage with customers. The Queues app is currently in private preview and will be generally available in June with Teams Premium. Please connect with your Microsoft representative or visit the Queues app nomination form to learn more and be considered for the preview.

Soon, an enhancement to Copilot for Service will allow agents to chat with Copilot during a meeting and ask questions over cases and contacts, summarize cases, reason over knowledge, and more. This builds on the current capability of using Copilot in Teams to browse and update CRM records. Download the Copilot for Service app for Teams and Outlook.

What’s next

Our vision with Copilot is to bring the power of generative AI to everyone. We are committed to continue to improve the Copilot experience in Teams to help everyone be more creative and productive.

Beyond this wave of AI-powered innovation, we continue to build a foundation for the future with a strong focus on the core fundamentals of Teams. These fundamentals provide the underlying experience that is essential to making Teams great for everyone—across performance, reliability, and ease of use. To learn more read Jeff Teper’s blog. And check our Tech Community for all the latest Microsoft Teams updates.

Learn more about Microsoft Copilot and visit the Copilot for work site for actionable guidance on how you can start transforming work with Copilot today.

Learn more about Copilot for Microsoft 365 for small and medium-sized businesses, including next steps for licensing and technical requirements, and get familiar with Copilot capabilities.

Visit WorkLab for critical research and insights on how generative AI is transforming work."
Microsoft_News,https://news.microsoft.com/2024/03/26/adobe-and-microsoft-partner-to-bring-new-generative-ai-capabilities-to-marketers-as-they-work-in-microsoft-365-applications/,,Adobe and Microsoft partner to bring new generative AI capabilities to marketers as they work in Microsoft 365 applications,"Adobe and Microsoft partner to bring new generative AI capabilities to marketers as they work in Microsoft 365 applications

Adobe and Microsoft partner to connect Adobe Experience Cloud workflows and insights with Microsoft Copilot to deliver generative-AI powered capabilities that enable marketers to increase collaboration, efficiency and creativity.

SAN JOSE, Calif. and REDMOND, Wash. – Mar. 26, 2024 – Today at Adobe Summit – the world’s largest digital experience conference – Adobe (Nasdaq:ADBE) and Microsoft (Nasdaq:MSFT) announced plans to bring Adobe Experience Cloud workflows and insights to Microsoft Copilot for Microsoft 365 to help marketers overcome application and data silos and more efficiently manage everyday workflows. These new integrated capabilities will bring relevant marketing insights and workflows from Adobe Experience Cloud applications and Microsoft Dynamics 365 to Microsoft Copilot, assisting marketers as they work in tools such as Outlook, Microsoft Teams and Word to develop creative briefs, create content, manage content approvals, deliver experiences and more.

“The demand for personalized content across social media, mobile and other fast-moving channels has been exploding, pushing marketers to drive greater efficiency and productivity in their everyday work,” said Amit Ahuja, senior vice president, Digital Experience Business at Adobe. “Marketers spend a great deal of their day working across Adobe and Microsoft applications, and the partnership provides a unique offering for marketing teams, streamlining daily tasks across planning, collaboration, create and campaign execution.”

“Microsoft and Adobe share a common goal of empowering marketers to focus on the work that’s most important – creating impactful campaigns and enhancing customer experiences,” said Jared Spataro, corporate vice president, AI at Work, Microsoft. “By integrating contextual marketing insights from Adobe Experience Cloud applications and Dynamics 365 within the flow of work through Copilot for Microsoft 365, we deliver on our shared goal while helping marketers streamline their efforts, break down barriers, and deliver exceptional results.”

The marketing discipline is complex and made up of specialized roles which require specialized tools – from designing brand content and managing campaigns, to tracking audience insights across channels with internal and external partners and reporting out results. This means marketers face challenges of working in silos and in different applications, which can lead to misalignment and negatively impact speed and productivity. According to a recent survey conducted by Microsoft[1], 43 percent of marketing and communications professionals reported that having to switch between digital applications and programs was disruptive to their creativity.

Together, Adobe and Microsoft will address these challenges. Initial capabilities will focus on addressing the needs of marketers who often work across multiple teams internally and externally while managing campaign goals, status and actions. The capabilities will address scenarios including:

Strategic insights in the flow of work : Enriched with relevant campaign insights from Adobe Experience Cloud applications such as Adobe Customer Journey Analytics and Adobe Workfront, combined with Dynamics 365, the Copilot for Microsoft 365 experience helps marketers get quick insights and updates in Outlook, Teams and Word. Marketers can ask questions to get the status of a marketing project, understand the effectiveness of a campaign, outstanding approvals, and actions to take, or the audience and KPIs being defined in the latest campaign brief.

: Enriched with relevant campaign insights from Adobe Experience Cloud applications such as Adobe Customer Journey Analytics and Adobe Workfront, combined with Dynamics 365, the Copilot for Microsoft 365 experience helps marketers get quick insights and updates in Outlook, Teams and Word. Marketers can ask questions to get the status of a marketing project, understand the effectiveness of a campaign, outstanding approvals, and actions to take, or the audience and KPIs being defined in the latest campaign brief. Create campaign briefs, presentations, website updates and emails with relevant context : Marketers can be even more data-driven without having to go to multiple tools or people for insights. Marketing insights from Adobe and Dynamics 365 will be available in Copilot for Microsoft 365 to create briefs, presentations for exec reviews, or any kind of report or message. Marketers can also create imagery with Adobe Firefly generative AI or copy for marketing experiences through Adobe Experience Manager Sites; marketers can create content in Word that gets published directly to channels such as web and mobile.

: Marketers can be even more data-driven without having to go to multiple tools or people for insights. Marketing insights from Adobe and Dynamics 365 will be available in Copilot for Microsoft 365 to create briefs, presentations for exec reviews, or any kind of report or message. Marketers can also create imagery with Adobe Firefly generative AI or copy for marketing experiences through Adobe Experience Manager Sites; marketers can create content in Word that gets published directly to channels such as web and mobile. Keep projects moving with in-context notifications and summaries: Often marketers will need to go into multiple applications, emails and chats to compile a project status – from feedback and approvals to work item changes or due dates. These integrated capabilities informed by Adobe Workfront can work across these applications to create notifications informed by relevant marketing data to stay on top of any changes and actions to take.

For more information, and updates, sign up here.

About Adobe

Adobe is changing the world through digital experiences. For more information, visit www.adobe.com.

About Microsoft

Microsoft (Nasdaq “MSFT” @microsoft) enables digital transformation for the era of an intelligent cloud and an intelligent edge. Its mission is to empower every person and every organization on the planet to achieve more.

For more information, press only:

Microsoft Media Relations, WE Communications for Microsoft, (425) 638-7777, [email protected]

[1] Global survey on function-specific pain points and opportunities

This survey was conducted as part of our Work Trend Index research by an independent research firm, Edelman Data x Intelligence, among 18,100 full-time employed or self-employed workers across 12 markets between July 21, 2023, and November 1, 2023."
Microsoft_News,https://cloudblogs.microsoft.com/dynamics365/bdm/2024/03/25/explore-the-next-wave-of-ai-innovation-at-the-microsoft-business-applications-launch-event/,,Explore the next wave of AI innovation at the Microsoft Business Applications Launch Event,"The potential for AI at work is practically endless—and understanding how your teams can accomplish more with generative AI is more important than ever. Every day, more companies are turning to AI features to help their employees work more efficiently, provide positive customer experiences faster, and stand out among competitors.

Join us on Wednesday, April 10, 2024 See what's new at the Microsoft Business Applications Launch Event Register now

Redefine what’s possible with AI

Join Microsoft product leaders and engineers on April 10, 2024, for an in-depth look at the latest AI features and capabilities in Dynamics 365 and Microsoft Power Platform. You’ll learn how advances in AI and Microsoft Copilot can help you connect teams, processes, and data, and respond to changing business needs with greater agility—and see how organizations across several industries already take advantage of the newest AI features to streamline business processes and accelerate low-code development.

Register now to see key presentations from Microsoft leaders, including:

Business Applications Launch Event—2024 release wave 1. Charles Lamanna, Microsoft Corporate Vice President of Business Applications and Platforms, will provide opening remarks and shed light on the strategy and vision behind new Copilot and core platform capabilities in 2024 release wave 1.

Amplifying contact centers and field service operations with AI. Jeff Comstock, Corporate Vice President, Dynamics 365 Customer Service, will share how Copilot is transforming the customer service landscape, boosting efficiency, reducing training costs, and ultimately delivering exceptional experiences for agents, frontline workers, and customers.

Streamline sales and marketing with Copilot. Lori Lamkin, Corporate Vice President, Dynamics 365 Sales and Marketing, will discuss how sellers can close more deals by optimizing sales and marketing strategies and increasing productivity.

That’s just a small sample of what we’ve got planned. You’ll also hear directly from other Microsoft leaders about their vision for AI, customer service, and operations, and get timely tips on how to use these new technologies to take on your business’ toughest challenges. If you have questions about new AI features, how Copilot experiences work, or what’s new in low-code tools, take advantage of the live Q&A chat with Microsoft experts throughout the event.

Explore new AI features and capabilities for Dynamics 365

We’re excited to share the latest AI features for Dynamics 365 spanning across end-to-end customer experiences, sales, finance, supply chain, commerce, and other areas. Here are just a few of the new features in 2024 release wave 1:

Microsoft Dynamics 365 Sales features include recommended content for documents, insights from past successful deals, and summaries of account details—including customer buying behavior, recent activity, and more.

features include recommended content for documents, insights from past successful deals, and summaries of account details—including customer buying behavior, recent activity, and more. Microsoft Copilot for Sales helps teams deliver more seamless experiences within Microsoft Teams and Outlook. New features include suggested updates to customer relationship management (CRMs) systems as sellers work and suggested responses based on customer questions across platforms.

helps teams deliver more seamless experiences within Microsoft Teams and Outlook. New features include suggested updates to customer relationship management (CRMs) systems as sellers work and suggested responses based on customer questions across platforms. Microsoft Dynamics 365 Customer Insights empowers every organization to unify and enhance customer data, using it for insightful analysis and intelligent actions. New features now make it easier and faster to ingest and manage data, while AI enables quick insights and easier access to analytics.

empowers every organization to unify and enhance customer data, using it for insightful analysis and intelligent actions. New features now make it easier and faster to ingest and manage data, while AI enables quick insights and easier access to analytics. Microsoft Dynamics 365 Finance includes more autonomous finance features, building intelligence, automation, and analytics around every business process. This release adds AI-powered experiences to ease setup of financial dimension defaulting.

See what AI can do for you

Microsoft customers are already doing amazing things with the new AI features in Dynamics 365, and we can’t wait to inspire you with their stories. Register now and join us to see what’s new in the 2024 release wave 1.

Microsoft Business Applications launch event

Wednesday, April 10, 2024

9:00–10:30 AM Pacific Time (UTC-7)"
Microsoft_News,https://techcommunity.microsoft.com/t5/microsoft-teams-blog/prompt-like-a-pro-prepare-for-your-week-with-microsoft-copilot/ba-p/4091969,,Prompt Like a Pro: Prepare for your week with Microsoft Copilot in Teams,"Do the number of meetings and tasks you have to juggle every week feel overwhelming? When your week ahead is full of meetings, emails to respond to, and content to review, it can be hard to know the best place to focus first and how to prioritize your time. Now there is a smart and easy way to plan and prioritize your time – just head to Microsoft Copilot in Teams. In this blog post, we will show you how you can use Copilot in Teams to get a weekly overview of your upcoming meetings and events and how you can use simple follow-up prompts to optimize and plan any week.



Get an overview of your meetings for the week

Thanks to Copilot in Teams, you have a quick and easy way to understand how best to spend your time before your week starts. As long as you have a Copilot for Microsoft 365 license, just open Copilot from your Teams chat pane and type out* the prompt: “What do I have coming up this week?”



Copilot will search your calendar to display a list of all your scheduled meetings, along with their date, time, and attendees. You can even ask Copilot to tell you what you have coming up tomorrow or even next month.



Organize your schedule

Continue your conversation with Copilot and build on your original prompt to start to understand how your time will be spent so you can better prepare for the week. Give Copilot a follow-up prompt like: “Organize my meetings into 5 categories with percentages so I can understand how I am planning to spend my time this week.” In doing so, Copilot will use the meetings it pulled from your calendar for the week and organize them into categories such as: 1:1 meetings, team meetings, personal time, other, and so on. Instead of what you would see from looking at your schedule on the Teams calendar, Copilot will output a more robust weekly overview, even providing a meeting participant list - something you would need to click into each meeting on your calendar for. This output will also show you exactly where you need to invest the most time in for that week. For example, if 40% of your meetings are 1-on-1s, then you know to spend about half of your time preparing for each of those individual meetings.





To make this information more useful and shareable, you can also use more prompts to have Copilot generate a table, chart, etc. from the numbers it provided.





Prioritize your preparation time

Now, you can get a complete idea for your week ahead in seconds rather than spending hours opening meeting invites and going back and forth between your calendar and prep documents. In doing so, you can spend time focusing on preparing for your meetings vs. figuring out what each meeting is about. It’s a great way to start any work week and help build a habit of prioritization and preparation that is made possible with the power of Copilot in Teams.



Additional resources

For more examples of prompts that Copilot can help you with, check out Copilot Lab. Filter by M365 app – Teams - to learn what prompts to use for meetings, in chats, and get tips for better optimized prompts in Teams and beyond!



What’s coming next

Copilot in Teams is constantly evolving and improving thanks to your input and feedback. Stay tuned for more tips on how to work with Copilot to plan for any week and before you know it you will be prompting like a pro! If you’re already using Copilot in Teams, share your favorite prompts in the comments for the chance to get featured in a future “Prompt Like a Pro” blog.

*While there are a lot of prompts you may have to write out yourself, there are also pre-built prompts that will be recommended for you to use with Copilot. Using pre-built prompts allows Copilot to provide a high-quality response and is a great foundation for additional prompts you may want to ask in your own words."
Microsoft_News,https://www.microsoft.com/en-us/microsoft-365/blog/2024/03/21/advancing-the-new-era-of-work-with-copilot-windows-and-surface/,,"Advancing the new era of work with Copilot, Windows, and Surface","At a digital event for commercial customers and partners, we shared an update on how we’re empowering organizations to advance in the new era of work with Microsoft Copilot, Windows, and two new Surface devices that will start to become available in April.

It’s been one year since we first introduced the world to Copilot for Microsoft 365, and data from our Work Trend Index research shows it’s already making employees more productive and creative, saving some as much as 10 hours per month.1 We’re continuing to innovate, bringing Copilot capabilities to our entire product portfolio, including the applications and services organizations are built on—from Windows and Microsoft 365 to Microsoft Teams, Edge, and more.

Read on for more details.

Delivering Copilot in Windows to every employee, across any device

Windows 11 and Windows 365 are at the heart of advancing this new era of work—making Microsoft Copilot available to every employee, on a secure and trusted platform, across any device. Copilot in Windows 11 serves as an orchestrator—securely lighting up across apps, files, and the web, to conduct tasks on a user’s behalf—from summarizing emails and meetings to personalizing and optimizing a new device.2

With Windows 365, employees can work securely and without limits on an approved device of their choice, whether it’s on a new PC, streamed from a Windows 365 Cloud PC, or using the two together. For employees who want to work flexibly, Windows 365 Cloud PCs are a great, secure option to help IT control costs and manage efficiently. And with the new Windows App, currently in preview, early adopters like Vodafone and Zurich Insurance Group enable their employees to connect securely to their cloud resources and access Windows 365 and other virtual services. We’ve already seen over three million active hours of usage of the Windows App across platforms since the preview launch.

Windows and Windows 365 are integral to a secure and flexible computing solution that helps businesses succeed with AI. Customers can take advantage of cloud management with AI in Microsoft Intune to automate and analyze their device estate to ensure management efficiencies and cost savings. Plus, they receive security enhancements with Windows devices that are always up to date with Windows Autopatch. Windows is also tightly integrated with an ecosystem that is innovating with new Windows AI PCs like the Surface for Business devices and delivering AI-powered apps built with Windows AI Studio.

Customers like Kantar have moved from on-premises management to cloud management with Microsoft Intune to deploy Windows 11 Enterprise, Windows 365 Cloud PCs, and Surface devices with Microsoft Copilot, improving employee productivity and satisfaction while streamlining costly, and time-consuming IT processes.

To learn more about how organizations can benefit with Windows 11 and Windows 365 in advancing this new era of work, visit the Windows Blog.

Introducing two new Surface for Business devices

As organizations embark on their AI journey, they need a trusted PC solution that brings Copilot experiences to life. We’re excited to announce our first AI-powered Surface PCs built exclusively for business: Surface Pro 10 and Surface Laptop 6. We designed these products from the ground up, to be packed with features business customers have been asking for—from Copilot to ports to NFC readers to security and performance, with the latest Intel® Core™ Ultra processors and integrated Neural Processing Units (NPUs) to power AI experiences with increased battery life and reduced tax on the Central Processing Unit (CPU) and Graphics Processing Unit (GPU).

These devices are built for Copilot, with the new Copilot key on Laptop 6 and on Pro 10 when paired with the new Surface Pro Keyboard, making the best AI experiences available at the push of a button.3 With improved NPU-powered Surface Studio cameras enabling Windows Studio Effects and new anti-reflective displays that make it easier to see the screen in almost any lighting condition, employees can connect from anywhere. And as part of our commitment to sustainability, these Surface devices are ENERGY STAR® certified, made with more recycled materials, and are repairable with replacement components with clear visual icons and built-in access to digital repair guidance.4

In addition to new devices, we’ve also continued to make foundational investments to ensure great IT management experiences with Surface. We’ve updated the Surface Management Portal which helps IT manage their fleet of Surface devices within Microsoft Intune, and we’ve also created the Surface IT Toolkit which helps with daily tasks like deployments, security, and data compliance.

We are committed to creating accessible products that drive inclusion in the workplace. We are proud to announce a new Surface Pro Keyboard with a bold keyset for easy reading, new Copilot accessibility features on Windows 11, and our Microsoft Adaptive Accessories are now available to our commercial customers. Follow the links to learn more about our new Surface devices and IT management offerings.

Get your organization AI-ready with Copilot, Windows, and Surface

In line with our company mission to empower every person and every organization to do more, we are committed to working alongside our customers to continue to understand the AI trends reshaping work and using data and insights to shape the innovation we deliver. We’re excited for what the future holds, and there’s never been a better time for organizations to get AI ready now—including upgrading to Windows 11 and get Windows 365 to deliver Copilot across every device, to every employee, more securely and adopting the latest Surface for businesses devices optimized for Copilot and AI.

1What Can Copilot’s Earliest Users Teach Us About Generative AI at Work? Work Trend Index Special Report, November 15, 2023.

2Copilot in Windows (in preview) is available in select global markets and will be rolled out to additional markets over time. Learn more. Copilot with commercial data protection is available at no additional cost for users with an Entra ID with an enabled, eligible Microsoft 365 license.

3When Copilot for Windows is not enabled, pressing the Copilot key will launch Windows Search.

4Surface Laptop 6 is made with more recycled materials than Surface Laptop 5, including a minimum of 25.8% recycled content in the enclosure. Surface Pro 10 is made with more recycled materials than Surface Pro 9, including a minimum of 72% recycled content in the enclosure. Based on validation performed by Underwriter Laboratories, Inc. using Environmental Claim Validation Procedure, UL 2809-2, Second Edition, November 7, 2023. ​"
Microsoft_News,https://www.microsoft.com/en-us/worklab/ai-data-drop-the-11-by-11-tipping-point/,,AI Data Drop: The 11 by 11 Tipping Point,"Sign up for the WorkLab newsletter to get the latest AI research, insights, and trends delivered straight to your inbox.

Since we first introduced Copilot to our earliest customers, we’ve been closely studying how people are using AI at work—what’s going well, where there are challenges, and what early behaviors can teach us about adopting and rolling out AI broadly. And we want to share what we’re learning with leaders who are looking to drive AI adoption with their own people. Up first: the findings we call “the 11-by-11 tipping point,” which show the time it takes for you and your people to start building an AI habit. Let us explain.

What we did: We asked 1,300 Copilot for Microsoft 365 users across different functions and industries about AI’s impact on their productivity, work enjoyment, and more. Then we analyzed which factors were more likely to influence these outcomes.

What we found: A time savings of just 11 minutes a day was the magic number where users started to see value from AI.

To be clear, most people actually saved more time each day: the most efficient users saved 30 minutes a day, the equivalent of 10 hours a month, while the average person saved 14 minutes a day, or nearly five hours each month. But according to our research, 11 minutes of time savings is all it takes for most people to feel like AI is useful—the key to getting a habit to stick.

And as it turns out, 11 is an important number. We also found that 11 weeks is the breakthrough moment at which most people say Copilot improves four key areas at work: productivity, work enjoyment, work-life balance, and the ability to attend fewer meetings. Thus, the 11-by-11 tipping point.

Making Work Better Over the course of about one business quarter (11 weeks), Copilot users saw improvement in four key outcomes: productivity, meeting relief, work enjoyment, and work-life balance. A set of four bar charts showing that Copilot users see improvements on key outcomes over the course of a business quarter. Over the course of 6, 10, and more than 10 weeks, 67%, 70%, and 75% of users say they are more productive; over the course of 6, 10, and more than 10 weeks, 45%, 49%, and 57% of users say it helps them enjoy work more; over the course of 6, 10, and more than 10 weeks, 23%, 27%, and 34% of users say it helps them have better work-life balance; over the course of 6, 10, and more than 10 weeks, 18%, 22%, and 37% say they are able to attend fewer meetings.

Why it matters: Just 11 minutes a day of time savings over 11 weeks of usage is the magic formula for unlocking Copilot value. That means that in a little less than a business quarter, most of the Copilot users at your company can form an AI habit—one that can power your organization to new heights.

So how do you get people to 11-by-11? First, find the easy wins that immediately save 11 minutes a day. To model how to catch up on missed meetings, tell your people not to worry about taking notes or listening to the recording, and instead ask AI to recap the key points. Executives can use it to summarize long documents or drawn-out email chains. Think about examples specific to different roles too: recruiters, for instance, can easily save 11 minutes by using AI to write up job descriptions. By narrowing in on those use cases that deliver from the start, your people will more quickly save 11 minutes a day.

Second, encourage them to stick with it until they’ve used AI for 11 weeks. Remind them that this is a new way of working and it takes time to build new habits—and model that behavior through your continued use of AI.

Over 11 weeks, that 11 minutes a day adds up to 10 hours saved—or one whole work week each year. That’s a habit we can get behind.

Methodology: The ongoing Copilot Usage in the Workplace survey launched in September 2023. It surveys both Microsoft employees and early users of Copilot at other companies, mostly in North America and Europe. All users included in the analysis had been using Copilot for at least three weeks.

Want more great insights on where work is headed?

Subscribe to the WorkLab newsletter."
Microsoft_News,https://blogs.microsoft.com/blog/2024/03/20/from-vision-to-reality-microsofts-partners-embrace-ai-to-deliver-customer-value/,,From vision to reality: Microsoft’s partners embrace AI to deliver customer value,"Artificial intelligence is a defining technology of our time. Over the past year we’ve begun to see how it can unlock profound possibilities for individuals, organizations and society — and it’s clear that we have only scratched the surface.

For Microsoft and our partners across industries, AI offers a generational moment to reimagine the capabilities that software and services can provide. Our goal at Microsoft is to innovate and democratize our breakthroughs in AI — and the opportunity for partners is far greater than the sum of AI technologies themselves.

For this State of the Partner Ecosystem moment, we’ll share how partners are seizing the opportunities that AI offers and making its promise real for organizations across the world. We’ll highlight partners who are building AI-powered solutions to innovate across industries, including three partners who are:

Helping people and organizations achieve , in months , what once might have been a multi-year endeavor.

Innovating in higher education by streamlining work in marketing, admissions and student advising.

Empowering real-time decision making at the point of impact across the supply chain.

First, we’ll look at how Microsoft is empowering our partners to innovate, build and differentiate with AI through a combination of technology advancements, an industry leading partner program and true market differentiation. During this time of AI transformation, there has never been a greater time to be a Microsoft partner, and our partners are fully embracing this new opportunity.

Unprecedented momentum: the Microsoft AI Cloud Partner Program

Microsoft is driving innovation in generative AI, with new Azure OpenAI Services and an expanding portfolio of Copilot offerings. Today, we offer the most comprehensive commercial portfolio in the market with AI infused everywhere from the cloud to the edge, and across every solution area.

Partners can tap into all this innovation through the Microsoft AI Cloud Partner Program. Through research, partnership, and new investments, we are bringing partners the capabilities and benefits to help them empower customers of every size, in every industry.

Just as AI capabilities are infused throughout our technology portfolio, AI benefits are wired throughout the partner program. And today we are announcing enhancements to enable partners to create an AI-powered future, including:

The expansion of AI skilling, boot camps and events

New benefits packages with product enhancements like Microsoft 365 developer, increased Azure credits, and Visual Studio enterprise, to support AI practice growth

New designations for partners to establish certified AI solutions or ways to differentiate themselves.

This builds on the incredible momentum we’ve seen since we announced the Microsoft AI Cloud Partner Program last July. In fact, the Microsoft AI Transformation Partner Playbook outlining new possibilities with AI has been downloaded over 35,000 times. Our free go-to-market asset, the Era of AI marketing campaign-in-a-box, has been downloaded over 13,250 times.

Today more than 13,000 partners building solutions with Microsoft Azure AI, serving more than 53,000 customers with generative AI capabilities alone. Our partner ecosystem is rising to meet demand with a nearly 250 percent increase in the number of generative AI-related partners in the past eight months.

When you add that up, it points to a year of exponential innovation and growth for partners, and we are continuing to develop new ways to support this growth curve. Here are some specifics on the updates we are making to the Microsoft AI Cloud Partner Program in the coming months.

Program updates, including new designations and certifications for partners

Solutions partner designations and specializations are one way we help partners differentiate themselves in the market. Designations and certifications help to verify skills and validate the effectiveness of solutions so customers can find the partner and technology that’s right for their needs.

To obtain designations and specializations, partners must meet skilling and performance requirements, and provide customer evidence to demonstrate their capabilities — and partners have embraced this opportunity with Microsoft AI. We have seen 58 percent growth since last July in partner designations for Azure Data and AI solutions, and 172 percent growth in partner specializations for the Build and Modernize AI apps with Azure and AI and Machine Learning designations.

To build on this momentum, today we are announcing several new designations for partners across software, services and training.

A new set of designations for partners who develop software: Solutions Partner with certified software

Today, we are pleased to announce the general availability of Solutions Partner[i] with certified software[ii] designations. Certified software designations provide an opportunity to better connect with customers and to unlock additional benefits from Microsoft.

By becoming a Solutions Partner with certified software, partners can differentiate their solution, increase their discoverability in the Microsoft Commercial Marketplace, connect with more customers, and take advantage of marketing and branding resources designed to help accelerate revenue growth in a rapidly expanding market.

There are two pathways to become a Solutions Partner with certified software: solution areas and Industry AI:

Solution areas. To become a Solutions Partner[i] with certified [ii] software for solution areas, a partner’s software must meet readiness and technical requirements and demonstrate a track record of customer success. Solution area designations include Azure, Business Applications, Modern Work and Security.

Industry AI. To become a Solutions Partner with certified software for Industry AI, in addition to the requirements above, a partner’s solution must also meet an industry-specific challenge aligned with the Microsoft Industry Cloud scenarios and include a Microsoft AI capability. Currently, partners can attain the following certified software designations for Industry AI: Healthcare AI, Retail AI, Financial Services AI, Manufacturing AI and Sustainability AI.

More than 75 partners with solutions across all five industries and from around the world have participated in the public preview of the designation, including Netherlands, Iceland, Germany, United Kingdom, France, Norway, Ireland, India, Canada and the United States. There are 49 solutions currently certified with an additional 27 in progress.

New Training Services Solutions Partner designations

We are also releasing new designations for partners who provide training services. Starting April 10, partners who qualify for Solutions Partner for Training Services designations will be able to complete enrollment.

Qualified partners will receive designation-specific badges distinguishing their services from other partner types within the Microsoft AI Cloud Partner Program. These badges greatly enhance customer discoverability, making it easier for them to identify partners with unique expertise and a proven track record of delivery quality training.

New Small and Medium Business (SMB) paths for Azure and Security Solutions Partner designations

Based on partner feedback, we are investing in our small- and mid-sized business ecosystem and creating a pathway for partners who focus on delivering solutions for SMB customers across Azure Data & AI, Digital & App Innovation, Infrastructure and Security. Later this year, we will introduce dedicated SMB paths for Solutions Partner designations for Azure​ and Security, adding to our existing SMB paths for Business Applications and Modern Work.

For partners who serve smaller businesses, this creates an exciting new opportunity — a new way to qualify for existing Solutions Partner designations, giving more partners access to the products, go-to-market resources, support, and advisory benefits that come with these designations. The new SMB paths will differentiate partners who can meet customer needs and drive customer success by validating those partners’ capabilities in our Azure and Security solution areas.

Additional details for the SMB paths for Azure and Security will be available in the coming weeks.

An update on the Support Services Solutions Partner designation

Today we are announcing that partners with a Solutions Partner for Support Services designation will soon receive exclusive new benefits, including paid support agreement pricing and access to a knowledge-based library of curated materials designed to help partners resolve incidents quickly and efficiently, in addition to customer-facing badging. General availability and more details will come later this year.

Equipping partners through AI skilling

Rapid innovation with AI technology has created an increased demand for partner skilling for both pre-sales and technical roles. Responding to partner feedback, we have launched a breadth of Microsoft AI-focused skilling workshops, boot camps and training events. Since July 2023, more than 350,000 partner personnel have also become skilled pre-sales and technical depth learners for Microsoft AI, Copilot and Fabric.

Microsoft AI partner training roadshow

In March, we launched an in-person training series called the Microsoft AI Partner Training Roadshow to target six cities globally through June, across India, the Bay Area, Germany, Japan and Brazil. Our inaugural event in India had 1,500 attendees from 40 partner organizations with 96 percent of participants agreeing that the event was valuable and 94 percent indicating they gained new skills to be successful in their roles. The roadshow is focused on in-person training on AI, targeting 270 partner organizations, and includes a keynote session highlighting the unique value of Microsoft AI, Fabric and Copilot for Microsoft 365, followed by a sales excellence and technical excellence tracks.

Copilot for Security upcoming release and partner skilling

To support our partners and customers in securing their businesses, we are excited to announce the general availability of Microsoft Copilot for Security in all commerce channels, including Cloud Solution Provider (CSP) channel, on April 1, 2024. We initiated an active Copilot for Security partner community at Inspire last year, which has since grown to more than 1,000 participants. Over the past six months, Microsoft has engaged with more than 100 Managed Security Service Providers (MSSP) and Independent Software Vendors (ISVs) in a Copilot for Security Partner private preview. Upcoming security skilling events include:

Microsoft Copilot for Security Partner Boot Camp – Helps participants understand how Microsoft Copilot for Security enables security analysts to move at the speed and scale of AI by augmenting the human experience. Starting April 16.

Threat Protection and Incident Response with Microsoft Sentinel Workshop – Participants will learn how to deploy and connect this SIEM and SOAR solution to different data sources and use intelligent security analytics and threat intelligence capabilities for attack detection, threat vulnerability, proactive hunting and threat response. April 22-25.

New AI skilling for sales/pre-sales and technical depth

Azure OpenAI Workshop – Designed to help participants deepen their understanding of Azure OpenAI Services, this is tailored for developers and data scientists aiming to do more with less. Starting April 16.

Microsoft Fabric Workshop – Participants will learn more about this comprehensive suite of services, including data lake, data engineering and data integration, all in one place. And learn how to implement this easy-to-use product that is designed to simplify analytics needs of enterprises. Starting April 8.

Copilot for Microsoft 365 Pre-Sales, Deployment and Adoption Bootcamp – Participants will explore how Copilot for Microsoft 365 provides real-time intelligent assistance, enabling users to enhance their creativity, productivity, and skills. Starting March 26.

New Partner Benefits

On Jan. 22, Microsoft launched three new benefits packages: Partner Launch Benefits, Partner Success Core Benefits and Partner Success Expanded Benefits. Purpose-built to meet the varied needs of partners at different stages of growth and help partners scale their business through a portfolio of key Microsoft benefits, the packages are available for purchase at a significant discount for partners.

These refreshed benefits follow partners through every element of the partner journey: from creating their solutions, to go-to-market, to differentiating their organizations in the marketplace. Beyond the three new packages, partners can continue to pursue Solutions Partner designations and specializations to differentiate their organizations in the Microsoft Commercial Marketplace and access additional product and support benefits. Partners who develop software IP can also tap into ISV Success, a collection of resources that help accelerate software solution development and amplify sales.

The feedback on the new packages has been incredibly positive, and we continue to listen to partner feedback and explore new ways to invest in our partners.

Update on Copilot for Cloud Solution Providers

On Jan. 16, Copilot for Microsoft 365 became generally available across all sales channels, including through our Cloud Solution Providers. General availability of Copilot for M365 opened a wealth of immediate opportunities for partners to deliver end-to-end services to help customers achieve a smooth transition into an AI-powered organization.

One Microsoft distribution partner, TD SYNNEX, has already engaged more than 2,000 partners in its enablement journey for Copilot for Microsoft 365, demonstrating the industry’s eagerness to harness the potential of generative AI. With more than 500 individuals certified in the program, TD SYNNEX provides its partners with the technical and operational expertise, solutions and resources to help partners leverage Copilot’s capabilities and gain a competitive edge.

From vision to reality: partners are delivering AI solutions around the world

We are committed to building AI capabilities across the Microsoft cloud, guided by our Responsible AI principles. Our partners enable us to scale and deliver those technologies to every organization and every person on the planet. We anticipated some remarkable innovation in this area, and in just over a year we have been amazed by the results and impact partners are achieving around the world.

Here are some of the ways Microsoft partners are developing differentiated solutions and helping customers transform their business processes across industries.

Accenture, together with Avanade, is working with Amadeus to develop a generative AI-powered interactive assistant using Microsoft technologies, including GPT models from Azure Open AI Service, Microsoft 365 and Teams, to allow corporate travelers to orchestrate complex travel-related tasks using only natural language.

Anthology Inc is providing AI-powered innovation for higher education through its student success and lifecycle engagement solution that is built on Microsoft Dynamics 365.

The Atlassian product suite — including Confluence, Trello, Jira and Atlas — improves productivity and collaboration. As part of the Microsoft Copilot Early Access Program, Atlassian enhanced its apps to empower users to track tasks, resolve issues and manage projects seamlessly.

Companies use Blue Yonder for end-to-end supply chain management. Blue Yonder, built on Azure, uses AI and ML to provide real-time decision-making power and workflows that help businesses fulfill orders and respond quickly to shifting market conditions.

CallMiner’s AI-driven platform empowers organizations to ingest and analyze every conversation that happens in the contact center and beyond to uncover insights, act, and drive transformational change.

Datadog integrates with all major Azure services, including Azure OpenAI Service. Now customers can better optimize costs, troubleshoot issues and monitor the performance of their AI-powered applications.

EY worked with Microsoft to create a generative AI chatbot to answer payroll questions from employees across the 159 countries and 49 languages that EY clients encompass.

Icertis Contract Intelligence Copilots are providing customers with assistive and generative natural language capabilities that cut through legalese and turn contracts into interactive assets that deliver insights and automation to drive businesses forward.

Intapp is enabling thousands of financial and professional services firms to harness the intelligence of their professionals through AI-powered software solutions.

LTI Mindtree is leveraging generative AI, powered by GitHub Copilot and Azure OpenAI Service, to accelerate the migration of legacy apps from on-premises to the cloud. Their methodology automates the creation of new cloud architecture, code conversion and documentation generation, resulting in an average reduction of 46 percent in migration time.

Sight Machine works with manufacturers to make their businesses stronger, more sustainable and more resilient. To better support manufacturers’ data accessibility needs, Sight Machine used Azure OpenAI Service to harness generative AI (GPT-4) and to develop Factory Copilot.

Veeam Software, recently announced an extended, five-year strategic partnership with Microsoft to innovate new solutions for protecting customers by integrating Veeam’s product family and Microsoft Copilot and AI services.

Looking ahead: unlimited opportunities for AI innovation

We have seen tremendous progress as partners seize the moment and turn the promise of AI into a reality around the world. Today, we have moved from talking about AI to applying AI at scale in ways no one could have imagined just a few months ago.

Microsoft is infusing AI across every layer of its tech stack, creating new ways to power organizations and industries, and unlocking new opportunities to deliver transformational value to customers.

Key to making all this a reality are the capabilities, services, product innovation and depth of industry knowledge delivered by our partners. Microsoft’s mission is to empower every person and every organization on the planet to achieve more. Our partners enable us to deliver on that commitment, in every customer segment, every geography, every day.

[i] “Solutions Partner” refers to a company that is a member of the Microsoft AI Cloud Partner Program and may offer software, services, and/or solutions to customers. Reference to “Solutions Partner” in any content, materials, resources, web properties, etc. and any associated designation should be not interpreted as an offer, endorsement, guarantee, proof of effectiveness or functionality, a commitment or any other type of representation or warranty on the part of Microsoft. All decisions pertaining to and related to your business needs including but not limited to strategies, solutions, partner selection, implementation, etc. rest solely with your business.

[ii] A certification is (A) specific to the solution’s interoperability with Microsoft products and (B) based on self-attestation by the solution owner. Solutions are only certified as of the date the solution is reviewed. Solution functionality and capability are controlled by the solution owner and may be subject to change. The inclusion of a solution in marketplace and any such designations should not be interpreted as an offer, endorsement, guarantee, proof of effectiveness or functionality, a commitment or any other type of representation or warranty on the part of Microsoft. All decisions pertaining and related to your business needs including but not limited to strategies, solutions, partner selection, implementation, etc. rest solely with your business.

Tags: AI, Microsoft AI Cloud Partner Program, Microsoft Copilot for Security, Microsoft Partners, Responsible AI"
Microsoft_News,https://blogs.microsoft.com/blog/2024/03/19/mustafa-suleyman-deepmind-and-inflection-co-founder-joins-microsoft-to-lead-copilot/,,"Mustafa Suleyman, DeepMind and Inflection Co-founder, joins Microsoft to lead Copilot","Satya Nadella, Chief Executive Officer, shared the below communication today with Microsoft employees.

I want to share an exciting and important organizational update today. We are in Year 2 of the AI platform shift and must ensure we have the capability and capacity to boldly innovate.

There is no franchise value in our industry and the work and product innovation we drive at this moment will define the next decade and beyond. Let us use this opportunity to build world-class AI products, like Copilot, that are loved by end-users! This is about science, engineering, product, and design coming together and embracing a learning mindset to push our innovation culture and product building process forward in fundamental ways.

In that context, I’m very excited to announce that Mustafa Suleyman and Karén Simonyan are joining Microsoft to form a new organization called Microsoft AI, focused on advancing Copilot and our other consumer AI products and research.

Mustafa will be EVP and CEO, Microsoft AI, and joins the senior leadership team (SLT), reporting to me. Karén is joining this group as Chief Scientist, reporting to Mustafa. I’ve known Mustafa for several years and have greatly admired him as a founder of both DeepMind and Inflection, and as a visionary, product maker, and builder of pioneering teams that go after bold missions.

Karén, a Co-founder and Chief Scientist of Inflection, is a renowned AI researcher and thought leader, who has led the development of some of the biggest AI breakthroughs over the past decade including AlphaZero.

Several members of the Inflection team have chosen to join Mustafa and Karén at Microsoft. They include some of the most accomplished AI engineers, researchers, and builders in the world. They have designed, led, launched, and co-authored many of the most important contributions in advancing AI over the last five years. I am excited for them to contribute their knowledge, talent, and expertise to our consumer AI research and product making.

At our core, we have always been a platform and partner-led company, and we’ll continue to bring that sensibility to all we do. Our AI innovation continues to build on our most strategic and important partnership with OpenAI. We will continue to build AI infrastructure inclusive of custom systems and silicon work in support of OpenAI’s foundation model roadmap, and also innovate and build products on top of their foundation models. And today’s announcement further reinforces our partnership construct and principles.

As part of this transition, Mikhail Parakhin and his entire team, including Copilot, Bing, and Edge; and Misha Bilenko and the GenAI team will move to report to Mustafa. These teams are at the vanguard of innovation at Microsoft, bringing a new entrant energy and ethos, to a changing consumer product landscape driven by the AI platform shift. These organizational changes will help us double down on this innovation.

Kevin Scott continues as CTO and EVP of AI, responsible for all-up AI strategy, including all system architecture decisions, partnerships, and cross-company orchestration. Kevin was the first person I leaned on to help us manage our transformation to an AI-first company and I’ll continue to lean on him to ensure that our AI strategy and initiatives are coherent across the breadth of Microsoft.

Rajesh Jha continues as EVP of Experiences & Devices and I’m grateful for his leadership as he continues to build out Copilot for Microsoft 365, partnering closely with Mustafa and team.

There are no other changes to the senior leadership team or other organizations.

We have been operating with speed and intensity and this infusion of new talent will enable us to accelerate our pace yet again.

We have a real shot to build technology that was once thought impossible and that lives up to our mission to ensure the benefits of AI reach every person and organization on the planet, safely and responsibly. I’m looking forward to doing so with you.

Satya"
Microsoft_News,https://www.microsoft.com/en-us/microsoft-cloud/blog/2024/03/18/transform-your-business-with-ai-skill-building-on-microsoft-learn/,,Transform your business with AI skill building on Microsoft Learn,"Explore how to build the skills needed to accelerate AI implementation at scale

Advances in AI, cloud, and other emerging technologies are empowering organizations to pursue new opportunities for growth and innovation. Read on to learn how skill building with Microsoft Learn is a critical element of your AI transformation strategy.

AI’s ubiquity across organizations means that business and technology leaders like you need to approach AI skill building in a different way. We know that you’re not only facing the challenge of keeping up with the rapid pace of technology, but you’re also grappling with a shortage of skilled workers.

It’s clear there is a pressing need for AI skilling. To help address the skills gap, this past year, Microsoft engaged more than 6 million people globally in learning activities with ambitions to skill everyone to use our AI technology.

It’s your AI learning journey

Today, it’s more important than ever to have the right skills so you can accelerate AI implementation at scale. While Microsoft’s AI apps and services empower you to innovate and accomplish more than you thought possible, we recognize it can be challenging to know where to begin.

We’re on this journey at Microsoft as well. We’re customer zero of our own products, exploring how to use AI to drive growth, unlock efficiency, and reduce operating costs. As we upskill ourselves in AI and understand how we can best use it in our day-to-day, we’re also exploring how to leverage AI to improve the learning experiences we offer.

Together with our customers and partners developing new AI skills, we’ve gathered key insights about what is necessary to nurture AI competency. We’ve designed a simple framework to help our customers chart their own course for building the necessary AI skills to realize the value of the Microsoft platform. Learn more with the Accelerate AI transformation with skill building position paper.

Accelerate AI transformation with skill building Read the position paper

Each organization has its own unique AI learning journey. Your goals and needs, and those of your team members, may vary depending on how much you know about AI and how you want to use it. It’s your AI learning journey.

Snapshot of the AI learning journey.

Understanding AI means getting to know the basics of AI, such as definitions and key terms, responsible AI, and how it benefits individuals and organizations.

means getting to know the basics of AI, such as definitions and key terms, responsible AI, and how it benefits individuals and organizations. Preparing for AI is about acquiring the skills to successfully get your organization ready to later use Microsoft Copilot and build AI-powered apps.

is about acquiring the skills to successfully get your organization ready to later use Microsoft Copilot and build AI-powered apps. Using AI means understanding Copilot and getting the skills to write effective prompts and get the best out of generative AI, so you can use Copilot successfully.

means understanding Copilot and getting the skills to write effective prompts and get the best out of generative AI, so you can use Copilot successfully. Building AI solutions is about learning skills to embed Al in apps using Microsoft Azure Al Services and skills to build your own copilots experiences with Microsoft Copilot Studio.

Microsoft Learn is your AI skill-building partner

No matter where you are on your AI learning journey, Microsoft Learn meets you there. Whether you’re just beginning to understand what AI is and how it might be beneficial to your organization, or you’re ready to use Copilot and productivity-enhancing AI, or you’re looking to build bespoke AI-powered solutions, we can help you reach your goals.

By offering comprehensive curated resources, tools, and guidance, Microsoft Learn supports you and your team as you build the skills necessary to execute new AI innovation projects and achieve your business objectives.

Here are some learning tools and resources to explore.

The AI learning hub

Begin with the AI learning hub, the go-to resource. In this hub, business leaders, business users, and technology professionals can find everything they need to gain AI skills, in a single place. They can explore training by role or by technology, options to learn with the support of the community or Microsoft Training Services Partners, and recommendations from our team on new topics to deep dive into.

AI learning hub Get skilled up and ready to power AI transformation Get started

Verifiable AI skills, with Microsoft Credentials

Take your team’s AI skills to the next level with Microsoft Credentials, which include Microsoft Certifications and Microsoft Applied Skills. Certifications offer the flexibility to grow the skills needed for critical roles, and Applied Skills offer the agility to expand the skills needed for key business scenarios. Together they bring verifiable skillsets aligned to AI job roles and AI projects, ensuring you’re building resilient and adaptable teams ready to take on new opportunities.

Explore Microsoft Credentials for AI and find role-based certifications like Azure AI Engineer or Azure Data Scientist, or scenario-based Applied Skills including developing generative AI solutions, training and deploying machine learning models, or creating analytics solutions with Microsoft Fabric.

Snapshot of Microsoft Credentials for AI.

The Microsoft Learn AI Skills Challenge

To build your team’s AI project-readiness and advance their skills in key technologies with a fun and engaging experience, be sure to have your team members register for the latest AI Skills Challenge.

From March 19 through April 19, 2024, participants can choose from four cutting-edge AI topics: Microsoft Fabric, Azure OpenAI, Azure Machine Learning, and Azure AI Fundamentals. Each topic features a challenge with a selection of learning resources, including community events, live and recorded learning sessions delivered by experts, plus Microsoft Credentials training and preparation resources.

By completing one of the challenges, participants become eligible for a free Microsoft Certification exam (terms and conditions apply). Encourage your team members to pick a topic and start becoming experts in AI today.

Start your AI learning journey now

However you’re looking to advance your organization, Microsoft Learn is the trusted source to help you get skilled up and ready to power AI transformation with the Microsoft Cloud.

Explore our Microsoft Learn Blog, follow us on X and LinkedIn, and get subscribed to “The Spark,” our Microsoft Learn LinkedIn newsletter, to stay updated on what’s new in AI and cloud skills."
Microsoft_News,https://azure.microsoft.com/en-us/blog/microsoft-and-nvidia-partnership-continues-to-deliver-on-the-promise-of-ai/,,Microsoft and NVIDIA continue to deliver on the promise of AI,"At NVIDIA GTC, Microsoft and NVIDIA are announcing new offerings across a breadth of solution areas from leading AI infrastructure to new platform integrations, and industry breakthroughs. Today’s news expands our long-standing collaboration, which has paved the way for revolutionary AI innovations that customers are now bringing to fruition.

Microsoft and NVIDIA collaborate on Grace Blackwell 200 Superchip for next-generation AI models

Microsoft and NVIDIA are bringing the power of the NVIDIA Grace Blackwell 200 (GB200) Superchip to Microsoft Azure. The GB200 is a new processor designed specifically for large-scale generative AI workloads, data processing, and high performance workloads, featuring up to a massive 16 TB/s of memory bandwidth and up to an estimated 30 times the inference on trillion parameter models relative to the previous Hopper generation of servers.

Microsoft has worked closely with NVIDIA to ensure their GPUs, including the GB200, can handle the latest large language models (LLMs) trained on Azure AI infrastructure. These models require enormous amounts of data and compute to train and run, and the GB200 will enable Microsoft to help customers scale these resources to new levels of performance and accuracy.

Microsoft will also deploy an end-to-end AI compute fabric with the recently announced NVIDIA Quantum-X800 InfiniBand networking platform. By taking advantage of its in-network computing capabilities with SHARPv4, and its added support for FP8 for leading-edge AI techniques, NVIDIA Quantum-X800 extends the GB200’s parallel computing tasks into massive GPU scale.

Azure will be one of the first cloud platforms to deliver on GB200-based instances

Learn More Build cutting-edge AI apps with Azure AI Services

Microsoft has committed to bringing GB200-based instances to Azure to support customers and Microsoft’s AI services. The new Azure instances-based on the latest GB200 and NVIDIA Quantum-X800 InfiniBand networking will help accelerate the generation of frontier and foundational models for natural language processing, computer vision, speech recognition, and more. Azure customers will be able to use GB200 Superchip to create and deploy state-of-the-art AI solutions that can handle massive amounts of data and complexity, while accelerating time to market.

Azure also offers a range of services to help customers optimize their AI workloads, such as Microsoft Azure CycleCloud, Azure Machine Learning, Microsoft Azure AI Studio, Microsoft Azure Synapse Analytics, and Microsoft Azure Arc. These services provide customers with an end-to-end AI platform that can handle data ingestion, processing, training, inference, and deployment across hybrid and multi-cloud environments.

Delivering on the promise of AI to customers worldwide

With a powerful foundation of Azure AI infrastructure that uses the latest NVIDIA GPUs, Microsoft is infusing AI across every layer of the technology stack, helping customers drive new benefits and productivity gains. Now, with more than 53,000 Azure AI customers, Microsoft provides access to the best selection of foundation and open-source models, including both LLMs and small language models (SLMs), all integrated deeply with infrastructure data and tools on Azure.

The recently announced partnership with Mistral AI is also a great example of how Microsoft is enabling leading AI innovators with access to Azure’s cutting-edge AI infrastructure, to accelerate the development and deployment of next-generation LLMs. Azure’s growing AI model catalogue offers, more than 1,600 models, letting customers choose from the latest LLMs and SLMs, including OpenAI, Mistral AI, Meta, Hugging Face, Deci AI, NVIDIA, and Microsoft Research. Azure customers can choose the best model for their use case.

“We are thrilled to embark on this partnership with Microsoft. With Azure’s cutting-edge AI infrastructure, we are reaching a new milestone in our expansion propelling our innovative research and practical applications to new customers everywhere. Together, we are committed to driving impactful progress in the AI industry and delivering unparalleled value to our customers and partners globally.” Arthur Mensch, Chief Executive Officer, Mistral AI

General availability of Azure NC H100 v5 VM series, optimized for generative inferencing and high-performance computing

Microsoft also announced the general availability of Azure NC H100 v5 VM series, designed for mid-range training, inferencing, and high performance compute (HPC) simulations; it offers high performance and efficiency.

As generative AI applications expand at incredible speed, the fundamental language models that empower them will expand also to include both SLMs and LLMs. In addition, artificial narrow intelligence (ANI) models will continue to evolve, focused on more precise predictions rather than creation of novel data to continue to enhance its use cases. Their applications include tasks such as image classification, object detection, and broader natural language processing.

Using the robust capabilities and scalability of Azure, we offer computational tools that empower organizations of all sizes, regardless of their resources. Azure NC H100 v5 VMs is yet another computational tool made generally available today that will do just that.

The Azure NC H100 v5 VM series is based on the NVIDIA H100 NVL platform, which offers two classes of VMs, ranging from one to two NVIDIA H100 94GB PCIe Tensor Core GPUs connected by NVLink with 600 GB/s of bandwidth. This VM series supports PCIe Gen5, which provides the highest communication speeds (128GB/s bi-directional) between the host processor and the GPU. This reduces the latency and overhead of data transfer and enables faster and more scalable AI and HPC applications.

The VM series also supports NVIDIA multi-instance GPU (MIG) technology, enabling customers to partition each GPU into up to seven instances, providing flexibility and scalability for diverse AI workloads. This VM series offers up to 80 Gbps network bandwidth and up to 8 TB of local NVMe storage on full node VM sizes.

These VMs are ideal for training models, running inferencing tasks, and developing cutting-edge applications. Learn more about the Azure NC H100 v5-series.

“Snorkel AI is proud to partner with Microsoft to help organizations rapidly and cost-effectively harness the power of data and AI. Azure AI infrastructure delivers the performance our most demanding ML workloads require plus simplified deployment and streamlined management features our researchers love. With the new Azure NC H100 v5 VM series powered by NVIDIA H100 NVL GPUs, we are excited to continue to can accelerate iterative data development for enterprises and OSS users alike.” Paroma Varma, Co-Founder and Head of Research, Snorkel AI

Microsoft and NVIDIA deliver breakthroughs for healthcare and life sciences

Microsoft is expanding its collaboration with NVIDIA to help transform the healthcare and life sciences industry through the integration of cloud, AI, and supercomputing.

By using the global scale, security, and advanced computing capabilities of Azure and Azure AI, along with NVIDIA’S DGX Cloud and NVIDIA Clara suite, healthcare providers, pharmaceutical and biotechnology companies, and medical device developers can now rapidly accelerate innovation across the entire clinical research to care delivery value chain for the benefit of patients worldwide. Learn more.

New Omniverse APIs enable customers across industries to embed massive graphics and visualization capabilities

Today, NVIDIA’s Omniverse platform for developing 3D applications will now be available as a set of APIs running on Microsoft Azure, enabling customers to embed advanced graphics and visualization capabilities into existing software applications from Microsoft and partner ISVs.

Built on OpenUSD, a universal data interchange, NVIDIA Omniverse Cloud APIs on Azure do the integration work for customers, giving them seamless physically based rendering capabilities on the front end. Demonstrating the value of these APIs, Microsoft and NVIDIA have been working with Rockwell Automation and Hexagon to show how the physical and digital worlds can be combined for increased productivity and efficiency. Learn more.

Microsoft and NVIDIA envision deeper integration of NVIDIA DGX Cloud with Microsoft Fabric

The two companies are also collaborating to bring NVIDIA DGX Cloud compute and Microsoft Fabric together to power customers’ most demanding data workloads. This means that NVIDIA’s workload-specific optimized runtimes, LLMs, and machine learning will work seamlessly with Fabric.

NVIDIA DGX Cloud and Fabric integration include extending the capabilities of Fabric by bringing in NVIDIA DGX Cloud’s large language model customization to address data-intensive use cases like digital twins and weather forecasting with Fabric OneLake as the underlying data storage. The integration will also provide DGX Cloud as an option for customers to accelerate their Fabric data science and data engineering workloads.

Accelerating innovation in the era of AI

For years, Microsoft and NVIDIA have collaborated from hardware to systems to VMs, to build new and innovative AI-enabled solutions to address complex challenges in the cloud. Microsoft will continue to expand and enhance its global infrastructure with the most cutting-edge technology in every layer of the stack, delivering improved performance and scalability for cloud and AI workloads and empowering customers to achieve more across industries and domains.

Join Microsoft at NVIDIA CTA AI Conference, March 18 through 21, at booth #1108 and attend a session to learn more about solutions on Azure and NVIDIA.

Learn more about Microsoft AI solutions"
Microsoft_News,https://www.microsoft.com/en-us/microsoft-365/blog/2024/03/14/bringing-copilot-to-more-customers-worldwide-across-life-and-work/,,Bringing Microsoft Copilot to more customers worldwide,"Copilot is your everyday AI companion, meant to bring the power of generative AI to everyone across work and life. We’re expanding availability and purchase options for individuals and organizations and bringing new value to Copilot Pro subscribers.

Since launching Copilot, it’s been exciting to see our customers bring AI into their lives—both personal and professional—creating stunning images, tackling their overflowing inboxes, jump-starting the writing process, catching up on missed meetings, and so much more. With Copilot, we’re committed to giving everyone the opportunity to supercharge their creativity and productivity. Available across devices, through web or through our Copilot mobile app on iOS or Android, it’s never been easier to get started with Microsoft Copilot.

The expansion of Copilot Pro offerings for individuals

We’re making Copilot in the free Microsoft 365 web apps part of your Copilot Pro subscription—no additional Microsoft 365 subscription required. While a Microsoft 365 Personal or Family subscription is still required to unlock Copilot in the desktop apps for PC and Mac, we’re excited to bring Copilot to Word, Outlook, and more free web apps to additional Pro subscribers.1 We’ll extend this benefit to our free mobile apps as well, including the Microsoft 365 app and Outlook for iOS and Android, in the coming months.

Microsoft Copilot GPT Builder Learn more

In January, we launched a curated set of Copilot GPTs that can be your personal trainer, travel agent, and sous chef. And now, the ability to build and share custom Copilot GPTs with Microsoft Copilot GPT Builder is available to all Copilot Pro subscribers. Copilot GPT Builder lets you create a personalized Copilot meant to assist you with specific tasks, based on your interests. You can make a Copilot GPT that acts as your career counselor, or a study buddy that helps you to learn a new skill—the possibilities are limitless, and you can do all this from within Copilot.

As part of our mission to empower every person on the planet to achieve more, we are making Copilot Pro available more broadly. Copilot Pro is now available in all 222 countries/regions where Copilot is available. We want all power users, creators, and anyone else to take their Copilot experience to the next level.

Copilot Pro For individuals, creators, and power users looking to take their Copilot experience to the next level. Discover more

And to make it easier for anyone to get started and experience all the features and benefits of Copilot Pro, we’re offering a one-month free trial for those who install our Copilot mobile app on iOS or Android.

With a Copilot Pro subscription, individuals gain the most advanced features and capabilities of Microsoft Copilot to supercharge their Copilot experience. This includes priority access to top-of-the-line models, AI capabilities in Microsoft 365 apps (a Microsoft 365 Personal or Family subscription is required to access Copilot in desktop apps), better image generation and editing capabilities, and access to Microsoft Copilot GPT Builder.

Copilot for Microsoft 365: Available to organizations of all sizes

While Copilot Pro is our best experience for individuals, Copilot for Microsoft 365 is our best experience for organizations. To empower every organization to become AI-powered, we’re making Copilot for Microsoft 365 available to businesses of all types and sizes—including frontline worker plans. Customers that have Microsoft 365 F3 and F1, Office 365 E1, Business Basic, and more will be eligible to purchase Copilot for Microsoft 365 in the coming weeks.2 That’s in addition to previously announced availability on Microsoft 365 E3 and E5, Office 365 E3 and E5, Business Standard, and Business Premium plans.

Copilot for Microsoft 365 works across your entire universe of data at work and is integrated into the Microsoft 365 apps millions of people use every day—Word, Excel, PowerPoint, Outlook, Microsoft Teams, and more—and the web. And with Copilot Studio, you can customize Copilot for Microsoft 365 using your business data or build your own copilot experiences. It’s built on the comprehensive approach of Microsoft to enterprise-grade security, privacy, identity, and compliance, and backed by the Microsoft Customer Copyright Commitment. 40% of the Fortune 100 have used Copilot for Microsoft 365 via our Early Access Program.3 That means tens of thousands of people at companies like Visa, BP, Honda, and Pfizer are already using Copilot to work in a new AI-powered way. As we said in January, we’ve seen faster adoption of Copilot for Microsoft 365 than our E3 or E5 suites.

What’s next?

Individuals can learn more about Copilot Pro. For actionable guidance on how your organization can get started with Copilot for Microsoft 365 today, visit Copilot for Work.

Download the Copilot App for a one-month free trial of Copilot Pro.

1Copilot Pro subscribers can use Copilot in the web versions of Word, Excel, PowerPoint, OneNote, and Outlook in the following languages: English, French, German, Italian, Japanese, Portuguese, Spanish, and Chinese Simplified. Those who have a separate Microsoft 365 Personal or Family subscription get the added benefit of using Copilot in the more fully featured desktop apps. Excel features are in English only and currently in preview. Copilot features in Outlook apply to accounts with @outlook.com, @hotmail.com, @live.com or @msn.com email addresses and are available in Outlook.com, Outlook built into Windows, and Outlook on Mac.

2Additional details and a complete list of eligible SKUs will be available on learn.microsoft.com.

3Microsoft Fiscal Year 2024 First Quarter Earnings Conference Call, Satya Nadella, Chairman and CEO and Amy Hood, EVP & CFO. October 24, 2023."
Microsoft_News,https://www.microsoft.com/en-us/industry/blog/government/2024/03/14/ai-innovation-takes-center-stage-at-the-world-governments-summit-2024/,,AI innovation takes center stage at the World Governments Summit 2024,"We were privileged to attend the World Governments Summit 2024 event in Dubai, United Arab Emirates on February 12 to 14, 2024. It was a momentous gathering of more than 10,000 leaders, ministers, and experts from around the world—coming together to shape the future of governments and find innovative solutions for major challenges.

The themes of the summit included government acceleration and transformation, AI, economic development, sustainability, and global health. As leaders in Microsoft for Government, we were struck by how deeply technology has become intertwined with governance. This was especially true with AI, which was pervasive in almost every discussion. The energy and excitement were palpable, and at times it felt as though we were attending a technology forum.

Microsoft for Government Empowering governments with technology to help solve society's biggest challenges Explore solutions

Top-of-mind AI adoption concerns for governments worldwide

Across all interactions with attendees, we heard a broad range of perspectives around AI and its role in the future of governments. The potential value of AI was not at issue. Overall, participants regarded the advent of AI, especially generative AI, as a historical shift on par with the internet or the Industrial Revolution, and there was overwhelming interest in putting it to work broadly for the advancement of society.

We also heard a range of perspectives surrounding generative AI. Among the common themes and questions on the minds of government leaders were the following:

Microsoft AI solutions Learn more

Developing legislation and regulations : How can governments take action to ensure safe, fair, and responsible AI adoption without stifling innovation?

: How can governments take action to ensure safe, fair, and responsible AI adoption without stifling innovation? Enabling inclusion : How can AI be infused throughout the world, and not just in wealthy societies, to create an inclusive and equitable environment based on the principles of privacy, trust, and transparency?

: How can AI be infused throughout the world, and not just in wealthy societies, to create an inclusive and equitable environment based on the principles of privacy, trust, and transparency? Ensuring security : How can governments protect sensitive data and assets in a world where nation state actors and criminals are launching aggressive cyberattacks using AI?

: How can governments protect sensitive data and assets in a world where nation state actors and criminals are launching aggressive cyberattacks using AI? Ensuring digital sovereignty : How can data be made available to AI while still conforming to the laws and regulations of the specific country or region where it resides?

: How can data be made available to AI while still conforming to the laws and regulations of the specific country or region where it resides? Training government workforces: How can government employees get appropriate, effective learning resources to quickly embrace and leverage new AI skills?

Clearly, these issues span the broad domains of technology, regulation, and legal and political considerations. It will take broad, long-term partnership and collaboration from many quarters to ensure that AI is employed in ways that benefit everyone, with minimal negative impact.

How governments are getting started with AI innovation

Every government’s situation and challenges are unique, but there are some important principles for every leader and organization to bear in mind. First is understanding that data underpins AI innovation. It is not possible to reap the benefits of generative AI without a modern data strategy, one that integrates diverse data sources, ensures data quality, establishes rules and processes for data access and management, and keeps data and systems secure.

This is why governments are increasingly recognizing that embracing AI requires migrating to the cloud. A modern platform, such as the Microsoft Cloud, provides the rich data services and hyperscale compute capabilities required to enable AI, plus the important security and compliance benefits that are built in.

With a strong cloud foundation, governments can start early innovation with AI. This begins by defining clear objectives that address an important, manageable priority. From there, a good first step is to build a limited use case using tools such as Microsoft Azure OpenAI Service, which let you test, learn, and iterate.

According to IDC, 64% of governments worldwide are in the early stages of exploring generative AI proof-of-concepts and use cases, with about half of those making significant investments. The top investments for state, regional, and local governments over the next 18 months are focused on supporting employees. Also essential for governments are programs to help train and hire for generative AI expertise, and working with trusted cloud providers who can deliver the scale and responsible partnership required for success.

Microsoft’s responsibility in the era of AI

Responsible AI has long been a cornerstone of Microsoft’s leadership in cloud and AI. Our recognition of the need for a global agreement on responsible AI and cybersecurity was articulated by Microsoft President and Vice Chair Brad Smith in his 2017 call for “The need for a Digital Geneva Convention.” Our commitment was further defined in the June 2022 Microsoft Responsible AI Standard, which defines a set of principles for responsible AI and offers a set of processes that governments can use to build their own governance frameworks and controls.

In an October 2023 update prepared for the United Kingdom AI Safety Summit, Microsoft’s AI Safety Policies were explained in depth. Also, at the Mobile World Congress in Barcelona in February 2024, Brad Smith discussed Microsoft’s AI Access Principles, detailing our role and responsibility as an AI innovator and a market leader, and our commitments to promote innovation and competition in the new AI economy. As more than 4 billion people in over 40 countries prepare to vote, Microsoft announced at the Munich Security Conference that it has joined a group of 20 leading technology companies to help combat the deceptive use of AI in 2024 elections.

Our experience at the World Governments Summit illuminated the sheer magnitude of the challenge of bringing AI to life for governments in ways that are fair, safe, equitable, and ultimately net-positive for all. It is a monumental challenge, which no single company, government, or entity can fully address. We are proud of Microsoft’s leadership in responsible AI, and we also recognize that there is much work yet to be done, and we cannot go at it alone.

Looking forward

For insights and assistance in moving forward with confidence, we invite government leaders to reach out to their Microsoft representative or technology partner. For a complete view of Microsoft’s commitments to responsible AI, see how we are empowering responsible AI practices."
Microsoft_News,https://www.microsoft.com/en-us/worklab/how-ai-can-help-you-have-a-smarter-more-thoughtful-conversations,,"AI Can Help You Have Smarter, More Thoughtful Conversations","This article first appeared in the WorkLab newsletter. Get exclusive insights on AI and the future of work by subscribing here.

The ability to clearly articulate what you want and why you need it is not just vitally important to how you interact with other people—it determines the quality of the responses you get from AI as well. It’s an insight Charles Duhigg, bestselling author of multiple productivity books, uncovered while researching his latest release, Supercommunicators: How to Unlock the Secret Language of Connection.

Duhigg recently joined us on the WorkLab podcast to explain why communication is having a moment. Here’s what he told us.

1. Communication is now a technical skill

In the age of AI, forward-looking leaders are already prioritizing communication skills when they hire. “We’re already seeing more and more emphasis on communication ability as something that employers are looking for,” Duhigg says. “The ability to show during an interview that you can communicate and connect well with others is going to tell that interviewer something about how you also interact with technology, and that’s going to be powerful.”

2. Want to get more from AI? Get more conversational!

“The future of tech is going to be more and more like having a conversation and less like using a calculator,” Duhigg says. “I have a 15-year-old son, and if he reads a book that none of his friends are reading, he’ll have a conversation with AI about it. It can be really edifying. Similarly, if you ask AI questions about how it got to an answer, or what other questions it thinks you should ask, it’ll reveal interesting and useful things, and open new avenues of inquiry.” Remember, AI isn’t just a computer spitting out answers; it can be an intellectual partner too.

3. Communicating emotion is a conversational superpower

“If you use emotional language with AI, you can increase its effectiveness,” Duhigg says. “Saying something like, ‘The answer to this will determine whether I get a promotion’ will raise the efficacy of the answer that it delivers.” Why? Duhigg says that AI models may be trained on data that contains emotional language, “so using emotional language helps to identify which parts of that dataset the AI ought to pay attention to.” Great communicators know that offering personal or emotional context helps engage others, whether it’s a person or an AI assistant.

4. Explaining what you need helps you understand what you need

“One of the reasons why conversation is so useful is because not only does it help us understand another person, it helps us understand ourselves.” That goes for conversational interactions with AI as well. “Sometimes we learn things just in what we say to AI, and then sometimes we learn things from what the machine responds with. And then there are times when I don’t even understand what question I want to ask AI, and it ends up helping me understand what I’m trying to get at.” Clearly articulating exactly what you are looking for helps you clarify in your own head what it is that you actually want.

5. AI can even help you upgrade your communication in other contexts

“I talk to researchers who are teaching negotiation skills, and they tell all their students to practice negotiations with AI and pay attention to, What surprises you? What objections do they raise? How do they come back that catches you off guard?” Leaders should absolutely use AI as a sounding board or a stand-in to game out different scenarios or rehearse difficult conversations.

For more productivity and communication insights from Charles Duhigg, check out the WorkLab podcast."
Microsoft_News,https://www.microsoft.com/en-us/worklab/podcast/how-do-you-solve-a-problem-thats-never-been-solved-before,,How Do You Solve a Problem That’s Never Been Solved Before?,"MOLLY WOOD: The best leaders step confidently into the unknown and bring their teams with them. Today, I’m talking to Dr. Britt Aylor, Director of Leadership Development at Microsoft, all about a framework for tackling new challenges, like the transition to AI, that are changing the way we work. Dr. Aylor is an expert in something called adaptive leadership. She got her doctorate in education from Harvard University, where she worked closely with Professor Ronald Heifetz, who’s a founding father of the adaptive leadership framework. Dr. Aylor joined Microsoft from the Broad Institute of MIT and Harvard, specifically so she could lead the charge in scaling adaptive leadership across the organization.

[Music]

MOLLY WOOD: Dr. Aylor, thanks so much for joining me.

BRITT AYLOR: Yes, thank you so much for having me.

MOLLY WOOD: All right, let’s jump right into the framework, because it seems like adaptive leadership, for lack of a better way to put it, is kind of a thing right now. [Laughter] What is it, and why is it suddenly so relevant?

BRITT AYLOR: Adaptive leadership is about leading on complex challenges with no existing solutions that, therefore, require us to navigate high levels of ambiguity, problem solve in the unknown, and mobilize stakeholders across the system to collectively engage in creating a solution. I do think it is a thing right now, and I think a lot has to do with us advancing into the AI space at a very accelerated rate. That in and of itself is an adaptive challenge.

Everything is going to be different. Everything is already changing. So, therefore, how do we operate effectively in the unknown? And adaptive leadership is a framework that lends itself really well to build that adaptive capacity in people, to problem solve in the unknown, and to operate with each other in a new collective intelligence capacity. For me, what is central to this style is a certain mindset. Of course, there are skills and capacities to build, but it really starts with shifting your thinking.

MOLLY WOOD: In your research you’ve come across two distinctions within the adaptive leadership framework. Can you tell us what those are and how to think about them?

BRITT AYLOR: One is around the what. What challenge are we grappling with at the moment? Is it technical, or is it adaptive? And technical challenges, first of all, have nothing to do with technology. What we mean are challenges that can be very complex. However, they have existing solutions and there’s a pathway we can follow. So we have a clear right and wrong, and moreover, we have deep expertise that we can leverage. In contrast, adaptive challenges are a completely different universe in that they are very complex. And what makes them especially taxing is that we have to navigate these really, really high levels of ambiguity. So it’s not so much even the complexity of the challenge; it’s actually the really high levels of ambiguity, because where do we start? Oftentimes we don’t even know what the challenge is. Asking the right questions is much more important than thinking, what are the solutions? Because chances are, we probably don’t yet have the solution. And so we really have to leverage the questions. And again, those questions may not naturally come to us because we may be in an old paradigm around how to solve a challenge that may seem similar, right? But that is actually more in the technical territory. And we know that applying what works in the technical to adaptive doesn’t work, and it actually creates boomerang challenges. I like to talk about Groundhog Day, the movie where you wake up in the same day, day after day. And that’s how I picture people feeling when they’re grappling with the same challenge, which is an adaptive challenge, and they try one technical fix after another. The challenge may go temporarily away because the temperature is lower, the symptoms are addressed, but the root causes are actually not identified and treated.

MOLLY WOOD: Can you give us some examples of technical challenges versus adaptive challenges?

BRITT AYLOR: A technical challenge could, for example, be building a plane or a rocket ship. Hugely complex, takes deep, deep expertise to do that. And the fact is we know how to build planes that can fly in the air. When the first plane was constructed, that actually was an adaptive challenge because we did it for the first time. Our technical challenges, chances are at some point they were adaptive, especially if they’re complex. But then as we learn our way forward, they actually move into the technical territory. In contrast, an example of an adaptive challenge would be, how do we address global warming? There’s the scientific perspective, there’s the global governance perspective, and then the question of, how do we reverse the effects we’ve created from a scientific perspective?

And then, even if we have that, how do we then engage globally, right, to get the buy-in across the critical stakeholders, to engage in a process that probably will require some cost, making some tough decisions. So that is in the territory of an adaptive challenge. We like to often operate in what I call more of the comfort zone, which works actually really well with technical challenges, because with technical challenges, we have the expertise and the solution pathway, so it’s just about executing. So we don’t need in-depth brainstorming. We don’t need involved decision making. We can leverage the solutions we have. But in the adaptive space, it’s a deep investment. And also, what I like to amplify is it’s an investment, and honestly, trying to operate an adaptive territory with technical ways of operating is actually a sunk cost. We need to first invest in growing adaptive capacity in our people.

MOLLY WOOD: It’s my understanding that you joined Microsoft, in part, specifically to scale adaptive leadership across the organization. And you didn’t just focus on executives, right? You may have started with Jared Spataro, who leads AI work at Microsoft, but then you worked with his whole team—managers and even individual contributors. Talk to us about that experience.

BRITT AYLOR: The most powerful way of actually having adaptive leadership come alive is when it can function as a closed circuit, when it’s not just the most senior leaders that understand adaptive leadership, but moreover, their direct reports and then the direct reports below that, so that the entire organization can have the same language and the same concepts, and therefore have the same decision-making framework of, how are we operating together? And what is needed in this situation? And so we started with the senior most leaders. And then we went to the other layers—we went to the management team, and then we did an event where all of Jared’s people were in the room, and moreover, they were in person in the room, which creates such a powerful learning environment. Adaptive really lends itself to in-person learning. A lot of this work is deeply emotional, because, again, change is difficult for people, in particular because it often leads to loss. It’s actually not change that people resist, it’s the loss element. And so that is one angle, for example, that we worked with Jared’s larger organization to really think collectively through, what does it mean to adapt? What does it mean to lead for change in this age of AI? And what will that take? And at the heart center of adaptive leadership, you know, the first level is understanding the language, understanding the concepts. And then the second level is really diagnosis. We need to diagnose. Are we in technical territory? Are we in adaptive territory? And that also leads us to the second distinction, which is authority versus leadership. Distinguishing between exercising authority that you have by virtue of the formal role you are in, versus leadership—and we actually define leadership as a verb. That activity can be executed from anywhere within the hierarchy. You do not need to be in a formal role that sanctions you with formal power.

Leadership is actually a self-chosen activity that can come from anywhere in the system. And the way that it maps to the context we’ve been talking about so far is that with technical problems in the world of the known, where we have existing solutions and deep expertise, authority is actually our go-to mechanism for leading. So there’s big, big value in authority, and organizations exist to a large extent to execute on the deep expertise on technical work that we do. Nine times out of 10 when I ask people, what does leadership mean to you? Even though there’s this excitement around leading for innovation, they actually give me the answer for authority, which is, I determine the situation and then I go to our expert solutions, and then I delegate and kind of deploy my team in the way that it makes sense. And I’m like, yes, that is an excellent way of operating in the world of technical and known. Leadership starts where authority ends. When we enter this world of the unknown, where we don’t know what the answers are, and that’s where it’s all about change and leadership and the adaptive framework. The primary activity of leading is navigating through this change territory, and doing that moreover with all of the stakeholders who are connected to the adaptive challenge. So adaptive leadership is never an activity of one. We always exercise leadership with other stakeholders who need to be part of the solution in order for it to stick.

MOLLY WOOD: And that feels like it goes to the heart of answering that question, too, about why it’s so important to do this training, to do this knowledge sharing at every level, because it sounds like what you’re saying is everyone can contribute to leadership.

BRITT AYLOR: You know, in the day and age of complexity that we are living in, we need the collective intelligence of everybody to come together. We have no chances of solving the adaptive challenges we’re facing nowadays if we rely on even just the genius brain of one. That equation, maybe it worked in the past at times. In the future, I think it is all about plugging into each other’s collective intelligence and amplifying that. And there’s a whole skill set around that, right? Some people find adaptive leadership an emotionally challenging territory because it’s often engaging with people who have a very, let’s say, at times an opposite point of view to your own, right? And that’s where we need to channel growth mindset, because it’s actually being deeply curious about that other perspective rather than being threatened by it. So instead of going, like, right and wrong, being like, That’s so curious. Let me understand more where this stakeholder’s coming from, because they might actually see something I am not. So it’s being deeply curious and kind of taking our ego out of it too.

MOLLY WOOD: You brought up this idea of change and the fear of loss, and that actually gets to a key component, I think, of adaptive leadership, this idea of psychological safety. I want to ask you about what that means in the context of the workplace, and how business leaders, especially as you’ve alluded to in a time of a lot of change, can ensure that they’ve built a culture that feels psychologically safe.

BRITT AYLOR: Part of the process that makes innovation possible is smart experimentation. The understanding has to be failure in the service of learning will be part of actually delivering success. I think that is a really important element to focus on. When we talk about psychological safety, when we decide this adaptive challenge or this capability solution, whatever it is, we want to build that in the innovative space that we do not yet know how to do. We are okay with a certain amount of failure, assuming we design smart experiments, but then learning and recovering quickly from failure, I think, is the other capacity that we are going to have to build in ourselves. And then, moreover, the overlay of the leadership at the top saying, We have decided this is really important to get us to this innovation, and therefore, we are expecting and understanding that a certain amount of failure and learning along the way is an investment we need to make. If that is explicitly understood and agreed, it creates psychological safety. I think actually that is a big unlock for being able to lead adaptively. But what often holds people back, I have found, is this fear around, What does that mean if I start to lead in adaptive ways? Because one of the frontiers we have, which is actually an adaptive challenge, is what are the metrics for being successful in this adaptive space? How do you measure incremental advances towards your innovation? The horizon can be very long on adaptive challenges. Again, going back to thinking around the adaptive challenge of global warming, we are talking years here, right? We’re probably talking decades. And so how do you even start to then parse out what is the timeline, and what do we consider success? And having those be measurable milestones that are acknowledged.

MOLLY WOOD: Well, so adaptive leadership is having a moment because of AI, but I wonder, can the unknown challenges that come with AI actually help us become better adaptive leaders?

BRITT AYLOR: I do think that AI will help us to navigate both the world of the known and the technical problems we’re facing, as well as the world of the unknown and the adaptive challenges. First of all, probably in the nearer future, a lot of the things that are in the technical realm, AI will actually start to be driving. A lot of that work will probably be increasingly done by AI. And so, I find it exciting. By AI being able to step into, increasingly, that technical expertise known world, it really frees us up to do what is uniquely human, which, I think, is operating in that frontier of knowledge space. Using collective intelligence, I think, AI will be able to help us connect with each other and also manage the knowledge.

MOLLY WOOD: If you had to give organizations some advice about how to proceed in times that are uncertain and how to take on this challenge of learning adaptive leadership, what would you say?

BRITT AYLOR: I think central to all of it is really starting to become very diagnostic, building that capacity, and then making a conscious choice and forming kind of a strategic picture around, what is the ratio of the work that falls into the world of the known versus the world of the unknown? I think top of mind of all our leaders should be thinking around, what is the ratio? And moreover, how am I going to shift gears between the two? And, building on that, how am I going to signal to my people that I’m shifting gears? If we uncouple what we talk about as leadership into the function of exercising authority versus leading for innovation, those are two fundamentally different ways of operating and showing up. And those expectations are very different. In order to—again, looping us back to psychological safety—in order to create psychological safety, we as leaders need to be very clear, as clear as we can be, of, are we operating in technical territory, and therefore, I’m going to show up in my authority role, because the solution path is clear and the game really is high efficiency and effectiveness. Let’s perform to the max versus signaling, Hey, I actually don’t know what the solution is in this innovative, adaptive space. And therefore I’m actually asking all of you to lean in. I’m asking for collective brainstorming. I am willing to make that investment of time and energy, because that’s the only way we’re going to navigate our way forward. And I think if leaders can provide that clarity—what is the territory I’m asking you to work in?—I think it will provide a fundamental psychological safety. But if there’s not clarity on, Hey, what territory am I working in, it can actually be very risky doing brainstorming and investing in innovation when, No, actually my leader above me wanted me to just execute on what we know how to do. So, being very clear on that distinction, I think, will go a really long way.

MOLLY WOOD: Dr. Britt Aylor, thank you again, Director of Leadership Development at Microsoft. We really appreciate the time.

BRITT AYLOR: Yes, thank you so much.

[Music]

MOLLY WOOD: And that’s it for this episode of WorkLab, the podcast from Microsoft. Please subscribe and check back for the next episode, where I’ll be speaking with Bryan Hancock, who’s the global lead of the talent management practice at McKinsey. We’ll be talking about why managers hold the key to unlocking AI. If you’ve got a question or a comment, please drop us an email at WorkLab@microsoft.com, and check out Microsoft’s Work Trend Indexes and the WorkLab digital publication, where you’ll find all of our episodes, along with thoughtful stories that explore how business leaders are thriving in today’s new world of work. You can find all of it at microsoft.com/WorkLab. As for this podcast, please rate us, review us, and follow us wherever you listen. It helps us out a ton. The WorkLab podcast is a place for experts to share their insights and opinions. As students of the future of work, Microsoft values inputs from a diverse set of voices. That said, the opinions and findings of our guests are their own, and they may not necessarily reflect Microsoft’s own research or positions. WorkLab is produced by Microsoft with Godfrey Dadich Partners and Reasonable Volume. I’m your host, Molly Wood. Sharon Kallander and Matthew Duncan produced this podcast. Jessica Voelker is the WorkLab editor."
Microsoft_News,https://azure.microsoft.com/en-us/blog/accelerate-your-productivity-with-the-whisper-model-in-azure-ai-now-generally-available/,,Accelerate your productivity with the Whisper model in Azure AI now generally available,"Share Accelerate your productivity with the Whisper model in Azure AI now generally available on LinkedIn

Share Accelerate your productivity with the Whisper model in Azure AI now generally available on X

Share Accelerate your productivity with the Whisper model in Azure AI now generally available on Facebook

Human speech remains one of the most complex things for computers to process. With thousands of spoken languages in the world, enterprises often struggle to choose the right technologies to understand and analyze audio conversations while keeping right data security and privacy guardrails in place. Thanks to generative AI, it has become easier for enterprises to analyze every customer interaction and derive actionable insights from these interactions.

Azure AI Build intelligent apps at enterprise scale with the Azure AI portfolio. Learn more

Azure AI offers an industry-leading portfolio of AI services to help customers make sense of their voice data. Our speech-to-text service in particular offers a variety of differentiated features through Azure OpenAI Service and Azure AI Speech. These features have been instrumental in helping customers develop multilingual speech transcription and translation, both for long audio files and for near-real-time and real-time assistance for customer service representatives.

Today, we are excited to announce that OpenAI Whisper on Azure is generally available. Whisper is a speech to text model from OpenAI that developers can use to transcribe audio files. Starting today, developers can begin using the generally available Whisper API in both Azure OpenAI Service as well as Azure AI Speech services on production workloads, knowing that it is backed by Azure’s enterprise-readiness promise. With all our speech-to-text models generally available, customers have greater choice and flexibility to enable AI powered transcription and other speech scenarios.

Since the public preview of the Whisper API in Azure, thousands of customers across industries across healthcare, education, finance, manufacturing, media, agriculture, and more are using it to translate and transcribe audio into text across many of the 57 supported languages. They use Whisper to process call center conversations, add captions for accessibility purposes to audio and video content, and mine audio and video data for actionable insights.

Learn more Invest in app innovation to stay ahead of the curve

We continue to bring OpenAI models to Azure to enrich our portfolio and address the next generation of use-cases and workflows customers are looking to build with speech technologies and LLMs. For instance, imagine building an end-to-end contact center workflow—with a self-service copilot carrying out human-like conversations with end users through voice or text; an automated call routing solution; real-time agent assistance copilots; and automated post-call analytics. This end-to-end workflow, powered by generative AI, has the potential to bring a new era in productivity to call centers around the world.

Whisper in Azure OpenAI Service

Azure OpenAI Service enables developers to run OpenAI’s Whisper model in Azure, mirroring the OpenAI Whisper model functionalities including fast processing time, multi-lingual support, and transcription and translation capabilities. OpenAI Whisper in Azure OpenAI Service is ideal for processing smaller size files for time-sensitive workloads and use-cases.

Lightbulb.ai, an AI innovator, is looking to transform call center workflows, has been using Whisper in Azure OpenAI Service.

“By merging our call center expertise with tools like Whisper and a combination of LLMs, our product is proven to be 500X more scalable, 90X faster, and 20X more cost-effective than manual call reviews and enables third-party administrators, brokerages, and insurance companies to not only eliminate compliance risk; but also to significantly improve service and boost revenue. We are grateful for our partnership with Azure, which has been instrumental in our success, and we’re enthusiastic about continuing to leverage Whisper to create unprecedented outcomes for our customers.” Tyler Amundsen, CEO and Co-Founder, Lightbulb.AI

To learn more about how to use the Whisper model with the Azure OpenAI Service click here: Speech to text with Azure OpenAI Service.

Try out the Whisper REST (representational state transfer) API in the Azure OpenAI Studio. The API supports translation services from a growing list of languages to English, producing English-only output.

OpenAI Whisper model in Azure AI Speech

Users of Azure AI Speech can leverage OpenAI’s Whisper model in conjunction with the Azure AI Speech batch transcription API. This enables customers to easily transcribe large volumes of audio content at scale for non-time-sensitive batch workloads.

Developers using Whisper in Azure AI Speech also benefit from the following additional capabilities:

Processing of large file sizes up to 1GB in size with the ability to process large amounts of files with up to 1000 files in a single request that processes multiple audio files simultaneously.

Speaker diarization which allows developers to distinguish between different speakers, accurately transcribe their words, and create a more organized and structured transcription of audio files.

And lastly, developers can use Custom Speech in Speech Studio or via API to finetune the Whisper model using audio plus human labeled transcripts.

Customers are using Whisper in Azure AI Speech for post-call analysis, deriving insights from audio and video recordings, and many more such applications.

For details on how to use the Whisper model with Azure AI Speech click here: Create a batch transcription.

Getting started with Whisper

Azure OpenAI Studio

Developers preferring to use the Whisper model in Azure OpenAI Service can access it through the Azure OpenAI Studio.

To gain access to Azure OpenAI Service, users need to apply for access.

Once approved, visit the Azure portal and create an Azure OpenAI Service resource.

After creating the resource, users can begin using Whisper.

Azure AI Speech Studio

Developers preferring to use the Whisper model in Azure AI Speech can access it through the batch speech-to-text in Azure AI Speech Studio.

The batch speech to text try-out allows you to compare the output of the Whisper model side by side with an Azure AI Speech model as a quick initial evaluation of which model may work better for your specific scenario.

The Whisper model is a great addition to the broad portfolio of capabilities that Azure AI offers. We are looking forward to seeing the innovative ways in which developers will take advantage of this new offering to improve business productivity and to delight users."
Microsoft_News,https://blogs.microsoft.com/blog/2024/03/13/from-vision-to-value-realization-a-closer-look-at-how-customers-are-embracing-ai-transformation-to-unlock-innovation-and-deliver-business-outcomes/,,From vision to value realization: A closer look at how customers are embracing AI Transformation to unlock innovation and deliver business outcomes,"Each quarter, I share a collection of customer and partner stories from around the world that highlight the incredible technological advancements shaping the future of industry. As a partner of choice, we are committed to helping organizations accelerate AI Transformation to unlock opportunities and realize material business value. Our ability to bend the curve on AI innovation is allowing us to live truer to our mission than ever before: to empower our customers and partners to achieve more.

I am sharing an additional blog this quarter because we are seeing so much inspiring AI Transformation and pragmatic innovation with our customers. Their impressive results are benefiting employees, businesses, and industry, and I would like to expand on a handful of stories that crystallize the tangible impact AI is having on organizations that embrace it:

Digital financial services firm Ally Financial is leveraging Microsoft Azure and Azure OpenAI Service to reduce manual tasks for its customer service associates, freeing up time for them to reinvent how they engage with customers. Previously, associates needed to take notes and write summaries after every call, which competed with the amount of time and attention they could give to their customers. By using generative AI to automate manual tasks, Ally empowered its associates to deliver a better, more personal experience while protecting vital customer data through a production-ready solution in only eight weeks. The new solution has cut associates’ post-call effort by 30% while capturing critical information automatically with over 85% accuracy — even finding details they may have previously missed in their conversations.

Global travel technology provider Amadeus deployed Copilot for Microsoft 365 to help empower its workforce, beginning with early adoption across a subset of employees. More than 90% of these employees are regularly using Copilot to save time drafting emails, summarize meetings and actions, and more effectively search for information across the web and internal assets. Now, the company is rolling out the solution across its wider workforce so employees around the world can benefit from its time-saving options to focus on more strategic tasks.

Global life sciences leader Bayer is using Copilot for Microsoft 365 to deliver productivity and collaboration benefits across its Crop Science, Pharmaceutical and Consumer Health divisions. With more than 700 use cases identified, they are already seeing a big impact from its implementation. Copilot is helping to summarize communications and expedite the search for information, saving employees hundreds of hours. Bayer also developed the Model Store — a Copilot plugin leveraging the Microsoft Teams platform — to search for information using natural language to close communication gaps between data scientists and laboratory researchers, locate the source of data faster, reduce barriers to finding information and help collaborate with the expert source. For example, Copilot helped a U.S. researcher identify a predictive model already developed by a researcher in Germany, preventing a duplicate model from being developed and saving two to three months of work.

Multinational brewer Carlsberg unified its developer organization around an integrated platform using GitHub Enterprise — reducing their toolchain from six tools to a single platform. This allowed for the seamless and effective integration of GitHub Copilot, which enhanced the synergy in their workflow and removed development roadblocks by providing valuable coding suggestions. Copilot adoption has been overwhelmingly positive, enhancing productivity across teams and proving to be a valuable learning tool for cloud developers by easing the learning curve required when working with new languages and platforms.

One of the top media companies in the world, dentsu, is using Copilot for Microsoft 365 to revolutionize workflows, support its talent and help rethink its services across a growing number of channels. By reducing and removing tactical tasks, employees can focus on the strategic part of their work to collaborate creatively. Employees are saving 30-40 minutes a day using Copilot for tasks such as summarizing chats, generating presentations and building executive summaries. They are reinvesting their time to focus on more thoughtful work without interruption, while having content served up within their workflows. Employees are now averaging 30-60 minutes less time on first drafts of messaging and 80% say they have a very positive view of Copilot.

Food industry giant Grupo Bimbo turned to Microsoft’s Azure AI technologies — including Azure OpenAI Service, Form Recognizer and Cognitive Search — to develop a copilot solution in two weeks that helped employees make queries about company policies. The copilot for internal control and risk management employs advanced AI technology to seamlessly convey information in a synthesized format, complemented by readily accessible reference links that pinpoint the exact sources of global policy. It can also respond in all languages where the company has collaborators and operations, no matter what language the query is originally made in. The primary benefit for the company has been its ability to promote compliance across 34 countries. Now, they are replicating the technology to build a copilot product that empowers all individuals and departments. For example, the copilot is helping their communications team draft emails, craft content for social media, propose images for marketing products, translate text and more.

U.S. healthcare organization Providence faced a deluge of incoming messages that required triage and interfered with the time providers needed to spend with their patients. Providence clinicians, informaticists and AI specialists developed a tool based on Azure OpenAI Service named ProvARIA to classify messages, direct them to the appropriate caregiver and free providers to focus on patient care. Providence piloted the tool with four separate clinics representing 27 different doctors and nurse practitioners, funneling all electronic communications into a centralized inbox in a single office. A group of medical assistants worked together to address the messages, processing about 10,000 messages in one month with a 35% improvement in turnaround time. Other groups within Providence enthusiastically joined the pilot, introducing efficiencies that allowed clinics to manage messages with fewer medical assistants — a boon when the limited number of qualified medical assistants is in high demand. Providence medical assistants are now processing 5,000 messages per day, covering 145 Providence clinics and 650 providers. The most profound outcome is one that cannot be measured, and one that had not been anticipated: caregivers have gained peace of mind knowing they have the time and focus to help all patients who need it.

One of the largest digital telco companies in Asia, Telkomsel, needed a way to ensure its customer support team was not overwhelmed by sharply rising demand. The company upgraded a virtual assistant within two weeks with Azure OpenAI Service to improve interactions across its 159 million mobile subscriber base and 8.5 million fixed broadband customers. The virtual agent is helping customer support agents deal with more complex issues without the distraction of routine inquiries and is reducing burnout from facing long call queues. By infusing light-hearted humor and emoticons into the conversation, the new virtual assistant “Veronika” intelligently combines the latest information from multiple FAQs to supply more insightful answers with a personal touch. Telkomsel has scaled the solution to handle up to 5 million transactions per month while delivering the robust security it requires. Since its introduction, self-service interactions have risen from 19% to 45%, with a 140% increase in average messages per user. Customer service agents who used to handle 8,000 calls a day now handle 1,000, freeing up time to increase their cross-selling efforts.

Leading telecommunications and technology company Telstra has scaled its AI adoption following promising pilots of generative AI solutions with front-line team members. Leveraging the Microsoft Cloud and Azure OpenAI Service capabilities, two pilot programs were developed: One Sentence Summary and Ask Telstra. Using Azure OpenAI Service’s large language models, One Sentence Summary transforms customer notes, interactions and transactions into a concise summary of a customer’s recent history and status. The solution enhances the efficiency and quality of interactions, reducing the need for customers to repeat information. Ninety percent of employees using the tool saved time and increased effectiveness, resulting in 20% less follow-up contact. Ask Telstra enables employees to search the company’s extensive internal knowledge base quickly and easily for information, powered by Azure OpenAI Service and Azure AI Search. Employees were able to gather information faster and more easily for customers, with over 80% agreeing the technology had a positive impact on customer interactions. Now the company is rolling out the pilots across all contact centers and store teams throughout 2024.

To pursue its digital transformation efforts, global multi-energy company TotalEnergies launched Microsoft Copilot to provide employees with a secure AI chat solution based on internal data. After a successful test phase across 300 employees, the company also launched Copilot for Microsoft 365 for their employees, resulting in improved operational efficiency and user adoption. The company is also focused on a new program to support and enhance employee skilling to get the most out of these new AI tools, including implementation of low code-no code solutions with Microsoft Power Platform.

To alleviate an overwhelming workload for doctors and medical staff in major cities across Vietnam, VinBrain introduced an AI platform into hospital workflows: DrAid™. Operating on an Electronic Medical Record (EMR) data system, DrAid™ harnesses Microsoft technologies —including Azure OpenAI Service —to aid physicians in diagnostic processes, treatment planning and the efficient management of burgeoning medical records. This platform is the first and only AI-driven X-ray diagnostic tool in Southeast Asia to receive U.S. Food and Drug Administration (FDA) certification, propelling Vietnam into the top six nations globally with FDA-approved AI products for chest X-ray diagnostics. Comprehensive screening is achieving an accuracy rate of up to 95%, and advanced imaging capabilities allow for the detection of liver cancer tumors as small as 5mm to help facilitate early-stage intervention and curative treatment. The tool is also reducing initial screening times by 80-85% and lowering time to analyze cases from 30 minutes to 5 minutes per case.

To scale digital platforms to more than 300 million businesses, public sector organizations and consumers across Europe and Africa, Vodafone is leveraging Microsoft’s generative AI to provide highly personalized and differentiated customer experiences across multiple channels. Their investment is already reinventing how Vodafone engages with customers and accelerating digital transformation. Early testing shows that AI-powered assistants are reducing average handling times and providing AI-generated responses with greater accuracy. Thanks to faster and more accurate responses, the company is also improving customer satisfaction scores.

Leading manufacturer Volvo Group needed the ability to extract data from images — such as photographs, stamps and printed text with handwritten notes over it — and translate documents to and from multiple languages to help its workers streamline invoices and claims document processing. Built on Microsoft Azure, Volvo created a six-week pilot program with a solution using Microsoft Azure AI services and AI Document Intelligence. After a four-month production timeline, they launched a solution that simplified document processing and meets the objectives of data extraction that has saved employees more than 10,000 manual hours — about 850-plus manual hours per month. Now, employees are enjoying their work more, with additional time to focus on innovation and tasks related to their specific skill sets.

I hope you find these stories of AI Transformation as promising and inspiring as I do. I invite you to read my January pre-earnings blog to learn more about how customers and partners are unlocking AI opportunity across industries: Embracing AI Transformation: How customers and partners are driving pragmatic innovation to achieve business outcomes with the Microsoft Cloud. I remain grateful for the opportunity we have at Microsoft to help our customers and partners realize pragmatic business value with AI, and look forward to finding ways we can help your organization achieve more.

Tags: AI, Azure, Azure OpenAI Service, Copilot for Microsoft 365, copilots, Microsoft Copilot"
Microsoft_News,https://news.microsoft.com/source/features/ai/ai-for-all-how-access-to-new-models-is-advancing-academic-research-from-astronomy-to-education/,,"AI ‘for all’: How access to new models is advancing academic research, from astronomy to education","In early 2023, Professor Alice Oh and her colleagues at the Korea Advanced Institute of Science and Technology (KAIST) realized they needed to address the quickly growing interest in OpenAI ChatGPT among KAIST’s students.

ChatGPT – a tool developed by OpenAI that runs on large language models and generates conversational responses based on people’s prompts – could lead to students taking shortcuts in their work but might also offer educational benefits, they reasoned. The group wanted to develop a research project that would engage students in using the technology, so they began thinking about how to develop their own chat application.

“We were in a hurry,” says Oh, a professor in the KAIST School of Computing. “Our semester started in March, and we wanted to have students start using this right away when the semester started.”

So-Yeon Ahn, an English professor at KAIST, guides students testing a platform created to assist English as a Foreign Language students with essay writing. Photo by Jean Chung for Microsoft.



A solution soon emerged. In April 2023, Microsoft Research launched an initiative that aims to accelerate the development and use of foundation models – large-scale AI models trained on vast amounts of data that can be used for a wide range of tasks.

Advancing Foundation Models Research (AFMR) provides academic researchers with access to state-of-the-art foundation models through Azure AI Services, with the goal of fostering a global AI research community and offering robust, trustworthy models that help further research in disciplines ranging from scientific discovery and education to healthcare, multicultural empowerment, legal work and design.

The initiative’s grant program includes 200 projects at universities in 15 countries, spanning a broad range of focus areas. Researchers at Boston’s Northeastern University are working on an AI-powered assistant designed to appear empathetic toward workers’ well-being. At Ho Chi Minh City University of Technology in Vietnam, researchers plan to create a fine-tuned large language model (LLM) specifically for Vietnamese. In Canada, researchers at the Université de Montréal are exploring how LLMs could help with molecular design and the discovery of new drugs.

Accessing foundation models can be challenging for academic researchers, who must often wait to use shared resources that can lack the computing power needed to run large models. Microsoft Research created the initiative to give researchers access to a range of powerful foundation models available through Azure and ensure that the development of AI is driven not just by industry, but also by the academic research community.

“We realized that to develop AI today, there is really a need for industry to open up capacity for academia,” says Evelyne Viegas, senior director of Research Catalyst at Microsoft Research. “Those different viewpoints could shape what we’re doing.”

With access to Azure OpenAI Service, which combines cutting-edge models from OpenAI with security, privacy and responsible AI protections offered in Azure, Oh and the KAIST team developed a platform that uses the models underlying ChatGPT for a chatbot to help college students write essays for English as a Foreign Language (EFL) courses. Students often write at night, when guidance from professors or teaching assistants isn’t available, Oh says, and EFL students frequently use tools to help navigate the challenges of writing in English.

The KAIST platform, developed through a Microsoft grant program offering academics access to advanced AI models, was designed to allow a chatbot only to answer students’ questions, but not write their essays for them. Photo by Jean Chung for Microsoft.



Oh’s team designed the chatbot to answer students’ questions but not write their essays for them. Over a semester, 213 EFL students used the tool to refine their essays; the platform collected the students’ questions and essay revisions they made based on the chatbot’s responses, then Oh’s team analyzed the data and published a paper about the experiment.

The researchers found that some students used the platform extensively and incorporated the feedback it provided. Many treated the chatbot like an “intelligent peer,” Oh says, suggesting that the technology can be a helpful complement to classroom instruction. And since the platform uses GPT-4, a large multimodal model developed by OpenAI that can communicate in multiple languages, students sometimes switched between English and their native language when using the platform, enabling more natural interactions.

The KAIST team plans to expand the platform to creative writing and conversational English classes. Oh sees tremendous potential for generative AI in education, particularly if models can be trained to show students how to reason through problems rather than simply providing answers.

“Universities should take full advantage of this and really start to think about how we can use these tools for scientific research and education,” she says.

‘Like having a super adviser’

Researchers at North Carolina Agricultural and Technical State University, who received a grant under the Microsoft program, are developing an AI-based traffic monitoring system capable of identifying road congestion and safety hazards. The project is aimed at automating much of the manual work required by traditional traffic monitoring systems.

The researchers used GPT-4 alongside other AI models that rely on traffic data collected by the federal government to analyze traffic patterns and congestion. Users interact with the system through a chatbot and can ask questions about current traffic conditions – like how busy traffic is at a particular location or the speed at which vehicles are traveling.

“It will make traffic management easier and more efficient,” says Tewodros Gebre, a Ph.D. student working on the project.

The system uses GPT-4 to interpret traffic data collected from sensors, drones and GPS, allowing transportation agencies, city planners and citizens who aren’t necessarily data scientists to quickly get information about traffic conditions through the chat application.

“We talk about data equity, and this combination with the chatbot makes the system available to people without them needing to go to this complex model and see what’s going on,” says Leila Hashemi-Beni, an associate professor in geospatial and remote sensing at the university. “People with different skill sets can still get the information they need from this system.”

The system, which is still in development, could also help identify the best evacuation routes after a natural disaster, she says.

“It’s not just transportation. This project has much bigger, broader impact. It gives us the opportunity for cutting-edge research that is very helpful to us as researchers and educators.”

Ioana Ciucă, second from left, is a fellow at The Australian National University and is organizing an effort to use AI to advance astronomy research. Photo courtesy of Boquan Chen.

A collaboration between astronomers at Harvard University and The Australian National University is leveraging GPT-4 in a different way. Seeking to use LLMs to accelerate astronomy research, the group, called UniverseTBD, developed an astronomy-based chat application that draws from more than 300,000 astronomy papers.

Alyssa Goodman, the Robert Wheeler Wilson Professor of Applied Astronomy at Harvard, says the application could eventually help young astronomers extract key information from academic papers and analyze data to develop their own research and theories.

“If you have a really good idea, it’s very hard to just search the literature and try to find everything,” Goodman says. “This is sort of like having a super adviser, a brilliant astronomer with an encyclopedic memory who can say, ‘Well, that could be a very good idea and here’s why,’ or ‘That’s likely a bad idea and here’s why.’”

The researchers hope to develop smaller language models for astronomy that will be accessible to astronomers of all levels, says Ioana Ciucă, the Jubilee Joint Fellow at The Australian National University leading UniverseTBD with Sandor Kruk, a data scientist at the European Space Agency, and Kartheik Iyer, a NASA Hubble Fellow at Columbia University.

“Our mission is to democratize science for everyone,” she says. “GPT-4 is a very large language model and it runs on a lot of resources. In our pursuit of democratizing access, we want to build smaller models that learn from GPT-4 and can also learn to speak the language of astronomy better than GPT-4. That’s what we’re envisioning.”

Many of the AFMR research projects focus on using LLMs for a range of societal benefits, from leveraging generative AI to assess pandemic risk to using vision and language models to help people who are blind or have low vision navigate outdoors."
Microsoft_News,https://blogs.microsoft.com/?p=52561616,,Microsoft makes the promise of AI in healthcare real through new collaborations with healthcare organizations and partners,"Just over a year ago, the healthcare industry was energized by the debut of generative AI and the promise this new technology held for delivering real-world outcomes that positively impact clinicians, patients, health systems, and the broader health and life sciences ecosystem. Since then, it has been a catalyst for the development of new use cases, opening possibilities for an entirely new era of innovation — and this shows no signs of slowing down. We continue to see AI adoption within healthcare grow, with 79% of healthcare organizations reporting that they’re currently using AI technology, according to a Microsoft-commissioned study through IDC[i]. AI also has a demonstrable business value, with healthcare organizations realizing a return on their AI investments within 14 months, along with an average return of $3.20 for every $1 they invest in AI[ii].

Working alongside healthcare organizations, Microsoft is making the promise of AI real by empowering the industry to tackle its biggest challenges and create a real difference in the lives of clinicians and patients. At the 2024 HIMSS Global Health Conference & Exhibition, we are highlighting how providers are adopting generative AI solutions and the impact the technology is making.

Stanford Medicine and Microsoft announced the enterprise-wide deployment of Nuance Dragon Ambient eXperience Copilot (DAX Copilot), providing conversational, ambient and generative AI to Stanford Medicine’s clinicians. This deployment aligns with Stanford Medicine’s mission to alleviate physician burnout and enhance patient care by streamlining administrative tasks. Stanford Medicine’s commitment to innovation, coupled with DAX Copilot’s ability to automate clinical documentation, has led to significant improvements in efficiency and patient-focused care. DAX Copilot enables healthcare organizations to adopt AI-powered clinical documentation applications at scale, leveraging existing investments in our trusted and extensible Dragon solutions. Stanford Health Care clinicians who used DAX Copilot reported through a preliminary survey that 96% of physicians stated that it was easy to use, and 78% reported that it expedited clinical notetaking. About two-thirds reported that DAX Copilot saved time.

and Microsoft announced the enterprise-wide deployment of Nuance Dragon Ambient eXperience Copilot (DAX Copilot), providing conversational, ambient and generative AI to Stanford Medicine’s clinicians. This deployment aligns with Stanford Medicine’s mission to alleviate physician burnout and enhance patient care by streamlining administrative tasks. Stanford Medicine’s commitment to innovation, coupled with DAX Copilot’s ability to automate clinical documentation, has led to significant improvements in efficiency and patient-focused care. DAX Copilot enables healthcare organizations to adopt AI-powered clinical documentation applications at scale, leveraging existing investments in our trusted and extensible Dragon solutions. Stanford Health Care clinicians who used DAX Copilot reported through a preliminary survey that 96% of physicians stated that it was easy to use, and 78% reported that it expedited clinical notetaking. About two-thirds reported that DAX Copilot saved time. WellSpan Health announced its widespread adoption of DAX Copilot, enhancing patient-physician interactions during exam room and telehealth visits. Leveraging generative AI, DAX Copilot automates clinical note drafting, allowing physicians to focus entirely on patients without the distraction of manual documentation. WellSpan’s decision to adopt DAX Copilot builds upon its successful use of Nuance solutions to streamline clinical workflows and improve patient care. Surveys indicate high satisfaction among physicians and patients, with DAX significantly improving the quality of interactions and reducing documentation burdens. This initiative reflects WellSpan’s commitment to delivering exceptional care experiences and addressing physician burnout by providing innovative tools to enhance efficiency and personalize care delivery.

announced its widespread adoption of DAX Copilot, enhancing patient-physician interactions during exam room and telehealth visits. Leveraging generative AI, DAX Copilot automates clinical note drafting, allowing physicians to focus entirely on patients without the distraction of manual documentation. WellSpan’s decision to adopt DAX Copilot builds upon its successful use of Nuance solutions to streamline clinical workflows and improve patient care. Surveys indicate high satisfaction among physicians and patients, with DAX significantly improving the quality of interactions and reducing documentation burdens. This initiative reflects WellSpan’s commitment to delivering exceptional care experiences and addressing physician burnout by providing innovative tools to enhance efficiency and personalize care delivery. Providence and Microsoft announced a strategic collaboration aimed at accelerating AI innovation in healthcare. Leveraging Microsoft Cloud for Healthcare and Azure as a standard platform, the collaboration focuses on delivering AI-powered applications to improve interoperability, generate clinical insights and enhance care delivery. Past successes from this relationship include Providence’s migration to cloud solutions and the adoption of AI-powered applications like Nuance’s DAX Copilot. By leveraging their combined expertise, the collaboration aims to rapidly scale existing solutions and create more personalized experiences for patients and clinicians. Through this initiative, Providence aims to transform healthcare delivery and improve outcomes by harnessing the power of the cloud and advanced AI technologies.

Reinforcing our commitment to Responsible AI

As incredible as AI – and all its potential – is, the important role clinicians play in determining its use and enabling responsible AI guidelines is vital. That’s why we remain steadfast in our commitment to our Responsible AI principles, which help to ensure safe, fair and responsible use of the technology. As part of this ongoing commitment, Microsoft has joined a consortium of healthcare leaders to announce the formation of the Trustworthy & Responsible AI Network (TRAIN), creating one of the first health AI networks aimed at operationalizing responsible AI principles to improve the quality, safety and trustworthiness of AI in health.

Serving as the technology-enabling partner for TRAIN, Microsoft is working with members that include AdventHealth, Advocate Health, Boston Children’s Hospital, Cleveland Clinic, Duke Health, Johns Hopkins Medicine, Mass General Brigham, MedStar Health, Mercy, Mount Sinai Health System, Northwestern Medicine, Providence, Sharp HealthCare, University of Texas Southwestern Medical Center, University of Wisconsin School of Medicine and Public Health and Vanderbilt University Medical Center – to share best practices and provide tools to enable measurement of outcomes associated with the implementation of AI. Additionally, OCHIN, which serves a national network of community health organizations with solutions, expertise, clinical insights and tailored technologies, and TruBridge, a partner and conduit to community healthcare, will work with TRAIN to help ensure that every organization, regardless of resources, has access to the benefits the network offers.

Additionally, we continue to take the necessary steps to ensure healthcare organizations can implement technology in compliance with the highest levels of security and privacy in mind. We recently announced the preview of healthcare data solutions in Microsoft Fabric, which enables healthcare organizations to break down data silos and harmonize their disparate healthcare data in a single unified store where analytics and AI workloads can operate at-scale. We are also pleased to share that Fabric now supports HIPAA (Health Insurance Portability and Accountability Act) compliance, allowing our U.S. healthcare industry customers and partners to compliantly use Fabric to store, process and analyze data.

Driving innovation through the Microsoft partner ecosystem

Microsoft’s unmatched global ecosystem of trusted partners is one of the key components that helps drive our innovation forward. This week, Cognizant announced that its TriZetto Assistant on Facets will leverage Microsoft Azure OpenAI Service and Semantic Kernel to provide access to generative AI within the TriZetto user interface. This new collaboration will help increase productivity and efficiency for healthcare payers and providers, while ensuring timely responses and improved care for patients.

Additionally, Microsoft for Startups announced a new collaboration with the American Medical Association’s (AMA) Physician Innovation Network. The Physician Innovation Network is a powerful match-making tool developed by the AMA to connect physicians, care team members, business liaisons and entrepreneurs in a shared mission to enhance healthcare. The collaboration extends the reach of the Physician Innovation Network to all startup founders in the Microsoft for Startups Founders Hub, so whether they’re driven to improve healthcare, collaborate with industry leaders or learn from healthcare experts, they will have access to a unique space for connection and innovation.

Without a doubt, these are incredibly exciting times, and we are proud to see our customers and partners adopting Microsoft’s generative AI solutions and putting them to use in the real world to make a meaningful impact in the lives of clinicians and patients. We look forward to continuing to play a leading role in fostering innovation with generative AI, and empowering healthcare providers and partners across the entire health and life sciences industries with leading-edge and responsible AI technologies that contribute to better experiences and outcomes in healthcare.

_____

[i] IDC InfoBrief, sponsored by Microsoft, The Business Opportunity of AI: How Leading Organizations Around the World Are Using AI to Drive Impact Across Every Industry, IDC #US51364223, Nov. 2023.

[ii] IDC Resource Map Document: IDC Business Value of AI Survey, sponsored by Microsoft, IDC #US51331223, Nov. 2023.

Tags: AI, healthcare, Microsoft Copilot, Microsoft Fabric, Microsoft for Startups, Responsible AI"
Microsoft_News,https://www.microsoft.com/en-us/microsoft-365/blog/2024/03/07/data-residency-in-the-ai-era-new-capabilities-to-manage-your-data/,,Announcing the expansion of Microsoft’s data residency capabilities,"In January, we updated our Microsoft Copilot product line-up to expand Copilot for Microsoft 365 to more businesses and announced no seat minimum for commercial plans.

Now we’re excited to announce the expansion of Microsoft’s data residency capabilities by adding content of interactions with Microsoft Copilot for Microsoft 365 to our portfolio of data residency commitments and offerings. We are expanding our product terms and Microsoft 365 data residency offerings to contractually guarantee that we will store the content of your interactions with Copilot for Microsoft 365 in the same country or region in which you store your existing Microsoft 365 content.

Since the early days of cloud computing, Microsoft has built our products and services with security, privacy, compliance, and transparency at their foundation. We know that you’re entrusting us with one of your most valuable assets—your data. Our time-tested approach to data privacy is grounded in our commitment to give you control over the data you put in the cloud, and this includes where you store it. The tremendous advancements AI has brought to productivity, security, and learning have placed a spotlight on these foundational data privacy and residency commitments, but they haven’t changed them. The technology has evolved, but our values are consistent.

New Copilot for Microsoft 365 data commitments and offerings

With this announcement, you have the assurance that content for interaction data with Copilot for Microsoft 365 will be stored according to your specified data storage location for Microsoft 365 data. This commitment only applies to customers whose tenants are provisioned in specific geographies, with add-on options available for additional geographies below. You can already delete content of interactions data with Copilot for Microsoft 365 at any time.

Microsoft 365 provides an array of data storage options to help support your data residency and privacy obligations. Each of the following also applies to content of interactions with Microsoft Copilot for Microsoft 365.

Product Terms Data Residency provides data residency commitments for Exchange Online, SharePoint Online, and Microsoft Teams in the following country and regions: Australia, Brazil, Canada, France, Germany, India, Japan, Norway, Qatar, South Africa, South Korea, Sweden, Switzerland, the United Kingdom, the United Arab Emirates, United States, and the European Union.

Advanced Data Residency add-on (ADR) provides eligible customers with expanded coverage of Microsoft 365 workloads, committed data residency in local datacenter regions, and prioritized tenant migration services. ADR is available in all the regions covered by Product Terms Data Residency, as well as Poland, Italy, and Israel with new local data center regions in Mexico and Spain coming soon.

Multi-Geo Capabilities add-on provides customers with the ability to expand their Microsoft 365 presence to multiple geographic regions within a single existing Microsoft 365 tenant. Multi-Geo Capabilities are available in the same set of local regions as ADR plus the three macro regions—Americas, Asia-Pacific, and European Union. Please review details for covered workloads.

EU Data Boundary allows customers in the European Union and the European Free Trade Association to keep their data in the EU.

What’s next?

We have updated our commitments to reflect the inclusion of Copilot for Microsoft 365 content interaction data. Customers within the scope of these commitments can rest assured that this data will be stored within their local region. Later this year, we will expand the Data Location Card in the Microsoft 365 admin center to include Copilot for Microsoft 365. This Data Location Card currently allows Microsoft 365 customers to view their specific geographic storage location for Exchange Online, SharePoint Online, and Microsoft Teams. For customers using the ADR add-on, the Data Location Card offers additional transparency of geo location for extended workloads.

We encourage you to contact your Microsoft account team to learn about the options available to manage your organization’s data, and especially whether Advanced Data Residency or Multi-Geo capabilities would help meet your data residency needs.

Our vision for Microsoft Copilot is to bring the power of generative AI to everyone. Thank you for your trust in us as we continue this journey together.

Learn more about Microsoft Copilot and visit the Copilot for Work site for actionable guidance on how you can start transforming work with Copilot today.

Take the power of AI on the go with the Copilot app—your everyday AI companion. Download now for a one-month free trial of Copilot Pro.

For critical research insights on the future of work and generative AI, subscribe to WorkLab.

Microsoft Copilot was used as an assistant to write and edit this blog."
Microsoft_News,https://news.microsoft.com/a-dai-in-the-life/,,A dAI in the life: Simple AI tricks for getting more out of each day,"AI is probably already a part of your day, helping navigate your trip to work, recommending movies you’ll like or predicting words when you’re texting friends.

But some of the latest tools can help you do even more. You can use AI to get dinner recipes for what’s in your fridge, advice on how to train your puppy, or a summary of an important meeting so you can focus on your coworkers instead of taking notes.

Welcome to Microsoft’s “A dAI in the life,” where people are sharing stories of how they’re using AI in their personal and professional lives. Take a peek through their daily diaries for tips and tricks that might be helpful, productive and fun."
Microsoft_News,https://news.microsoft.com/source/features/digital-transformation/educators-and-students-now-have-a-secure-ai-scaffolding-to-support-them-in-the-classroom/,,Educators and students now have a secure AI ‘scaffolding’ to support them in the classroom,"Clare Prowse needs ideas for a “medical mystery” course for her 10th-grade biology students and has turned to AI. As the sample curriculum it created scrolls down her screen, she gushes over its bullet points and ready-to-use formatting — not to mention its suggestion of exploring a famous historical case she hadn’t thought of in years.

“Oh, the mystery of Phineas Gage, that would be a fascinating one,” says Prowse, who’s been using Microsoft Copilot for the last few months to help with “the work that adds to a full day of classes” as she teaches at Seattle’s O’Dea High School. “I might not use all of this, but it gets me thinking. It gave me the scaffold, and now I can go off and do this.”

From helping to draft course plans to inspiring homework ideas to jump-starting recommendation letters, teachers worldwide are reveling in the time savings they’re seeing with new AI tools such as Copilot. The technology is helping them focus more on their classrooms — and on the paradigm shift underway for learners as those same tools are rolled out to students. Educators of students from children to adult researchers are starting to change the way they teach, focusing more on the fundamentals of each subject and less on the clerical aspects of assignments.

“The impact of AI in education is huge,” Prowse says.

Educators have been using Copilot with their school accounts, and soon students — including kids at O’Dea, a Catholic all-boys high school in Seattle — will have access, too. (Photo by Dan DeLong)

Ge Yan, a professor at Indiana University’s Kelley School of Business, began using Copilot for Microsoft 365 last November to take advantage of its assistance with various administrative tasks.

Yan likes to know his audience to help him tailor his teaching approach, so before every new class begins, he securely downloads the roster into Excel and breaks out demographics such as ages, genders, grade levels, majors, where students are from and more.

Even though he has a computer science MBA and more than two decades of experience creating spreadsheets and pivot tables, Yan found that Copilot in Excel could handle the job more efficiently. Being able to simply ask questions in the tool, rather than having to manipulate columns and cells between each query, helped his thought process flow more smoothly and naturally, Yan says, giving him a better picture of each incoming class.

Ge Yan, a professor at Indiana University.

Yan realized the same benefits could extend to students.

Educators have already begun piloting Copilot for Microsoft 365, and starting in April, higher education students 18 and older will be eligible, too.

So Yan started shifting his lessons to focus on the data insights his students should be contemplating instead of how to create pie charts to show what they find.

“Even for business majors,” who ostensibly do need to know how to build spreadsheets, Yan says, “we’re transitioning to teach them more of the what and why rather than the how to do that stuff.”

Yan was curious what his 8-year-old daughter, Tanya, would think about Copilot. She doesn’t share his interest in data or technology, but she likes birds, and was excited about a bird-watching assignment for school. So he downloaded a dataset from a national avian association.

“I said, ‘Do you know what’s the most observed species in Indiana?’ She said, ‘I don’t.’ I said, ‘OK, let’s type it in and ask.’ And boom, it’s the red cardinal,” Yan says. “There were a thousand observations in that file, and she was able to see the top three and their colors and sizes, and then I said, ‘OK, let’s go to the park and see if we can find those birds.’”

Ge Yan helped his technology-averse daughter, Tanya, use Copilot for a “learner-centric” experience looking for birds in Indiana. (Photo provided by Yan)

Instead of being given information and instructions, Yan was able to help Tanya extract knowledge from the database herself, unlocking new awareness as she saw the full context of where a falcon fits among the hundreds of birds in their state, he says. And instead of spending the afternoon in front of a computer learning how to create a pivot table, the father and daughter got to spend more time outside, pondering concepts such as why purple martins might prefer the climate in Indiana.

“It wasn’t spoon-fed to her by a parent or teacher,” Yan says. “It’s a learner-centric model. If I’m the one designing the pivot table and I’m interested in the color of the bird, then guess what, what the kids are seeing first is going to be the color of the bird.

“But now, as long as someone knows how to type and can translate the insight they’re looking for into a prompt,” Yan says, “they can do data analysis with Copilot in three seconds.”

Anne Leftwich, associate vice president for learning technologies at Indiana University.

Anne Leftwich uses the word “phenomenal” a lot when she talks about how AI has helped her reduce “the laborious minutiae tasks” that come with her job as associate vice president for learning technologies at Indiana University.

Leftwich started out using Copilot in Teams to provide transcripts, summaries and action items from meetings with faculty, staff and students. If she was late, got distracted by an urgent email, or had to step away to walk her kids to the bus stop, she’d prompt Copilot for a summary of the timeframe she’d missed and then could jump into the discussion without having to interrupt the flow by asking fellow participants to catch her up.

“I have too many tabs open in my brain, so this is helpful in keeping track of all those things,” she says. “And the nice part about Copilot (for Microsoft 365) is that it’s all staying within your unit’s data cloud.”

Before long, Leftwich started to “play with all the buttons and try all the things” — and that’s when the time savings really started adding up.

Being a teacher is never just about teaching. There’s planning, developing assignments, making rubrics, creating quizzes, writing recommendation letters, communicating with students and parents, researching, writing papers and presentations, and more. Leftwich says AI tools now help her complete administrative tasks in minutes that used to take hours.

Anne Leftwich started using Copilot in Teams to help her get caught up in meetings if she had to step away — such as to walk her daughters, Holland and Bryn, to the bus stop. The time savings really added up when she began using the AI tool in PowerPoint and Word as well. (Photo provided by Leftwich)

For the self-described design-challenged professor — “I’m a former elementary school teacher, and everything I do tends to turn into rainbows and sparkles” — who has to create hundreds of presentations every year, Copilot in PowerPoint has made a big difference. Leftwich can pull an outline into the app, type in a few guiding prompts, and within moments Copilot crafts a polished, professional, cohesive design that she says she never could have come up with on her own, even if she’d spent hours working on it.

Clerical assistance aside, it’s the chat function with AI tools that causes the most consternation in education circles. New technology such as Copilot is based on large language models that have been trained by running huge amounts of data through algorithms, or sets of instructions, that helps them learn patterns and relationships in language so they can respond the way a human might when they answer questions and solve problems. But the systems can’t tell the difference between what’s real and what’s fake, so they can give inaccurate responses.

Prowse says her students started using AI in their schoolwork as soon as it became widely available through ChatGPT at the end of 2022. While she readily knows whether something is accurate or suspect when she asks it a biology question, she says, her students don’t, and need to be taught how to fact-check the results.

Clare Prowse, a biology teacher at Seattle’s O’Dea High School. (Photo by Dan DeLong)

“But it’s my job to prepare them for life, and this is going to be part of their lives,” Prowse says. “Copilot will be one of those things everyone has. So I thought, I’d rather take this bull by the horns and get in there and talk to them about what it can do well and what it can’t.”

To make sure she’s assessing a student’s grasp of the material, rather than an AI program’s knowledge of it, Prowse gives the kids clear parameters for when and how they’re allowed to use the tools. She has certain assignments done in the classroom without devices, for example. Once O’Dea students get Copilot on their school accounts, she plans to ask them to share their tutoring chats so she can see the follow-up questions they ask and if those demonstrate they’ve understood the information.

Most exciting for Prowse, she plans to have Copilot help students with one of her favorite assignments: creating podcasts about ecological systems. It’s a popular project, but Prowse finds it frustrating to spend a biology class talking about intro music, the best Q&A format, or how to structure an episode so it’s less than two minutes long.

Clare Prowse helps O’Dea High School student Giulio Banchero during a biology class. (Photo by Dan DeLong)

“They do the research, but then it can take them four whole class periods just to write the script,” she says. “So I’ll use AI to shorten up the time it takes on the podcasts and let me teach them more science — and they’ll have a really nice product at the end that they can be really proud of.”

Educators and students 18 and older can use Copilot with their school accounts, giving them commercial data protection and a secure chat service. And Microsoft is expanding that option with a private preview program for younger learners in coming months.

While Prowse and others are cautious about the new technology, they say its impact on both sides of the education equation — teachers and students — is providing a springboard for more creativity and a framework that frees up time from organizational tasks to focus on the subjects being taught.

“And once the students learn how to use AI and get enough practice,” Prowse says, “the scaffolding thing will work for them, just like it works for me.”

Top photo: Clare Prowse, a teacher at Seattle’s O’Dea High School, helps students Hutton Leverett, Hugh Lear and Moriah Abner. (Photo by Dan DeLong)"
Microsoft_News,https://blogs.windows.com/msedgedev/2024/02/29/ai-powered-tools-in-edge/,,Latest (and greatest) AI-powered tools in Edge you didn’t know you needed,"Advances in AI technology can be intimidating and maybe even overwhelming, but they do open up a whole new set of tools to help you tackle your day.

At Microsoft Edge, we’ve been developing AI-powered tools to help you browse smarter and achieve more than you thought possible. And what better time than now to make AI work for you.

To get you started, we are breaking down our top AI-powered tools you didn’t know you needed:

Find exactly what you’re looking for, faster

Microsoft Copilot tops this list, as your everyday AI companion, saving you time on common tasks like starting a draft message or finding the information you need, faster. However, did you know that Copilot can do even more when accessed in Edge? In Edge, you can not only ask Copilot for information, but you can also ask questions about information you’re viewing on the browser – at home or on the go. Let’s say you’re using Copilot to do research on starting a garden. While viewing that “Gardening 101” article, you can get explanations on certain portions by simply highlighting the text to ask Copilot. And that’s not all – this past month we’ve added even more functionality to Copilot that’s only available in Edge:

New to Copilot in Edge is video highlights . Copilot in Edge can now help you find exactly what you need within a video in less time. Take the gardening example. Say you find a good beginners guide video; Copilot in Edge will break it down for you into clickable time stamps, so you can jump to the parts of the video that matter most to you or go back to specific parts you want to rewatch. You can also ask Copilot questions about the video like, “what does this video say about best time of the year to start a garden?” This is a time saver – not just for DIY projects, but training videos and more – even catching sports highlights!

. Copilot in Edge can now help you find exactly what you need within a video in less time. Take the gardening example. Say you find a good beginners guide video; Copilot in Edge will break it down for you into clickable time stamps, so you can jump to the parts of the video that matter most to you or go back to specific parts you want to rewatch. You can also ask Copilot questions about the video like, “what does this video say about best time of the year to start a garden?” This is a time saver – not just for DIY projects, but training videos and more – even catching sports highlights! You can now use screenshots in Copilot to find exactly what you want. For example, say you find a photo of a plant you love, but have no other information, simply use the screenshot tool in Copilot in Edge and give prompts like “What is the name of this plant?” This functionality is now generally available in Edge.

Keep your browser organized

The browser is a key part of our online life. We do everything in it: work, learn, manage finances, entertainment, shopping – and we often do these tasks in the same window. It is not surprising that keeping tabs organized becomes more of a necessity. Turns out, AI can also help you keep your browser organized.

Aside from being able to align tabs vertically and pin tabs, Edge can also automatically organize your tabs into groups using the power of AI. Tab auto-grouping is an AI-powered tool we launched back in September of last year, and we’ve received great feedback so far. With tab auto-grouping you can organize your tabs in less time. For example, as you go deeper into your gardening research, it is likely that you’ll have many tabs from articles to shopping to videos, which you’d like to organize and keep for future reference. To access tab groups, simply select the Tab Action Menu located next to your tabs and then select Organize tabs to let Microsoft Edge group them by relevance and assign them a name and a color. You can also give Copilot the prompt in chat to group similar tabs, and it will get it done for you in no time. Tab groups are automatically pinned by default, so if you close your browser, they will be there when you return. Also, we make sure you’re getting the best browser performance by putting inactive tab groups to sleep, therefore allowing active groups to perform better.

Shop online with confidence

If you’re looking to shop for all the products you’ll need to start gardening, Microsoft Edge is the best place to start. With built-in tools like coupons, price comparison, price history, and cash back, shoppers can save over $400 per year with Microsoft Edge. Edge is also equipped with Copilot to deliver AI-powered shopping assistance, comprehensive buying guides, smart product comparisons, review summaries, and more. Our goal is to make it easy to get the right product at the right price and enjoy the thrill of every purchase on Edge.

I cannot move to the next item on our list without talking about our newest shopping (and security feature): Wallet. This Microsoft Edge tool combines shopping convenience and data security. Wallet is designed to be the one place where you store your payment methods, passwords, and more. With Wallet, you can also access your Microsoft Rewards or Cashback balances or use online payment security measures like virtual cards 1 to protect you from hacks and leaks. It all works seamlessly with the data you have already securely stored in Microsoft Edge.

Explore the web in ways that work best for you

Read aloud is another fan favorite we’d like to remind you about. We’ve heard customers love using it as a hands-free way to cook with their favorite recipes, and it’s made a big difference in terms of making web content more accessible to all. In fact, it’s helped users read more than 150 million articles every year.

Read aloud is one of our original AI-powered tools and is designed to allow you to step away from the screen and listen to content while performing other tasks. From an accessibility perspective, it can help improve your reading comprehension by hearing content at your own pace, in your desired language. With Read aloud, you can be out working in your yard and listening along to a step-by-step article on getting the soil ready for planting. Because, yes, that is right, read aloud is not just available on desktop, it is also available in the Edge mobile app – both on iOS and Android. And even if your connection is spotty in the yard, it works offline 2 . You can also adjust the pace to faster or slower and customized voice options, and it even works with PDFs.

To access Read aloud on desktop, simply click on the Read aloud icon on your Edge tool bar to get started. On mobile, you can access from the main menu, or from the address bar icon.

To learn more, visit aka.ms/edge-ai-powered and please continue to send us your feedback as we work to create web experiences and tools to give you a smarter way to browse.

Remember, if you’re running a Windows PC, you already have Microsoft Edge installed, so check it out and see why Microsoft Edge is the smarter way to browse. For those who want to try Microsoft Edge and are on a macOS, mobile or Linux device, download it and let us know what you think 3 !"
Microsoft_News,https://blogs.windows.com/windowsexperience/2024/02/29/microsoft-copilot-improvements-for-windows-11/,,Microsoft Copilot improvements for Windows 11,"Microsoft Copilot is your everyday AI companion. As we continue to innovate with Windows, we’re delighted to introduce some useful new features to our Copilot Preview1 for Windows 11. These new capabilities build on the introduction of the Copilot Key on new Windows 11 PC keyboards2, updates to the Copilot icon on the taskbar, and the ability to dock, undock and resize the Copilot pane.

Starting today, we introduce plugins from your favorite apps like OpenTable, Shopify and Kayak, as well as new skills to simplify your tasks and use of Windows. We can’t wait for you to try these.

In addition to the new features in Copilot, over the next month, we are bringing even more value to Windows 11. We are adding new AI editing capabilities in Photos designed to make creating simpler, enabling easier video editing with the preview of Clipchamp silence removal, and launching improvements to features like Snap, Widgets and Inking, making it even easier to get things done. For our commercial customers, we are also making it even easier to securely manage updates across your organization.

Copilot in Windows 11

New plugins

With Copilot in Windows, you can now use plugins for easy access to some of your favorite applications.

Need to make a dinner reservation with friends? Ask Copilot and OpenTable to handle it. Change your mind and want to stay in? Simply prompt Copilot with “Create a healthy dinner party menu for 8” and watch your options unfold. Not happy with the salad suggested? Ask Copilot to swap it for a vegetable and when you’re ready to shop, Instacart is right there for you, all within Copilot in Windows.

Over the next month, we will be adding new ways to connect and get things done from partners like Shopify, Klarna and Kayak, in addition to what OpenTable and Instacart and a growing list of other Copilot in Windows plugins can do.

New skills

Sometimes we all need a little help in getting things done, including adjusting our PC settings, quickly accessing the tools and information to make learning and doing easier, and finding the fastest access to help, all at our fingertips.

Beginning in late March, you will see the following new skills enabled within your Copilot in Windows experience. To use these skills, simply type in a prompt to Copilot in Windows. For example, type “enable battery saver” or “turn off battery saver” and Copilot will take the appropriate action and confirm completion.

Settings: Turn on/off battery saver Show device information Show system information Show battery information Open storage page

Accessibility: Launch live captions Launch narrator Launch screen magnifier Open voice access page Open text size page Open contrast themes page Launch voice input

Device information: Show available Wi-Fi network Display IP address Show available storage space Empty recycle bin



New creativity app updates

Building on the success of our AI-enhanced Inbox apps, today we begin rolling out two exciting updates designed to make creating simpler.

Generative Erase: When using the Photos app, you can now select and remove unwanted objects or imperfections from your images using the new Generative Erase feature. Snapped the ideal sunset photo but want to remove the airplane flying above? Generative Erase in Photos can do just that.

Clipchamp silence removal preview: Gaps in conversation are natural in real life, but awkward in a video. With the addition of Clipchamp silence removal, removing those gaps in the audio track is easy. The preview of silence removal in Clipchamp starts to become available today.

Accessible by default

Voice Shortcuts: Save your voice and finish tasks faster with new Voice Shortcuts. You can now create custom commands to quickly accomplish what you’re trying to do using just a single phrase. From pasting text and media, pressing keyboard keys or mouse clicks, to opening folders, files, apps or URLs, Voice Shortcuts are there to help.

Multi-Display: To make navigating a multiple monitor setup even easier, you can now use voice commands across connected screens, making it easier than ever to navigate between displays or move files and apps.

More to love on Windows 11

Windows 11 and your Android platform phone

Your Windows 11 PC and Android phone connection just got better. Soon you will be able to access recent photos on your PC or use your phone as a webcam on all video conferencing apps, making your Android device a productivity partner to your Windows 11 PC.

Intelligent Snap suggestions: Make the most of your screen real estate with new personalized layout suggestions. Snap suggestions help you quickly organize open apps based on how you use them, making it even easier to get things done.

Widgets: Many of us experience information overload from time to time, but still need to stay up to date on the information we care about most. Now with the new Widgets board experience, you are able to create a focused board and organize your Widgets into distinct categories – whether for work or play. If you’re looking to catch up on current events, you’ll find the familiar experience currently available through your feed located right in the discovery dashboard.

Windows Ink: Windows Ink enables natural writing on pen-capable PCs. With this update, we are expanding the number of apps and languages available to Windows Ink to include your favorites like Photos, Paint, WhatsApp and Messenger, all offering greater flexibility for where you ink or type.

Share content to more third-party apps: Need to share your favorite vacation photo with a friend on Snapchat? Windows 11 has expanded the file sharing options to include additional apps like WhatsApp, Snapchat and Instagram, with more apps like Facebook Messenger coming soon.

A unified management solution for our enterprise customers

For our enterprise customers, we are simplifying the update management solution by unifying the Windows Update for Business deployment service with Autopatch into a single update management solution.

Windows Autopatch will now become the unifying Windows update management solution, providing a single way in which organizations can manage updates while maintaining the highest level of control. Windows Autopatch provides the update solution for Windows PCs, Microsoft 365 applications, Microsoft Edge and Teams, and will now leverage AI to program the necessary updates and reduce the impact on team productivity. Learn more about what’s new in Autopatch.

How to take advantage of these new and improved features

Many of these new experiences will start to become available today, via Windows Update and new apps available via Microsoft Store updates. Windows 11 devices will get new functionality at different times, as we will be gradually rolling out some of these new features over the coming weeks initially via controlled feature rollout (CFR) to consumers. Consumers with eligible devices running Windows 11, versions 22H2 and 23H2, who are interested in experiencing these new enhancements now can choose to do so by going to Settings > Windows Update and turning on “Get the latest updates as soon as they’re available” and then selecting “Check for updates.” We anticipate broad availability for most new features by the April 2024 security update release for all eligible devices.

Most of these new Windows 11 features will be enabled by default in the March 2024 optional non-security preview release for all editions of Windows 11, versions 23H2 and 22H2. IT admins who want to get the new Windows 11 features can use the enable and control optional updates policy to enable optional updates for their managed devices.

As is our normal practice, we will closely monitor the rollout of these new Windows 11 features and continue to share timely information on the status of the rollout and known issues (open and resolved) via the Windows release health dashboard and @WindowsUpdate. Please continue to tell us about your experience by providing comments or suggestions via Feedback Hub.

For a full list of features available via Windows Update, learn more here.

Ready to upgrade to a new Windows 11 PC? Find the PC that’s right for you.

1 Copilot in Windows (in preview) is available in select global markets and will be rolled out to additional markets over time. Learn more.

2 When Copilot for Windows is not available or enabled on the device, pressing the Copilot key will launch Windows Search. The Copilot key will be available on many new Windows 11 PCs starting in early 2024."
Microsoft_News,https://blogs.windows.com/msedgedev/2024/02/29/ai-powered-tools-in-edge/,,Latest (and greatest) AI-powered tools in Edge you didn’t know you needed,"Advances in AI technology can be intimidating and maybe even overwhelming, but they do open up a whole new set of tools to help you tackle your day.

At Microsoft Edge, we’ve been developing AI-powered tools to help you browse smarter and achieve more than you thought possible. And what better time than now to make AI work for you.

To get you started, we are breaking down our top AI-powered tools you didn’t know you needed:

Find exactly what you’re looking for, faster

Microsoft Copilot tops this list, as your everyday AI companion, saving you time on common tasks like starting a draft message or finding the information you need, faster. However, did you know that Copilot can do even more when accessed in Edge? In Edge, you can not only ask Copilot for information, but you can also ask questions about information you’re viewing on the browser – at home or on the go. Let’s say you’re using Copilot to do research on starting a garden. While viewing that “Gardening 101” article, you can get explanations on certain portions by simply highlighting the text to ask Copilot. And that’s not all – this past month we’ve added even more functionality to Copilot that’s only available in Edge:

New to Copilot in Edge is video highlights . Copilot in Edge can now help you find exactly what you need within a video in less time. Take the gardening example. Say you find a good beginners guide video; Copilot in Edge will break it down for you into clickable time stamps, so you can jump to the parts of the video that matter most to you or go back to specific parts you want to rewatch. You can also ask Copilot questions about the video like, “what does this video say about best time of the year to start a garden?” This is a time saver – not just for DIY projects, but training videos and more – even catching sports highlights!

. Copilot in Edge can now help you find exactly what you need within a video in less time. Take the gardening example. Say you find a good beginners guide video; Copilot in Edge will break it down for you into clickable time stamps, so you can jump to the parts of the video that matter most to you or go back to specific parts you want to rewatch. You can also ask Copilot questions about the video like, “what does this video say about best time of the year to start a garden?” This is a time saver – not just for DIY projects, but training videos and more – even catching sports highlights! You can now use screenshots in Copilot to find exactly what you want. For example, say you find a photo of a plant you love, but have no other information, simply use the screenshot tool in Copilot in Edge and give prompts like “What is the name of this plant?” This functionality is now generally available in Edge.

Keep your browser organized

The browser is a key part of our online life. We do everything in it: work, learn, manage finances, entertainment, shopping – and we often do these tasks in the same window. It is not surprising that keeping tabs organized becomes more of a necessity. Turns out, AI can also help you keep your browser organized.

Aside from being able to align tabs vertically and pin tabs, Edge can also automatically organize your tabs into groups using the power of AI. Tab auto-grouping is an AI-powered tool we launched back in September of last year, and we’ve received great feedback so far. With tab auto-grouping you can organize your tabs in less time. For example, as you go deeper into your gardening research, it is likely that you’ll have many tabs from articles to shopping to videos, which you’d like to organize and keep for future reference. To access tab groups, simply select the Tab Action Menu located next to your tabs and then select Organize tabs to let Microsoft Edge group them by relevance and assign them a name and a color. You can also give Copilot the prompt in chat to group similar tabs, and it will get it done for you in no time. Tab groups are automatically pinned by default, so if you close your browser, they will be there when you return. Also, we make sure you’re getting the best browser performance by putting inactive tab groups to sleep, therefore allowing active groups to perform better.

Shop online with confidence

If you’re looking to shop for all the products you’ll need to start gardening, Microsoft Edge is the best place to start. With built-in tools like coupons, price comparison, price history, and cash back, shoppers can save over $400 per year with Microsoft Edge. Edge is also equipped with Copilot to deliver AI-powered shopping assistance, comprehensive buying guides, smart product comparisons, review summaries, and more. Our goal is to make it easy to get the right product at the right price and enjoy the thrill of every purchase on Edge.

I cannot move to the next item on our list without talking about our newest shopping (and security feature): Wallet. This Microsoft Edge tool combines shopping convenience and data security. Wallet is designed to be the one place where you store your payment methods, passwords, and more. With Wallet, you can also access your Microsoft Rewards or Cashback balances or use online payment security measures like virtual cards 1 to protect you from hacks and leaks. It all works seamlessly with the data you have already securely stored in Microsoft Edge.

Explore the web in ways that work best for you

Read aloud is another fan favorite we’d like to remind you about. We’ve heard customers love using it as a hands-free way to cook with their favorite recipes, and it’s made a big difference in terms of making web content more accessible to all. In fact, it’s helped users read more than 150 million articles every year.

Read aloud is one of our original AI-powered tools and is designed to allow you to step away from the screen and listen to content while performing other tasks. From an accessibility perspective, it can help improve your reading comprehension by hearing content at your own pace, in your desired language. With Read aloud, you can be out working in your yard and listening along to a step-by-step article on getting the soil ready for planting. Because, yes, that is right, read aloud is not just available on desktop, it is also available in the Edge mobile app – both on iOS and Android. And even if your connection is spotty in the yard, it works offline 2 . You can also adjust the pace to faster or slower and customized voice options, and it even works with PDFs.

To access Read aloud on desktop, simply click on the Read aloud icon on your Edge tool bar to get started. On mobile, you can access from the main menu, or from the address bar icon.

To learn more, visit aka.ms/edge-ai-powered and please continue to send us your feedback as we work to create web experiences and tools to give you a smarter way to browse.

Remember, if you’re running a Windows PC, you already have Microsoft Edge installed, so check it out and see why Microsoft Edge is the smarter way to browse. For those who want to try Microsoft Edge and are on a macOS, mobile or Linux device, download it and let us know what you think 3 !"
Microsoft_News,https://blogs.microsoft.com/blog/2024/02/29/introducing-microsoft-copilot-for-finance-the-newest-copilot-offering-in-microsoft-365-designed-to-transform-modern-finance/,,Introducing Microsoft Copilot for Finance – the newest Copilot offering in Microsoft 365 designed to transform modern finance,"Today we’re announcing the public preview of Microsoft Copilot for Finance, the newest Copilot offering designed for business functions that extends Microsoft Copilot for Microsoft 365 and revolutionizes how finance teams approach their daily work. Copilot for Finance joins Copilot for Sales and Copilot for Service, now generally available, to provide AI-powered, role-based workflow automation, recommendations and guided actions in the flow of work.

Finance departments are critical partners in strategic decisions impacting the direction of a company. Eighty percent of finance leaders and teams face challenges to take on more strategic work outside the operational portions of their roles[1]. However, 62% of finance professionals say they are stuck in the drudgery of data entry and review cycles [2]. Copilot for Finance can help free up time for finance to play more of a strategic role in delivering counsel and insights to the business by streamlining financial tasks, automating workflows and providing insights in the flow of work.

Copilot for Finance includes Copilot for Microsoft 365, which means it supercharges Excel, Outlook and other widely used productivity apps with workflow and data-specific insights for the finance professional. Copilot for Finance draws on essential context from your existing financial data sources, including traditional Enterprise Resource Planning (ERP) systems, such as Microsoft Dynamics 365 and SAP, and the Microsoft Graph.

In public preview today, Copilot for Finance introduces several key features to enhance financial operations:

Helps financial analysts quickly conduct a variance analysis in Excel using natural language prompts to review data sets for anomalies, risks and unmatched values. This type of analysis helps finance provide strategic insights to business leaders about where it is meeting, exceeding or falling short of planned financial outcomes and why.

to review data sets for anomalies, risks and unmatched values. This type of analysis helps finance provide strategic insights to business leaders about where it is meeting, exceeding or falling short of planned financial outcomes and why. Simplifies the reconciliation process in Excel with automated data structure comparisons and guided troubleshooting to help move from insight to action, which helps ensure the reliability and accuracy of financial records.

with automated data structure comparisons and guided troubleshooting to help move from insight to action, which helps ensure the reliability and accuracy of financial records. Provides a complete summary of relevant customer account details in Outlook , such as balance statements and invoices, to expedite the collections process.

, such as balance statements and invoices, to expedite the collections process. Enables customers to turn raw data in Excel into presentation-ready visuals and reports ready to be shared across Outlook and Teams.

Customers transforming business operations with Microsoft Copilot

The Copilot offerings designed for business functions help workers tackle a common problem: getting from insights to impact – with the relevant data and workflows specific to their roles. The latest Work Trend Index survey revealed that people are drowning in data. Roughly a quarter of their day is spent searching for information – roughly 50% of the information they consume each day is deemed necessary for their job, and a recent survey found roles like sales, finance and supply chain have role-specific needs from their data.

Copilot helps break down information and application silos while actively deriving insights, recommendations and guidance from a variety of data sources — all in accordance with Microsoft’s responsible AI principles. With Microsoft Copilot Studio, businesses can further customize Copilot for business processes inside of Copilot for Microsoft 365 and its role-based extensions.

Copilot for Sales is already helping sellers at more than 30,000 organizations. Companies including dentsu, Lumen Technologies, Northern Trust, Schneider Electric, Visa and hundreds more are empowering their employees with Copilot across their sales, service and finance departments.

Here is what a few of the companies had to say:

“Artificial intelligence is transforming the way businesses operate and thrive. At dentsu, we are constantly searching for ways to bring the power of generative AI to all our employees with a framework defined on ethical and responsible AI principles. Building on the existing use cases we’ve defined to empower our workforce with Microsoft Copilot for Microsoft 365 and Microsoft Copilot for Sales, we are excited to participate in the preview of Microsoft Copilot for Finance. We see potential for Copilot for Finance to accelerate the impact of our finance professionals by optimizing routine processes, and we anticipate efficiency gains will free up finance capacity to focus on performance across our organization.” – Carolyn Isaacs, Global Director Finance Services, dentsu

“Northern Trust’s digital workplace transformation is rooted in empowering our employees with technology that enhances and optimizes the services that they provide our clients. Deploying Microsoft Copilot for Service is a milestone in this transformation journey and we are excited for the potential of this AI-powered solution to help modernize our client relations organization, streamline processes for our employees, and elevate our client experience.” – Shaelyn Otikor SVP, Head of Global Digital Workplace Strategy, Asset Servicing, Northern Trust

“Building on our 30-year history of embracing AI, Visa is on a journey to roll out generative AI across our entire company to empower our employees and develop new solutions to serve and protect our cardholders, merchants and the broader ecosystem. We’ve seen our employees embrace the broad rollout of Microsoft Copilot for Microsoft 365, and we’re excited to continue to bring employees new ways to take advantage of the technology, transforming the ways in which we work and how we service our clients.” – Don Hobson, Chief Information Officer, Visa

At Microsoft, we are also an AI-powered organization, leveraging Copilot for Sales and Copilot for Service to improve seller and agent workflows and transform customer experiences:

Microsoft Copilot for Sales empowers sellers to close deals faster with AI-assisted insights and recommendations. Our study of Microsoft sellers who use Copilot for Sales at least weekly found it makes them more productive, saving an average of 90 minutes per week – and 67% reported it allowed them to spend more time with customers. “We have seen firsthand that an AI-powered sales organization is a more successful sales organization. Not only has Copilot for Sales helped our global sales team simplify tasks and save time, but it has also strengthened our customer relationships with AI-supported insights and recommendations that are personalized and tailored to each customer.” – Judson Althoff, Microsoft EVP and Chief Commercial Officer

Our study of Microsoft sellers who use Copilot for Sales at least weekly found it makes them more productive, saving an average of 90 minutes per week – and 67% reported it allowed them to spend more time with customers. Microsoft Copilot for Service is modernizing the contact center with AI to enhance service experiences and boost agent productivity . In Microsoft’s customer service department – one of the largest in the world – there has been a 12% reduction in average case handling times (the time actively spent on resolving customer cases via chat) in two different customer support business areas while using similar capabilities in Copilot in Dynamics 365 Customer Service. The benefits and use cases from our own Copilot deployment will continue to shape Copilot for Service and its capabilities. “Generative AI has been a game-changer for our own contact center at Microsoft. Agents spend less time searching for information, allowing them to focus more time on helping customers solve complex challenges. Moreover, newer agents experience significant benefits, feeling more confident and capable in their roles. This has led to reduced onboarding times and increased job satisfaction.” – Mala Anand, Microsoft CVP Customer Experience & Success

. In Microsoft’s customer service department – one of the largest in the world – there has been a 12% reduction in average case handling times (the time actively spent on resolving customer cases via chat) in two different customer support business areas while using similar capabilities in Copilot in Dynamics 365 Customer Service. The benefits and use cases from our own Copilot deployment will continue to shape Copilot for Service and its capabilities. Microsoft Copilot for Finance streamlines financial processes and surfaces insights for better-informed decision making. Microsoft’s world-class finance organization has long prioritized adoption of AI and automation tools to modernize operations, reduce financial risk and support the company’s priorities with strategic insights. The team has helped inform the Copilot for Finance product capabilities and roadmap. “Our finance organization is just like any other – looking for technology to help us do our work in a more efficient and impactful way – and we’re excited to track our journey as customer zero of Microsoft Copilot for Finance” – Cory Hrncirik, Modern Finance Lead, Microsoft

Microsoft’s world-class finance organization has long prioritized adoption of AI and automation tools to modernize operations, reduce financial risk and support the company’s priorities with strategic insights. The team has helped inform the Copilot for Finance product capabilities and roadmap.

Companies of all sizes are moving beyond AI experimentation and embracing Microsoft Copilot to strategically empower those closest to their customer interactions and critical operations to create new business value. To get started with the new Copilot for Finance, visit: aka.ms/CopilotforFinancePreview.

[1] Future of Finance Trends | Microsoft Dynamics 365

[2] Metric of the Month: Time Allocation in Finance | CFO

Tags: AI, Copilot for Finance, Copilot for Microsoft 365"
Microsoft_News,https://www.microsoft.com/en-us/worklab/podcast/charles-duhigg-on-how-to-build-new-habits-for-the-ai-era,,Charles Duhigg on How to Build New Habits for the AI Era,"CHARLES DUHIGG: Everything that we can see about the future of tech is it’s going to be more and more like having a conversation, and less and less like using a calculator. And the faster we get into the habit of thinking about which conversation is the right kind of conversation with this particular type of AI or this particular interface, the faster we’re going to be able to use that tool effectively.

MOLLY WOOD: Today I’m talking to Charles Duhigg, a Pulitzer Prize–winning reporter, a bestselling author, and a renowned expert on the science of productivity, habit formation, and effective communication. We talked with him about how to use those good habits and human communication skills to unlock all the potential of AI, but also how to use AI to improve our human communication. Here’s my conversation with Charles.

[Music]

MOLLY WOOD: So Charles, your books, The Power of Habit and Smarter Faster Better, have really become touchstones for people who want to become more productive and form good habits. What’s your nutshell advice for leaders who are interested in these topics?

CHARLES DUHIGG: The biggest and most important thing is to understand that real productivity comes from building the habits that allow us to think more deeply, particularly when thought is needed. When we’re feeling stressed, when we’re feeling overwhelmed, when someone says, “I need an answer right now.” The ability to step back and say, How do I get myself to think more deeply at this moment? How do I get myself to be innovative on demand? Those are the things that lead to productivity. Productivity is not busyness. Productivity is about making the right choice when a choice is genuinely needed.

MOLLY WOOD: How, if at all, are your views evolving as technology evolves, the world around us evolves? I mean, it’s a combination of phones and now this question of AI and efficiency. How’s the thinking evolving, if at all?

CHARLES DUHIGG: So I think that one of the things that—let’s take generative AI, which has really been this huge disruptive force in a lot of positive ways within the tech industry and just the world at large. I’ve talked to a number of people who are working with it and designing it and developing it, and one of the things that they’ve consistently said is, this is essentially an add-on for human intelligence that makes human intelligence even more valuable. Because when you think about it, so much of what we do every day to be successful does not actually draw on our unique intelligence, right? The fact that I can sit at a computer and reply to 30 or 40 emails in an hour, whereas my competitor can only do 20 emails, means I’m going to beat them. But that’s not because I’m smarter than them, that’s because I’m more of a masochist than them. And so one of the things that AI will do, is it allows us to take those rote, unthinking activities, the activities that don’t really use our complete intellectual might, but instead just use a portion of it, and it’ll allow us to complete those tasks much more quickly. So I was talking to Mustafa Suleyman, who’s started an AI company, and I asked him, How do you think this is going to change the landscape? And he said, “I think for smart people, this will give them even more of an advantage. And for people who aren’t used to relying on their intelligence, who aren’t used to relying on their smarts, it’s going to pose a challenge to them because it’s going to force them to think in new and different ways.” That doesn’t mean they aren’t intelligent, they aren’t smart—and intelligence means different things to different people in different settings. But it does mean that now we’re going to be able to access that raw human intelligence, whereas before it was often mediated by just brute force.

MOLLY WOOD: Right, I mean, it feels like a kind of interesting, layered question of habit development and productivity. First, you have to develop a new habit around an entirely new technology, and then you have to filter for the correct habits to develop.

CHARLES DUHIGG: That’s exactly right. And what’s really interesting, though, is that it happens very automatically, right? A) because of how our brains form habits, but B) because this is what we know about technology and how we learn to use it. If you go back and you look at when telephones first became popular, there were all these articles about the fact that people would never be able to have a real conversation on the telephone. Because you couldn’t see each other, you couldn’t use non-verbal communication. And what’s interesting is that they were right at first. If you listen to early conversations or read transcripts on the telephone, they’re all very wooden and stilted. People aren’t actually communicating with each other. They basically figured this would be good for, like, sending grocery orders or stock orders. But of course, by the time you and I were teenagers, we could spend like seven hours on the phone and it was some of our closest, most intimate discussions ever. And it’s because humans have this amazing ability to learn how to use tech in the way that that tech is best used. Now sometimes that can be perverted, right? I think social media is a good example of when you can have undue influences that shape how we use tech. But for those of us who want to use tech and think about that tech, the process of building habits about when to use AI and how to use it, it’ll be very organic.

MOLLY WOOD: So you brought up this idea of communication. Your latest book is called Supercommunicators. This is a really big topic right now. Communication is one of the fundamental, so-called soft skills, and I think we’re realizing it’s one of the keys to really making AI work well for you. Tell me a little bit about what you learned in writing this book and what we can learn from people who are effective communicators.

CHARLES DUHIGG: So we’re living through this golden age of understanding the science of communication because of advances in neural imaging and data collection. A lot of the same things that make it possible for us to build things like GPT have also given us real insights into how people communicate with each other. And in particular what researchers have learned is that there are some questions that are more powerful than others in drawing people out. Those are known as deep questions because they ask about things like values and beliefs and experiences. We tend to think of a discussion as being about one thing, but actually each discussion is made up of multiple kinds of conversations, and that they tend to fall into one of three buckets, usually a practical conversation or an emotional conversation or a social conversation. But the fact that there is this science, this kind of calculus of why some people are better at communicating than others are, means that A) we can all learn how to do it, but B) it gives us insights into how we are going to need to communicate with, say, machines in the future. I mean, one of the things that’s interesting is—I have a 15-year-old son. The way he uses Bing and ChatGPT is, he has a conversation with it. He reads a book and none of his friends are reading it. And so he’ll open up a window and he’ll have a conversation with the computer about the book, and he finds it really edifying. It allows him to explore his own ideas and to get exposed to other perspectives that he hadn’t thought about. I, of course, never have a conversation with ChatGPT or Bing because I still think of a computer as a calculator, something that you give a problem and they return an answer. But everything that we can see about the future of tech is, it’s going to be more and more like having a conversation and less and less like using a calculator. And the faster we get into the habit of thinking about which conversation is the right kind of conversation with this particular type of AI or this particular interface, the faster we’re going to be able to use that tool effectively.

MOLLY WOOD: Tell me a little more about learning to be a good communicator before we talk more about using those skills with AI. It is counterintuitive to think that this is a skill that can be learned and developed.

CHARLES DUHIGG: The funny thing is it’s absolutely a skill. There are some people who are consistently good at this, and what sets them apart is not that they’re more charismatic or that they’re an extrovert—in fact, oftentimes they aren’t. What sets them apart is simply that they’ve thought about communication a little bit more deeply than other folks. So one of the things that we know about supercommunicators, for instance, is that they ask 10 to 20 times as many questions as the average person, but the questions that they ask, a lot of them we don’t even register as questions because they say things like, Huh, that’s interesting. What happened next? Or, what’d you say then? Oh yeah, what’d you think about that? There’s these questions that invite us into the conversation. And then they ask deep questions. Questions that ask us about our values, our beliefs, and our experiences. And that can sound kind of daunting, but that’s as simple as saying to someone like, What do you do for a living? Oh, I’m an attorney. Oh really? Did you always want to be an attorney? What made you decide to go to law school? Do you love your job? Those are three easy questions to ask, but all three of them are deep questions, because they get the other person to reveal something essential and meaningful about themselves. And then supercommunicators tend to reciprocate. They understand what kind of conversation is happening because they’re looking for clues. They match that kind of conversation—what’s known in psychology as the matching principle—and in doing so, they find a way to connect with someone and then invite them to match back.

MOLLY WOOD: So let’s bring this into this context of AI. We’ve talked on this show in previous episodes about how managers who seem to do the best job getting the most utility from AI are good at clearly articulating needs, delineating tasks, giving relevant context. But it sounds like you’re also saying that there is something in just being vulnerable or having a conversation or asking questions back to AI, the way you would interact with a person—or at least, is that what you’re learning from watching your son do this and combining it with what you’re learning about communication?

CHARLES DUHIGG: Yeah, that’s certainly true if we’re having conversations with other humans, right? That we tend to focus on what we want to say rather than trying to figure out what kinds of questions we can ask. And with AI, what’s really interesting—and again, we’re living through a period where we’re still trying to figure this out and we’re learning things every single day. But one of the things that we know is that, for instance, if you use emotional language with AI, you can increase its effectiveness. So if you use please and thank you, that tends to get you better answers. If you say something like, I need you to answer this question for my job, and it’s really, really important to me because the answer that you give me will determine whether I get a promotion, and I’m really hopeful that I get a promotion. Now there’s no reason why the large language model should care about you, and yet there’s something about presenting the question in that way that will raise the efficacy of the answer that it delivers. And it has to do with—obviously the training dataset that it was taught on has a lot of emotional language in it, and so it’s helping to identify which parts of that dataset it ought to pay attention to. And so it makes sense that this would have an impact. But because large language models are trained on the copus of human communication, the same rules that make humans good or bad communicators also influence whether the LLM gives us a good or bad answer. And a lot of it is about this back and forth. So one of the things that I’ve learned from my 15-year-old is, if you ask the AI questions about how it got to an answer—or more importantly, what other questions it thinks you should ask—it’ll say some really interesting and useful things. Sometimes it reveals a kind of an avenue that hadn’t even occurred to me to go down of inquiry.

MOLLY WOOD: What’s interesting is that as I hear you describe just that one example—if you help me with this answer and the answer is good enough, there’s a possibility I’ll get a promotion. That is also something that maybe wouldn’t occur to me to say to another person because it would be showing some vulnerability or it would be communicating in a way I didn’t think was that comfortable, but it would raise the stakes for that person also. It sounds like what you’re saying is, yeah, if this thing is trained on how to communicate effectively, then this is also what we should be doing with humans.

CHARLES DUHIGG: That’s exactly right. And one of the things that’s interesting about what you just said is, it wouldn’t occur to you to say that because it would be exposing a vulnerability, and you’re exactly right. There is this natural instinct not to expose that vulnerability, but what we know is that when you do expose a vulnerability, you actually make it more likely that the other person likes you and wants to help you, and most importantly, trusts you. Our ability to expose a vulnerability is at the core of the superpower that is communication. And this makes sense because, when you think about it, the way that communication evolved was it became the thing that set Homo sapiens apart. It’s the thing that allowed Homo sapiens to succeed better than any other species. Because I could take an idea or a feeling, or a hope or an aspiration, and I could share it with you, and in my sharing, you experience that hope and that feeling, and that idea. Sharing what’s going on inside our own head is what’s going on in communication. In fact, it’s known within the neural literature as neural entrainment. You and I are having a conversation right now and we’re separated by hundreds if not thousands of miles, but if we could detect it, what we would see is, even though we can’t see each other, our eyes are starting to dilate at similar rates. Our breath patterns and heart rates are starting to match each other. Most importantly, what’s happening inside our heads, our neural activity is starting to look more and more similar. That’s what neural entrainment is, and that’s the core of communication, that I can describe an emotion and feel it myself. And in describing it to you, you start to feel it. You experience it, your brain becomes like mine. And the reason why that’s really important when it comes to vulnerability is that one of the loudest forms of communication is exposing vulnerability. If somebody says something vulnerable, we almost cannot prevent ourselves from listening to them, because, historically, exposing a vulnerability meant that something was really important.

MOLLY WOOD: So now it seems like we have this duality again, which is that, in workplaces, I would say we arguably have not prioritized communication as much as we could and should. And now it is going to be the natural tendency, certainly of maybe people—I think we’re about the same age because I have a son about the same age, and our tendency is going to be to boss the computer around, because that’s just how we’ve been trained to interact, and there’s a double training that may need to happen: communicating better, full stop, and communicating better with AI to get the most out of it. But luckily it’s all the same skill, and now we just have to look for it when we hire.

CHARLES DUHIGG: And what I love about it is that we can practice with AI. So one of the things that AI allows us to do—and people are already creating AI agents that do this—is it allows us to try out different communication techniques and sort of try and anticipate how people will react. So one of the things that when I talk to researchers who are working on negotiations and teaching negotiations is that they say, they tell all their students, before you have a negotiation, we’re going to have an in-class exercise. You’re going to have to negotiate over an issue. I want you to go have this negotiation first with AI. Pay attention to what surprises you. What objections do they raise? How do they come back that catches you off guard? So we get to practice having a conversation before we actually have the conversation, which is of course, something that we normally do with our friends, but our friends get tired of it at some point and say, I don’t want to, I don’t want to role play with you anymore, I got other stuff to do. But equally, I think one of the things that we’re going to see is that when we are hiring, you’re going to see more and more emphasis on communication ability as something that employers are looking for. And we’re already seeing this. We’re already seeing that the ability to get along well with others is critical to the success of teams and to individuals. But even more, now that communication is a technical skill in addition to a human skill, the ability to show during an interview that you can communicate and connect well with others is going to tell that interviewer something about how you also interact with technology, and that’s going to be powerful.

MOLLY WOOD: I feel like there is so much potential in the idea of AI as this sort of communication sandbox, you know, whether it’s practicing for an interview or a tough conversation, or even just being better at conversation. I know people who are actually using it for exactly that purpose. It’s a really compelling use case.

CHARLES DUHIGG: Yeah. There’s a technique called “looping for understanding” that’s really powerful, particularly in conversations that are hard conversations or where there’s some conflict. Looping for understanding is this technique where you ask a deep question, you repeat back what the person tells you in your own words to prove to them that you’re listening. And then the third step, and this is the one we tend to forget, is that you ask them if you got it right. Now just even hearing that, we know how effective that is, right, that if I loop for understanding, if I repeat back what someone said in a conflict conversation and I ask them if I got it right, we know that that’s going to make the conversation go better. But it’s so easy to forget to do that when we’re in the middle of that conversation because we’re feeling heated and overwhelmed. And so think about how effective, how powerful it is just to practice looping for understanding with AI, to get into the habit of when you say something to me, that I, instead of just replying and telling you my thoughts, I just take a beat and say, Here’s what I hear you saying. Tell me if I’m getting this right and repeat it back. Habits, of course, become habits because we do them habitually, and AI gives us that sandbox to allow us to practice those habits until they just become automatic.

MOLLY WOOD: So speaking of habits, at the end of The Power of Habit, you wrote about habits you picked up as a result of writing the book. Can you give me some examples of communication habits that you’ve adopted, specifically on the topic of AI? What habits are you building around AI? How are you using it in your personal and or professional life?

CHARLES DUHIGG: I basically experiment with it all the time. And some stuff it’s not good at, but then there’s other times when I don’t even understand what question I want to ask it, and it ends up helping me understand what I’m trying to get at. Oftentimes for technical questions, I’m like, How do I make Excel do X? Or if I just ask ChatGPT or Bing, it’ll often tell me what the command is right away, and I just plug it in. And so the key is, I think, the same way that we didn’t learn how to use telephones as a species until we just experimented with them for a while, we’re not going to figure out how to use AI really without experimenting. Luckily, the experimentation is kind of fun.

MOLLY WOOD: Sometimes it turns out that all you really need is reinforcement, right? Like you think you already know the answer, but you need to have it confirmed from another source.

CHARLES DUHIGG: Right, and it lays it out in a kind of a way that it’s easier to grasp. This is one of the reasons why conversation is so useful, because not only does it help us understand another person, it helps us understand ourselves. Sometimes simply forcing myself to explain my problem to another person helps me figure out what the problem actually is. The fact that we can have these dialogues with someone who doesn’t get bored and won’t betray our confidences, or won’t allow their own biases to influence us—sometimes we learn things just in what we say, and then sometimes we learn things from what the machine responds with, where we say, oh man, I wish it hadn’t said that, but I guess that’s true, or, no no no, that’s not right. That’s not right. It doesn’t understand at all. We begin to understand what’s actually going on. I did this piece for the New Yorker about OpenAI and Microsoft and the relationship between them. And one of the things that came across really strongly was that both OpenAI and Microsoft, and I think this is a real strength in asset, they essentially are trying to introduce the technology at a pace where people can absorb it. There’s a lot that we could do with AI right now that isn’t being commercialized, in part because it’s unclear how to commercialize it, and it’s unclear how it’ll be used, but also because people aren’t prepared to use it. If you go to the doctor, right now, GPT4 is a pretty good diagnostician. But if you go in and I tell you, Here’s what the machine or the computer says is wrong with you, you’re probably going to say, actually, I’d like to talk to the doctor or the nurse. Like, it’s not just enough to get it from a machine. And so part of this is, how do we introduce this technology into people’s lives in a way that they are prepared to absorb and use it rather than alienating them.

MOLLY WOOD: Okay, so bringing this back to business… I’m a leader. What question should I be asking myself when I wake up every morning?

CHARLES DUHIGG: I mean, I think that leaders would say, What am I paranoid about? But I think probably the better question is, What’s the most meaningful thing I can do today? Particularly once you’re a leader, your day becomes so jam-packed with task after task after task, and solving other people’s problems. You can easily become reactive and spend all of your time just reacting to what life throws at you. But really good leaders say, No, I’m not going to be reactive. I’m going to find the thing that’s most important to me to be proactive on, and I’m going to make that happen. They do this with presidents, the president of the United States. One of the jobs of the chief of staff is to make sure that the only problems that end up on his desk are either problems only he can solve, or problems that correspond with what he wants to solve, because otherwise he could be drowned in the number of questions and issues that come up every day.

MOLLY WOOD: What are some common work habits you think will be irrelevant in the near future?

CHARLES DUHIGG: Ooh, that’s a good question.

MOLLY WOOD: Please tell me it is reading all my emails.

CHARLES DUHIGG: [Laughter] I think anything that’s boring is kind of potentially on that list. So take data analysis. Oftentimes, instead of doing the data analysis, I just dump it into AI and I tell it what I want it to figure out and it goes and it does it for me. And I need to spot-check to make sure it’s not hallucinating, but it’s made data analysis so much easier for me. And the reason why is because data analysis, it’s boring. Coming up with what I want to analyze? That’s an interesting question. Doing the analysis can be kind of drudge work. And you mentioned emails. The truth of the matter is there’s some emails you love to get, and there’s some emails that delight you and entertain you, and there’s some emails that you don’t mind responding to, in fact you enjoy responding to. And then others where it’s just like, okay, here’s something to put on my calendar, and I need to tell this person what my availability is. All those little drudge tasks. Those are the things that are going to disappear, and that’s for the good.

MOLLY WOOD: As you look across this intersection of business and technology, what are you excited about?

CHARLES DUHIGG: I am really excited about what I hope is going to be another Cambrian explosion in tech. When I graduated from college in 1997, it was like the Wild West. There were a thousand different companies doing a thousand different things, and that’s what I think is happening right now. We are seeing again this opportunity for a land grab, for the Cambrian explosion, for someone with a new and unexpected idea who can sort of turn the world upside down the same way that, frankly, OpenAI did. Who had ever heard of OpenAI really two years ago? I’m excited.

MOLLY WOOD: Thank you so much.

CHARLES DUHIGG: Thank you. This was wonderful. Thanks so much for having me on.

[Music]

MOLLY WOOD: Thank you again to Charles Duhigg, journalist, communications and productivity guru, and author of the new book Supercommunicators. Please subscribe to our podcast and check back for the next episode where I’ll be talking to Dr. Britt Aylor, Director of Leadership Development at Microsoft, about why we should all strive to think like an adaptive leader. If you’ve got a question or a comment, please drop us an email at WorkLab@microsoft.com, and check out Microsoft’s Work Trend Indexes and the WorkLab digital publication, where you’ll find all of our episodes along with thoughtful stories that explore how business leaders are thriving in today’s new world of work. You can find all of it at Microsoft.com/WorkLab. As for this podcast, please rate us, review us, and follow us wherever you listen. It helps us out a ton. The WorkLab podcast is a place for experts to share their insights and opinions. As students of the future of work, Microsoft values inputs from a diverse set of voices. That said, the opinions and findings of our guests are their own, and they may not necessarily reflect Microsoft’s own research or positions. WorkLab is produced by Microsoft with Godfrey Dadich Partners and Reasonable Volume. I’m your host, Molly Wood. Sharon Kallander and Matthew Duncan produced this podcast. Jessica Voelker is the WorkLab editor."
Microsoft_News,https://blogs.microsoft.com/blog/2024/02/28/join-us-in-2024-events-to-get-your-teams-ai-ready/,,Join us in 2024 — events to get your teams AI-ready,"2023 was a year of exciting growth and innovation here at Microsoft. This year’s focus is to empower our customers and partners through AI transformation, and we’re excited to share what will be an impactful lineup of events for 2024. Attending any of these events provides you with the opportunity to learn, grow and make defining connections with experts from around the world.

Expect to see enhancements in some of this year’s events. Azure AI-powered natural language assistants will provide personalized session recommendations, summarize content and answer your event-related questions. To meet the needs of a global audience, we are also offering options to participate in person, online and on-demand so you can choose what format works best for you. We structure these events to support the goals of our audiences and ensure that anyone attending has a great experience.

Visit our events site to find out which ones are right for you.

It’s not too late to register for this ongoing series of one-day, in-person experiences around the world. These events bring together those on the cutting edge of innovation — including decision-makers, industry experts, thought leaders and developers — to focus on how AI will revolutionize work. So far, we’ve welcomed thousands of senior leaders and developers in six locations around the globe with keynotes highlighting the latest innovations in AI. Tour stops remain in Berlin, Paris, São Paulo and Seoul, where you can attend interactive workshops and learn how you can unlock the power of AI. Go to the Microsoft AI Tour site to sign up.

In-demand experts, distinguished engineers and developers are gathering in Seattle for our annual Microsoft Build. This celebration of technology is a chance to hear the latest announcements and get hands-on with new technology. Learn how to create new features and opportunities with AI and copilots, dive deep into the latest tech, and develop the skills that are needed for tomorrow — today.

Seattle, Washington & online | May 21-23, 2024

Microsoft Inspire: the next chapter

We are evolving the event previously known as Microsoft Inspire. In July, we will kick off our fiscal year with partners in tandem with our Microsoft sellers by providing a digital engagement to share strategic priorities, investments and key program changes. We look forward to sharing more details soon.

Online | July 2024

With this change, we will also welcome partners to join us at Microsoft Ignite for an in-person experience in November to see the latest Microsoft innovations, network and celebrate the Partner of the Year Award winners.

Our biggest event of the year is getting even bigger for customers and partners, and we’re returning to Chicago!

Join IT professionals, implementers, developers, architects and more in checking out the latest tech Microsoft has to offer. With demos and firsthand access to new AI solutions and copilots, this is your chance to explore the latest tools, receive deep technical training and get questions answered by Microsoft experts. We’re bringing the best of our customer and partner event experiences to the Windy City and online so you can participate in the festivities and discover how AI can enhance your organization.

In addition to seeing the latest technology firsthand, senior leaders and decision-makers are invited to learn more about how to lead in the era of AI and find robust networking opportunities.

If you’re looking to expand your AI knowledge, create connections and push the boundaries of what we can accomplish together, there’s no better event than Microsoft Ignite.

Chicago, Illinois & online | Nov. 18-22, 2024

Find an event in your region

Visit our full global events catalog for a complete list of events, including some that could even be in your area. There, you can filter events by product, role or industry to find something specific to your needs or interests.

We hope to see you

It’s very exciting to bring you opportunities that showcase the growth and innovation that’s being done at Microsoft to help you do more with AI. Whether you’re a customer, partner, IT professional, decision-maker or developer, if you’re looking to achieve more ― there’s an event for you.

Tags: Microsoft AI Tour, Microsoft Build, Microsoft Ignite, Microsoft Inspire"
Microsoft_News,https://www.microsoft.com/en-us/worklab/to-build-ai-into-your-habits-picture-a-pyramid,,"To Build AI Into Your Work Habits, Picture a Pyramid","Sign up for the WorkLab newsletter to get the latest AI research, insights, and trends delivered straight to your inbox.

This article first appeared in the WorkLab newsletter. Get exclusive insights on AI and the future of work by subscribing here.

As leaders and their teams build new habits with generative AI, it’s helpful to think about work in three categories. First, there are the tasks we can hand off to AI almost entirely. Next: those where AI can give us a boost to get better results. And finally, there is the meaningful, human work for which AI frees up time. As we spend less time on the mundane—73 percent of early users of Microsoft Copilot said it helped them complete tasks faster—we make more room for the work that inspires and energizes us, and that brings the most value to our organizations.

So, which category does a given task or project fit into? Picture a pyramid: The tasks that make up your day form the basic building blocks, which you can slot into different layers, from the ground to the summit. Here’s the blueprint:

Tier 1

The base layer of your workday consists of tasks that are, well, basic. This is the not-particularly-exciting work you can strip off your to-do list and hand over to AI. Some examples:

Every week, you sit through an attendance-optional, 60-minute status update on Microsoft Teams because there might be 30 seconds in there that end up being relevant. With Copilot, take that hour back and follow up later: “Did anyone mention my name?”

Overseas colleagues spin up a loooong email thread overnight. Instead of reading every twist and turn of the debate, ask Copilot for an executive summary with just the key points.

You’re rooting through files and channels to track down a data point someone mentioned. Instead, just ask Copilot to surface it: “Find the sales projections for the Southeast region.”

Time saved and mundane tasks dispatched, you’re ready for the next level…

Tier 2

This is the work you’re good at, that you enjoy—and that you can enhance with help from AI. Let’s say you’re writing a crucial memo, email, or sales pitch. Copilot can produce the rough draft, then it can help you sharpen and improve it as you make your edits. A few things you can ask:

Does this writeup accomplish its objective?

Will it resonate with its intended audience?

What did I forget to mention?

You got that done quickly! Now you have more time to do your best work. You’re ready for...

Tier 3

What’s the apex of the workday? For many of us, it’s when we get time to do our most meaningful work—the work that’s most human. When AI saves us time, we should get into the habit of making space for something rewarding. If you use Copilot to skip a non-essential video call, be proactive about slotting in something meaningful instead. For example:

Work on that strategic or creative project you’re always wishing you had more time for.

If you’re focused on being a better manager, connect with a direct report.

Refresh and recharge by taking a walk.

As you sit down to work today, look at your to-do list. What can you tap AI to do for you? What can you do better yourself with help from AI? And with the time you’re saving, where can you slot in something meaningful? It’s a new way of thinking about work—and a new way to see the structure of your day."
Microsoft_News,https://azure.microsoft.com/en-us/blog/modernizing-and-monetizing-telecom-networks-with-ai-powered-azure-for-operators/,,Modernizing telecom networks with AI-powered Azure for Operators,"I’m looking forward to joining our customers and partners at Mobile World Congress (MWC), February 26 to February 29, 2024, in Barcelona. Advancements in generative AI continue to accelerate the pace of industry transformation, with telecommunications emerging as a leader in AI adoption.

Read the blog Accelerating Telco Transformation in the Era of AI by Jason Zander, Executive Vice President, Strategic Missions and Technology, to learn how operators are using Microsoft’s AI and Copilot solutions to elevate customer experiences, streamline business operations, monetize 5G investments, and modernize their network.

In this blog, I will share a number of exciting updates about our Azure for Operators portfolio of cloud-based solutions that enable operators to drive innovation and efficiency in the network. We are proud to announce an expanding customer base and the infusion of AI across Azure for Operators products.

Modernize networks with a hybrid carrier-grade platform and AI-powered automation and insights

Deep integration of the network with the Azure cloud is foundation to using AI-powered automation and insights to unlock improved efficiency, scalability, security, and reliability. Since the general availability announcement of Azure Operator Nexus—our carrier grade, hybrid platform, our progress includes:

Additional Operator Nexus deployments supporting 5G standalone roll outs as primary platform.

Expanding capabilities to address national security requirements in multiple regions.

Increasing support for common operational requirements and refining approach to the DevSecOps models supporting multi-vendor network function deployments.

Additional form factors to support RAN and additional workloads.

As a service model to support customer and partner lab deployments in Microsoft datacenters.

Expanded Nexus Ready program with over 20 certified partners and over 80 network functions.

Operator Nexus enables operators to run workloads on-premises or on Azure, seamlessly deploying and managing everything from the bare metal to the network to the tenant. Purpose-built for and validated by tier 1 operators to run mission-critical workloads, Operator Nexus:

Accelerates time to market for new services.

Lowers total cost of ownership (TCO).

Drives operational efficiency and resiliency.

Critically, improves the security of highly distributed, software-based networks.

“As part of e& UAE’s transformation to becoming a digital telco we are excited to collaborate closely with Microsoft as we drive innovation in our services and excellence in our customer experience. The use of Azure Operator Nexus and Azure Operator 5G Core to support our core network will better enable us to leverage the power of AI and automation and provide new avenues for monetization.” —Khalid Murshed, Chief Technology and Information Officer, e& UAE.

Azure for Operators Learn how telecom operators are transforming with Azure. Discover more

“AT&T is moving to the next phase of our cloud migration that includes deploying Microsoft’s Azure Operator Nexus platform in our network as part of the next phase of our 5G SA deployment. Continuing its leadership in cloud networking, AT&T is using cloud native DevOps tools to drive improvements such as one-touch deployment, vendor-agnostic framework, CI/CD integration, automated network testing, in-service upgrades, and advanced security and compliance management. Azure Operator Nexus’ API-driven solution helped us to significantly simplify, automate, and improve the deployment cycle time for cloud infrastructure software and configuration in our data centers.” —Yigal Elbaz, Senior Vice President, Network CTO.

Read our tech community blog to learn more about Azure Operator Nexus.

AI-enabled insights for operators

Azure Operator Insights and Copilot in Azure Operator Insights empower operators to drive efficiency, speed, and accuracy in network operations. Copilot in Azure Operator Insights, now in limited preview, represents a game-changer for network engineers. Copilot in Azure Operator Insights will empower network engineers to spend more time solving and less time diagnosing customer problems by efficiently identifying, mitigating, and resolving network issues. This service brings operator-focused gen AI-infused product enables operators to move from reactive, to proactive, and predictive network management. Network health can be continuously monitored across multiple underlying management systems, allowing for anomalous health metrics to be detected and the interaction of complex services to be more easily visualized. Network health alerts proactively inform the LLM-based prompts, accelerating the ability to mitigate using suggestions analyzed from data sources such as product manuals, support websites, user forums, and troubleshooting guides. Accumulated experiences are used to further tune the AI model using information maintained in the operator’s subscription.

Today, Azure Operator Insights and Copilot in Azure Operator Insights are delivering AI-infused insights to drive network efficiency for customers like 3UK and participating partners including Amdocs, Accenture, and ServiceNow.

Azure Operator Insights removes data silos and delivers actionable business insights by enabling the collection and analysis of massive quantities of network data gathered from complex multi-vendor network functions. Leveraging ingest and query technology designed to support Azure itself, Azure Operator Insights can analyze data streams sized at multiple petabytes per day in timeframes that cannot be achieved with conventional toolsets. Operator Insights helps operators tackle complex scenarios such as network health, performance, security, end-to-end customer experience, and operations efficiency.

Azure Operator Insights uses a modern data mesh architecture enabling complex domains to be broken into manageable sub-domains called data products that integrate massive datasets from different sources and vendors. This new capability, data product factory, enables operators, network equipment providers, and solution integrators to develop unique data products that can be published to Azure Marketplace or for individual customer use. We are excited to be working with Accenture and Amdocs as our initial collaborators with the Azure Operator Insights data product factory.

“3UK is using Azure Operator Insights to leverage the latest AI advancements through the Copilot in Azure Operator Insights product. This is an exciting development that brings together the latest in generative AI and supports our commitment to better connectivity, every day, for every customer.” —Iain Milligan, Chief Network Officer, 3UK.

Visit our tech community blog for more use cases.

Modern mobile packet core

Azure Operator 5G Core, now in public preview, is designed to meet the evolving needs of mobile network operators, offering a fully containerized carrier-grade, any-G, hybrid mobile packet core with fully integrated network functions that run on-premises or in-cloud. It is a modern architecture proven in the field at scale based on acquired packet core technology from our Affirmed Networks acquisition.

Key features since private preview include:

Inline user plane services provide operators with efficient network resource utilization in a reduced footprint while improving overall user experience.

APIs for repeatable and consistent automation for rapid, error-free service rollouts.

Micro service architecture supports 2G to 5G in single deployment.

Containerization drives high performance and efficiency.

Integrated with cloud-based services for zero trust security, AI based automation, and advanced analytics.

Rapid time to market with DevSecOps-based approach.

For more information about these enhancements for Azure Operator 5G Core, visit our tech community blog.

Security and compliance for telecom workloads

We are committed to supporting our customers’ security and compliance obligations. In deepening our commitment, we have joined the GSMA Network Equipment Security Assurance Scheme (NESAS) to help ensure the security and compliance of our products. Specific to the United Kingdom (UK), we support the UK Telecoms Security Assurance (TSA) code of practice.

“We are delighted to welcome Microsoft Azure for Operators to the Network Equipment Security Assurance Scheme (NESAS). By joining NESAS, Microsoft demonstrates its leadership to providing secure and trustworthy solutions for the telecom industry. NESAS provides a common security framework that enhances transparency and confidence in the network equipment supply chain. We look forward to working with Microsoft and other members of the scheme to advance the security and reliability of telecom networks around the world.” —Samantha Kight, Head of Industry Security, GSMA.

Monetize 5G investments and enhance customer experiences with modern connected applications

For operators, the ability to monetize a differentiated network experience requires exposing key capabilities to developers and ISVs, whose efforts accelerate the development of modern connected applications, speeding adoption, and value creation. The announcements in this section make it possible for operators to monetize AI, programmable network, and edge compute.

Announcing Azure Operator Call Protection in public preview

We are announcing a new service that uses AI to protect consumers from telephone scam calls. Azure Operator Call Protection uses real-time analysis of voice content, alerting consumers when there is suspicious in-call activity. Operator Call Protection works on any endpoint (mobile or landline) and is entirely network-derived (no app download required) making for simple monetization of the service as either a premium feature or part of a service bundle. It is built on Azure Communications Gateway, which enables connectivity between an operator voice network and Microsoft Teams and other cloud communication services. Operators participating in preview include British Telecom Group and Far EasTone.

“We’ve already implemented various measures to protect our customer base from many millions of scam calls and texts, but with fraud a growing problem in the UK, we are always looking at how we can take consumer protection to the next level. That’s why we are collaborating with Microsoft to pilot Azure Operator Call Protection and analyze how, by using advanced (AI) capabilities, we can further enhance our defenses against fraudulent activity.” —Reza Rahnama, MBE, MD Mobile Networks, BT Group.

Visit our tech community blog for more information about Azure Operator Call Protection.

Azure Programmable Connectivity (APC) is now available in public preview as an Azure service. Now fully integrated into the Azure Marketplace, APC empowers operators to commercialize their network APIs and simplifies their access for developers. APC provides seamless access to Open Gateway for developers to create cloud and edge-native applications that interact with the intelligence of the network. By providing a unified, standard interface across operator networks, developers can create cloud and edge-native applications that interact with the intelligence of networks.

We are actively collaborating with global operators integrating their network APIs to develop a strong partner ecosystem (such as AT&T, BT, Claro, Deutsche Telekom, MEO, Orange, Rogers, Singtel, Telefonica, T-Mobile, TIM Brasil, Verizon, and Vivo). We also continue working with network technology partners and network programmability aggregators, such as Ericsson and Vonage, as well as Nokia and Nokia’s Network as Code platform, making concrete progress accelerating the ecosystem on network programmability.

“Verizon’s network APIs enable developers to create new experiences, ease pain points in customer interactions, and improve customer security by enabling access to Verizon network APIs through Azure’s APC, developers across the globe can benefit from Verizon’s deep knowledge of the data environment and expansive network resource.” —Srini Kalapala, Senior Vice President of Technology and Product Development, Verizon.

Learn how APC is revolutionizing the way developers interact with network API services and learn how enterprises are taking advantage of network-aware applications.

Azure private MEC enables operators to support modern connected applications with high-performance, ultra-low-latency edge solutions. Here are a few examples of how enterprises are transforming operations with 5G:

Noble Corporation , one of the largest offshore drilling contractors in the world, is deploying Azure private MEC to provide mobility solutions for the crew while increasing efficiency. “With Tampnet’s Private Offshore Network and Azure private MEC, onsite connectivity is no longer a challenge for Noble. Connected workers, and safe and secure networks are accelerating implementation of digital initiatives for improved offshore operations.” —Juan Vesga, OTG Project Manager, Noble Corporation .

, one of the largest offshore drilling contractors in the world, is deploying Azure private MEC to provide mobility solutions for the crew while increasing efficiency. “With Tampnet’s Private Offshore Network and Azure private MEC, onsite connectivity is no longer a challenge for Noble. Connected workers, and safe and secure networks are accelerating implementation of digital initiatives for improved offshore operations.” . Trinity Broadcast Networks (TBN), has installed a private 5G network deployment from our partner, Trilogy NextGen Networks, in the Dallas-Fort Worth metroplex. “As the new home for many of TBN’s most popular news and entertainment programs, as well as ‘Dr. Phil Primetime,’ it was essential to create a facility that delivers the ultimate state-of-the-art experience. Our partnership with Trilogy NextGen helps us invigorate the world of broadcasting, as we push the boundaries of content creation to inspire, inform, and uplift audiences around the world.” — Russell Hall, Senior Vice President of Production, TBN .

(TBN), has installed a private 5G network deployment from our partner, Trilogy NextGen Networks, in the Dallas-Fort Worth metroplex. “As the new home for many of TBN’s most popular news and entertainment programs, as well as ‘Dr. Phil Primetime,’ it was essential to create a facility that delivers the ultimate state-of-the-art experience. Our partnership with Trilogy NextGen helps us invigorate the world of broadcasting, as we push the boundaries of content creation to inspire, inform, and uplift audiences around the world.” . 5G PORTAL–the Offshore Renewable Energy (ORE) Catapult, together with Microsoft and a wider consortium of partners, have created an offshore 5G equipped testbed, covering the Port of Grimsby and the operational Lynn and Inner Dowsing Wind Farm.

Expanding partner ecosystem for modern connected applications

Our partners are actively developing modern connected applications that run on Azure private MEC. We have onboarded more than 20 ISVs and dozens of SI and operator partners. Learn more below about some of the new partner solutions available on Azure Marketplace.

Glartek’s Augmented & Connected Worker platform uses AR to support enterprise operations.

Augmented & Connected Worker platform uses AR to support enterprise operations. Scenera’s MAIstro software as a service (SaaS) offers a comprehensive solution for orchestrating AI analytics seamlessly from edge to cloud.

MAIstro software as a service (SaaS) offers a comprehensive solution for orchestrating AI analytics seamlessly from edge to cloud. Tampnet’s offshore private networks provide secure connectivity for offshore operators and vessels.

offshore private networks provide secure connectivity for offshore operators and vessels. Taqtile Manifest® Mixed Reality Work Instruction Solution leverages mixed reality to improve operational workflows.

Manifest® Mixed Reality Work Instruction Solution leverages mixed reality to improve operational workflows. T-Mobile’s 5G Advanced Network Solutions provides “right-sized” solutions for enterprises.

5G Advanced Network Solutions provides “right-sized” solutions for enterprises. Zebra Technologies Corporation’s Workcloud Communication platform enables secure and reliable communication for front-line workers.

See how ISV partners are powering AI-enabled applications.

Get started today

Microsoft and our ecosystem partners are building a truly “better together” architecture that holistically addresses the needs of network operators as they transform their networks. Looking ahead, we remain committed to being the most trusted co-innovation partner through every stage of the digital evolution, working with operators and enterprises to future-proof networks and unlock new revenue streams in a cloud- and AI-native future.

Invitation to operators, system integrators, and network managers

Sign up now to get access to exclusive insights on how to accelerate transformation in the era of AI.

For CSPs interested in modernizing and monetizing their network investments, contact us today.

Invitation to enterprises, developers, and ISVs"
Microsoft_News,https://blogs.microsoft.com/on-the-issues/2024/02/26/microsoft-ai-access-principles-responsible-mobile-world-congress/,,Microsoft’s AI Access Principles: Our commitments to promote innovation and competition in the new AI economy,"As we enter a new era based on artificial intelligence, we believe this is the best time to articulate principles that will govern how we will operate our AI datacenter infrastructure and other important AI assets around the world. We are announcing and publishing these principles – our “AI Access Principles” – today at the Mobile World Congress in Barcelona in part to address Microsoft’s growing role and responsibility as an AI innovator and a market leader.

Like other general-purpose technologies in the past, AI is creating a new sector of the economy. This new AI economy is creating not just new opportunities for existing enterprises, but new companies and entirely new business categories. The principles we’re announcing today commit Microsoft to bigger investments, more business partnerships, and broader programs to promote innovation and competition than any prior initiative in the company’s 49-year history. By publishing these principles, we are committing ourselves to providing the broad technology access needed to empower organizations and individuals around the world to develop and use AI in ways that will serve the public good.

These new principles help put in context the new investments and programs we’ve announced and launched across Europe over the past two weeks, including $5.6 billion in new AI datacenter investments and new AI skilling programs that will reach more than a million people. We’ve also launched new public-private partnerships to advance responsible AI adoption and protect cybersecurity, new AI technology services to support network operators, and a new partnership with France’s leading AI company, Mistral AI. As much as anything, these investments and programs make clear how we will put these principles into practice, not just in Europe, but in the United States and around the world.

These principles also reflect the responsible and important role we must play as a company. They build in part on the lessons we have learned from our experiences with previous technology developments. In 2006, after more than 15 years of controversies and litigation relating to Microsoft Windows and the company’s market position in the PC operating system market, we published a set of “Windows Principles.” Their purpose was to govern the company’s practices in a manner that would both promote continued software innovation and foster free and open competition.

I’ll never forget the reaction of an FTC Commissioner who came up to me after I concluded the speech I gave in Washington, D.C. to launch these principles. He said, “If you had done this 10 years ago, I think you all probably would have avoided a lot of problems.”

Close to two decades have gone by since that moment, and both the world of technology and the AI era we are entering are radically different. Then, Windows was the computing platform of the moment. Today, mobile platforms are the most popular gateway to consumers, and exponential advances in generative AI are driving a tectonic shift in digital markets and beyond. But there is wisdom in that FTC Commissioner’s reaction that has stood the test of time: As a leading IT company, we do our best work when we govern our business in a principled manner that provides broad opportunities for others.

The new AI era requires enormous computational power to train, build, and deploy the most advanced AI models. Historically, such power could only be found in a handful of government-funded national laboratories and research institutions, and it was available only to a select few. But the advent of the public cloud has changed that. Much like steel did for skyscrapers, the public cloud enables generative AI.

Today, datacenters around the world house millions of servers and make vast computing power broadly available to organizations large and small and even to individuals as well. Already, many thousands of AI developers – in startups, enterprises, government agencies, research labs, and non-profit organizations around the world – are using the technology in these datacenters to create new AI foundation models and applications.

These datacenters are owned and operated by cloud providers, which include larger established firms such as Microsoft, Amazon, Google, Oracle, and IBM, as well as large firms from China like Alibaba, Huawei, Tencent, and Baidu. There are also smaller specialized entrants such as Coreweave, OVH, Aruba, and Denvr Dataworks Corporation, just to mention a few. And government-funded computing centers clearly will play a role as well, including with support for academic research. But building and operating those datacenters is expensive. And the semiconductors – or graphical processing units (GPUs) – that are essential to power the servers for AI workloads remain costly and in short supply. Although governments and companies are working hard to fill the gap, doing so will take some time.

With this reality in mind, regulators around the world are asking important questions about who can compete in the AI era. Will it create new opportunities and lead to the emergence of new companies? Or will it simply reinforce existing positions and leaders in digital markets?

I am optimistic that the changes driven by the new AI era will extend into the technology industry itself. After all, how many readers of this paragraph had, two years ago, even heard of OpenAI and many other new AI entrants like Anthropic, Cohere, Aleph Alpha, and Mistral AI? In addition, Microsoft, along with other large technology firms are dynamically pivoting to meet the AI era. The competitive pressure is fierce, and the pace of innovation is dizzying. As a leading cloud provider and an innovator in AI models ourselves and through our partnership with OpenAI, we are mindful of our role and responsibilities in the evolution of this AI era.

Throughout the past decade, we’ve typically found it helpful to define the tenets – in effect, the goals that guide our thinking and drive our actions as we navigate a complex topic. We then apply these tenets by articulating the principles we will apply as we make the decisions needed to govern the development and use of technology. I share below the new tenets on which we are basing our thinking on this topic, followed by our 11 AI Access Principles.

Our AI Access Tenets

Fundamentally, there are five tenets that define Microsoft’s goals as we focus on AI access, including our role as an infrastructure and platforms provider.

First, we have a responsibility to enable innovation and foster competition. We believe that AI is a foundational technology with a transformative capability to help solve societal problems, improve human productivity, and make companies and countries more competitive. As with prior general-purpose technologies, from the printing press to electricity, railroads, and the internet itself, the AI era is not based on a single technology component or advance. We have a responsibility to help spur innovation and competition across the new AI economy that is rapidly emerging.

AI is a dynamic field, with many active participants based on a technology stack that starts with electricity and connectivity and the world’s most advanced semiconductor chips at the base. It then runs up through the compute power of the public cloud, public and proprietary data for training foundation models, the foundation models themselves, tooling to manage and orchestrate the models, and AI-powered software applications. In short, the success of an AI-based economy requires the success of many different participants across numerous interconnected markets.

You can see here the technology stack that defines the new AI era. While one company currently produces and supplies most of the GPUs being used for AI today, as one moves incrementally up the stack, the number of participants expands. And each layer enables and facilitates innovation and competition in the layers above. In multiple ways, to succeed, participants at every layer of the technology stack need to move forward together. This means, for Microsoft, that we need to stay focused not just on our own success, but on enabling the success of others.

Second, our responsibilities begin by meeting our obligations under the law. While the principles we are launching today represent a self-regulatory initiative, they in no way are meant to suggest a lack of respect for the rule of law or the role of regulators. We fully appreciate that legislators, competition authorities, regulators, enforcers, and judges will continue to evolve the competition rules and other laws and regulations relevant to AI. That’s the way it should be.

Technology laws and rules are changing rapidly. The European Union is implementing its Digital Markets Act and completing its AI Act, while the United States is moving quickly with a new AI Executive Order. Similar laws and initiatives are moving forward in the United Kingdom, Canada, Japan, India, and many other countries. We recognize that we, like all participants in this new AI market, have a responsibility to live up to our obligations under the law, to engage constructively with regulators when obligations are not yet clear, and to contribute to the public dialogue around policy. We take these obligations seriously.

Third, we need to advance a broad array of AI partnerships. Today, only one company is vertically integrated in a manner that includes every AI layer from chips to a thriving mobile app store. As noted at a recent meeting of tech leaders and government officials, “The rest of us, Microsoft included, live in the land of partnerships.”

People today are benefiting from the AI advances that the partnership between OpenAI and Microsoft has created. Since 2019, Microsoft has collaborated with OpenAI on the research and development of OpenAI’s generative AI models, developing the unique supercomputers needed to train those models. The ground-breaking technology ushered in by our partnership has unleashed a groundswell of innovation across the industry. And over the past five years, OpenAI has become a significant new competitor in the technology industry. It has expanded its focus, commercializing its technologies with the launch of ChatGPT and the GPT Store and providing its models for commercial use by third-party developers.

Innovation and competition will require an extensive array of similar support for proprietary and open-source AI models, large and small, including the type of partnership we are announcing today with Mistral AI, the leading open-source AI developer based in France. We have also invested in a broad range of other diverse generative AI startups. In some instances, those investments have provided seed funding to finance day-to-day operations. In other instances, those investments have been more focused on paying the expenses for the use of the computational infrastructure needed to train and deploy generative AI models and applications. We are committed to partnering well with market participants around the world and in ways that will accelerate local AI innovations.

Fourth, our commitment to partnership extends to customers, communities, and countries. More than for prior generations of digital technology, our investments in AI and datacenters must sustain the competitive strengths of customers and national economies and address broad societal needs. This has been at the core of the multi-billion-dollar investments we recently have announced in Australia, the United Kingdom, Germany, and Spain. We need constantly to be mindful of the community needs AI advances must support, and we must pursue a spirit of partnership not only with others in our industry, but with customers, governments, and civil society. We are building the infrastructure that will support the AI economy, and we need the opportunities provided by that infrastructure to be widely available.

Fifth, we need to be proactive and constructive, as a matter of process, in working with governments and the IT industry in the design and release of new versions of AI infrastructure and platforms. We believe it is critical for companies and regulators to engage in open dialogue, with a goal of resolving issues as quickly as possible – ideally, while a new product is still under development. For our part, we understand that Microsoft must respond fully and cooperatively to regulatory inquiries so that we can have an informed discussion with regulators about the virtues of various approaches. We need to be good listeners and constructive problem solvers in sorting through issues of concern and identifying practical steps and solutions before a new product is completed and launched.

Our AI Access Principles

The aforementioned tenets come together to shape the new principles we are announcing below. It’s important to note that, given the safety, security, privacy, and other issues relating to responsible AI, we need to apply all these principles subject to objective and effective standards to comply with our legal obligations and protect the public. These are discussed further below. Subject to these requirements, we are committed to the following 11 principles:

Provide access and support for AI developers who create models and applications

We are committed to enabling AI innovation and fostering competition by making our cloud computing and AI infrastructure, platforms, tools, and services broadly available and accessible to software developers around the world. We want Microsoft Azure to be the best place for developers to train, build, and deploy AI models and to use those models safely and securely in applications and solutions. This means:

As we grow chip capacity, we are expanding Microsoft’s cloud computing AI infrastructure to enable the training and deployment of more foundation models, both proprietary and open source, and large and small

Today, our partnership with OpenAI is supporting the training of the next generation of OpenAI models and increasingly enabling customers to access and use these models and Microsoft’s CoPilot applications in local datacenters. At the same time, we are committed to supporting other developers, training, and deploying proprietary and open-source AI models, both large and small.

Today’s important announcement with Mistral AI launches a new generation of Microsoft’s support for technology development in Europe. It enables Mistral AI to accelerate the development and deployment of its next generation Large Language Models (LLMs) with access to Azure’s cutting-edge AI infrastructure. It also makes the deployment of Mistral AI’s premium models available to customers through our Models-as-a-Service (MaaS) offering on Microsoft Azure, which model developers can use to publish and monetize their AI models. By providing a unified platform for AI model management, we aim to lower the barriers and costs of AI model development around the world for both open source and proprietary development. In addition to Mistral AI, this service is already hosting more than 1,600 open source and proprietary models from companies and organizations such as Meta, Nvidia, Deci, and Hugging Face, with more models coming soon from Cohere and G42.

We are committed to expanding this type of support for additional models in the months and years ahead.

We are making AI models and development tools broadly available to software applications developers around the world, so every nation can build its own AI economy

As reflected in Microsoft’s Copilots and OpenAI’s ChatGPT itself, the world is rapidly benefiting from the use of a new generation of software applications that access and use the power of AI models. But our applications will represent just a small percentage of the AI-powered applications the world will need and create. For this reason, we’re committed to ongoing and innovative steps to make the AI models we host and the development tools we create broadly available to AI software applications developers around the world in ways that are consistent with responsible AI principles.

This includes the Azure OpenAI service, which enables software developers who work at start-ups, established IT companies, and in-house IT departments to build software applications that call on and make use of OpenAI’s most powerful models. It extends through Models as a Service to the use of other open source and proprietary AI models from other companies, including Mistral AI, Meta, and others.

We are also committed to empowering developers to build customized AI solutions by enabling them to fine-tune existing models based on their own unique data sets and for their specific needs and scenarios. With Azure Machine Learning, developers can easily access state-of-the-art pre-trained models and customize them with their own data and parameters, using a simple drag-and-drop interface or code-based notebooks. This helps companies, governments, and non-profits create AI applications that help advance their goals and solve their challenges, such as improving customer service, enhancing public safety, or promoting social good. This is rapidly democratizing AI and fostering a culture of even broader innovation and collaboration among developers.

We are also providing developers with tools and repositories on GitHub that enable them to create, share, and learn from AI solutions. GitHub is the world’s largest and most trusted platform for software development, hosting over 420 million repositories and supporting more than 100 million developers, including 90% of the Fortune 100. We are committed to supporting the AI developer community by making our AI tools and resources available on GitHub, giving developers access to the latest innovations and best practices in AI development, as well as the opportunity to collaborate with other developers and contribute to the open source community. As one example, just last week we made available an open automation framework to help red team generative AI systems.

Ensure choice and fairness across the AI economy

We understand that AI innovation and competition require choice and fair dealing. We are committed to providing organizations, AI developers, and data scientists with the flexibility to choose which AI models to use wherever they are building solutions. For developers who choose to use Microsoft Azure, we want to make sure they are confident we will not tilt the playing field to our advantage. This means:

We are making available public APIs to enable developers to access and use AI models we host on Microsoft Azure

The AI models that we host on Azure, including the Microsoft Azure OpenAI API service, are all accessible via public APIs. Microsoft publishes documentation on its website explaining how developers can call these APIs and use the underlying models. This enables any application, whether it is built and deployed on Azure or other private and public clouds, to call these APIs and access the underlying models.

We are supporting a common public API to enable network operators to support software developers

Network operators are playing a vital role in accelerating the AI transformation of customers around the world, including for many national and regional governments. This is one reason we are supporting a common public API through the Open Gateway initiative driven by the GSM Association, which advances innovation in the mobile ecosystem. The initiative is aligning all operators with a common API for exposing advanced capabilities provided by their networks, including authentication, location, and quality of service. It’s an indispensable step forward in enabling network operators to offer their advanced capabilities to a new generation of AI-enabled software developers. We have believed in the potential of this initiative since its inception at GSMA, and we have partnered with operators around the world to help bring it to life.

Today at Mobile World Congress, we are launching the Public Preview of Azure Programmable Connectivity (APC). This is a first-class service in Azure, completely integrated with the rest of our services, that seamlessly provides access to Open Gateway for developers. It means software developers can use the capabilities provided by the operator network directly from Azure, like any other service, without requiring specific work for each operator.

Developers may choose how to distribute and sell their AI models, tools and applications for deployment and use on Microsoft Azure, whether via the Azure Marketplace or directly to customers

We are committed to maintaining Microsoft Azure as an open cloud platform, much as Windows has been for decades and continues to be. That means in part ensuring that developers can choose how they want to distribute and sell their AI software to customers for deployment and use on Microsoft Azure. We provide a marketplace on Azure through which developers can list and sell their AI software to Azure customers under a variety of supported business models. Developers who choose to use the Azure Marketplace are also free to decide whether to use the transaction capabilities offered by the marketplace (at a modest fee) or whether to sell licenses to customers outside of the marketplace (at no fee). And, of course, developers remain free to sell and distribute AI software to Azure customers however they choose, and those customers can then upload, deploy, and use that software on Azure.

We respect the needs of developers by ensuring we do not use any non-public information or data from the training, building, deployment, or use of developers’ AI models in Microsoft Azure to compete with those models

We believe that trust is central to the success of Microsoft Azure. We build this trust by serving the interests of AI developers and customers who choose Microsoft Azure to train, build, and deploy foundation models. In practice, this also means that we avoid using any non-public information or data from the training, building, deployment, or use of developers’ AI models to compete against them.

We enable customers using Microsoft Azure to switch to another cloud provider by enabling them to easily export and transfer their data

We know that customers can and do use multiple cloud providers to meet their AI and other computing needs. And we understand that the data our customers store on Microsoft Azure is their data. So, we are committed to enabling customers to easily export and transfer their data if they choose to switch to another cloud provider. We recognize that different countries are considering or have enacted laws limiting the extent to which we can pass along the costs of such export and transfer. We will comply with those laws.

Meet our societal responsibilities

We recognize that new AI technologies raise an extraordinary array of critical questions. These involve important societal issues such as privacy, safety, security, the protection of children, and the safeguarding of elections from deepfake manipulation, to name just a few. These and other issues require that tech companies create guardrails for their AI services, adapt to new legal and regulatory requirements, and work proactively in multistakeholder efforts to meet broad societal needs. We’re committed to fulfilling these responsibilities, including through the following priorities:

We are supporting the physical and cybersecurity needs of all the AI models and applications that run in our AI datacenters

We are committed to safeguarding the physical security of our AI datacenters, as they host the infrastructure and data that power AI solutions. We follow strict security protocols and standards to ensure that our datacenters are protected from unauthorized access, theft, vandalism, fire, or natural disasters. We monitor and audit our datacenters to detect and prevent any potential threats or breaches. Our datacenter staff are trained and certified in security best practices and are required to adhere to a code of conduct that respects the privacy and confidentiality of our customers’ data.

We are also committed to safeguarding the cybersecurity of our AI models and applications, as they process and generate sensitive information for our customers and society. We use state-of-the-art encryption, authentication, and authorization mechanisms to protect data in transit and at rest, as well as the integrity and confidentiality of AI models and applications. We also use AI to enhance our cybersecurity capabilities, such as detecting and mitigating cyberattacks, identifying and resolving vulnerabilities, and improving our security posture and resilience.

We’re building on these efforts with our new Secure Future Initiative (SFI). This brings together every part of Microsoft and has three pillars. It focuses on AI-based cyber defenses, advances in fundamental software engineering, and advocacy for stronger application of international norms to protect civilians from cyber threats.

We are applying a strong Responsible AI Standard to keep people at the center of AI design decisions and respect enduring values, including fairness, reliability and safety, privacy and security, inclusiveness, transparency, and accountability

As AI becomes more pervasive and impactful, we recognize the need to ensure that our technology is developed and deployed in a way that is ethical, trustworthy, and aligned with human values. That is why we have created the Microsoft Responsible AI Standard, a comprehensive framework that guides our teams on how to build and use AI responsibly.

The standard covers six key dimensions of responsible AI: fairness; reliability and safety; privacy and security; inclusiveness; transparency; and accountability. For each dimension, we define what these values mean and how to achieve our goals in practice. We also provide tools, processes, and best practices to help our teams implement the standard throughout the AI lifecycle, from design and development to deployment and monitoring. The approach that the standard establishes is not static, but instead evolves and improves based on the latest research, feedback, and learnings.

We are investing in initiatives to spread AI skilling broadly around the world

We recognize that countries need more than advanced AI chips and datacenters to sustain their competitive edge and unlock economic growth. AI is changing jobs and the way people work, requiring that people master new skills to advance their careers. That’s why we’re committed to marrying AI infrastructure capacity with AI skilling capability, combining the two to advance innovation.

In just the past few months, we’ve combined billions of dollars of infrastructure investments with new programs to bring AI skills to millions of people in countries like Australia, the United Kingdom, Germany, and Spain. We’re launching training programs focused on building AI fluency, developing AI technical skills, supporting AI business transformation, and promoting safe and responsible AI development. Our work includes the first Professional Certificate on Generative AI.

Typically, our skilling programs involve a professional network of Microsoft certified training services partners and multiple industry partners, universities, and nonprofit organizations. Increasingly, we find that major employers want to launch new AI skilling programs for their employees, and we are working with them actively to provide curricular materials and support these efforts.

One of our most recent and important partnerships is with the AFL-CIO, the largest federation of labor unions in the United States. It’s the first of its kind between a labor organization and a technology company to focus on AI and will deliver on three goals: (1) sharing in-depth information with labor leaders and workers on AI technology trends; (2) incorporating worker perspectives and expertise in the development of AI technology; and (3) helping shape public policy that supports the technology skills and needs of frontline workers.

We’ve learned that government institutions and associations can typically bring AI skilling programs to scale. At the national and regional levels, government employment and educational agencies have the personnel, programs, and expertise to reach hundreds of thousands or even millions of people. We’re committed to working with and supporting these efforts.

Through these and other initiatives, we aim to democratize access to AI education and enable everyone to harness the potential of AI for their own lives and careers.

We are managing our AI datacenters in an environmentally sensitive manner and using AI to advance environmental sustainability needs

In 2020, Microsoft set ambitious goals to be carbon negative, water positive and zero waste by 2030. We recognize that our datacenters play a key part in achieving these goals. Being responsible and sustainable by design also has led us to take a first-mover approach, making long-term investments to bring as much or more carbon-free electricity than we will consume onto the grids where we build datacenters and operate.

We also apply a holistic approach to the Scope 3 emissions relating to our investments in AI infrastructure, from the construction of our datacenters to engaging our supply chain. This includes supporting innovation to reduce the embodied carbon in our supply chain and advancing our water positive and zero waste goals throughout our operations.

At the same time, we recognize that AI can be a vital tool to help accelerate the deployment of sustainability solutions from the discovery of new materials to better predicting and responding to extreme weather events. This is why we continue to partner with others to use AI to help advance breakthroughs that previously would have taken decades, underscoring the important role AI technology can play in addressing some of our most critical challenges to realizing a more sustainable future.

***

We know that the principles governing our approach are only a first step. We expect that we will need to evolve these principles and our approach as AI technology and industry moves forward and the applicable law and regulations change. We look forward to continuing dialogue with the many stakeholders that are now playing critical roles in building the new AI economy. If experience teaches us anything, it’s that we’ll all need to succeed together.

Update 2/27/2024: This blog was updated to reflect the latest stats from GitHub.

Tags: ChatGPT, datacenters, generative ai, Github, Mobile World Congress, open ai, Responsible AI"
Microsoft_News,https://azure.microsoft.com/en-us/blog/microsoft-and-mistral-ai-announce-new-partnership-to-accelerate-ai-innovation-and-introduce-mistral-large-first-on-azure/,,Introducing Mistral-Large on Azure in partnership with Mistral AI,"Share Microsoft and Mistral AI announce new partnership to accelerate AI innovation and introduce Mistral Large first on Azure on LinkedIn

Share Microsoft and Mistral AI announce new partnership to accelerate AI innovation and introduce Mistral Large first on Azure on X

Share Microsoft and Mistral AI announce new partnership to accelerate AI innovation and introduce Mistral Large first on Azure on Facebook

The AI industry is undergoing a significant transformation with growing interest in more efficient and cost-effective models, emblematic of a broader trend in technological advancement. In the vanguard is Mistral AI, an innovator and trailblazer. Their commitment to fostering the open-source community and achieving exceptional performance aligns harmoniously with Microsoft’s commitment to develop trustworthy, scalable, and responsible AI solutions.

Today, we are announcing a multi-year partnership between Microsoft and Mistral AI, a recognized leader in generative artificial intelligence. Both companies are fueled by a steadfast dedication to innovation and practical applications, bridging the gap between pioneering research and real-world solutions.

Mistral Large Introducing Mistral Large, our most advanced large language model (LLM) Subscribe today

This partnership with Microsoft enables Mistral AI with access to Azure’s cutting-edge AI infrastructure, to accelerate the development and deployment of their next generation large language models (LLMs) and represents an opportunity for Mistral AI to unlock new commercial opportunities, expand to global markets, and foster ongoing research collaboration.

“We are thrilled to embark on this partnership with Microsoft. With Azure’s cutting-edge AI infrastructure, we are reaching a new milestone in our expansion propelling our innovative research and practical applications to new customers everywhere. Together, we are committed to driving impactful progress in the AI industry and delivering unparalleled value to our customers and partners globally.” Arthur Mensch, Chief Executive Officer, Mistral AI

Microsoft’s partnership with Mistral AI is focused on three core areas:

Supercomputing infrastructure: Microsoft will support Mistral AI with Azure AI supercomputing infrastructure delivering best-in-class performance and scale for AI training and inference workloads for Mistral AI’s flagship models. Scale to market: Microsoft and Mistral AI will make Mistral AI’s premium models available to customers through the Models as a Service (MaaS) in the Azure AI Studio and Azure Machine Learning model catalog. In addition to OpenAI models, model catalog offers a diverse selection of both open-source and commercial models. The ability to use Microsoft Azure Consumption Commitment (MACC) for purchasing Mistral AI’s models is available today. Azure’s AI-optimized infrastructure and enterprise-grade capabilities offer Mistral AI additional opportunities to promote, sell, and distribute their models to Microsoft customers worldwide. AI research and development: Microsoft and Mistral AI will explore collaboration around training purpose-specific models for select customers, including European public sector workloads.

Expand your AI functions with Azure and Mistral AI

In November 2023, at Microsoft Ignite, Microsoft unveiled the integration of Mistral 7B into the Azure AI model catalog accessible through Azure AI Studio and Azure Machine Learning. We are excited to announce Mistral AI’s flagship commercial model, Mistral Large, available first on Azure AI and the Mistral AI platform, marking a noteworthy expansion of our offerings. Mistral Large is a general-purpose language model that can deliver on any text-based use case thanks to state-of-the-art reasoning and knowledge capabilities. It is proficient in code and mathematics, able to process dozens of documents in a single call, and handles French, German, Spanish, and Italian (in addition to English).

This latest addition of Mistral AI’s premium models into Models as a Service (MaaS) within Azure AI Studio and Azure Machine Learning provides Microsoft customers with a diverse selection of the best state-of-the-art and open-source models for crafting and deploying custom AI applications, paving the way for novel AI-driven innovations.

“We have tested Mistral Large through the Azure AI Studio in a use case aimed at internal efficiency. The performance was comparable with state-of-the-art models with even better latency. We are looking forward to exploring further this technology in our business.” Philippe Rambach, Chief AI Officer, Schneider Electric

“After exploring Mistral Large during its early access period, we’ve been impressed by its performance on medical terminology. As we continue to innovate in healthcare, we’re open to collaborations that can help us and our partners grow together. Mistral AI represents an exciting opportunity for mutual advancement in artificial intelligence, both in France and internationally.” Nacim Rahal, Senior Director, Data and AI, Doctolib

“The Mistral AI models have been crucial in enhancing productivity and collaboration at CMA CGM. Their advanced capabilities have significantly improved the performance of our internal personal assistant, MAIA. Employees are now able to quickly access and engage with information like never before. We are confident that Mistral AI on Azure is the right choice to support our employees and drive innovation across our organization.” Séverine Grégoire, Head of Digital, Innovation and AI at CMA CGM

Microsoft is committed to supporting global AI innovation and growth, offering world-class datacenter AI infrastructure, and developing technology securely to empower individuals with the skills they need to leverage AI effectively. This partnership with Mistral AI is founded on a shared commitment to build trustworthy and safe AI systems and products. It further reinforces Microsoft’s ongoing efforts to enhance our AI offerings and deliver unparalleled value to our customers. Additionally, the integration into AI Studio ensures that customers can utilize Azure AI Content Safety and responsible AI tools, further enhancing the security and reliability of AI solutions.

Explore solutions with Azure and Mistral AI today

Visit the Mistral Large model card and sign in with your Azure subscription to get started with Mistral Large on Azure AI today. You can also review the technical blog to learn how to use Mistral Large on Azure AI. Visit Mistral AI’s blog to get deeper insights about the model."
Microsoft_News,https://blogs.microsoft.com/blog/2024/02/25/accelerating-telco-transformation-in-the-era-of-ai/,,Accelerating telco transformation in the era of AI,"AI is redefining digital transformation for every industry, including telecommunications. Every operator’s AI journey will be distinct. But each AI journey requires cloud-native transformation, which provides the foundation for any organization to harness the full potential of AI, driving innovation, efficiency and business value.

This new era of AI will create incredible economic growth and represent a profound shift as a percentage impact on global GDP, which is just over $100 trillion. So, when we look at the potential value driven by this next generation of AI technology, we may see a boost to global GDP of an additional $7 trillion to $10 trillion.

Embracing AI will help operators unlock new revenue streams, deliver superior customer experiences and pioneer future innovations for growth.

The AI-powered future cloud for telecommunications

Operators can now leverage cloud services that are adaptive, purpose-built for telecommunications and span from near edge on-premises environments to the far edges of Earth and space to monetize investments, modernize networks, elevate customer experiences and streamline business operations with AI.

Our aim is to be the most trusted co-innovation partner for the telecommunications industry. We want to help accelerate telco transformation and empower operators to succeed in the era of AI, which is why we are committed to working with operators, enterprises and developers on the future cloud.

At MWC in Barcelona this week, we are announcing updates to our Azure for Operators portfolio to help operators seize the opportunity ahead in a cloud- and AI-native future.

Monetize investments and unlock innovation for customers

AI opens new growth opportunities for operators. The biggest potential is that operators, as they embrace this new era of cloud and AI, can also help their customers in their own transformation.

For example, spam calls and malicious activities are a well-known menace and are growing exponentially, and often impact the most vulnerable members of society. Besides the annoyance, the direct cost of those calls adds up. For example, in the United States, FTC data for 2023 shows $850 million in reported fraud losses stemming from scam calls.

Today, we are announcing the public preview of Azure Operator Call Protection, a new service that uses AI to help protect consumers from scam calls. The service uses real-time analysis of voice content, alerting consumers who opt into the service when there is suspicious in-call activity. Azure Operator Call Protection works on any endpoint, mobile or landline, and it works entirely through the network without needing any app installation.

In the U.K., BT Group is trialing Azure Operator Call Protection to identify, educate and protect their customers from potential fraud, making it harder for bad actors to take advantage of their customers.

We are also announcing the public preview of Azure Programmable Connectivity (APC), which provides a unified, standard interface across operators’ networks. APC provides seamless access to Open Gateway for developers to create cloud and edge-native applications that interact with the intelligence of the network. APC also empowers operators to commercialize their network APIs and simplifies their access for developers and is available in the Azure Marketplace.

Run AI-driven networks on a carrier-grade, hybrid cloud platform

AI opens incredible opportunities to modernize network operations, providing new levels of real-time insights, intelligence and automation. Operators, such as Three UK, are already using Azure Operator Insights to eliminate data silos and deliver actionable business insights by enabling the collection and analysis of massive quantities of network data gathered from complex multi-vendor network functions. Designed for operator-specific workloads, operators tackle complex scenarios with Azure Operator Insights, such as understanding the health of their networks and the quality of their subscribers’ experiences.

Azure Operator Insights uses a modern data mesh architecture for dividing complex domains into manageable sub-domains called data products. These data products integrate large datasets from different sources and vendors to provide data visibility from disaggregated networks for comprehensive analytical and business insights. Using this data product factory capability, operators, network equipment providers and solution integrators can create unique data products for one customer or published to the Azure Marketplace for many customers to use.

Today, we are also announcing the limited preview of Copilot in Azure Operator Insights, a groundbreaking, operator-focused, generative AI capability helping operators move from reactive to proactive and predictive in tangible ways. Engineers use the Copilot to interact with network insights using natural language and receive simple explanations of what the data means and possible actions to take, resolving network issues quickly and accurately, ultimately improving customer satisfaction.

Copilot in Azure Operator Insights is delivering AI-infused insights to drive network efficiency for customers like Three UK and participating partners including Amdocs, Accenture and BMC Remedy. Three UK is using Copilot in Azure Operator Insights to unlock actionable intelligence on network health and customer experience quality of service, a process that previously took weeks or months to assess, is now possible to perform in minutes.

Additionally, with our next-generation hybrid cloud platform, Azure Operator Nexus, we offer the ability to future-proof the network to support mission-critical workloads, and power new revenue-generating services and applications. This immense opportunity is what drives operators to modernize their networks with Azure Operator Nexus, a carrier-grade, hybrid cloud platform and AI-powered automation and insights — unlocking improved efficiency, scalability and reliability. Purpose-built for and validated by tier one operators to run mission-critical workloads, Azure Operator Nexus enables operators to run workloads on-premises or on Azure, where they can seamlessly deploy, manage, secure and monitor everything — from the bare metal to the tenant.

E& UAE is taking advantage of the Azure Operator Nexus platform to lower total cost of ownership (TCO), leverage the power of AI to simplify operations, improve time to market and focus on their core competencies. And operations at AT&T that took months with previous generations of technology now take weeks to complete with Azure Operator Nexus.

We continue to build robust capabilities into Azure Operator Nexus, including new deployment options giving operators the flexibility to use one carrier-grade platform to deliver innovative solutions on near-edge, far-edge and enterprise edge.

Read more about the latest Azure for Operator updates here.

Accelerate business transformation with AI

Operators are creating differentiation by collaborating with us to improve customer experiences and streamline their business operations with AI. Operators are leveraging Microsoft’s copilot stack and copilot experiences across our core products and services, such as Microsoft Copilot, Microsoft Copilot for M365 and Microsoft Security Copilot to drive productivity and improve customer experiences.

Last year AT&T launched Ask AT&T, a generative AI tool designed to help employees be more effective, creative and innovative. An early use case for Ask AT&T was to enable software developers to write and refine code — in many cases, AT&T is seeing a 25-50% productivity gain for their developers. Since its launch, the company has identified many other use cases for the solution. Today, approximately 68,000 employees have access to Ask AT&T and are using it for anything from vulnerability remediation in IT to analysis of the vast data flows the company manages on its network. The company is currently training Ask AT&T on contracts and financial materials to assist with HR questions and making our care representatives even more effective at supporting our customers.

launched Ask AT&T, a generative AI tool designed to help employees be more effective, creative and innovative. An early use case for Ask AT&T was to enable software developers to write and refine code — in many cases, AT&T is seeing a 25-50% productivity gain for their developers. Since its launch, the company has identified many other use cases for the solution. Today, approximately 68,000 employees have access to Ask AT&T and are using it for anything from vulnerability remediation in IT to analysis of the vast data flows the company manages on its network. The company is currently training Ask AT&T on contracts and financial materials to assist with HR questions and making our care representatives even more effective at supporting our customers. Teams at Lumen use Copilot to surface relevant policies, summarize tickets and easily find repair instructions from manuals. They can quickly create presentations, new business proposals and statements of work. Giving their workforce the digital tools they need to deliver dramatically improved customer experiences with greater ease is an essential part of the company’s transformation.

use Copilot to surface relevant policies, summarize tickets and easily find repair instructions from manuals. They can quickly create presentations, new business proposals and statements of work. Giving their workforce the digital tools they need to deliver dramatically improved customer experiences with greater ease is an essential part of the company’s transformation. Telefónica evolves Kernel, its digital framework for the creation of advanced services, to the next level by adding new Microsoft Azure AI services to power every relevant use case with generative AI capabilities at scale. New Kernel 2.0 integrates all the digital services from the Telefónica Group to enable private-first, secure and standardized access to data and APIs, providing a foundation for value-added services that can be developed faster and with higher customer impact.

evolves Kernel, its digital framework for the creation of advanced services, to the next level by adding new Microsoft Azure AI services to power every relevant use case with generative AI capabilities at scale. New Kernel 2.0 integrates all the digital services from the Telefónica Group to enable private-first, secure and standardized access to data and APIs, providing a foundation for value-added services that can be developed faster and with higher customer impact. Indonesian-based Telkomsel introduced Veronika — a virtual assistant that integrates Microsoft Azure OpenAI Service. Veronika is rooted in natural language processing and machine learning, and recommends telco packages based on customers’ needs, and it can quickly and accurately address customer concerns. Since deploying Veronika, Telkomsel has been able to address rising call volumes without increasing agents. They have seen a significant drop in call volumes for their agents who are now handling 1,000 calls a day (down from 8,000 previously) and can now focus on increased cross-selling.

introduced Veronika — a virtual assistant that integrates Microsoft Azure OpenAI Service. Veronika is rooted in natural language processing and machine learning, and recommends telco packages based on customers’ needs, and it can quickly and accurately address customer concerns. Since deploying Veronika, Telkomsel has been able to address rising call volumes without increasing agents. They have seen a significant drop in call volumes for their agents who are now handling 1,000 calls a day (down from 8,000 previously) and can now focus on increased cross-selling. To increase customer satisfaction, Vodafone will apply the power of Microsoft Azure OpenAI to deliver frictionless, real-time, proactive and hyper-personalized experiences across all Vodafone customer touchpoints, including its digital assistant TOBi (available in 13 countries). Vodafone employees will also be able to leverage the AI capabilities of Microsoft Copilot to transform working practices, boost productivity and improve digital efficiency.

An average operator spends 20% of annual revenue on capital expenditures. However, this investment does not translate into an equivalent increase in revenue growth. Operators need to empower their service teams with data-driven insights to increase productivity, enhance care, use conversational AI to enable self-service, expedite issue resolution and deliver frictionless customer experiences at scale.

Partnering with Microsoft in the era of AI

Together with our partner ecosystem, we are investing in creating a comprehensive set of solutions for the telecommunications industry. This includes the Azure for Operators portfolio — a carrier-grade hybrid cloud platform, voice core, mobile core and multi-access edge compute, as well as our suite of generative AI solutions that holistically address the needs of network operators as they transform their networks.

As customers continue to embrace generative AI, we remain committed to working with operators and enterprises alike to future-proof networks and unlock new revenue streams in a cloud- and AI-native future.

Tags: AI, Azure for Operators, Azure Operator Call Protection, Azure Operator Insights, Azure Operator Nexus, Copilot in Azure Operator Insights"
Microsoft_News,https://azure.microsoft.com/en-us/blog/explore-cutting-edge-ai-solutions-with-microsoft-at-nvidia-gtc/,,Explore cutting-edge AI solutions with Microsoft at NVIDIA GTC,"Welcome to the new era, where AI is driving innovation and rapidly changing what applications look like, how they’re designed and built, and how they’re delivered. Businesses in nearly every industry are racing to apply AI in their products and operations to better engage customers, increase productivity, and gain a competitive edge.

Most companies are familiar with the transformative capabilities of AI but are unclear where and how to best apply AI in their business. To accelerate AI development and integration, organizations need a trusted partner with AI expertise that can help them determine their AI strategy and provide comprehensive, unified services, infrastructure, and tools specifically designed for AI.

Realize cutting-edge AI capabilities Join Microsoft at the NVIDIA GTC AI Conference March 18-21 Register now

Companies of all sizes are turning to Microsoft for innovative, secure, and responsible AI services. Microsoft provides full-stack AI solutions—including developer tools, application services, and supercomputing infrastructure built specifically for AI, plus a global team of AI experts that can help organizations accelerate their AI production.

Continuously investing to deliver the latest responsible and secure AI technologies, Microsoft is committed to helping companies transform their business with AI. Hear how Microsoft is helping organizations around the world achieve more with Microsoft AI in this video.

Delivering cutting-edge AI services

In 2023, Microsoft unveiled yet another round of AI innovations, from AI services to silicon, that can help any business accelerate AI production. Whether you need to add intelligence to your existing applications or create new ones from scratch, Microsoft Azure has the right AI services and infrastructure.

Microsoft Azure AI Studio, now in preview, empowers organizations and developers to innovate with AI. The platform, accessibly and responsibly designed, provides a one-stop shop to seamlessly explore, build, test, and deploy AI solutions using state-of-the-art AI tools and machine learning models. Developers can build generative AI applications, including copilot experiences, using out-of-the-box and customizable tooling and models with built-in security and compliance.

Microsoft Copilot and Microsoft Copilot for Azure transform productivity and business processes, from office workers and front-line workers to developers and IT professionals. Azure AI Services offers pre-built cognitive services that can perform tasks like vision, speech, and decision making, to custom machine learning solutions that can be built and deployed using Azure Machine Learning. Azure OpenAI Service offers industry-leading coding and language AI models and the latest advancements in generative AI for content creation, conversation AI, and data grounding.

Azure supercomputing infrastructure provides the latest AI-optimized silicon featuring new Microsoft custom-designed chips—Azure Maia 100 and Azure Cobalt 100, NVIDIA® H100 and H200 Tensor Core graphics processing unit (GPU)-optimized Azure virtual machines, and NVIDA AI foundry service on Azure.

Experience the innovation at NVIDIA GTC

Join Microsoft at the NVIDIA GTC AI Conference March 18–21 at booth #1108 in San Jose, CA (or virtually) to discover how these cutting-edge Azure AI services and supercomputing infrastructure can help power your AI transformation. Through in-person and on-demand sessions, live discussions, and hands-on demos, attendees can:

Get to know the core Azure AI services and technologies that power some of the world’s largest and most complex AI models and applications.

Discover how to accelerate the delivery of generative AI and large language models.

Explore how Azure AI Studio and purpose-built cloud infrastructure can accelerate AI development and deployment.

Learn from best practices and customer experiences to speed your AI journey.

Attend Microsoft sessions

Register for a Microsoft in-person or on-demand session at NVIDIA GTC. See the full list of and register for Microsoft sessions.

Featured sessions

S63275 Power your AI transformation with the Microsoft Cloud

S63277 Unlocking Generative AI in the Enterprise with NVIDIA on Azure

S63274 The Next Level of GenAI with Azure OpenAI Service and Copilot

S63273 Deep Dive into Training and Inferencing Large Language Models on Azure

S63276 Behind the scenes with Azure AI infrastructure

Talks and panels

S61190 The Small Models Revolution

S62777 The Role of Generative AI in Modern Medicine

S61936 A Deep Dive into Sustainable Cloud Computing

S62336 ONNX Runtime: Accelerated AI Deployment for PC Apps

S62730 Generative AI Adoption and Operational Challenges in Government

S62783 Digitalizing the World’s Largest Industries with OpenUSD and Generative AI

S62504 Optimizing Your AI Strategy to Develop and Deploy Novel Deep Learning Models in the Cloud for Medical Image Analysis

S62447 Best Practices in Networking for AI: Perspectives from Cloud Service Providers

Meet with Microsoft

Visit Microsoft in person at booth #1108 where we’ll showcase the latest in AI services and supercomputing infrastructure. Join live discussion sessions (in-booth theater), connect with Microsoft AI experts, and try out the latest technology and hardware. Can’t join in person? Visit us virtually via the NVIDIA GTC site starting March 18.

Get hands-on training

Microsoft is proud to host NVIDIA Hands-On Training at GTC. Attend full-day, hands-on, instructor-led workshops offered onsite and virtually. Participants will have access to a fully-configured GPU-accelerated server in the cloud and the chance to earn an NVIDIA certificate of subject matter competency.

Register today

We’re excited to meet with you in person or virtually at the NVIDIA GTC AI Conference. With over 900 inspiring sessions, 200+ exhibits, 20+ technical workshops, and tons of unique networking events, discover what’s next in AI and accelerated computing at NVIDIA GTC. Register today.

Learn more about Azure AI

Azure AI Solutions

NVIDIA | Accelerated Computing in Microsoft Azure"
Microsoft_News,https://techcommunity.microsoft.com/t5/microsoft-teams-blog/prompt-like-a-pro-stay-on-top-of-your-chats-with-copilot-in/ba-p/4064175,,Prompt Like a Pro: Stay on top of your chats with Copilot in Teams,"Microsoft Teams is a powerful tool for collaborating with your colleagues and sharing information in real time. However, it can be challenging to keep track of what is happening in your Teams conversations. Staying on top of everything is even harder when you have been traveling for work, are in training for a week, or work with a team that is in different time zones. How do you ensure that you haven’t missed any important action items, decisions made, topics discussed, or anything else that might be relevant to your work?



Get chat highlights with Copilot in Teams

Copilot in Teams chat can help you stay up to speed on all your conversations. If you have a Copilot for Microsoft 365 license, you can leverage Copilot to answer questions, provide insights, and suggest actions based on your chat messages. And one of the most useful prompts to use with Copilot in Teams is generating chat highlights. Now, with a few clicks, you can generate a 7-day highlight that synthesizes the key information from your chats. Simply go into any chat and click the “More prompts” button in the bottom left corner and select ""Highlights from the past 7 days” or write it yourself in the chat function.



You can choose other time periods to look back on as well – either 1 day or 30 days - to build on what you first selected, or you could find out about any open items and decisions that were made while you were away. You can even write your own twist on this prompt, such as “Highlights since Monday,” to catch up on messages sent since a specific day. Using a pre-built prompt allows Copilot in Teams to provide a high-quality response and is a great foundation for additional prompts you may want to ask.



The information Copilot will tell you

When you ask Copilot for your chat highlights, it will look through your messages and extract the most important information for you. It will tell you things like*:

Who joined the team

What tasks were assigned, completed, or overdue

What decisions were made or what opinions were shared

What meetings were scheduled, held, or canceled

What files were shared, edited, or commented on

What topics were discussed or what questions were asked

What feedback was given or what praise was received

What problems were encountered or what solutions were proposed

What announcements were made or what events were planned

What everyone shared they would do over the weekend

Copilot will present the chat highlights in a concise and clear summary, with citations that – when clicked on - take you to where that message is in the chat so you can get more context.



You can also use further prompting of your own to customize the chat highlights by filtering them by date, channel, person, or keyword. By writing your own detailed prompts, you can ask Copilot to show you chat highlights related to a project, or only those from a specific person or on a particular topic.



Save time with Copilot

Instead of spending hours scrolling through your chat messages to find the information you need, now you can do it in seconds with Copilot in Teams chat. In doing so, you can free up your time like never before and focus that time on doing more meaningful work. You can also improve your team collaboration by staying informed, aligned, and engaged as soon as you use this prompt.



Additional resources

If you want to find more examples of prompts that Copilot can help you with, check out Copilot Lab. There you can filter by M365 app to learn what Prompts to use in Teams and get tips for better optimized prompts. You can also suggest some great prompts you have used that you think others would benefit from in their conversations with Copilot.



What’s coming next

Copilot in Teams is constantly evolving and improving thanks to your input and feedback. Stay tuned for more tips on how to work with Copilot to make your team conversations more productive and fun, and before you know it you will be prompting like a pro! For those reading that already have a Copilot in Microsoft 365 license, feel free to share your favorite prompts in the chat for the chance to get featured in a future “Prompt Like a Pro” blog.

* If Copilot does not give you this information, use your own words with a follow-up prompt to get the answer you are looking for."
Microsoft_News,https://www.microsoft.com/en-us/worklab/podcast/how-to-become-an-ai-powered-organization,,How to Become an AI-Powered Organization,"The year 2024 will be remembered as the moment when AI-powered organizations shifted into overdrive.

As business leaders tap the full potential of this transformative technology, they are grappling with important new questions. Like, what’s the best way to implement smart AI policies across my organization? How will AI transform the way my company hires and trains people? How will it help me cross all sorts of items off of my to-do lists, and change the way I manage email and meetings? Most importantly, what is the smartest way to make use of all the time that AI can save me?

In the new season of the WorkLab podcast from Microsoft, we bring you answers to these vital questions.

The show is hosted by Molly Wood, who has spent more than two decades reporting on the innovations revolutionizing technology and business for CNET/CBS, the New York Times, Marketplace, WIRED, and The Atlantic. Last season, she explored the future of work with thought leaders like futurist Amy Webb, Microsoft Chief Scientific Officer Eric Horvitz, Harvard Business School’s Christina Wallace, and LinkedIn vice president Aneesh Raman.

This season she’ll talk with more experts, bringing you the hard data, real-world lessons, and actionable insights you need to ensure that your organization thrives.

New episodes of the WorkLab podcast will be available starting on February 28. You can follow the show on Apple Podcasts, Spotify, or wherever you get your podcasts.

Here’s a transcript of the Season 6 trailer.

Hey there, I’m Molly Wood. I’m the host of WorkLab, a Microsoft podcast for business leaders, which will soon be back with a new season.

WorkLab is, in a nutshell, your unfair advantage for getting ahead in our new world of work—meaning everything from productivity hacks to leadership insights to, oh yeah, AI.

This season we’re helping leaders prepare for the way AI is fundamentally transforming jobs, organizations, entire industries, the whole economy. We bring top experts, hard data, and actionable insights to answer the questions that are keeping you up at night.

Like, how will I need to reinvent processes in this AI era, from customer service to sales, to HR? If AI really does rescue organizations from mundane tasks and busy work, what’s the best way to use the time we get back?

How will AI transform my company in the next few months, let alone the next few years, and how am I supposed to even prepare for that? Don’t panic—we got you.

Season 6 launches on February 28. I cannot wait to see what we uncover, and I really hope you’ll join me."
Microsoft_News,https://blogs.microsoft.com/on-the-issues/2024/02/16/ai-deepfakes-elections-munich-tech-accord/,,Meeting the moment: combating AI deepfakes in elections through today’s new tech accord,"As the months of 2024 unfold, we are all part of an extraordinary year for the history of both democracy and technology. More countries and people will vote for their elected leaders than in any year in human history. At the same time, the development of AI is racing ever faster ahead, offering extraordinary benefits but also enabling bad actors to deceive voters by creating realistic “deepfakes” of candidates and other individuals. The contrast between the promise and peril of new technology has seldom been more striking.

This quickly has become a year that requires all of us who care about democracy to work together to meet the moment.

Today, the tech sector came together at the Munich Security Conference to take a vital step forward. Standing together, 20 companies [1] announced a new Tech Accord to Combat Deceptive Use of AI in 2024 Elections. Its goal is straightforward but critical – to combat video, audio, and images that fake or alter the appearance, voice, or actions of political candidates, election officials, and other key stakeholders. It is not a partisan initiative or designed to discourage free expression. It aims instead to ensure that voters retain the right to choose who governs them, free of this new type of AI-based manipulation.

The challenges are formidable, and our expectations must be realistic. But the accord represents a rare and decisive step, unifying the tech sector with concrete voluntary commitments at a vital time to help protect the elections that will take place in more than 65 nations between the beginning of March and the end of the year.

While many more steps will be needed, today marks the launch of a genuinely global initiative to take immediate practical steps and generate more and broader momentum.

What’s the problem we’re trying to solve?

It’s worth starting with the problem we need to solve. New generative AI tools make it possible to create realistic and convincing audio, video, and images that fake or alter the appearance, voice, or actions of people. They’re often called “deepfakes.” The costs of creation are low, and the results are stunning. The AI for Good Lab at Microsoft first demonstrated this for me last year when they took off-the-shelf products, spent less than $20 on computing time, and created realistic videos that not only put new words in my mouth, but had me using them in speeches in Spanish and Mandarin that matched the sound of my voice and the movement of my lips.

In reality, I struggle with French and sometimes stumble even in English. I can’t speak more than a few words in any other language. But, to someone who doesn’t know me, the videos appeared genuine.

AI is bringing a new and potentially more dangerous form of manipulation that we’ve been working to address for more than a decade, from fake websites to bots on social media. In recent months, the broader public quickly has witnessed this expanding problem and the risks this creates for our elections. In advance of the New Hampshire primary, voters received robocalls that used AI to fake the voice and words of President Biden. This followed the documented release of multiple deepfake videos beginning in December of UK Prime Minister Rishi Sunak. These are similar to deepfake videos the Microsoft Threat Analysis Center (MTAC) has traced to nation-state actors, including a Russian state-sponsored effort to splice fake audio segments into excerpts of genuine news videos.

This all adds up to a growing risk of bad actors using AI and deepfakes to deceive the public in an election. And this goes to a cornerstone of every democratic society in the world – the ability of an accurately-informed public to choose the leaders who will govern them.

This deepfake challenge connects two parts of the tech sector. The first is companies that create AI models, applications, and services that can be used to create realistic video, audio, and image-based content. And the second is companies that run consumer services where individuals can distribute deepfakes to the public. Microsoft works in both spaces. We develop and host AI models and services on Azure in our datacenters, create synthetic voice technology, offer image creation tools in Copilot and Bing, and provide applications like Microsoft Designer, which is a graphic design app that enables people easily to create high-quality images. And we operate hosted consumer services including LinkedIn and our Gaming network, among others.

This has given us visibility to the full range of the evolution of the problem and the potential for new solutions. As we’ve seen the problem grow, the data scientists and engineers in our AI for Good Lab and the analysts in MTAC have directed more of their focus, including with the use of AI, on identifying deepfakes, tracking bad actors, and analyzing their tactics, techniques, and procedures. In some respects, we’ve seen practices we’ve long combated in other contexts through the work of our Digital Crimes Unit, including activities that reach into the dark web. While the deepfake challenge will be difficult to defeat, this has persuaded us that we have many tools that we can put to work quickly.

Like many other technology issues, our most basic challenge is not technical but altogether human. As the months of 2023 drew to a close, deepfakes had become a growing topic of conversation in capitals around the world. But while everyone seemed to agree that something needed to be done, too few people were doing enough, especially on a collaborative basis. And with elections looming, it felt like time was running out. That need for a new sense of urgency, as much as anything, sparked the collaborative work that has led to the accord launched today in Munich.

What is the tech sector announcing today – and will it make a difference?

I believe this is an important day, culminating hard work by good people in many companies across the tech sector. The new accord brings together companies from both relevant parts of our industry – those that create AI services that can be used to create deepfakes and those that run hosted consumer services where deepfakes can spread. While the challenge is formidable, this is a vital step that will help better protect the elections that will take place this year.

It’s helpful to walk through what this accord does, and how we’ll move immediately to implement it as Microsoft.

The accord focuses explicitly on a concretely defined set of deepfake abuses. It addresses “Deceptive AI Election Content,” which is defined as “convincing AI-generated audio, video, and images that deceptively fake or alter the appearance, voice, or actions of political candidates, election officials, and other key stakeholders in a democratic election, or that provide false information to voters about when, where, and how they can lawfully vote.”

The accord addresses this content abuse through eight specific commitments, and they’re all worth reading. To me, they fall into three critical buckets worth thinking more about:

First, the accord’s commitments will make it more difficult for bad actors to use legitimate tools to create deepfakes. The first two commitments in the accord advance this goal. In part, this focuses on the work of companies that create content generation tools and calls on them to strengthen the safety architecture in AI services by assessing risks and strengthening controls to help prevent abuse. This includes aspects such as ongoing red team analysis, preemptive classifiers, the blocking of abusive prompts, automated testing, and rapid bans of users who abuse the system. It all needs to be based on strong and broad-based data analysis. Think of this as safety by design.

This also focuses on the authenticity of content by advancing what the tech sector refers to as content provenance and watermarking. Video, audio, and image design products can incorporate content provenance features that attach metadata or embed signals in the content they produce with information about who created it, when it was created, and the product that was used, including the involvement of AI. This can help media organizations and even consumers better separate authentic from inauthentic content. And the good news is that the industry is moving quickly to rally around a common approach – the C2PA standard – to help advance this.

But provenance is not sufficient by itself, because bad actors can use other tools to strip this information from content. As a result, it is important to add other methods like embedding an invisible watermark alongside C2PA signed metadata and to explore ways to detect content even after these signals are removed or degraded, such as by fingerprinting an image with a unique hash that might allow people to match it with a provenance record in a secure database.

Today’s accord helps move the tech sector farther and faster in committing to, innovating in, and adopting these technological approaches. It builds on the voluntary White House commitments first embraced by several companies in the United States this past July and the European Union’s Digital Services Act’s focus on the integrity of electoral processes. At Microsoft, we are working to accelerate our work in these areas across our products and services. And we are launching next month new Content Credentials as a Service to help support political candidates around the world, backed by a dedicated Microsoft team.

I’m encouraged by the fact that, in many ways, all these new technologies represent the latest chapter of work we’ve been pursuing at Microsoft for more than 25 years. When CD-ROMs and then DVDs became popular in the early 1990s, counterfeiters sought to deceive the public and defraud consumers by creating realistic-looking fake versions of popular Microsoft products.

We responded with an evolving array of increasingly sophisticated anti-counterfeiting features, including invisible physical watermarking, that are the forerunners of the digital protection we’re advancing today. Our Digital Crimes Unit developed approaches that put it at the global forefront in using these features to protect against one generation of technology fakes. While it’s always impossible to eradicate any form of crime completely, we can again call on these teams and this spirit of determination and collaboration to put today’s advances to effective use.

Second, the accord brings the tech sector together to detect and respond to deepfakes in elections. This is an essential second category, because the harsh reality is that determined bad actors, perhaps especially well-resourced nation-states, will invest in their own innovations and tools to create deepfakes and use these to try to disrupt elections. As a result, we must assume that we’ll need to invest in collective action to detect and respond to this activity.

The third and fourth commitments in today’s accord will advance the industry’s detection and response capabilities. At Microsoft, we are moving immediately in both areas. On the detection front, we are harnessing the data science and technical capabilities of our AI for Good Lab and MTAC team to better detect deepfakes on the internet. We will call on the expertise of our Digital Crimes Unit to invest in new threat intelligence work to pursue the early detection of AI-powered criminal activity.

We are also launching effective immediately a new web page – Microsoft-2024 Elections – where a political candidate can report to us a concern about a deepfake of themselves. In essence, this empowers political candidates around the world to aid with the global detection of deepfakes.

We are combining this work with the launch of an expanded Digital Safety Unit. This will extend the work of our existing digital safety team, which has long addressed abusive online content and conduct that impacts children or that promotes extremist violence, among other categories. This team has special ability in responding on a 24/7 basis to weaponized content from mass shootings that we act immediately to remove from our services.

We are deeply committed to the importance of free expression, but we do not believe this should protect deepfakes or other deceptive AI election content covered by today’s accord. We therefore will act quickly to remove and ban this type of content from LinkedIn, our Gaming network, and other relevant Microsoft services consistent with our policies and practices. At the same time, we will promptly publish a policy that makes clear our standards and approach, and we will create an appeals process that will move quickly if a user believes their content was removed in error.

Equally important, as addressed in the accord’s fifth commitment, we are dedicated to sharing with the rest of the tech sector and appropriate NGOs the information about the deepfakes we detect and the best practices and tools we help develop. We are committed to advancing stronger collective action, which has proven indispensable in protecting children and addressing extremist violence on the internet. We deeply respect and appreciate the work that other tech companies and NGOs have long advanced in these areas, including through the Global Internet Forum to Counter Terrorism, or GIFCT, and with governments and civil society under the Christchurch Call.

Third, the accord will help advance transparency and build societal resilience to deepfakes in elections. The final three commitments in the accord address the need for transparency and the broad resilience we must foster across the world’s democracies.

As reflected in the accord’s sixth commitment, we support the need for public transparency about our corporate and broader collective work. This commitment to transparency will be part of the approach our Digital Safety Unit takes as it addresses deepfakes of political candidates and the other categories covered by today’s accord. This will also include the development of a new annual transparency report we will publish that covers our policies and data about how we are applying them.

The accord’s seventh commitment obliges the tech sector to continue to engage with a diverse set of global civil society organizations, academics, and other subject matter experts. These groups and individuals play an indispensable role in the promotion and protection of the world’s democracies. For more than two centuries, they have been fundamental to the advance of democratic rights and principles, including their critical work to advance the abolition of slavery and the expansion of the right to vote in the United States.

We look forward, as a company, to continued engagement with these groups. When diverse groups come together, we do not always start with the same perspective, and there are days when the conversations can be challenging. But we appreciate from longstanding experience that one of the hallmarks of democracy is that people do not always agree with each other. Yet, when people truly listen to differing views, they almost always learn something new. And from this learning there comes a foundation for better ideas and greater progress. Perhaps more than ever, the issues that connect democracy and technology require a broad tent with room to listen to many different ideas.

This also provides a basis for the accord’s final commitment, which is support for work to foster public awareness and resilience regarding deceptive AI election content. As we’ve learned first-hand in recent elections in places as distant from each other as Finland and Taiwan, a savvy and informed public may provide the best defense of all to the risk of deepfakes in elections. One of our broad content provenance goals is to equip people with the ability to look easily for C2PA indicators that will denote whether content is authentic. But this will require public awareness efforts to help people learn where and how to look for this.

We will act quickly to implement this final commitment, including by partnering with other tech companies and supporting civil society organizations to help equip the public with the information needed. Stay tuned for new steps and announcements in the coming weeks.

Does today’s tech accord do everything that needs to be done?

This is the final question we should all ask as we consider the important step taken today. And, despite my enormous enthusiasm, I would be the first to say that this accord represents only one of the many vital steps we’ll need to take to protect elections.

In part this is because the challenge is formidable. The initiative requires new steps from a wide array of companies. Bad actors likely will innovate themselves, and the underlying technology is continuing to change quickly. We need to be hugely ambitious but also realistic. We’ll need to continue to learn, innovate, and adapt. As a company and an industry, Microsoft and the tech sector will need to build upon today’s step and continue to invest in getting better.

But even more importantly, there is no way the tech sector can protect elections by itself from this new type of electoral abuse. And, even if it could, it wouldn’t be proper. After all, we’re talking about the election of leaders in a democracy. And no one elected any tech executive or company to lead any country.

Once one reflects for even a moment on this most basic of propositions, it’s abundantly clear that the protection of elections requires that we all work together.

In many ways, this begins with our elected leaders and the democratic institutions they lead. The ultimate protection of any democratic society is the rule of law itself. And, as we’ve noted elsewhere, it’s critical that we implement existing laws and support the development of new laws to address this evolving problem. This means the world will need new initiatives by elected leaders to advance these measures.

Among other areas, this will be essential to address the use of AI deepfakes by well-resourced nation-states. As we’ve seen across the cybersecurity and cyber-influence landscapes, a small number of sophisticated governments are putting substantial resources and expertise into new types of attacks on individuals, organizations, and even countries. Arguably, on some days, cyberspace is the space where the rule of law is most under threat. And we’ll need more collective inter-governmental leadership to address this.

As we look to the future, it seems to those of us who work at Microsoft that we’ll also need new forms of multistakeholder action. We believe that initiatives like the Paris Call and Christchurch Call have had a positive impact on the world precisely because they have brought people together from governments, the tech sector, and civil society to work on an international basis. As we address not only deepfakes but almost every other technology issue in the world today, we find it hard to believe that any one part of society can solve a big problem by acting alone.

This is why it’s so important that today’s accord recognizes explicitly that “the protection of electoral integrity and public trust is a shared responsibility and a common good that transcends partisan interests and national borders.”

Perhaps more than anything, this needs to be our North Star.

Only by working together can we preserve timeless values and democratic principles in a time of enormous technological change.

[1] Adobe, Amazon, Anthropic, ARM, ElevenLabs, Google, IBM, Inflection AI, LinkedIn, McAfee, Meta, Microsoft, Nota, OpenAI, Snap, Stability AI, TikTok, TrendMicro, TruePic, and X.

Tags: AI for Good, artificial intelligence, cyber influence, cybersecurity, deepfakes, Defending Democracy Program, Microsoft Designer, MTAC, Responsible AI, Tech Accord to Combat Deceptive Use of AI in 2024 Elections"
Microsoft_News,https://news.microsoft.com/2024/02/16/technology-industry-to-combat-deceptive-use-of-ai-in-2024-elections/,,Technology industry to combat deceptive use of AI in 2024 elections,"Technology industry to combat deceptive use of AI in 2024 elections

20 leading technology companies including Adobe, Amazon, Google, IBM, Meta, Microsoft, OpenAI, TikTok, and X pledge to work together to detect and counter harmful AI content

MUNICH – February 16, 2024 – Today at the Munich Security Conference (MSC), leading technology companies pledged to help prevent deceptive AI content from interfering with this year’s global elections in which more than four billion people in over 40 countries will vote.

The “Tech Accord to Combat Deceptive Use of AI in 2024 Elections” is a set of commitments to deploy technology countering harmful AI-generated content meant to deceive voters. Signatories pledge to work collaboratively on tools to detect and address online distribution of such AI content, drive educational campaigns, and provide transparency, among other concrete steps. It also includes a broad set of principles, including the importance of tracking the origin of deceptive election-related content and the need to raise public awareness about the problem. The accord is one important step to safeguard online communities against harmful AI content, and builds on the individual companies’ ongoing work.

Digital content addressed by the accord consists of AI-generated audio, video, and images that deceptively fake or alter the appearance, voice, or actions of political candidates, election officials, and other key stakeholders in a democratic election, or that provide false information to voters about when, where, and how they can vote.

As of today, the signatories are: Adobe, Amazon, Anthropic, Arm, ElevenLabs, Google, IBM, Inflection AI, LinkedIn, McAfee, Meta, Microsoft, Nota, OpenAI, Snap, Stability AI, TikTok, TrendMicro, Truepic, and X.

Participating companies agreed to eight specific commitments:

Developing and implementing technology to mitigate risks related to Deceptive AI Election content, including open-source tools where appropriate

Assessing models in scope of this Accord to understand the risks they may present regarding Deceptive AI Election Content

Seeking to detect the distribution of this content on their platforms

Seeking to appropriately address this content detected on their platforms

Fostering cross-industry resilience to Deceptive AI Election Content

Providing transparency to the public regarding how the company addresses it

Continuing to engage with a diverse set of global civil society organizations, academics

Supporting efforts to foster public awareness, media literacy, and all-of-society resilience

These commitments apply where they are relevant for services each company provides.

“Elections are the beating heart of democracies. The Tech Accord to Combat Deceptive Use of AI in 2024 elections is a crucial step in advancing election integrity, increasing societal resilience, and creating trustworthy tech practices,” said Ambassador Christopher Heusgen, Munich Security Conference Chairman. “MSC is proud to offer a platform for technology companies to take steps toward reigning in threats emanating from AI while employing it for democratic good at the same time.”

“Transparency builds trust,” said Dana Rao, General Counsel and Chief Trust Officer at Adobe. “That’s why we’re excited to see this effort to build the infrastructure we need to provide context for the content consumers are seeing online. With elections happening around the world this year, we need to invest in media literacy campaigns to ensure people know they can’t trust everything they see and hear online, and that there are tools out there to help them understand what’s true.”

“Democracy rests on safe and secure elections,” said Kent Walker, President, Global Affairs at Google. “Google has been supporting election integrity for years, and today’s accord reflects an industry-side commitment against AI-generated election misinformation that erodes trust. We can’t let digital abuse threaten AI’s generational opportunity to improve our economies, create new jobs, and drive progress in health and science.”

“Disinformation campaigns are not new, but in this exceptional year of elections – with more than 4 billion people heading to the polls worldwide – concrete, cooperative measures are needed to protect people and societies from the amplified risks of AI-generated deceptive content,” said Christina Montgomery, Vice President and Chief Privacy & Trust Officer, IBM. “That’s why IBM today reaffirmed our commitment to ensuring safe, trustworthy, and ethical AI, signing the ‘Tech Accord to Combat Deceptive Use of AI in 2024 Elections’ alongside industry peers at the Munich Security Conference.”

“With so many major elections taking place this year, it’s vital we do what we can to prevent people being deceived by AI-generated content,” said Nick Clegg, President, Global Affairs at Meta. “This work is bigger than any one company and will require a huge effort across industry, government and civil society. Hopefully, this accord can serve as a meaningful step from industry in meeting that challenge.”

“As society embraces the benefits of AI, we have a responsibility to help ensure these tools don’t become weaponized in elections,” said Brad Smith, Vice Chair and President of Microsoft. “AI didn’t create election deception, but we must ensure it doesn’t help deception flourish.”

“We’re committed to protecting the integrity of elections by enforcing policies that prevent abuse and improving transparency around AI-generated content,” said Anna Makanju, Vice President of Global Affairs at OpenAI. “We look forward to working with industry partners, civil society leaders and governments around the world to help safeguard elections from deceptive AI use.”

“It’s crucial for industry to work together to safeguard communities against misleading and deceptive AI in this historic election year,” said Theo Bertram, VP, Global Public Policy, TikTok. “This builds on our continued investment in protecting election integrity and advancing responsible and transparent AI-generated content practices through robust rules, new technologies, and media literacy partnerships with experts.”

Linda Yaccarino, CEO of X said, “In democratic processes around the world, every citizen and company has a responsibility to safeguard free and fair elections, that’s why we must understand the risks AI content could have on the process. X is dedicated to playing its part, collaborating with peers to combat AI threats while also protecting free speech and maximizing transparency.”

More information can be found at: AIElectionsAccord.com.

Press Contact:

[email protected]"
Microsoft_News,https://techcommunity.microsoft.com/t5/microsoft-teams-blog/get-more-out-of-hybrid-meetings-with-teams-rooms-and-copilot/ba-p/4057302,,Get more out of hybrid meetings with Teams Rooms and Copilot,"Many organizations are asking how to get the most out of Artificial Intelligence (AI) to drive team productivity and make smarter and quicker business decisions. Microsoft Copilot has been embraced by early adopters for its ability to get clarity, update teams faster, and generate new ideas. This has been game-changing for individuals at work. But for teams, the conversations that happen in meetings are the building blocks to strategy, action items, and decisions. How do you capture the key insights and outcomes from your team discussions, and follow up on them efficiently?



The answer is simple: enabling Copilot in every space with Teams Rooms. The heaviest Copilot usage to date has been people using Copilot in Teams. * When asked how it has impacted their daily workflow, 70 percent reported they are more productive, 84 percent found it easier to take action after a meeting, and 79 percent say it reduced their administrative workload. Copilot in Teams lets you ask specific questions, seek clarifications, summarize perspectives expressed during meetings, and quickly organize meeting actions – all powered by responses sourced from meeting transcripts.



To fully leverage the potential of Copilot in Teams for hybrid meetings, it's essential that every participant, no matter their location, maintains their distinct identity during these meetings. This is precisely where Teams Rooms devices play a pivotal role.

Using Copilot in Teams to get insights from a meeting

Maintain your identity in meetings

The most essential input for Copilot in Teams is the identity of each speaker. Copilot needs a meeting transcript, with attribution for every speaker, to deliver meeting summaries, insights, and action items. In a hybrid meeting, without speaker recognition, the video and audio feed for people in the room would be attributed to the space (e.g., Conference Room 1), not the individuals speaking, making it difficult to query individuals’ contributions, summarize everyone’s perspectives, and tackle those to-do items.



Teams Rooms devices use advanced technology called speaker recognition to analyze the distinct vocal characteristics of each speaker, such as pitch, tone, and speaking style, to create a voiceprint for each participant, akin to a fingerprint for their voice.



With speaker recognition, Teams Rooms can identify speakers during live transcription in shared meeting rooms, ensuring clear and precise voice capture for every participant. This allows you to effortlessly track who said what during the meeting through intelligent meeting recap and Copilot.



To enable speaker recognition for your employees, you can set up a voice profile in minutes using the Teams Desktop app. Each person gets a unique voice signature, stored securely in your organization's tenant in Microsoft Cloud to assure that every contribution is accurately captured in every meeting, enabling Copilot and intelligent meeting recap – and helping you drive your work forward.

Optimizing Transcription Precision with Intelligent Speakers

Speaker recognition is currently enabled by intelligent speakers certified for Teams. Intelligent speakers are designed with multiple microphones to provide high-quality audio, maximizing accuracy in recognition and transcription and boasting an industry-leading reduction of what is referred to as “word error rate.”

That said, we get it – intelligent speakers are not yet in every Teams Room. That is why we announced at Ignite last year that speaker recognition will soon extend to existing hardware. While we're delighted to extend the capability of speaker recognition to more rooms, it's important to note that the quality may not match that of an intelligent speaker device. So, it's essential to evaluate the advantages of incorporating an intelligent speaker, particularly in crucial spaces where attaining the highest quality transcription and attribution is vital.

Get smarter insights, tasks, and decisions from your meetings

For many customers, the struggle lies in capturing key meeting insights, tracking decisions, and managing action items efficiently, all while ensuring efficient use of time and resources. Copilot, when paired with Teams Rooms devices, enables you to ask natural language questions about hybrid meeting details and participants, and receive instant answers and insights.



Imagine you're in a hybrid meeting, a mix of in-person and remote participants. It's crucial to stay on top of the discussion and make sure everyone is on the same page. You simply prompt Copilot in Teams to “summarize the key takeaways from our discussion today.” Copilot, powered by Teams Rooms devices, promptly compiles the highlights, maintaining each speaker's identity even when they're in the meeting room, ensuring a seamless experience for all participants, whether in-person or remote.

Using Copilot to summarize a hybrid meeting

AI has impact beyond Copilot, ensuring everyone is seen, heard, and recognized

Attending hybrid meetings and being able to see everyone in the room more clearly and intelligently can be a challenge, especially when there are multiple participants in the same physical space. How do you make sure that the remote participants can see the faces and expressions of the in-room participants, and that the camera continues to frame them as they move around the room?



When someone in the physical room speaks, IntelliFrame, using its intelligent camera technology, brings them into focus for online attendees, capturing every expression and gesture. It's like having a savvy camera assistant that focuses on each speaker. Integrating certified for Teams intelligent cameras and speakers with speaker recognition and Copilot enhances meetings, creating an immersive and interactive experience for all, regardless of location. Additionally, creating recognition profiles for IntelliFrame enables the camera to identify and label meeting participants, enriching meetings further. When combined with speaker recognition and Copilot, this fosters engagement and team cohesion, resulting in seamless and productive meetings for everyone.

IntelliFrame in Teams Rooms helps remote meeting participants get a better view of people in the room

Future-proof your meetings: Teams Rooms and Copilot

Copilot and Teams Rooms are the dynamic duo for hybrid meetings, bringing AI-powered features and effortless collaboration to tackle the challenges and unlock the benefits of hybrid setups. Whether clarifying who's speaking, extracting smart meeting insights, ensuring inclusivity, or providing clear visibility of participants, Copilot and Teams Rooms provide richer meeting experiences to improve your team's collaboration, engagement, and productivity. Even if you don't have Copilot yet, you can begin with Teams Rooms devices. It’s the first step in enhancing your hybrid work environments and preparing for integrating with Copilot in the future. Learn more about upgrading your meeting spaces and the latest innovations in Microsoft Teams Rooms. You will be ready to seamlessly transition to the full capabilities of Copilot and set the stage for a smarter, more connected meeting experience.



* What Can Copilot’s Earliest Users Teach Us About Generative AI at Work? Work Trend Index Special Report by Microsoft WorkLab, November 15, 2023."
Microsoft_News,https://www.microsoft.com/en-us/microsoft-365/blog/2024/02/13/making-our-generative-ai-products-safer-for-consumers/,,Making our generative AI products safer for consumers,"Over the past year, generative AI has seen tremendous growth in popularity and is increasingly being adopted by people and organizations. At its best, AI can deliver incredible inspiration and help unlock new levels of creativity and productivity. However, as with all new technologies, a small subset of people may attempt to misuse these powerful tools. At Microsoft, we are deeply focused on minimizing the risks of harmful use of these technologies and are committed to keeping these tools even more reliable and safer.

The goal of this blog is to outline the steps we are taking to ensure a safe experience for customers who use our consumer services like the Copilot website and Microsoft Designer.

Responsible AI process and mitigation

Since 2017, we’ve been building a responsible AI program that helps us map, measure, and manage issues before and after deployment. Governing—including policies that implement our AI principles, practices that help our teams build safeguards into our products, and processes to enable oversight—is critical throughout all stages of the Map, Measure, Manage framework as illustrated below. This overall approach reflects the core functions of NIST’s AI Risk Management Framework.

The Map, Measure, Manage framework

Map: The best way to develop AI systems responsibly is to identify issues and map them to user scenarios and to our technical systems before they occur. With any new technology, this is challenging because it’s hard to anticipate all potential uses. For that reason, we have several types of controls in place to help identify potential risks and misuse scenarios prior to deployment. We use techniques such as responsible AI impact assessments to identify potential positive and negative outcomes of our AI systems across a variety of scenarios and as they might affect a variety of stakeholders. Impact assessments are required for all AI products, and they help inform our design and deployment decisions.

We also conduct a process called red teaming that simulates attacks and misuse scenarios, along with general use scenarios that could result in harmful outputs, on our AI systems to test their robustness and resilience against malicious or unintended inputs and outputs. These findings are used to improve our security and safety measures.

Measure: While mapping processes like impact assessments and red teaming help to identify risks, we draw on more systematic measurement approaches to develop metrics that help us test, at scale, for those risks in our AI systems pre-deployment and post-deployment. These include ongoing monitoring through a diverse and multifaceted dataset that represents various scenarios where threats may arise. We also establish guidelines to annotate measurement datasets that help us develop metrics as well as build classifiers that detect potentially harmful content such as adult content, violent content, and hate speech.

We are working to automate our measurement systems to help with scale and coverage, and we scan and analyze AI operations to detect anomalies or deviations from expected behavior. Where appropriate, we also establish mechanisms to learn from user feedback signals and detected threats in order to strengthen our mitigation tools and response strategies over time.

Manage: Even with the best systems in place, issues will occur, and we have built processes and mitigations to manage issues and help prevent them from happening again. We have mechanisms in place in each of our products for users to report issues or concerns so anyone can easily flag items that could be problematic, and we monitor how users interact with the AI system to identify patterns that may indicate misuse or potential threats.

In addition, we strive to be transparent about not only risks and limitations to encourage user agency, but also that content itself may be AI-generated. For example, we take steps to disclose the role of generative AI to the user, and we label audio and visual content generated by AI tools. For content like AI-generated images, we deploy cryptographic methods to mark and sign AI-generated content with metadata about its source and history, and we have partnered with other industry leaders to create the Coalition for Content Provenance and Authenticity (C2PA) standards body to help develop and apply content provenance standards across the industry.

Finally, as generative AI technology evolves, we actively update our system mitigations to ensure we are effectively addressing risks. For example, when we update a generative AI product’s meta prompt, it goes through rigorous testing to ensure it advances our efforts to deliver safe and effective responses. There are several types of content filters in place that are designed to automatically detect and prevent the dissemination of inappropriate or harmful content. We employ a range of tools to address unique issues that may occur in text, images, video, and audio AI technologies and we draw on incident response protocols that activate protective actions when a possible threat is identified.

Ongoing improvements

We are aware that some users may try to circumvent our AI safety measures and use our systems for malicious purposes. We take this threat very seriously and we are constantly monitoring and improving our tools to detect and prevent misuse.

We believe it is our responsibility to stay ahead of bad actors and protect the integrity and trustworthiness of our AI products. In the rare cases where we encounter an issue, we aim to address it promptly and adjust our controls to help prevent it from recurring. We also welcome feedback from our users and stakeholders on how we can improve our AI safety architecture and policies and each of our products includes a feedback form for comments and suggestions.

We are committed to ensuring that our AI systems are used in a safe, responsible, and ethical manner."
Microsoft_News,https://www.microsoft.com/en-us/security/blog/2024/02/14/staying-ahead-of-threat-actors-in-the-age-of-ai/,,Staying ahead of threat actors in the age of AI,"Over the last year, the speed, scale, and sophistication of attacks has increased alongside the rapid development and adoption of AI. Defenders are only beginning to recognize and apply the power of generative AI to shift the cybersecurity balance in their favor and keep ahead of adversaries. At the same time, it is also important for us to understand how AI can be potentially misused in the hands of threat actors. In collaboration with OpenAI, today we are publishing research on emerging threats in the age of AI, focusing on identified activity associated with known threat actors, including prompt-injections, attempted misuse of large language models (LLM), and fraud. Our analysis of the current use of LLM technology by threat actors revealed behaviors consistent with attackers using AI as another productivity tool on the offensive landscape. You can read OpenAI’s blog on the research here. Microsoft and OpenAI have not yet observed particularly novel or unique AI-enabled attack or abuse techniques resulting from threat actors’ usage of AI. However, Microsoft and our partners continue to study this landscape closely.

The objective of Microsoft’s partnership with OpenAI, including the release of this research, is to ensure the safe and responsible use of AI technologies like ChatGPT, upholding the highest standards of ethical application to protect the community from potential misuse. As part of this commitment, we have taken measures to disrupt assets and accounts associated with threat actors, improve the protection of OpenAI LLM technology and users from attack or abuse, and shape the guardrails and safety mechanisms around our models. In addition, we are also deeply committed to using generative AI to disrupt threat actors and leverage the power of new tools, including Microsoft Copilot for Security, to elevate defenders everywhere.

A principled approach to detecting and blocking threat actors

The progress of technology creates a demand for strong cybersecurity and safety measures. For example, the White House’s Executive Order on AI requires rigorous safety testing and government supervision for AI systems that have major impacts on national and economic security or public health and safety. Our actions enhancing the safeguards of our AI models and partnering with our ecosystem on the safe creation, implementation, and use of these models align with the Executive Order’s request for comprehensive AI safety and security standards.

In line with Microsoft’s leadership across AI and cybersecurity, today we are announcing principles shaping Microsoft’s policy and actions mitigating the risks associated with the use of our AI tools and APIs by nation-state advanced persistent threats (APTs), advanced persistent manipulators (APMs), and cybercriminal syndicates we track.

These principles include:

Identification and action against malicious threat actors’ use: Upon detection of the use of any Microsoft AI application programming interfaces (APIs), services, or systems by an identified malicious threat actor, including nation-state APT or APM, or the cybercrime syndicates we track, Microsoft will take appropriate action to disrupt their activities, such as disabling the accounts used, terminating services, or limiting access to resources.

Notification to other AI service providers: When we detect a threat actor’s use of another service provider’s AI, AI APIs, services, and/or systems, Microsoft will promptly notify the service provider and share relevant data. This enables the service provider to independently verify our findings and take action in accordance with their own policies.

Collaboration with other stakeholders: Microsoft will collaborate with other stakeholders to regularly exchange information about detected threat actors’ use of AI. This collaboration aims to promote collective, consistent, and effective responses to ecosystem-wide risks.

Transparency: As part of our ongoing efforts to advance responsible use of AI, Microsoft will inform the public and stakeholders about actions taken under these threat actor principles, including the nature and extent of threat actors’ use of AI detected within our systems and the measures taken against them, as appropriate.

Microsoft remains committed to responsible AI innovation, prioritizing the safety and integrity of our technologies with respect for human rights and ethical standards. These principles announced today build on Microsoft’s Responsible AI practices, our voluntary commitments to advance responsible AI innovation and the Azure OpenAI Code of Conduct. We are following these principles as part of our broader commitments to strengthening international law and norms and to advance the goals of the Bletchley Declaration endorsed by 29 countries.

Microsoft and OpenAI’s complementary defenses protect AI platforms

Because Microsoft and OpenAI’s partnership extends to security, the companies can take action when known and emerging threat actors surface. Microsoft Threat Intelligence tracks more than 300 unique threat actors, including 160 nation-state actors, 50 ransomware groups, and many others. These adversaries employ various digital identities and attack infrastructures. Microsoft’s experts and automated systems continually analyze and correlate these attributes, uncovering attackers’ efforts to evade detection or expand their capabilities by leveraging new technologies. Consistent with preventing threat actors’ actions across our technologies and working closely with partners, Microsoft continues to study threat actors’ use of AI and LLMs, partner with OpenAI to monitor attack activity, and apply what we learn to continually improve defenses. This blog provides an overview of observed activities collected from known threat actor infrastructure as identified by Microsoft Threat Intelligence, then shared with OpenAI to identify potential malicious use or abuse of their platform and protect our mutual customers from future threats or harm.

Recognizing the rapid growth of AI and emergent use of LLMs in cyber operations, we continue to work with MITRE to integrate these LLM-themed tactics, techniques, and procedures (TTPs) into the MITRE ATT&CK® framework or MITRE ATLAS™ (Adversarial Threat Landscape for Artificial-Intelligence Systems) knowledgebase. This strategic expansion reflects a commitment to not only track and neutralize threats, but also to pioneer the development of countermeasures in the evolving landscape of AI-powered cyber operations. A full list of the LLM-themed TTPs, which include those we identified during our investigations, is summarized in the appendix.

Summary of Microsoft and OpenAI’s findings and threat intelligence

The threat ecosystem over the last several years has revealed a consistent theme of threat actors following trends in technology in parallel with their defender counterparts. Threat actors, like defenders, are looking at AI, including LLMs, to enhance their productivity and take advantage of accessible platforms that could advance their objectives and attack techniques. Cybercrime groups, nation-state threat actors, and other adversaries are exploring and testing different AI technologies as they emerge, in an attempt to understand potential value to their operations and the security controls they may need to circumvent. On the defender side, hardening these same security controls from attacks and implementing equally sophisticated monitoring that anticipates and blocks malicious activity is vital.

While different threat actors’ motives and complexity vary, they have common tasks to perform in the course of targeting and attacks. These include reconnaissance, such as learning about potential victims’ industries, locations, and relationships; help with coding, including improving things like software scripts and malware development; and assistance with learning and using native languages. Language support is a natural feature of LLMs and is attractive for threat actors with continuous focus on social engineering and other techniques relying on false, deceptive communications tailored to their targets’ jobs, professional networks, and other relationships.

Importantly, our research with OpenAI has not identified significant attacks employing the LLMs we monitor closely. At the same time, we feel this is important research to publish to expose early-stage, incremental moves that we observe well-known threat actors attempting, and share information on how we are blocking and countering them with the defender community.

While attackers will remain interested in AI and probe technologies’ current capabilities and security controls, it’s important to keep these risks in context. As always, hygiene practices such as multifactor authentication (MFA) and Zero Trust defenses are essential because attackers may use AI-based tools to improve their existing cyberattacks that rely on social engineering and finding unsecured devices and accounts.

The threat actors profiled below are a sample of observed activity we believe best represents the TTPs the industry will need to better track using MITRE ATT&CK® framework or MITRE ATLAS™ knowledgebase updates.

Forest Blizzard

Forest Blizzard (STRONTIUM) is a Russian military intelligence actor linked to GRU Unit 26165, who has targeted victims of both tactical and strategic interest to the Russian government. Their activities span across a variety of sectors including defense, transportation/logistics, government, energy, non-governmental organizations (NGO), and information technology. Forest Blizzard has been extremely active in targeting organizations in and related to Russia’s war in Ukraine throughout the duration of the conflict, and Microsoft assesses that Forest Blizzard operations play a significant supporting role to Russia’s foreign policy and military objectives both in Ukraine and in the broader international community. Forest Blizzard overlaps with the threat actor tracked by other researchers as APT28 and Fancy Bear.

Forest Blizzard’s use of LLMs has involved research into various satellite and radar technologies that may pertain to conventional military operations in Ukraine, as well as generic research aimed at supporting their cyber operations. Based on these observations, we map and classify these TTPs using the following descriptions:

LLM-informed reconnaissance: Interacting with LLMs to understand satellite communication protocols, radar imaging technologies, and specific technical parameters. These queries suggest an attempt to acquire in-depth knowledge of satellite capabilities.

Interacting with LLMs to understand satellite communication protocols, radar imaging technologies, and specific technical parameters. These queries suggest an attempt to acquire in-depth knowledge of satellite capabilities. LLM-enhanced scripting techniques: Seeking assistance in basic scripting tasks, including file manipulation, data selection, regular expressions, and multiprocessing, to potentially automate or optimize technical operations.

Microsoft observed engagement from Forest Blizzard that were representative of an adversary exploring the use cases of a new technology. All accounts and assets associated with Forest Blizzard have been disabled.

Emerald Sleet

Emerald Sleet (THALLIUM) is a North Korean threat actor that has remained highly active throughout 2023. Their recent operations relied on spear-phishing emails to compromise and gather intelligence from prominent individuals with expertise on North Korea. Microsoft observed Emerald Sleet impersonating reputable academic institutions and NGOs to lure victims into replying with expert insights and commentary about foreign policies related to North Korea. Emerald Sleet overlaps with threat actors tracked by other researchers as Kimsuky and Velvet Chollima.

Emerald Sleet’s use of LLMs has been in support of this activity and involved research into think tanks and experts on North Korea, as well as the generation of content likely to be used in spear-phishing campaigns. Emerald Sleet also interacted with LLMs to understand publicly known vulnerabilities, to troubleshoot technical issues, and for assistance with using various web technologies. Based on these observations, we map and classify these TTPs using the following descriptions:

LLM-assisted vulnerability research: Interacting with LLMs to better understand publicly reported vulnerabilities, such as the CVE-2022-30190 Microsoft Support Diagnostic Tool (MSDT) vulnerability (known as “Follina”).

Interacting with LLMs to better understand publicly reported vulnerabilities, such as the CVE-2022-30190 Microsoft Support Diagnostic Tool (MSDT) vulnerability (known as “Follina”). LLM-enhanced scripting techniques : Using LLMs for basic scripting tasks such as programmatically identifying certain user events on a system and seeking assistance with troubleshooting and understanding various web technologies.

Using LLMs for basic scripting tasks such as programmatically identifying certain user events on a system and seeking assistance with troubleshooting and understanding various web technologies. LLM-supported social engineering: Using LLMs for assistance with the drafting and generation of content that would likely be for use in spear-phishing campaigns against individuals with regional expertise.

Using LLMs for assistance with the drafting and generation of content that would likely be for use in spear-phishing campaigns against individuals with regional expertise. LLM-informed reconnaissance: Interacting with LLMs to identify think tanks, government organizations, or experts on North Korea that have a focus on defense issues or North Korea’s nuclear weapon’s program.

All accounts and assets associated with Emerald Sleet have been disabled.

Crimson Sandstorm

Crimson Sandstorm (CURIUM) is an Iranian threat actor assessed to be connected to the Islamic Revolutionary Guard Corps (IRGC). Active since at least 2017, Crimson Sandstorm has targeted multiple sectors, including defense, maritime shipping, transportation, healthcare, and technology. These operations have frequently relied on watering hole attacks and social engineering to deliver custom .NET malware. Prior research also identified custom Crimson Sandstorm malware using email-based command-and-control (C2) channels. Crimson Sandstorm overlaps with the threat actor tracked by other researchers as Tortoiseshell, Imperial Kitten, and Yellow Liderc.

The use of LLMs by Crimson Sandstorm has reflected the broader behaviors that the security community has observed from this threat actor. Interactions have involved requests for support around social engineering, assistance in troubleshooting errors, .NET development, and ways in which an attacker might evade detection when on a compromised machine. Based on these observations, we map and classify these TTPs using the following descriptions:

LLM-supported social engineering: Interacting with LLMs to generate various phishing emails, including one pretending to come from an international development agency and another attempting to lure prominent feminists to an attacker-built website on feminism.

Interacting with LLMs to generate various phishing emails, including one pretending to come from an international development agency and another attempting to lure prominent feminists to an attacker-built website on feminism. LLM-enhanced scripting techniques : Using LLMs to generate code snippets that appear intended to support app and web development, interactions with remote servers, web scraping, executing tasks when users sign in, and sending information from a system via email.

Using LLMs to generate code snippets that appear intended to support app and web development, interactions with remote servers, web scraping, executing tasks when users sign in, and sending information from a system via email. LLM-enhanced anomaly detection evasion: Attempting to use LLMs for assistance in developing code to evade detection, to learn how to disable antivirus via registry or Windows policies, and to delete files in a directory after an application has been closed.

All accounts and assets associated with Crimson Sandstorm have been disabled.

Charcoal Typhoon

Charcoal Typhoon (CHROMIUM) is a Chinese state-affiliated threat actor with a broad operational scope. They are known for targeting sectors that include government, higher education, communications infrastructure, oil & gas, and information technology. Their activities have predominantly focused on entities within Taiwan, Thailand, Mongolia, Malaysia, France, and Nepal, with observed interests extending to institutions and individuals globally who oppose China’s policies. Charcoal Typhoon overlaps with the threat actor tracked by other researchers as Aquatic Panda, ControlX, RedHotel, and BRONZE UNIVERSITY.

In recent operations, Charcoal Typhoon has been observed interacting with LLMs in ways that suggest a limited exploration of how LLMs can augment their technical operations. This has consisted of using LLMs to support tooling development, scripting, understanding various commodity cybersecurity tools, and for generating content that could be used to social engineer targets. Based on these observations, we map and classify these TTPs using the following descriptions:

LLM-informed reconnaissance : Engaging LLMs to research and understand specific technologies, platforms, and vulnerabilities, indicative of preliminary information-gathering stages.

: Engaging LLMs to research and understand specific technologies, platforms, and vulnerabilities, indicative of preliminary information-gathering stages. LLM-enhanced scripting techniques : Utilizing LLMs to generate and refine scripts, potentially to streamline and automate complex cyber tasks and operations.

: Utilizing LLMs to generate and refine scripts, potentially to streamline and automate complex cyber tasks and operations. LLM-supported social engineering : Leveraging LLMs for assistance with translations and communication, likely to establish connections or manipulate targets.

: Leveraging LLMs for assistance with translations and communication, likely to establish connections or manipulate targets. LLM-refined operational command techniques: Utilizing LLMs for advanced commands, deeper system access, and control representative of post-compromise behavior.

All associated accounts and assets of Charcoal Typhoon have been disabled, reaffirming our commitment to safeguarding against the misuse of AI technologies.

Salmon Typhoon

Salmon Typhoon (SODIUM) is a sophisticated Chinese state-affiliated threat actor with a history of targeting US defense contractors, government agencies, and entities within the cryptographic technology sector. This threat actor has demonstrated its capabilities through the deployment of malware, such as Win32/Wkysol, to maintain remote access to compromised systems. With over a decade of operations marked by intermittent periods of dormancy and resurgence, Salmon Typhoon has recently shown renewed activity. Salmon Typhoon overlaps with the threat actor tracked by other researchers as APT4 and Maverick Panda.

Notably, Salmon Typhoon’s interactions with LLMs throughout 2023 appear exploratory and suggest that this threat actor is evaluating the effectiveness of LLMs in sourcing information on potentially sensitive topics, high profile individuals, regional geopolitics, US influence, and internal affairs. This tentative engagement with LLMs could reflect both a broadening of their intelligence-gathering toolkit and an experimental phase in assessing the capabilities of emerging technologies.

Based on these observations, we map and classify these TTPs using the following descriptions:

LLM-informed reconnaissance: Engaging LLMs for queries on a diverse array of subjects, such as global intelligence agencies, domestic concerns, notable individuals, cybersecurity matters, topics of strategic interest, and various threat actors. These interactions mirror the use of a search engine for public domain research.

Engaging LLMs for queries on a diverse array of subjects, such as global intelligence agencies, domestic concerns, notable individuals, cybersecurity matters, topics of strategic interest, and various threat actors. These interactions mirror the use of a search engine for public domain research. LLM-enhanced scripting techniques: Using LLMs to identify and resolve coding errors. Requests for support in developing code with potential malicious intent were observed by Microsoft, and it was noted that the model adhered to established ethical guidelines, declining to provide such assistance.

Using LLMs to identify and resolve coding errors. Requests for support in developing code with potential malicious intent were observed by Microsoft, and it was noted that the model adhered to established ethical guidelines, declining to provide such assistance. LLM-refined operational command techniques: Demonstrating an interest in specific file types and concealment tactics within operating systems, indicative of an effort to refine operational command execution.

Demonstrating an interest in specific file types and concealment tactics within operating systems, indicative of an effort to refine operational command execution. LLM-aided technical translation and explanation: Leveraging LLMs for the translation of computing terms and technical papers.

Salmon Typhoon’s engagement with LLMs aligns with patterns observed by Microsoft, reflecting traditional behaviors in a new technological arena. In response, all accounts and assets associated with Salmon Typhoon have been disabled.





In closing, AI technologies will continue to evolve and be studied by various threat actors. Microsoft will continue to track threat actors and malicious activity misusing LLMs, and work with OpenAI and other partners to share intelligence, improve protections for customers and aid the broader security community.

Appendix: LLM-themed TTPs

Using insights from our analysis above, as well as other potential misuse of AI, we’re sharing the below list of LLM-themed TTPs that we map and classify to the MITRE ATT&CK® framework or MITRE ATLAS™ knowledgebase to equip the community with a common taxonomy to collectively track malicious use of LLMs and create countermeasures against:

LLM-informed reconnaissance: Employing LLMs to gather actionable intelligence on technologies and potential vulnerabilities.

Employing LLMs to gather actionable intelligence on technologies and potential vulnerabilities. LLM-enhanced scripting techniques: Utilizing LLMs to generate or refine scripts that could be used in cyberattacks, or for basic scripting tasks such as programmatically identifying certain user events on a system and assistance with troubleshooting and understanding various web technologies.

Utilizing LLMs to generate or refine scripts that could be used in cyberattacks, or for basic scripting tasks such as programmatically identifying certain user events on a system and assistance with troubleshooting and understanding various web technologies. LLM-aided development : Utilizing LLMs in the development lifecycle of tools and programs, including those with malicious intent, such as malware.

: Utilizing LLMs in the development lifecycle of tools and programs, including those with malicious intent, such as malware. LLM-supported social engineering : Leveraging LLMs for assistance with translations and communication, likely to establish connections or manipulate targets.

: Leveraging LLMs for assistance with translations and communication, likely to establish connections or manipulate targets. LLM-assisted vulnerability research : Using LLMs to understand and identify potential vulnerabilities in software and systems, which could be targeted for exploitation.

: Using LLMs to understand and identify potential vulnerabilities in software and systems, which could be targeted for exploitation. LLM-optimized payload crafting : Using LLMs to assist in creating and refining payloads for deployment in cyberattacks.

: Using LLMs to assist in creating and refining payloads for deployment in cyberattacks. LLM-enhanced anomaly detection evasion : Leveraging LLMs to develop methods that help malicious activities blend in with normal behavior or traffic to evade detection systems.

: Leveraging LLMs to develop methods that help malicious activities blend in with normal behavior or traffic to evade detection systems. LLM-directed security feature bypass : Using LLMs to find ways to circumvent security features, such as two-factor authentication, CAPTCHA, or other access controls.

: Using LLMs to find ways to circumvent security features, such as two-factor authentication, CAPTCHA, or other access controls. LLM-advised resource development: Using LLMs in tool development, tool modifications, and strategic operational planning.

Learn more

Read the sixth edition of Cyber Signals, spotlighting how we are protecting AI platforms from emerging threats related to nation-state cyberthreat actors: Navigating cyberthreats and strengthening defenses in the era of AI.

For the latest security research from the Microsoft Threat Intelligence community, check out the Microsoft Threat Intelligence Blog: https://aka.ms/threatintelblog.

To get notified about new publications and to join discussions on social media, follow us on LinkedIn at https://www.linkedin.com/showcase/microsoft-threat-intelligence, and on X (formerly Twitter) at https://twitter.com/MsftSecIntel.

To hear stories and insights from the Microsoft Threat Intelligence community about the ever-evolving threat landscape, listen to the Microsoft Threat Intelligence podcast: https://thecyberwire.com/podcasts/microsoft-threat-intelligence."
Microsoft_News,https://blogs.microsoft.com/on-the-issues/2024/02/13/generative-ai-content-abuse-online-safety/,,Combating abusive AI-generated content: a comprehensive approach,"Each day, millions of people use powerful generative AI tools to supercharge their creative expression. In so many ways, AI will create exciting opportunities for all of us to bring new ideas to life. But, as these new tools come to market from Microsoft and across the tech sector, we must take new steps to ensure these new technologies are resistant to abuse.

The history of technology has long demonstrated that creativity is not confined to people with good intentions. Tools unfortunately also become weapons, and this pattern is repeating itself. We’re currently witnessing a rapid expansion in the abuse of these new AI tools by bad actors, including through deepfakes based on AI-generated video, audio, and images. This trend poses new threats for elections, financial fraud, harassment through nonconsensual pornography, and the next generation of cyber bullying.

We need to act with urgency to combat all these problems.

In an encouraging way, there is a lot we can learn from our experience as an industry in adjacent spaces – in advancing cybersecurity, promoting election security, combating violent extremist content, and protecting children. We are committed as a company to a robust and comprehensive approach that protects people and our communities, based on six focus areas:

1. A strong safety architecture. We are committed to a comprehensive technical approach grounded in safety by design. Depending on the scenario, a strong safety architecture needs to be applied at the AI platform, model, and applications levels. It includes aspects such as ongoing red team analysis, preemptive classifiers, the blocking of abusive prompts, automated testing, and rapid bans of users who abuse the system. It needs to be based on strong and broad-based data analysis. Microsoft has established a sound architecture and shared our learning via our Responsible AI and Digital Safety Standards, but it’s clear that we will need to continue to innovate in these spaces as technology evolves.

2. Durable media provenance and watermarking. This is essential to combat deepfakes in video, images, or audio. Last year at our Build 2023 conference, we announced media provenance capabilities that use cryptographic methods to mark and sign AI-generated content with metadata about its source and history. Together with other leading companies, Microsoft has been a leader in R&D on methods for authenticating provenance, including as a co-founder of Project Origin and the Coalition for Content Provenance and Authenticity (C2PA) standards body. Just last week, Google and Meta took important steps forward in supporting C2PA, steps that we appreciate and applaud.

We are already using provenance technology in the Microsoft Designer image creation tools in Bing and in Copilot, and we are in the process of extending media provenance to all our tools that create or manipulate images. We are also actively exploring watermarking and fingerprinting techniques that help to reinforce provenance techniques. We’re committed to ongoing innovation that will help users quickly determine if an image or video is AI generated or manipulated.

3. Safeguarding our services from abusive content and conduct. We’re committed to protecting freedom of expression. But this should not protect individuals that seek to fake a person’s voice to defraud a senior citizen of their money. It should not extend to deepfakes that alter the actions or statements of political candidates to deceive the public. Nor should it shield a cyber bully or distributor of nonconsensual pornography. We are committed to identifying and removing deceptive and abusive content like this when it is on our hosted consumer services such as LinkedIn, our Gaming network, and other relevant services.

4. Robust collaboration across industry and with governments and civil society. While each company has accountability for its own products and services, experience suggests that we often do our best work when we work together for a safer digital ecosystem. We are committed to working collaboratively with others in the tech sector, including in the generative AI and social media spaces. We are also committed to proactive efforts with civil society groups and in appropriate collaboration with governments.

As we move forward, we will draw on our experience combating violent extremism under the Christchurch Call, our collaboration with law enforcement through our Digital Crimes Unit, and our efforts to better protect children through the WeProtect Global Alliance and more broadly. We are committed to taking new initiatives across the tech sector and with other stakeholder groups.

5. Modernized legislation to protect people from the abuse of technology. It is already apparent that some of these new threats will require the development of new laws and new efforts by law enforcement. We look forward to contributing ideas and supporting new initiatives by governments around the world, so we can better protect people online while honoring timeless values like the protection of free expression and personal privacy.

6. Public awareness and education. Finally, a strong defense will require a well-informed public. As we approach the second quarter of the 21st century, most people have learned that you can’t believe everything you read on the internet (or anywhere else). A well-informed combination of curiosity and skepticism is a critical life skill for everyone.

In a similar way, we need to help people recognize that you can’t believe every video you see or audio you hear. We need to help people learn how to spot the differences between legitimate and fake content, including with watermarking. This will require new public education tools and programs, including in close collaboration with civil society and leaders across society.

Ultimately, none of this will be easy. It will require hard but indispensable efforts every day. But with a common commitment to innovation and collaboration, we believe that we can all work together to ensure that technology stays ahead in its ability to protect the public. Perhaps more than ever, this must be our collective goal.

Tags: AI, Bing, Christchurch Call, Copilot, digital safety, generative ai, Microsoft Designer, Online Safety, Responsible AI, WeProtect Global Alliance"
Microsoft_News,https://news.microsoft.com/three-big-ai-trends-to-watch-in-2024/,,3 big AI trends to watch in 2024,"By Vanessa Ho



2023 was a major year for generative AI, as it went from research labs to real life with millions of people using it through popular tools like ChatGPT and Microsoft Copilot. This year, AI is expected to become more accessible, nuanced and integrated in technologies that improve everyday tasks and help solve some of the world’s most challenging problems.

Here are three important AI trends to keep an eye on in 2024."
Microsoft_News,https://www.microsoft.com/en-us/industry/blog/telecommunications/2024/02/06/mwc-barcelona-2024-accelerating-telco-transformation-in-the-era-of-ai/,,MWC Barcelona 2024: Accelerating telco transformation in the era of AI,"Generative AI provides a big boost to the telecommunications industry Read the blog

I am excited to return to Mobile World Congress (MWC), February 26 to February 29, 2024, in Barcelona. AI has become a strategic imperative for telecom companies to gain a competitive edge and thrive in the market. AI has been proven to accelerate transformation by enabling telcos to provide better customer service and experience, optimize network performance and reliability, enhance security, and innovate new products and services. We are specifically seeing how generative AI is providing a big boost to the telecommunications industry. Microsoft has a long history of partnering with telecommunications companies, and the era of AI has provided tremendous opportunities for joint innovation and collaboration.

This year, we look to inspire and enable telco transformation at the world’s largest and most influential connectivity event. Keep an eye out for compelling updates from Microsoft Azure for Operators and industry-making news from partners. We look forward to discussions around the latest use cases in the industry.

MWC Barcelona 2024 The world's largest and most influential connectivity event Register now

Powerful Microsoft and partner demos in the booth

Microsoft empowers telecommunications organizations to achieve more through a trusted and secure platform supported by a comprehensive partner ecosystem. Our booth (3H30 in Hall 3) will showcase several scenarios that are critical to enabling the transformation process.

Microsoft azure openai service Discover solutions

Elevate customer experiences

Empower service teams with data-driven insights to increase productivity and enhance care. Come see how many customers are using Microsoft Azure OpenAI Service to enable self-service, expedite issue resolution, and deliver frictionless customer experiences at scale. Learn about end-to-end customer care powered by AI and see various industry use cases from customers: Telkomsel, Vodafone, MTN, and NTT (other solutions to be announced).



Amdocs, in partnership with Microsoft, launched a unified Customer Engagement Platform leveraging the power of generative AI. Integrated with Microsoft Dynamics 365, it is an all-encompassing, AI-powered marketing, sales, commerce, and customer service platform serving consumer and enterprise customers on a single, open, telco, and cloud-native platform.

Empower service teams with data-driven insights to increase productivity and enhance care. Come see how many customers are using Microsoft Azure OpenAI Service to enable self-service, expedite issue resolution, and deliver frictionless customer experiences at scale. Learn about end-to-end customer care powered by AI and see various industry use cases from customers: Telkomsel, Vodafone, MTN, and NTT (other solutions to be announced). Amdocs, in partnership with Microsoft, launched a unified Customer Engagement Platform leveraging the power of generative AI. Integrated with Microsoft Dynamics 365, it is an all-encompassing, AI-powered marketing, sales, commerce, and customer service platform serving consumer and enterprise customers on a single, open, telco, and cloud-native platform. Streamline business operations

Use cloud-native apps, smart processes, and automation to streamline workflows, improve operations, and connect your business. Work and collaborate securely with anyone, anywhere, anytime, using intelligent tools. Witness Microsoft Copilot for Microsoft 365 in action along with exciting new demos from Microsoft Mesh and Teams Phone Mobile. Visit TM Forum in our booth and learn how AI has boosted developer productivity. Experience how GitHub Copilot simplifies the creation and consumption of TM Forum Open APIs by generating the required code that complies to the API guidelines in the development language of your choice.

Use cloud-native apps, smart processes, and automation to streamline workflows, improve operations, and connect your business. Work and collaborate securely with anyone, anywhere, anytime, using intelligent tools. Witness Microsoft Copilot for Microsoft 365 in action along with exciting new demos from Microsoft Mesh and Teams Phone Mobile. Visit TM Forum in our booth and learn how AI has boosted developer productivity. Experience how GitHub Copilot simplifies the creation and consumption of TM Forum Open APIs by generating the required code that complies to the API guidelines in the development language of your choice. Modernize the network

Run modern networks and carrier-grade workloads on a trusted, hybrid cloud platform purpose-built for operators to optimize existing investments and improve network efficiency, scalability, and reliability. Transform your service management experience into a modern cloud service and remove data silos and deliver business insights from your massive datasets. Witness our end-to-end security solutions leveraging Microsoft Security Copilot and Nokia’s NetGuard Cybersecurity Dome.

Run modern networks and carrier-grade workloads on a trusted, hybrid cloud platform purpose-built for operators to optimize existing investments and improve network efficiency, scalability, and reliability. Transform your service management experience into a modern cloud service and remove data silos and deliver business insights from your massive datasets. Witness our end-to-end security solutions leveraging Microsoft Security Copilot and Nokia’s NetGuard Cybersecurity Dome. Monetize 5G and beyond

Drive today’s new revenue streams and tomorrow’s growth by exposing operators’ innovation to consumers, enterprises, and developers in the Microsoft Cloud, spanning 5G to space and beyond.



See new Azure for Operators demonstrations of solutions for the enterprise edge along with Etisalat and Pegatron 5G.

copilot for microsoft 365 Learn more

Microsoft and industry experience in the sessions

Take advantage of the opportunity to hear from Microsoft executives and industry experts on stage in the following sessions:

Check back for more sessions to be announced.

Our commitment to industry

Microsoft empowers telecommunications organizations to achieve more through a trusted and secure platform built to elevate customer experiences, streamline business operations, accelerate network transformation, reinvent product innovation and monetization, and build a secure data-driven business. Stay tuned for exciting announcements at MWC Barcelona 2024.

Our commitment to the telecommunications industry extends beyond MWC Barcelona 2024. More information can be found on the Microsoft for telecommunications website."
Microsoft_News,https://news.microsoft.com/source/asia/features/indias-schoolteachers-are-drafting-better-lesson-plans-faster-thanks-to-a-copilot/,,"India’s schoolteachers are drafting better lesson plans faster, thanks to a copilot","Shiksha copilot is part of Project VeLLM, Microsoft Research India’s platform to develop specialized generative AI copilots that are accessible to everyone from teachers to farmers to small business owners. Shiksha means education in Sanskrit.

It is built on Microsoft Azure OpenAI Service and combined with the school curriculum and learning objectives. Azure Cognitive Service is used to ingest the text in textbooks including how the content is organized.

With Shiksha copilot, the researchers hope India’s army of overstretched government schoolteachers could soon get a break – and their students could enjoy livelier and richer lessons.

From the teacher’s perspective, the biggest benefit is the time saved preparing for class. Ravindra, who has taught science and math at the Government Higher Primary School Venkatarayanadoddi for 15 years, says he used to spend up to 40 minutes putting pen to paper to write a single lesson plan. “Now we can have a new lesson within 10 minutes,” he said.

In this school of five teachers and 69 students, whose parents mostly grow mangoes or rear silkworms for a living, resources can be scarce. So Ravindra modifies the plan as needed. If he doesn’t have materials needed for a suggested activity, he asks Shiksha copilot for another idea, specifying what he does have on hand. If a video is too long, he asks for a shorter one. He can also modify assignments and ask questions.

“The old method of chalk and blackboard is not sufficient anymore,” said Ravindra. “The time saved by Shiksha, I’m spending with the kids.”

Click here to load media

Big class sizes

Creating lesson plans has always been laborious work. A teacher starts with government curricula, usually textbooks, then creates one based on the school’s resources, the make-up of learners and the teacher’s own ability and experience. If that’s not hard enough, now try capturing the attention of a generation fed on social media and online videos.

Here, teachers also grapple with bigger class sizes than elsewhere. In Indian primary schools, there is one teacher to every 33 students versus the world average of 23, according to UNESCO 2020 data. In China, the ratio is 1:16; in Brazil, it’s 1:20 and North America is 1:14.

In India, as people move from villages to cities, urban class sizes can balloon to between 40 and 80 students, according to the Bengaluru-based Sikshana Foundation.

Over the years, that has led even people with minimal incomes to resort to borrowing money to send their kids to private schools, said CEO Prasanna Vadayar.

Vadayar grew up in Karnataka and moved to the U.S. to pursue a master’s in computer engineering from Texas A&M University before starting a successful software business in Austin, Texas. He returned to India to head Sikshana in 2007 while on a sabbatical. He’s still here.

Prasanna Vadayar, chief executive officer of Sikshana Foundation, at his Bengaluru office. Photo by Selvaprakash Lakshmanan for Microsoft.

Sikshana Foundation’s mission is to reverse the exodus from government schools by raising the quality of education – permanently. “When people ask me why I joined Sikshana,” said Vadayar, “I tell them ‘to shut it down.’”

Sikshana is known for its low-cost, effective interventions that can be adopted by the government. It now works in six states across India, covering 50,000 schools and impacting three million students.

Its Prerana project, for example, provides opportunities for students to be peer leaders and rewards students for small, daily achievements, from regular attendance to doing well in academics and sports. Students get shiny stars of colored foil that they can collect and safety-pin to their shirts, and colorful stickers denoting lessons learned. Kids get motivated and parents can easily see what their child has achieved.

Prerana was adopted by the Karnataka government in 2018 and rolled out across the state.

A couple of years ago, Vadayar noticed how teachers were bogged down preparing for lessons and tried to find a solution but gave up, pending the right tech. In early 2023, when Microsoft Research India came knocking with Shiksha copilot, Vadayar remembers thinking, “Boom!”

Generative AI for the masses

In Microsoft, Sikshana found a partner with the tech solution it was seeking. In Sikshana, Microsoft found an avenue to test the solution in schools and hopefully, mass adoption, possibly beyond India.

“This is a global problem,” said Vadayar. “The learning ecosystem is not able to keep up with technology in the class and teachers are not able to keep up their learning chops. Kids expect something more.”

Akshay Nambi and Tanuja Ganu are researchers on Shiksha copilot at Microsoft Research India and have worked closely on other projects.

(L-R) Akshay Nambi and Tanuja Ganu, researchers at Microsoft Research India, posing for a portrait outside the Sikshana Foundation office in Bengaluru. Photo by Selvaprakash Lakshmanan for Microsoft.

“A year ago, we wanted to look at how we could apply GenAI to solve real-world problems at population scale,” Ganu said. Added Nambi, “Shiksha copilot is a research vehicle for us to understand how users use them and get user feedback to improve the overall copilot experience.”

Generative AI tools are built on large language models (LLMs) that synthesize massive amounts of data to generate text, code, images and more. But results can be imperfect. In recent months, researchers have sought to improve accuracy by adding specific domain knowledge – in this case, the education curriculum of Karnataka state.

Retrieving information from that knowledge base cuts the risk of errors, said Nambi. That information is then brought into the LLM which generates the lesson plan. The copilot is multimodal, meaning it includes images and video as well as text, and draws publicly available videos from the internet. Finally, Azure OpenAI Service content filters and built-in prompts keep out inappropriate content, for example, racial or caste-related issues. Through it all, the teacher is the “expert in the loop,” Nambi said, with students having no direct contact with Shiksha copilot.

At the end of December 2023, the Sikshana Foundation surveyed the teachers on their experience with Shiksha. Five were from urban schools and 25 from rural schools. The majority were teaching in Kannada, with just six teaching in English.

The vast majority of respondents said Shiksha copilot cut their lesson plan preparation from an hour or more to between five and 15 minutes and 90 percent said they only needed to make minor modifications, if any, to the plans generated. Each teacher generated on average three to four lesson plans each week.

“Every class is becoming lively”

For the small cohort of teachers trying out the system, it’s already making a difference.

The Government Higher Primary School Basavanahalli in the town of Nelamangala on the outskirts of Bengaluru is an L-shaped building painted orange and lime green, with a dusty schoolyard where students from grades one to eight assemble and play. The school has 13 teachers, 438 students and an average class size of 30.

Science and math teacher Mahalakshmi Ashok, who has been testing Shiksha copilot, says it has freed up time for her to add activities in class.

Sitting in the teachers’ meeting room, where the walls are lined with portraits of Karnataka notables, Mahalakshmi fires up her laptop and opens Shiksha copilot.

Mahalakshmi Ashok, a government schoolteacher and acting headmistress, actively engaged with the Shiksha copilot at Government Higher Primary School in Basavanahalli, Karnataka state, India. Photo by Selvaprakash Lakshmanan for Microsoft.

The first page is a series of fields with drop-down menus: Select education board, medium (English or Kannada for now, with other local languages to come), class, semester, subject (currently English, Math, Social Science and Science) and topic.

She picks Science, types “Circulatory System” and selects Duration: 40 minutes. Instantly, Shiksha copilot generates a lesson plan – with the option to generate a PDF, PowerPoint slides or handout – together with suggested activities, videos and assessment. After each sub-section, there is a choice of three emojis to rate what’s been generated.

In the past, Mahalakshmi said, when teaching the cardiovascular system, she might have drawn a diagram of a heart on the blackboard and talked through its function. Recently, she tried a new activity suggested by Shiksha copilot. Each student put a finger on their wrist to locate their pulse and measured the beats per minute. They compared results and discussed why some might have a faster or slower heartbeat than others.

One copilot-suggested activity – a blood-typing lab – was out of the question. But another activity – taking one’s blood pressure – might be possible. Mahalakshmi thinks she might bring a blood pressure cuff from home next time for the kids to try out.

“Obviously, they like these experiments,” said Mahalakshmi, who has taught for 20 years and is also the current acting head of school. “Each and every class is becoming lively. The learning has become easier.”

Mahalakshmi Ashok, a government schoolteacher and acting headmistress, demonstrates a science experiment suggested by the Shiksha copilot at Government Higher Primary School in Basavanahalli, Karnataka state, India. Photo by Selvaprakash Lakshmanan for Microsoft.

At a recent science class on “Separation of Substances,” she brought in small bags of rice, wheat, sand and water to illustrate the lesson. The class of 6th graders, wearing all-white uniforms, the girls with hair in looped braids, already knew the concepts. They yelled in unison as Mahalakshmi went through the motions, “Handpicking! Winnowing! Sedimentation! Filtration!” and so on.

Asked if she had taught this way before, she said “No,” cocked her head and added, “Because I’m getting more time, no?”

Beyond lesson plans

The next phase is to expand the pilot to 100 schools by the end of the academic year in March, said Smitha Venkatesh, chief program officer at the Sikshana Foundation. Then starting in April, the team will start curating the best-rated lesson plans, so teachers can modify existing plans instead of having to create new ones.

Smitha, who joined Sikshana 11 years ago after studying and working in the U.S., said she has come to understand the myriad challenges teachers face.

Smitha Venkatesh, chief program officer, Sikshana Foundation, at Government Higher Primary School Venkatarayanadoddi, Kanakapura, Karnataka state, India. Photo by Selvaprakash Lakshmanan for Microsoft.

“There is the perception that government schools are not good,” she said. “But we acknowledge that teachers are doing so much more than just teaching. Not just make sure students learn, but also make sure they get their uniforms, make sure they have their meals, conduct census, etc. Shiksha copilot can help teachers deliver better within the time constraints.”

Perhaps in the future, Shiksha copilot can also help with other tasks such as scheduling classes or tracking learning, said Smitha. Maybe it can also help students who are struggling.

“AI is exciting, yes,” she said. “But at the end of the day, can it help the teacher, and can it help the child?”

Top image: Teacher Ravindra K. Nagaiah with his 7th grade science class at Government Higher Primary School Venkatarayanadoddi in Kanakapura, Karnataka state, India. Photo by Selvaprakash Lakshmanan for Microsoft."
Microsoft_News,https://blogs.microsoft.com/blog/2024/02/07/delivering-copilot-for-everyone/,,Delivering Copilot for everyone,"As we approach Super Bowl weekend, we’re thrilled to be a part of the festivities for the first time in four years. This year, we’re proud to celebrate the transformative power of AI and Microsoft Copilot, showcasing peoples’ “watch me” moments with Copilot enabling people to do things previously unattainable. With a simple sentence or two, you will see a budding entrepreneur turn a fledgling idea for a new product into an actionable business plan, a filmmaker’s concept into a rich set of storyboards, and a fantasy football player’s team come to life with a mascot image they can edit inline.

Coincident with the launch of our Super Bowl ad, we are also launching a significant new update to our Microsoft Copilot experience on copilot.microsoft.com and our Copilot app on iOS and Android app stores. Today when you visit Copilot, you will see a more streamlined look and feel designed to help you bring your ideas to life and more easily gain understanding about the world. We have introduced a cleaner, sleeker look and feel for answers and a fun new carousel of suggested prompts to showcase the power of Copilot.

Today marks exactly one year since our entry into AI-powered experiences for people with Bing Chat. In that year we have learned so many new things and seen the use of our Copilot experiences explode with over 5 billion chats and 5 billion images created to date which have led to sustained growth in Edge and Bing share. Now with Copilot as our singular experience for people looking to get more out of AI creation, we are today introducing further image creation capabilities.

With Designer in Copilot, you can go beyond just creating images to now customize your generated images with inline editing right inside Copilot1, keeping you in the flow of your chat. Whether you want to highlight an object to make it pop with enhanced color, blur the background of your image to make your subject shine, or even reimagine your image with a different effect like pixel art,2 Copilot has you covered, all for free. If you’re a Copilot Pro subscriber, in addition to the above, you can also now easily resize and regenerate images between square and landscape without leaving chat. Lastly, we will soon roll out our new Designer GPT inside Copilot, which offers an immersive, dedicated canvas inside of Copilot where you can visualize your ideas.

YouTube Video Click here to load media

Copilot is free to use and works on Microsoft Edge, Chrome, Firefox and Safari. Or download the Copilot mobile app on iOS or Android.

AI is the defining technology of our time. Microsoft’s advancements in AI align with our company mission to empower every person and organization on the planet to achieve more. With Copilot, we’re democratizing our breakthroughs in AI to help make the promise of AI real for everyone.

1Available in English in the United States, United Kingdom, Australia, India and New Zealand.

215 daily boosts included in Copilot, 100 daily boosts with a Copilot Pro subscription to be used for creative needs, faster image generation, and more detailed images.

Tags: AI, Copilot Pro, Microsoft Copilot, Microsoft Designer"
Microsoft_News,https://news.microsoft.com/source/asia/features/village-by-village-creating-the-building-blocks-for-ai-tools-with-work-that-also-educates/,,"Village by village, creating the building blocks for AI tools with work that also educates","“At Microsoft, we say we want to empower the entire planet, right? And more than half the world’s population uses languages other than English.”

Bali says that AI has greatly sped up the process of language preservation and its use in large language models (LLMs). This is useful in creating online and AI tools, but also for preserving rare or dying languages.

“Now we can create these copilot kinds of things really quickly,” she says. “Previously when we were talking about language preservation, we were talking about efforts that took place over decades, literally. … All of that can now be shortened to months.”

Karya, which says it is on pace to engage with more than 100,000 workers by the end of 2024, seeks participants who need work and education the most – often women in rural areas. In addition to a premium wage, it offers training and other kinds of support when the work is done.

‘Technology can really, really help amplify people’s desires’

Chopra grew up in a “basti” – an informal settlement – in Delhi and says that the inequities he witnessed growing up had a profound effect on his sense of purpose while studying computer science with a focus on AI at Stanford University in California.

“When I moved back to India, the first thing I realized was, everywhere I went, people had the intent or the will to get out of poverty, everyone works really hard, everyone has aspiration,” he says. “And they have the capacity to learn new skills. And if those two things exist, technology can really, really help amplify people’s desires, to make something of themselves.”

The work Bokale did over the course of 11 days was part of a pilot project to test whether the work of inputting data could be combined with the learning of useful information. While earning what for them was a substantial amount of money, they’d also be learning about the financial tools they need to make the best use of it.

The material was presented as a serialized story about two sisters, and it was this story that the workers read aloud into their smartphones to capture the sounds and rhythms of spoken Marathi. “We really enjoyed the story,” Bokale says, “And in that story, there were common people who are working hard every day. The money they earned would be easily spent, there were no savings. In short, the question was how to save.”

Safiya Husain, Karya’s chief impact officer, said that the story format proved a success, and that many of the participants read the story out loud to their families and friends.

Safiya Husain, the chief impact officer of Karya. Photo by Chris Welsch for Microsoft.

“They would say, ‘I’m going to do this work and read the story to you,” Husain says. “And they would actually get excited and wonder, ‘Oh, what is happening next? Will she get her loan? Or will she have enough money to pay for the wedding?’”

She says that by combining work with education, Karya was trying to treat its workers with respect and create outcomes beyond income that are meaningful. “We were paying people for their time, and we were saying what they were doing was valuable,” she says. “It wasn’t just, here’s a lesson to learn in your spare time.”

Husain says she hopes that eventually many of the Karya workers will join the organization in different roles, working as organizers and local administrators. In the big picture, she says, the aim is to put technology to work for everyone.

“When we’re collecting data in these languages like Marathi, we’re trying to make sure that these communities and these populations, which have millions and millions of speakers, are not being left behind in the technology revolution,” she says.

Engaging whole communities in the project

Kalika Bali, the Microsoft researcher, says one of the keys to the success of Karya is that it strives to engage whole communities in the project. Most of Karya’s workers are women, and she says they have more “circles of trust” to cross than men.

“The men only need to ask two things: will this work for me, and will I get paid?” she says. “Women have to ask; will my family accept it? Will this bring a bad name to my family and myself by doing this? Is this going to harm me in some way? Only then does it come to the platform and the money.”

“The advantage with Karya is that it has created a lot of trust on the ground. They are really engaged with the communities they’re in,” she says.

In her neighborhood in Pune, Bokale is a well-known figure who is universally known as Baby Tai, tai meaning “elder sister.” She runs an informal financial network with several dozen other women who pool savings monthly and take turns taking a larger amount to use for things like starting a small business or paying school fees. Women often show up on her tree-shaded patio to talk business or just hang out. Her chili and spice grinding equipment is in a small tin shed on one side of the small yard.

From left, Parvati Kemble, Surekha Sanjay Gaikwad and Baby Rajaram Bokale discussing their self-help banking group in the Kharadi neighborhood of Pune, India. Photo by Chris Welsch for Microsoft.

Surekha Sanjay Gaikwad, 51, is one of her neighbors and friends. She runs a small grocery store about a half hour from her home. She also reads Marathi into her phone for Karya. Sitting with Bokale on her front steps, she burst into a wide grin when asked what she liked about the experience.

“I couldn’t believe I could do it at home,” she says. “I don’t have to get on a bus again or go anywhere else at the end of the day.”

The education component of the work was a plus, Gaikwad said. She learned how to create a fixed deposit at the bank, and she did just that as a way to save more effectively for her son’s college studies.

Over the course of a recent morning, several other women who had worked for Karya stopped at Bokale’s home to chat. Meena Jadhav, 55, had used the money to buy material and sewing tools for her tailoring business – she made shirts to sell. Thanks to what she learned, she said, she can now use a savings account and knows how to use an ATM. She didn’t know you could withdraw and deposit money without going to the bank.

Another woman used the lessons she learned and the cash she earned to start a savings account for her daughter’s education.

They all said they enjoyed the work and found the information about financial planning and online tools useful. An added benefit for the women, Bokale says, was learning that their smartphones could open doors to other kinds of opportunities.

She says many of the other women in the pilot project didn’t know how to use a smartphone at all beforehand. “Their husbands and in-laws, they’re saying ‘Oh, you’ve learned so many new things, and that’s so great.’”

Top image: Baby Rajaram Bokale with some of the women in her informal investment group. By recording and writing Marathi in their smartphones they helped create datasets to be used to create AI language models."
Microsoft_News,https://azure.microsoft.com/en-us/blog/how-hr-block-is-using-azure-openai-service-to-bring-ease-to-american-taxpayers-this-season/,,How H&R Block is using Azure OpenAI Service to bring ease to American taxpayers this season,"Share How H&R Block is using Azure OpenAI Service to bring ease to American taxpayers this season on LinkedIn

Share How H&R Block is using Azure OpenAI Service to bring ease to American taxpayers this season on X

Share How H&R Block is using Azure OpenAI Service to bring ease to American taxpayers this season on Facebook

In 2023, we saw generative AI usher in a wave of new innovations, from Microsoft Copilot to the “last song” from The Beatles to helping rural India farmers gain easier access to government services. These AI innovations are now starting to show up in our everyday lives and have a positive impact for millions of people around the world.

Last week, as part of Microsoft’s FY24 Q2 Earnings, we announced we now have 53,000 Azure AI customers. Over one-third are new to Azure this calendar year.

And we have great momentum with Azure OpenAI Service, too, which became generally available just over 12 months ago, empowering developers and organizations to build AI applications with OpenAI’s latest models (including GPT-4 Turbo with Vision, fine-tuning for the foundational models, and DALL-E 3) backed by the enterprise capabilities of our Azure cloud. We continue to introduce new innovation with Azure OpenAI Service including Assistants API in preview, text-to-speech capabilities, support for new models, and updates to fine-tuning API.

Azure AI Build intelligent apps at enterprise scale with the Azure AI portfolio Learn more

Today, thousands of organizations around the world are using Azure OpenAI service to drive meaningful business impact for people and society. We are seeing increased usage from AI-first startups like DeepBrain, Perplexity, and SymphonyAI, as well as the world’s biggest companies. Over half of the Fortune 500 use Azure OpenAI today, including AT&T, Walmart, Ally Financial, and Carmax.

Helping taxpayers with AI Tax Assist

It’s no secret that filing taxes can be stressful, overwhelming, and time-consuming. According to the IRS, the average taxpayer spends 13 hours preparing their return. As we enter this year’s tax season (the IRS officially began accepting eFiling from individuals on January 29), it’s especially exciting to see how H&R Block is leveraging the generative AI capabilities of Azure to help ease the filing process for taxpayers this year.

Almost half (46%) of the 146 million tax filers in the U.S. prepare and file their own taxes. This season, those 69 million DIYers will have the ability to simplify the tax preparation process with H&R Block AI Tax Assist.1

Sound familiar? You may have caught a glimpse of AI Tax Assist commercials last month during the NFL playoffs, or when the solution first launched in December 2023.

H&R Block AI Tax Assist is a generative artificial intelligence (GenAI) experience that harnesses the power of Azure OpenAI Service to help streamline the tax preparation process for individuals, the self-employed and small business owners to file and manage their taxes confidently.

“With H&R Block AI Tax Assist, we are enhancing the DIY tax filing experience. By applying generative AI tools with our unique ability to provide human expertise at scale, we’re taking a step forward in innovation to help make the tax filing process easier. We’re thrilled to work with Microsoft and leverage the power of Azure OpenAI Service to transform how Americans do their taxes.” – Heather Watts, Senior Vice President of Consumer Tax Products, H&R Block

Leveraging data from H&R Block’s The Tax Institute and the experience of more than 60,000 tax professionals, H&R Block AI Tax Assist helps DIY customers efficiently work through the tax preparation process by assisting with:

Tax Information: AI Tax Assist can provide information on tax forms, deductions, and credits, maximizing potential refunds and minimizing tax liability.

AI Tax Assist can provide information on tax forms, deductions, and credits, maximizing potential refunds and minimizing tax liability. Tax Preparation: AI Tax Assist can guide individuals through questions as they prepare and file their taxes, answer tax theory questions and offer navigation instructions when needed.

AI Tax Assist can guide individuals through questions as they prepare and file their taxes, answer tax theory questions and offer navigation instructions when needed. Tax Knowledge: AI Tax Assist can answer free-form tax-related questions, providing dynamic responses that clarify tax terms and give guidance on specific tax rules or general information about the U.S. and state tax system.

AI Tax Assist can answer free-form tax-related questions, providing dynamic responses that clarify tax terms and give guidance on specific tax rules or general information about the U.S. and state tax system. Tax Changes: AI Tax Assist can answer questions about the tax code, recently changed laws and tax policies.

“H&R Block has built a long-standing partnership with Microsoft starting with migration to Azure as a part of our broader digital transformation. As we considered platform partners for building the AI Tax Assist and AI Platforms more broadly, we indexed heavily on speed-to-market while ensuring we did it safely, responsibly, and honoring the trust our clients place in our brand every day. The capabilities of Azure OpenAI Service to enable responsible deployment of AI were critical in helping build confidence in this new solution and allowed us to deploy this new technology at scale to our clients early in our journey.” – Alan Lowden, Chief Information Officer, H&R Block

Driving business impact with Azure AI

Like H&R Block, organizations including AT&T, Inflection AI, PwC, Siemens and Volvo are using Azure AI to reimagine customer experiences, remove friction in business-critical processes to help end-users and employees focus their time and energy on valuable work.

Whether building a copilot, a chatbot, or a creative assistant, businesses are taking advantage of Azure AI’s model choice, flexibility and multimodal capabilities through Azure AI Studio to innovate faster and more responsibly across a range of diverse services including education, financial services, healthcare, manufacturing, and risk management.

Our commitment to responsible AI

With Responsible AI tools in Azure, Microsoft is empowering organizations to build the next generation of AI apps safely and responsibly. Azure AI Content Safety is a state-of-the art AI system that helps organizations keep AI-generated content safe and create better online experiences for everyone. Customers—from startup to enterprise—are applying the capabilities of Azure AI Content Safety to social media, education and employee engagement scenarios to help construct AI systems that operationalize fairness, privacy, security, and other responsible AI principles.

Get started with Azure OpenAI Service

1- Internal Revenue Service Data Book"
Microsoft_News,https://blogs.microsoft.com/on-the-issues/2024/02/05/journalism-news-generative-ai-democracy-forward/,,Here’s how we’re working with journalists to create the newsrooms of the future with AI,"What will the newsroom of the future look like?

Today, Microsoft is launching several collaborations with news organizations to adopt generative AI. In a year where billions of people will vote in democratic elections worldwide, journalism is critical to creating healthy information ecosystems, and it is our mission, working with the industry, to ensure that newsrooms can innovate to serve this year and in the future.

Through these new programs, we are helping these organizations identify and refine the procedures and policies to use AI responsibly in newsgathering and business practices, helping train a new generation of reporters on best uses of AI and identify ways AI can help create efficient business practices and help build sustainable newsrooms for generations to come.

Semafor will work with us to harness AI tools to assist journalists in their research, source discovery, translation, and more with Semafor Signals, helping journalists provide a diverse array of credible local, national, and global sources to their audience.

will work with us to harness AI tools to assist journalists in their research, source discovery, translation, and more with Semafor Signals, helping journalists provide a diverse array of credible local, national, and global sources to their audience. The Craig Newmark Graduate School of Journalism at CUNY will invite experienced journalists to a tuition-free program to explore ways to incorporate generative AI into their work and newsrooms in a three-month hybrid and highly interactive program. The AI Journalism Lab will be run by Nikita Roy, a data scientist, entrepreneur, and host of the podcast Newsroom Robots, which explores AI applications in journalism.

at CUNY will invite experienced journalists to a tuition-free program to explore ways to incorporate generative AI into their work and newsrooms in a three-month hybrid and highly interactive program. The AI Journalism Lab will be run by Nikita Roy, a data scientist, entrepreneur, and host of the podcast Newsroom Robots, which explores AI applications in journalism. The Online News Association is launching programming to support journalists and newsroom leaders as they navigate the evolving AI ecosystem. ONA’s AI in Journalism Initiative offers a menu of opportunities addressing what is possible across the newsroom through AI, collaboratively exploring and experimenting with tools, and creating opportunities for greater audience reach and business sustainability.

is launching programming to support journalists and newsroom leaders as they navigate the evolving AI ecosystem. ONA’s AI in Journalism Initiative offers a menu of opportunities addressing what is possible across the newsroom through AI, collaboratively exploring and experimenting with tools, and creating opportunities for greater audience reach and business sustainability. The GroundTruth Project, which sends local journalists into newsrooms around the world through its Report for America and Report for the World programs, will add an AI track of work for its corps members through the AI in Local News initiative with the goal of helping make reporting and newsrooms themselves more efficient and sustainable for the future.

which sends local journalists into newsrooms around the world through its Report for America and Report for the World programs, will add an AI track of work for its corps members through the AI in Local News initiative with the goal of helping make reporting and newsrooms themselves more efficient and sustainable for the future. Nota, a startup dedicated to putting high-quality AI tools into newsrooms to help improve newsroom operations, has expanded to more than a 100 newsrooms with support from Microsoft. Its suite of tools are helping newsrooms reach new audiences, expand social media presence and better tailor content to audience information needs. Nota will soon release a new tool called PROOF, an assistive recommendation widget that will give real-time tips to journalists and editors about how to better reach audiences with their content through readability, SEO analysis, link integrity, and more.

These collaborators are established industry groups, leading academics, local news champions, and global newsrooms who are seeking to educate, experiment, lead, and scale AI solutions that support the industry. Each organization will have access to Microsoft experts, technology, and support this year, and has committed to sharing the results of their projects with the wider industry to teach, inspire, and innovate the way news will be produced in the future.

Working directly with newsrooms, universities, journalists, and industry groups, we will help these organizations use AI to grow audiences, streamline time-consuming tasks in the newsroom, and build sustainable business operations. Our goal is to support thriving, sustainable newsrooms with the technology they need to perform the essential function of informing the world.

These projects build on Microsoft’s existing commitment to sustainable journalism, and pledges to reduce risk, restore trust, and rebuild capacity in news ecosystems through the Democracy Forward program.

Local, national, and global news organizations depend on being able to innovate responsibly with emerging technology to stay competitive. The survival of fact-based news is inextricably linked to healthy democracies, thriving communities, and civic participation. Journalism has an essential function in fighting against information operations and threats to democracy.

Central to all of these commitments is journalists themselves.

Healthy news organizations do not exist without journalists who know their communities and topics, have deep relationships with leaders in government and civic life, and understand how to reach their communities. This work is challenging – and our goal is to find ways to support journalists in this mission, not replace them. By working with these organizations, we hope to shed light on the promise that the newsroom of the future can hold.

Tags: AI, journalism, Responsible AI, Semafor"
Microsoft_News,https://cloudblogs.microsoft.com/dynamics365/bdm/2024/02/01/microsoft-copilot-for-sales-and-copilot-for-service-are-now-generally-available/,,Microsoft Copilot for Sales and Copilot for Service are now generally available,"Microsoft is dedicated to helping organizations transform the way people work using secure, enterprise-grade AI capabilities, no matter which business applications teams depend on. Starting today, you can seamlessly integrate role-specific Copilot capabilities into Microsoft 365 applications and popular customer relationship management (CRM) and contact center systems for sales and customer service professionals.

Now generally available, Microsoft Copilot for Sales and Microsoft Copilot for Service bring together the power of Microsoft Copilot for Microsoft 365 with role-specific insights and actions to streamline business processes, automate repetitive tasks, and unlock creativity. Both provide flexibility to integrate with your existing contact center and CRM systems, such as Salesforce and ServiceNow, to get more done with less effort.

Transform sales productivity with Copilot for Sales

Sellers today face more challenges than ever. A recent survey revealed that 79% of sellers are supporting more customers and accounts than the previous year.1 Gartner® research recommends that to drive better sales impact, “sellers must relinquish some control over customer interactions and give AI-powered technology—generative AI, emotion AI and digital humans—more responsibility to execute core selling activities…Let salespeople focus on where they excel: engaging buyers on a human level to understand their needs, motivations and objections, and ultimately validate that a purchase is right for them.”2

At Microsoft, we have been working hard to deliver an AI solution that would address these needs. Last fall, we announced our vision for Copilot for Sales, an AI assistant designed for sales teams to maximize productivity and close more deals. We’re excited to announce that Copilot for Sales is now generally available. Copilot for Sales builds on Copilot for Microsoft 365, enhancing it with connectivity to CRM platforms like Microsoft Dynamics 365 Sales and Salesforce Sales Cloud to bring sales-specific insights and recommendations to apps like Outlook, Microsoft Teams, and Word.

Today, Copilot for Sales helps sellers and sales managers:

Generate sales meeting preparation briefs in Word.

Summarize emails and surface relevant buying intent and budget, authority, need, timing (BANT) analysis in Outlook.

Generate emails in Outlook with relevant product, account, relationship, and opportunity information from their CRM system and Microsoft Graph.

Add leads and update CRM records directly from Outlook.

View meeting preparation notes and real-time sales insights during calls in Teams.

View sales meeting summaries in Teams with conversation analysis, sales keywords and KPIs, and suggested tasks.

Create collaborative deal rooms in Teams that sync with CRM data.

Copilot for Microsoft 365 is also included in Copilot for Sales, providing sellers with additional productivity enhancements, like:

Generate presentations in PowerPoint.

Generate plans and organize team information in OneNote.

Ask questions in natural language to catch up on customer interactions using Microsoft Copilot’s chat experience.

Late this month, Copilot for Sales will also bring CRM connectivity to the Microsoft Copilot chat experience, allowing sellers and sales managers to get quick insights on conversion and win rate, sales cycle, and pipeline. Later this year, we plan to enhance Copilot experiences in Microsoft PowerPoint and OneNote as well, tailoring them to address seller-specific needs with CRM connectivity.

Early adopter customers of Copilot for Sales are already seeing an impact in their sales organizations. Avanade employees have been previewing Copilot for Sales capabilities like updating Dynamics 365 Sales records from Outlook, summarizing email threads, generating email drafts, and summarizing meetings with conversation intelligence. These AI capabilities have helped Avanade employees show their clients that they are top of mind, while helping them work more productively.

When we interviewed Copilot for Sales users at Avanade, they reported that Copilot minimizes the need to jump between different interfaces, and the email summary feature saves them 30 to 60 minutes per week. And the impact goes beyond just time savings; Copilot for Sales is improving the quality of sellers’ interactions with their customers as well.

“When our sellers can reduce the time spent on sifting through multiple channels to find what matters with Copilot for Sales, we can be more focused so that we can deliver with clients and drive our business strategy faster.” —Jennifer Ferrara, Global Business Lead, Avanade

Read more about Avanade’s adoption of Copilot for Sales.

Copilot for Sales Maximize productivity and close more sales. Start today

Transform the agent experience with Copilot for Service

In December 2023, we introduced Copilot for Service—the next step in our journey to help organizations realize the benefits of generative AI by extending their existing investments in CRM and contact center solutions. We are excited to announce that Copilot for Service is now generally available.

Often, an organization’s knowledge is distributed across disparate systems—customer records and case histories in one or multiple CRM systems, along with information scattered across knowledge base articles, public websites, offline files, and more. As a result, agents are tasked with navigating multiple apps to not only access critical insights, but also then manage their engagement with customers, collaborate with internal teams, and take action. According to Gartner, “43 percent of (customer service) reps reported they were overwhelmed by the number of systems and tools needed to complete work.”3

Copilot for Service unlocks an organization’s trusted knowledge to accelerate onboarding and case resolution, improve efficiency, and automate tasks for agents in their flow of work. Without costly development time, organizations can simply point to their data and, in a few minutes, unlock generative AI-powered conversations across their knowledge bases. And for agents, they can tap into this knowledge with a copilot embedded directly in their desktop software of choice such as Salesforce, as well as the other tools they already use every day like Outlook and Teams.

Today, Copilot for Service can help organizations:

Enable generative AI-powered conversations across all of their data with simplified point-and-click access to public websites, SharePoint, knowledge base articles, and offline files.

Access knowledge sources with pre-built integrations for Salesforce, ServiceNow, and Zendesk.

Embed a copilot in agent desktops from Salesforce and other channels to support agents where they work.

Copilot for Microsoft 365 is also included in Copilot for Service. We will introduce additional features in Microsoft 365 apps beginning later this month that will integrate data from CRM systems like Microsoft Dynamics 365 Customer Service and Salesforce Service Cloud including:

In Outlook, use Copilot to summarize and draft emails, access case summaries, browse and update CRM records, and schedule meetings informed by case summaries and other relevant information from CRM records.

In Teams, use Copilot to browse and update CRM records during a meeting, as well as recap meetings, suggest follow-up action items, and create tasks that can all be saved to CRM systems directly from Teams.

In the Microsoft Copilot chat experience, use Copilot to ask questions over cases and contacts, as well as summarize cases—all from CRM data.

We’re thrilled to see the initial impact that our early adopter customers and partners are having with Copilot for Service. RSM, the leading provider of assurance, tax, and consulting services for the middle market, is equipping agents with the information they need to support customers without changing applications or searching through hundreds of knowledge articles.

“Six months ago, we launched a pilot focused on leveraging Microsoft Copilot for Service and Microsoft Copilot Studio, which provides a framework to build AI-enabled business processes. We have been working to execute against use cases for our own business with a focus on practical AI, and we are thrilled to now be in a position to bring this productivity enhancing technology to help clients implement AI for their businesses.” —Christian Hutter, RSM’s Microsoft practice leader

Copilot for Service Modernize your contact center with Copilot designed for service. Start today

Take the next step

Both Copilot for Sales and Copilot for Service are available now for $50 per user/month, which includes the Copilot for Microsoft 365 license. If you already have Copilot for Microsoft 365, you can purchase Copilot for Sales or Copilot for Service for an additional $20 per user/month.

Learn more about Copilot for Sales and Copilot for Service.

Sources:

1. Microsoft. “Sellers’ attitudes about AI.” June 2023. An Ipsos study commissioned by Microsoft. Study included 700 participants who use professional CRM systems at organizations of at least 300 people. Industries include Financial Services, Professional Services, Manufacturing, Retail, Technology, and Healthcare.

2. Gartner Article, Focus Your Sellers on the Critical Art of Being Human, September 2023, https://www.gartner.com/en/articles/focus-your-sellers-on-the-critical-art-of-being-human

GARTNER is a registered trademark and service mark of Gartner, Inc. and/or its affiliates in the U.S. and internationally and is used herein with permission. All rights reserved.

3. Gartner Ebook, Gartner for Customer Service The Connected Rep Deliver better customer service by enabling reps with technology, 2023, https://www.gartner.com/en/customer-service-support/trends/the-customer-service-customer-rep"
Microsoft_News,https://www.microsoft.com/en-us/microsoft-365/blog/2024/01/31/the-right-way-to-ai-what-were-learning-from-customers/,,The right way to AI: what we’re learning from customers,"In the quarterly earnings call on Tuesday, Satya laid out a bold direction for AI in 2024.

“We’ve moved from talking about AI to applying AI at scale.“ —Satya Nadella, Microsoft Chairman and CEO

Already, we see AI rapidly transforming work for organizations across the world. In the latest Work Trend Index report, 70% of early Copilot for Microsoft 365 users said they were more productive, and 68% felt it improved the quality of their work. Overall, users were 29% faster in a series of tasks like searching, writing, and summarizing. The best Copilot users even saved more than 10 hours per month.

Today on WorkLab, we shared key insights and learnings from our customers and our own employees as they roll out Copilot. These inspiring examples show that with the right approach, AI can be a powerful tool for innovation and growth, but it is not a one-size-fits-all solution. Copilot is unlike any new technology that’s come before it, and leaders need to take a deliberate approach to embrace, deploy, and adopt it.

Copilot Lab Learn more

We’ve also received valuable early feedback from customers on how we can improve Copilot. And we’re applying that feedback to make the experience better for everyone. We introduced Copilot Lab to help customers turn a good prompt into a great one, share favorite prompts with coworkers, and get inspired. And customers who want to leverage the power of Copilot in Teams meetings—but without creating a recording—now have the option to enable it without transcription.

As the technology continues to evolve and get better, the extent to which an organization gets value from it will also largely depend on its intentional and programmatic approach to rolling it out.

Start applying these critical lessons to your rollout today, and be sure to share your own Copilot tips with us on social media.

Copilot for Microsoft 365 is now available to businesses of all sizes—with no seat minimum."
Microsoft_News,https://blogs.microsoft.com/?p=52561502,,Embracing AI Transformation: How customers and partners are driving pragmatic innovation to achieve business outcomes with the Microsoft Cloud,"This past year was one of technology’s most exciting with the emergence of generative AI, as leaders everywhere considered the possibilities it represented for their organizations. Many recognized its value and are eager to continue innovating, while others are inspired by what it has unlocked and are seeking ways to adopt it. At Microsoft, we are focused on developing responsible AI strategies grounded in pragmatic innovation and enabling AI Transformation for our customers. As I talk to customers and partners about the outcomes they are seeing — and rationalize those against Microsoft’s generative AI capabilities — we have identified four areas of opportunity for organizations to empower their AI Transformation: enriching employee experiences, reinventing customer engagement, reshaping business processes and bending the curve on innovation. With these as a foundation, it becomes easier to see how to bring pragmatic AI innovation to life, and I am proud of the impact we have made with customers and partners around the world. From developing customer-focused AI and cloud services for millions across Europe and Africa with Vodafone, to empowering customers and employees with generative AI capabilities with Walmart, I look forward to what we will help you achieve in the year ahead.

Enriching employee experiences and shaping the future of work with copilot technology

Bayer employees are collaborating better on worldwide research projects and saving time on daily tasks with Copilot for Microsoft 365, while Finnish company Elisa is helping knowledge workers across finance, sales and customer service streamline routine tasks. Banreservas is driving employee productivity and enhancing decision-making, and Hong Kong’s largest transportation companies — Cathay and MTR — are streamlining workflows, improving communications, and reducing time-consuming administrative tasks. Across professional services, KPMG has seen a 50% jump in employee productivity, Dentsu is saving hundreds of employees up to 30 minutes per day on creative visualization processes, and EY is making it easier to generate reports and access insights in near real-time with Copilot for Microsoft 365. In Malaysia, financial services organization PNB is saving employees time searching through documents and emails and AmBank employees are enhancing the quality and impact of their work. At Hargreaves Lansdown, financial advisers are using Copilot for Microsoft 365 and Teams to drive productivity and make meetings more inclusive. Avanade is helping sellers save time updating contact records and summarizing email threads with Copilot for Dynamics 365, while HSO Group, Vixxo, and 9altitudes are streamlining work for field and service teams.

Reinventing customer engagement with generative AI to deliver greater value and increased satisfaction

MECOMS is making it possible for utility customers to ask questions and get suggestions about how to reduce power consumption using Microsoft Fabric and copilot on their Power Pages portal. Schneider Electric has built a Resource Advisor copilot to equip customers with enhanced data analysis, visualization, decision support and performance optimization. California State University San Marcos is finding ways to better understand and personalize the student journey while driving engagement with parents and alumni using Dynamics 365 Customer Insights and Copilot for Dynamics 365. With Azure OpenAI Service, Adecco Group is bolstering its services and solutions to enable worker preparedness as generative AI reshapes the workforce, UiPath has already helped one of its insurance customers save over 90,000 hours through more efficient operations, and Providence has developed a solution for clinicians to respond to patient messages up to 35% faster. Organizations are building generative AI assistants to help employees save time, improve customer service and focus on more complex work, including Domino’s, LAQO and OCBC. Within a few weeks of introducing its copilot to personalize customer service, Atento has increased customer satisfaction by 20% and team productivity by 30% while reducing operational errors by nearly 20%, and Turkey-based Setur is personalizing travel planning with a chatbot to customize responses in multiple languages for its 60,000 daily users. In the fashion industry, Coats Digital launched an AI assistant in six weeks to make customer onboarding easier. Greece-based ERGO Insurance partnered with EBO to provide 24/7 personalized assistance with its virtual agent, and H&R Block introduced AI Tax Assist to help individuals and small business owners file and manage their taxes confidently while saving costs.

Reshaping business processes to uncover efficiencies, improve developer creativity and spur AI innovation

Siemens built its own industrial copilot to simplify virtual collaboration of design engineers and front-line workers, accelerate simulation times and reduce tasks from weeks to minutes. With help from Neudesic , Hanover Research designed a custom AI-powered research tool to streamline workflows and identify insights up to 10 times faster. With Microsoft Fabric, organizations like the London Stock Exchange Group and Milliman are reshaping how teams create more value from data insights, while Zeiss is streamlining analytics workflows to help teams make more customer-centric decisions. Volvo Group has saved more than 10,000 manual hours by launching a custom solution built with Azure AI to simplify document processing. By integrating GitHub Copilot, Carlsber g has significantly enhanced productivity across its development team; and Hover, SPH Media, Doctolib and CloudZero have improved their workflows within an agile and secure environment. Mastery Logistics Systems and Novo Nordisk are using GitHub Copilot to automate repetitive coding tasks for developers, while Intertech is pairing it with Azure OpenAI Service to enhance coding accuracy and reduce daily emails by 50%. Swiss AI-driven company Unique AG is helping financial industry clients reduce administrative work, speed up existing processes and improve IT support; and PwC is simplifying its audit process and increasing transparency for clients with Azure OpenAI Service. By leveraging Power Platform, including AI and Copilot features, Epiq has automated employee processes, saving over $500,000 in annual costs and 2,000 hours of work each month, PG&E is addressing up to 40% of help desk demands to save more than $1 million annually, and Nsure is building automations that reduce manual processing times by over 60% and costs by 50%. With security top of mind, WTW is using Microsoft Copilot for Security to accelerate its threat-hunting capabilities by making it possible for cyber teams to ask questions in natural language, while LTIMindtree is planning on using it to reduce training time and strengthen security analyst expertise.

Bending the curve on innovation across industries with differentiated AI offerings

To make disaster response more efficient, nonprofit Team Rubicon is quickly identifying and engaging the right volunteers in the right locations with the help of Copilot for Dynamics 365. Netherlands-based TomTom is bringing the benefits of generative AI to the global automotive industry by developing an advanced AI-powered voice assistant to help drivers with tasks like navigation and temperature control. In Vietnam, VinBrain has developed one of the country’s first comprehensive AI-powered copilots to support medical professionals with enhanced screening and detection processes and encourage more meaningful doctor-patient interactions. Rockwell Automation is delivering industry-first capabilities with Azure OpenAI Service to accelerate time-to-market for customers building industrial automation systems. With a vision to democratize AI and reach millions of users, Perplexity.AI has brought its conversational answer engine to market in six months using Azure AI Studio. India’s biggest online fashion retailer, Myntra, is solving the open-ended search problem facing the industry by using generative AI to help shoppers figure out what they should wear based on occasion. In Japan, Aisin Corp has developed a generative AI app to empower people who are deaf or hard of hearing with tasks like navigation, communication and translation; and Canada-based startup Natural Reader is making education more accessible on-the-go for students with learning differences by improving AI voice quality with Azure AI. To solve one of the most complex engineering challenges — the design process for semiconductors — Synopsys is bringing in the power of generative AI to help engineering teams accelerate time-to-market.

As organizations continue to embrace AI Transformation, it is critical they develop clarity on how best to apply AI to meet their most pressing business needs. Microsoft is committed to helping our customers and partners accelerate pragmatic AI innovation and I am excited by the opportunities before us to enrich employee experiences, reinvent customer engagement, reshape business processes and bend the curve on innovation. As a technology partner of choice — from our differentiated copilot capabilities to our unparalleled partner ecosystem and unique co-innovation efforts with customers — we remain in service to your successful outcomes. We are also dedicated to preserving the trust we have built through our partnership approach, responsible AI solutions and commitments to protecting your data, privacy and IP. We believe this era of AI innovation allows us to live truer to our mission than ever before, and I look forward to continuing on this journey with you to help you achieve more.

Tags: AI, Azure, Azure AI, Azure OpenAI Service, Copilot for Dynamics 365, Copilot for Microsoft 365, Innovation, Microsoft AI, Microsoft Cloud, Microsoft Copilot for Security, Microsoft Partners, Microsoft Power Platform"
Microsoft_News,https://www.microsoft.com/en-us/worklab/5-new-habits-will-help-you-get-the-most-out-of-ai-in-2024,,5 New Habits Will Help You Get the Most Out of AI in 2024,"BBy now, almost everyone has experimented with generative AI. And as leaders commit to rolling out Microsoft Copilot across their workforces, the individual productivity gains and organization-wide effects will be unmistakable. If 2023 was all about the promise of AI, 2024 will be about the proof.y now, almost everyone has experimented with generative AI. And as leaders commit to rolling out Microsoft Copilot across their workforces, the individual productivity gains and organization-wide effects will be unmistakable. If 2023 was all about the promise of AI, 2024 will be about the proof.

To build an AI-powered organization, where new technology supports human ingenuity at every level, leaders need to help their teams embrace new mindsets and habits. As 2024 opens, here are five habits to hone as you guide your teams through the transition.





1. Generative AI gives people time back—use it well.

When people get things done faster with Copilot, over half say they use that extra time for focus work, according to data from our latest Work Trend Index Special Report. That’s a promising productivity trend, but about one in six people say they use it to attend extra meetings—which might be counterproductive if they’re already spending long hours on calls and in conference rooms. “As leaders, we have a responsibility to help people redeploy the time savings from generative AI to other high-value work,” says Colette Stallbaumer, General Manager of Microsoft 365 & Future of Work.

Be intentional about that new space on your calendar, and encourage your teams to do the same. Reflect on the priorities of your role and your wider organization, and think about how you can empower people to do work that energizes them and drives the business forward. If you’re looking to be a better manager, you might spend more time coaching your teams. If you’re in sales, you’ll probably want to nurture customer relationships. For many roles, cultivating human connections will be key. Which brings us to the next item on the list…



2. People skills matter more now, not less.

For employers, the most in-demand skill is management, with communication, leadership, and teamwork also high on the list, according to job-posting data analyzed by LinkedIn. In other words, so-called “soft skills” matter a lot in the age of generative AI. As AI continues to transform work, LinkedIn VP Aneesh Raman envisions “a world of work that’s more human, not less.”

“People skills are going to come more to the center of individual career growth, and people-to-people collaboration is going to come into the center more for company growth,” Raman, who is head of LinkedIn’s Opportunity Project, told us recently on the WorkLab podcast. Employers will become educators as people learn new skills and master new tools, he says: “For leaders, you’ve got to start with communicating clearly, compassionately, and empathetically with your teams.”



3. With Copilot, there’s really no such thing as a stupid question.

In Microsoft Teams meetings, think of your private side chats with Copilot as a judgment-free zone, and encourage your employees to see it that way too. Lost track of what people are talking about? Enlist Copilot’s help to catch up. Can’t think of a question to ask to keep the conversation going? Ask for a suggestion. “One thing I’m hearing from customers is that Copilot gives them a feeling of psychological safety,” says Alexia Cambon, a Senior Director at Microsoft who leads research for the Work Trend Index. “It’s a support system that’s there for you, and the pressure is off to take notes or capture every single thing that’s said.”

That backup can be particularly comforting for people who participate in meetings conducted in their second or third language, or for some neurodivergent attendees. “The positive impact we’ve seen on people who’ve got workplace accessibility needs has been incredible,” says Vicki Holman, Collaboration Platform Owner at Hargreaves Lansdown, a UK-based financial services company. “I’ve had people tell me they suffer from stress that makes it difficult for them to stay present in meetings.” But when they get a recap or notes from Copilot, she says, it helps people “review information and overcome their anxiety around meetings.”



4. Spend less time searching for stuff.

We all spend a lot of time at work tracking down information. Where does that data point live? Who sent it to me? Where’s the most up-to-date file? Was the information in an email or a Teams message or a video conference? Searching for information is such second nature that employees might not even realize it’s a pain point.

A surprising fact: In our global survey of 18,100 people, respondents said they spend more time searching for information (27% of their day) than creating (24%), communicating (24%), or consuming it (25%). And people say only half (50%) of the information they take in every day is necessary for their job. Copilot eases this pain by scanning your entire data universe—emails, meetings, chats, documents, and more, plus the web—to find what you’re looking for. Leaders should encourage managers and employees to start every search by using Copilot, and then share great prompts and codify key learnings along the way.



5. Reset your brain from “command mode” to “conversation mode.”

The web has trained people to search for things by typing quick strings of keywords into a box. With generative AI, we’ll need to relearn the art of conversational back-and-forth. “Search is a one-and-done question, usually,” says A.J. Brush, a researcher on human-computer interaction and Partner Group Product Manager at Microsoft. But when you’re working with Copilot, follow-up questions are powerful, she says. If you’re not getting what you want, drop in more context: “I’m trying to do X.” “The goal is to Y.” “Can you help me Z?” You can keep the conversation going as long as you want—you won’t bore anybody or seem needy.

Another way to think of this concept: “If you want to get a better answer, you have to know how to ask a better question,” Microsoft CVP and Deputy CTO Sam Schillace told us on the WorkLab podcast. As he puts it, ask smart to get smart.

Working with Copilot is like having an endlessly patient assistant by your side to help manage the pace and volume of work, process everything that happens in meetings, and give your creativity a boost. It requires flexing new muscles and building new habits, and that’s something that all leaders need to take into account as they meet this moment with a sense of exploration, empathy, and ultimately, humanity."
Microsoft_News,https://news.microsoft.com/source/features/digital-transformation/reading-coach-ai-help-students-create-stories-fluency/,,‘Amazement in their eyes’: Reading Coach uses AI to help students create their own stories,"Have we got a story for you.

Actually, let’s rephrase that: Author Kayleen Torres has a story for you. And here’s how it starts:

Once upon a time, in a land far away, dwelled a most curious feline known as Luna. Luna, a monochromatic domesticized cat with piercing emerald-tinted eyes, had a deep-seated yearning for adventure and exploration beyond the norm.

Kayleen’s enchanting plot ultimately twirls and twists to reveal that Luna struts into a soccer stadium where some athletes invite her to join their game. Turns out, Luna can seriously boot the ball with her fuzzy paws. Soon, that green-eyed kitty with the daring spirit becomes a star.

“Her team wins because the cat, like, scores a goal – or something,” Kayleen explains. “A cat is, like, my favorite animal.”

Yes, the author is 10 years old.

A fifth grader at Baldwin Academy, an elementary school near Los Angeles, Kayleen created her tale using the new version of Microsoft Reading Coach. The free tool now harnesses generative AI, which helps learners produce their own stories. They can pick their characters and settings – all while working at their reading level.

Fifth grader Joshua Munoz reads aloud a story that was freshly generated by Reading Coach.

Kayleen is one of several hundred students in the U.S., the U.K. and India now testing the enhanced Reading Coach as part of a public preview. The pilot’s largest group spans about 75 students in the Hacienda La Puente Unified School District, which includes Baldwin Academy.

“They love it,” says Ana Ruiz, a fifth-grade teacher at Baldwin Academy. “Every student can choose what they want it to be. I have students who read at a ninth-grade level, kids who need reading support and students in-between. Being able to pick a reading level is such a game changer.”

Reading Coach – one of the Learning Accelerators available via Microsoft Education – also directs students to read their stories aloud into a computer microphone. It then detects the words they find challenging and guides them to independently say and practice those terms.

For Kayleen, her practice words included “principal,” “little” and “cool.” She uses Reading Coach about once a day, she says, often on a computer at her home in La Puente, California.

“With AI, it’s different from all the other stuff (at school) because you make it yourself,” Kayleen says. “I like the feeling of that. I like to do the stuff that I make.”

At home or at school, kids can use Reading Coach as a Windows application or a browser-based experience.

Joshua Munoz and his teacher, Ana Ruiz, read a story he just created.

Of course, bringing generative AI into the classroom marks a pivotal moment for some teachers.

A recent survey of 500 U.S. teachers found that most use AI in their instruction. Most respondents said the tech had improved educational outcomes. Still, some acknowledged they worry about AI leading to plagiarism or to a decrease in teacher-student interactions.

Ruiz says the generative AI in Reading Coach quickly soothed her own unease.

“I’m excited because the kids are excited,” Ruiz says. “Anything that’s going to get them to read, I’m willing to try.

“I was concerned (about the AI component), thinking: How is this going to work? Are the stories going to be any good?” she adds. “One of the immediate things my students said: ‘The stories are funny.’ They love that.”

Within Reading Coach, students can follow three modes: generate a story with AI, read a passage from its digital library, or paste in text from an article or textbook. Currently, the content is only available in U.S.-English. Other languages and dialects are coming soon.

Teresa Magpayo Castro.

The AI story mode offers 15 main character options (from dog to dragon to superhero) plus seven locations (from space to school to stadium). Students pluck one from each category. Next, they designate their reading level (from kindergarten up to middle school).

Once the selections are made, AI does the rest. About two seconds later, a fully formed story appears. Each distinctive narrative generated by the tool offers a beginning, a middle and a satisfying ending.

“When they saw it the first time, the students did not realize that AI was doing it – it almost looked to them like magic,” says Teresa Magpayo Castro, a technology teacher on special assignment in the Hacienda La Puente Unified School District.

“It was cool for them to see that AI is not just this big thing that has nothing to do with them,” Magpayo Castro adds. “It’s something they can use in school in a constructive way. You saw the amazement in their eyes.”

When it comes to AI, Baldwin student Martina Della Siega agrees.

“I mean,” she says, “it’s pretty cool.”

The fifth grader still recounts one of her favorite AI stories – about a girl from a Christian family who was invited to a friend’s bat mitzvah where she sampled latkes and danced to a traditional Jewish song. Another story Martina created involved a specialized doctor.

“I really like how it teaches you to say the words you can’t pronounce,” says Martina, 10. “Because there are many words that sometimes I don’t understand.

“Like ‘neurosurgeon.’ And I still don’t know if I’m saying that right.”

(Yep, she nailed it.)

Martina Della Siega.

Both Martina and Kayleen say the latest version of Reading Coach has boosted their reading speed. They know that because after a student reads a story aloud, the tool reveals the percentage of words they pronounced accurately and how many correct words they read per minute.

Teachers see those same metrics, allowing them to track how each student is progressing – or not.

“That’s one of the most powerful things about this,” Magpayo Castro says. “This tool allows me to consistently, constantly assess their reading fluency – and move forward with instruction.

“I can’t move students forward if I don’t know where they are. And students’ abilities are constantly moving. How they did last week may not be how they’re doing now.”

Reading Coach allows students, teachers and parents to track fluency metrics.

In a classroom with nearly 40 students, it’s difficult for teachers to pull individual students aside to listen to their fluency or pinpoint their specific reading gaps. When they do, it often takes time away from other instructional tasks.

But at Baldwin Academy, teachers say Reading Coach is giving them more time with students.

“I always tell people that as a teacher, I’m unwilling to take something new on my plate because it’s already full,” says Ricardo Recinos, a technology teacher on special assignment in the Hacienda La Puente Unified School District.

“With a tool like this, yes, we’re putting one more thing on the plate. But by doing that, we’ve discovered we’re taking a lot of stuff off that plate. It brings the ability to differentiate (the reading content) between students. It’s been incredible.”

As technology teachers, Magpayo Castro and Recinos both advocated for Reading Coach as a new classroom tool.

Ricardo Recinos.

“When I heard about it, I knew we had to bring it to these teachers,” Magpayo Castro says. “They need tools like this to make sure they’re meeting every student where they are, to make sure they’re not leaving pockets of students behind.”

And for kids like Dominic Vazquez Garcia, 10, Reading Coach is igniting a love of words.

After his schoolwork is done, he now looks for other items to read, says his mother, Elvira Vazquez Garcia.

“He’s been reading my text messages,” she says. “Or he says, ‘I’m going to open the mail, do you want me to read it?’

“No,” she adds with a laugh, “I don’t want him to read it.”

But those moments underscore something else Dominic’s mother appreciates about Reading Coach.

“I like it because it’s fun and entertaining for Dominic,” Vazquez Garcia says. “For myself, I know what he’s doing. I can hear him reading it. I don’t have to, like, be on top of him, making sure he’s safe.”

Welcome words to exhausted parents everywhere.

For more information on the enhanced Reading Coach, check out this recent post from the Microsoft Education Blog.

All photos by Mark Maryanovich. Top photo: student Joshua Munoz, teacher Ana Ruiz, and student Martina Della Siega use Reading Coach in the library at Baldwin Academy in La Puente, California."
Microsoft_News,https://blogs.microsoft.com/on-the-issues/2024/01/24/national-ai-research-resource-nairr-artificial-intelligence/,,Broadening AI innovation: Microsoft’s pledge to the National AI Research Resource pilot,"We are delighted to announce our support for the National AI Research Resource (NAIRR) pilot, a vital initiative highlighted in the President’s Executive Order on the Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence. This initiative aligns with our commitment to broaden AI research and spur innovation by providing greater computing resources to AI researchers and engineers in academia and non-profit sectors. We look forward to contributing to the pilot and sharing insights that can help inform the envisioned full-scale NAIRR.

The NAIRR’s objective is to democratize access to the computational tools essential for advancing AI in critical areas such as safety, reliability, security, privacy, environmental challenges, infrastructure, health care, and education. Advocating for such a resource has been a longstanding goal of ours, one that promises to equalize the field of AI research and stimulate innovation across diverse sectors. As a commissioner on the National Security Commission on AI (NSCAI), I worked with colleagues on the committee to propose an early conception of the NAIRR, underlining our nation’s need for this resource as detailed in the NSCAI Final Report. Concurrently, we enthusiastically supported a university-led initiative pursuing a national computing resource. It’s rewarding to see these early ideas and endeavors now materialize into a tangible entity.

Our backing of the NAIRR pilot builds on our enduring support for the academic research community with resources and model access for deep learning through initiatives like the Turing Academic Program (MS-TAP) and Accelerate Foundation Models Research (AFMR) program.

As part of our commitment to the NAIRR pilot, Microsoft will contribute:

$20 million in Microsoft Azure compute credits

Access to leading-edge models, including those available via Azure OpenAI Service

Advanced resources for developing trustworthy AI, including tools for research in AI fairness, accuracy, reliability, transparency, privacy, security, and model orchestration

Resources to enable HIPAA-compliant computing in support of health care research

Innovative tools for scientific discovery via Azure Quantum Elements

Collaborative opportunities with Microsoft’s scientists and engineers

As we continue on this shared journey of AI innovation, it is crucial to equip the broader research community with the necessary resources to pioneer advancements at the frontiers of our understandings and capabilities. The NAIRR pilot represents a significant step in this direction, bolstering collaborative efforts and promoting a well-resourced, inclusive approach to AI innovation. This commitment is more than just an investment in technology; it’s an investment in our future, and a testament to the power of broad collaboration in unlocking the full potential of AI to benefit humanity.

Tags: AI, NAIRR, Responsible AI"
Microsoft_News,https://www.microsoft.com/en-us/security/blog/2024/01/18/microsoft-at-legalweek-secure-data-and-gain-efficiencies-with-microsoft-purview-ediscovery-enhanced-by-generative-ai/,,Connect with Microsoft at Legalweek 2024,"The legal profession is known for being cautious or hesitant to adopt new technologies. However, when it comes to AI, it seems like legal professionals are ready to be on the leading edge of AI implementation. A Thomson Reuters survey of legal professionals found that 82% agree that AI can be useful in legal work and 51% agree that AI should be applied to legal work.1

With the growing use of AI in litigation and number of data storage locations, the process of ediscovery gets increasingly more complex and must be more agile, comprehensive, and integrated. The tools legal professionals need in today’s digital environment necessitate using advanced tools such as AI to locate the relevant data quickly and securing data in a way that complies with myriad regulations and major challenges.

To help you secure data and address your needs efficiently in the age of AI, we’re making it easier to safeguard and manage compliance of data using generative AI tools. Recent advanced capabilities of Microsoft Purview eDiscovery are aimed at giving you the advantage. If you’re attending the Legalweek conference in New York City from January 29 to February 1, 2024, we’d love to connect. Read on for an overview of what you can expect our experts to discuss, and keep scrolling for sessions and other ways to connect with us at Legalweek.

Microsoft at Legalweek: How generative AI helps address eDiscovery challenges

Microsoft is continuously innovating to ensure our solutions help organizations achieve their objectives, and Microsoft Purview is no exception. We are committed to enhancing Microsoft Purview for an improved overall user experience. Offering the advantages of AI is a further step toward this commitment. In November 2023, we announced new features and capabilities of Microsoft Purview eDiscovery harnessing Microsoft Security Copilot.

The latest release of eDiscovery enables the search, discovery, preservation, review, and export of Copilot interactions in Microsoft 365 across Word, Excel, PowerPoint, Microsoft Teams, and other applications. This boosts the efficiency of eDiscovery—an essential tool that allows you to search for evidence and gain an understanding of what occurred for informed decision-making.

Here are two advantages of the combination of eDiscovery and generative AI for legal professionals:

Efficient handling of massive datasets

The volume of data produced in litigation necessitates a solution that can keep up. Microsoft Purview eDiscovery features intelligent, machine learning capabilities to make it easier to locate the most relevant items for review, and help you get started quickly.

Two new Copilot capabilities in Microsoft Purview help you better manage huge datasets by helping you to:

Accelerate and refine your search : A successful investigation relies on an accurate search but query-building can be challenging. Creating a query in Keyword Query Language (KQL) can be time-consuming. Soon available in preview, a new capability lets you provide a prompt in natural language and Copilot will translate the query into KQL.

: A successful investigation relies on an accurate search but query-building can be challenging. Creating a query in Keyword Query Language (KQL) can be time-consuming. Soon available in preview, a new capability lets you provide a prompt in natural language and Copilot will translate the query into KQL. Accelerate and navigate your investigation: Based on conversations with our customers, eDiscovery admins and managers spent 60% of their time reviewing evidence collected in review sets. Soon in preview, a new capability lets you generate document summaries and walks you through your investigation with guided prompts.

Compliance with constantly changing regulations

Integrating AI technology like Microsoft Security Copilot into your existing eDiscovery workflows gives you more careful accounting of your sensitive or confidential information or evidence of intellectual property. This makes it much easier to satisfy the numerous regulations that dictate how data can be collected, stored, used, and managed.

Microsoft Purview makes it easy to comply by providing tools for data risk identification and regulatory requirement management. In addition, this solution features expanded risk detections gathering signals from infrastructure clouds and third-party apps, including Amazon Web Services (AWS), Box, Dropbox, and GitHub.

Compliance is also easier because the solution allows you to:

Ensure more consistent protections regardless of data type.

Discover, label, and classify data across sources, including Microsoft Fabric, Microsoft Azure, and AWS.

Restrict access to sensitive data (determined by labels or roles).

Detect business violations.

Gain visibility into generative AI app usage.

Mark your calendar for these Legalweek sessions

There’s more we’ll cover at Legalweek 2024. During three sessions, Microsoft experts and legal experts will provide a glimpse at the current cybersecurity challenges in the legal sector as well as share strategies to tackle these challenges with modern cybersecurity and technology solutions.

The Microsoft sessions at Legalweek are:

Session Title Speakers Session Date and Time Session Description Forthcoming Proposed Changes to the Federal Rules of Civil Procedure: A Strategic Update Chris Hurlebaus, Microsoft Principal Technical Specialist, and Nicholas Kim, Senior Corporate Counsel, join Faegre Drinker Biddle & Reath LLP Partner Tracey Salmon-Smith, Exxon Mobile Executive Counselor Robert Levy, and Orrick Senior eDiscovery and Privacy Attorney Jeffrey McKenna January 30, 2024, 2:00 PM ET-3:00 PM ET This session will discuss the recently proposed changes to the Federal Rules of Civil Procedure and impending changes to address data security and confidential information protection. Learn how these changes might impact your practice. Navigating the Cyber Threat Terrain: Cybersecurity, Privacy and Legal Sector Focus Manny Sahota, Microsoft Director, Global Cloud Privacy, Regulatory Risk, and Compliance; Daniel Ostrach, Microsoft Senior Corporate Counsel; Joseph Lee, Arnold & Porter Director, Information Security and Compliance; Sabrina Ceccarelli, Global Vice President, Assistant General Counsel, Commercial, Lightspeed Commerce Inc.; and Rachi Messing, Co-Founder, Altorney Wednesday, January 31, 2024, 11:30 AM ET-12:30 PM ET This session will discuss the latest cyberattack trends and share how organizations are adapting their strategies in response to these cyberthreats. They will also dive into how these threats are intensifying due to stringent regulations and how Microsoft can help organizations comply with these regulatory demands. Decoding the Role of AI in Litigation Microsoft Account Technology Strategist (ATS) Jennifer Cody and Microsoft Principal Product Manager Bhavanesh Rengarajan will join Drew Berweger, Counsel of Chiesa Shahinian & Giantomasi PC; Shannon Capone Kirk, Managing Principal & Global Head, Advanced E-discovery and AI Strategy Practice at Ropes & Gray LLP; Lance Koonce, Partner at Klaris Law; and Bansri M. McCarthy, Associate at Morgan Lewis Wednesday, January 31, 2024, 3:30 PM ET-4:30 PM ET This session will explore the different types of AI and common misconceptions, and offer strategies for leveraging AI technologies in legal proceedings. Hear perspectives on potential uses for AI in litigation, including predictive analytics of court decisions, automated document review, legal research, drafting, and due diligence.

Connect with Microsoft at Legalweek

If you seek strategies for safeguarding and managing the compliance of your data, check out one or more of our sessions at Legalweek. Throughout the conference, you can also interact with our Microsoft experts directly in a few ways:

Stop by Booth #3105 in Americas Hall 2 to learn how Microsoft solutions can address your challenges.

in Americas Hall 2 to learn how Microsoft solutions can address your challenges. Request to attend the Executive Breakfast on Tuesday, January 30, 2024.

on Tuesday, January 30, 2024. Request dedicated time with our eDiscovery experts, who will be available between 9:00 AM ET and 5:00 PM ET, Monday, January 29, 2024, through Thursday, February 1, 2024. We’d love to connect. Hope to see you there!

Learn more

Learn more about Microsoft Purview eDiscovery.

To learn more about Microsoft Security solutions, visit our website. Bookmark the Security blog to keep up with our expert coverage on security matters. Also, follow us on LinkedIn (Microsoft Security) and X (@MSFTSecurity) for the latest news and updates on cybersecurity.

1New report on ChatGPT & generative AI in law firms shows opportunities abound, even as concerns persist, Thomson Reuters. April 17, 2023."
Microsoft_News,https://news.microsoft.com/how-ai-can-help-you-banish-bad-meetings/,,How AI can help you banish bad meetings,"If your workdays are filled with meetings, you’re not alone. The amount of time people spend this way has gone up nearly three times since 2020, according to

a recent

Microsoft Work Trend Index report

.

Problem is, meetings aren’t always productive — the same report found that “inefficient meetings” are the top barrier to getting things done.

Whether you’re running late, showing up unprepared or struggling to get everyone on the same page, h"
Microsoft_News,https://powerbi.microsoft.com/en-us/blog/copilot-in-power-bi-preview-is-available-worldwide/,,Copilot in Power BI (preview) is available worldwide,"During November 2023, we unveiled the public preview of Copilot in Microsoft Fabric. This preview includes Copilot for Power BI, Data Factory and Data Science & Data Engineering. Since then, we have been gradually rolling this feature out and today, we are excited to announce that our Copilot preview is now available to all customers with Premium/Fabric capacity

Getting started with copilot

With our current preview, users can create reports faster and easier in the Power BI web experience. Based on a high-level prompt, Copilot for Power BI in Fabric creates an entire report page for you by identifying the tables, fields, measures, and charts that would help you get started. You can then customize the page using our existing editing experiences. Copilot can also help you understand your semantic model and even suggest topics for your report pages. It’s a fast and easy way to get started with a report, especially if you’re less familiar with report creation in Power BI.

In addition to report creation, we’re excited to bring the Copilot’s unique ability to summarize data to the Smart Narrative visual, now rebranded as the Narrative with Copilot visual. This visual summarizes the data and insights on the page, across your report, or even for your own template if you need to define a specific summary. However you choose to use it, the Narrative with Copilot visual accelerates how you communicate insights about the data that matters most. The visual is available in the Power BI service and in Power BI Desktop.

How to enable Copilot for your organization

Before you can use Copilot capabilities in Power BI, your administrator needs to enable Copilot in Microsoft Fabric. This can be done with a new tenant setting group, “Copilot and Azure OpenAI Service (preview)”, in the admin portal.

Since December 2023, we shipped a new feature that allows tenant admins to enable AI and Copilot in Power BI for specific security groups in addition to the entire organization. This means that Copilot can now be tailored to the needs of different groups within your organization. More granular AI and Copilot setting on Capacity level is coming.

Fabric Copilot is powered by Azure Open AI large language models and are currently deployed to limited data centers. As of January 2024, if your data is located outside of the US or France, the Copilot preview will be disabled by default unless your Tenant administrator enables the “Data sent to Azure OpenAI can be processed outside your tenant’s geographic region, compliance boundary, or national cloud instance” tenant setting. To learn how to get to the tenant settings, see About tenant settings.

We look forward to your feedback about Copilot in Power BI!

Next Steps"
Microsoft_News,https://news.microsoft.com/2024/01/15/vodafone-and-microsoft-sign-10-year-strategic-partnership-to-bring-generative-ai-digital-services-and-the-cloud-to-more-than-300-million-businesses-and-consumers/,,"Vodafone and Microsoft sign 10-year strategic partnership to bring generative AI, digital services and the cloud to more than 300 million businesses and consumers","Vodafone and Microsoft sign 10-year strategic partnership to bring generative AI, digital services and the cloud to more than 300 million businesses and consumers

Vodafone and Microsoft to transform the customer experience using Microsoft’s generative AI

Vodafone to scale its new standalone IoT business with Microsoft

Partnership will expand M-Pesa to improve financial inclusion across Africa

Vodafone to grow enterprise business with new Microsoft services for small and medium-sized businesses (SMEs)

Vodafone to accelerate digital transformation and operational efficiencies in virtual data center migration to Microsoft Azure

LONDON and REDMOND, Wash. — Jan. 15, 2024 — Vodafone and Microsoft Corp. on Tuesday announced a new, far-reaching 10-year strategic partnership that leverages their respective strengths in offering scaled digital platforms to more than 300 million businesses, public sector organizations, and consumers across Europe and Africa.

Through the partnership, the companies will collaborate to transform Vodafone’s customer experience using Microsoft’s generative AI; hyperscale Vodafone’s leading managed IoT connectivity platform; develop new digital and financial services for businesses, particularly SMEs across Europe and Africa; and overhaul its global data center cloud strategy.

Vodafone will invest $1.5 billion over the next 10 years in cloud and customer-focused AI services developed in conjunction with Microsoft. Additionally, Microsoft will use Vodafone’s fixed and mobile connectivity services.

Microsoft also intends to invest in Vodafone’s managed IoT connectivity platform, which will become a separate, standalone business by April 2024. The new company will attract new partners and customers, driving growth in applications and expanding the platform to connect more devices, vehicles and machines.

The digital services generated by the new partnership will use the latest generative AI technology to provide a highly personalized and differentiated customer experience across multiple channels. They will be built on unbiased and ethical privacy and security policies under Vodafone’s established framework for responsible AI.

Margherita Della Valle, Vodafone Group chief executive, said: “Today, Vodafone has made a bold commitment to the digital future of Europe and Africa. This unique strategic partnership with Microsoft will accelerate the digital transformation of our business customers, particularly small and medium-sized companies, and step up the quality of customer experience for consumers.”

“This new generation of AI will unlock massive new opportunities for every organization and every industry around the world,” said Satya Nadella, chairman and CEO, Microsoft. “We are delighted that together with Vodafone we will apply the latest cloud and AI technology to enhance the customer experience of hundreds of millions of people and businesses across Africa and Europe, build new products and services, and accelerate the company’s transition to the cloud.”

The companies have identified five key areas of collaboration:

Generative AI: To increase customer satisfaction, the companies will apply the power of Microsoft Azure OpenAI to deliver frictionless, real-time, proactive and hyperpersonalized experiences across all Vodafone customer touchpoints, including its digital assistant TOBi (available in 13 countries). Vodafone employees will also be able to leverage the AI capabilities of Microsoft Copilot to transform working practices, boost productivity and improve digital efficiency.

To increase customer satisfaction, the companies will apply the power of Microsoft Azure OpenAI to deliver frictionless, real-time, proactive and hyperpersonalized experiences across all Vodafone customer touchpoints, including its digital assistant TOBi (available in 13 countries). Vodafone employees will also be able to leverage the AI capabilities of Microsoft Copilot to transform working practices, boost productivity and improve digital efficiency. Scaling IoT: Microsoft intends to invest in Vodafone’s new, standalone global Internet of Things (IoT)-managed connectivity platform, which connects 175 million devices and platforms worldwide. Vodafone also plans to become part of the Azure ecosystem making the IoT platform available to a vast developer and third-party community using open APIs.

Microsoft intends to invest in Vodafone’s new, standalone global Internet of Things (IoT)-managed connectivity platform, which connects 175 million devices and platforms worldwide. Vodafone also plans to become part of the Azure ecosystem making the IoT platform available to a vast developer and third-party community using open APIs. Africa digital acceleration: Microsoft intends to help further scale M-Pesa, already the largest financial technology platform in Africa, by housing it on Azure and enabling the launch of new cloud-native applications. The companies are also launching a purpose-led program that seeks to enrich the lives of 100 million consumers and 1 million SMEs across the African continent. The goal is to enhance digital literacy, skilling and youth outreach programs, as well as offer digital services to the underserved SME market. The partnership aims to boost financial services innovation, building a community of certified developers.

Microsoft intends to help further scale M-Pesa, already the largest financial technology platform in Africa, by housing it on Azure and enabling the launch of new cloud-native applications. The companies are also launching a purpose-led program that seeks to enrich the lives of 100 million consumers and 1 million SMEs across the African continent. The goal is to enhance digital literacy, skilling and youth outreach programs, as well as offer digital services to the underserved SME market. The partnership aims to boost financial services innovation, building a community of certified developers. Enterprise growth: Vodafone will extend its commitment to distributing Microsoft services, including Microsoft Azure, security solutions and modern work offerings such as Microsoft Teams Phone Mobile, as part of its strategy to become Europe’s leading platform for business. This enables business customers to deploy Microsoft’s cloud-based services at pace with low adoption and running costs, as well as support the estimated 24 million SMEs across Europe through the provision of a managed platform that grows with their business.

Vodafone will extend its commitment to distributing Microsoft services, including Microsoft Azure, security solutions and modern work offerings such as Microsoft Teams Phone Mobile, as part of its strategy to become Europe’s leading platform for business. This enables business customers to deploy Microsoft’s cloud-based services at pace with low adoption and running costs, as well as support the estimated 24 million SMEs across Europe through the provision of a managed platform that grows with their business. Cloud transformation: Vodafone will accelerate its cloud transformation by modernizing its data centers on Microsoft Azure. This will improve its responsiveness to customers, while simplifying and reducing the operational costs of its IT estate. As a result, Vodafone will be able to replace multiple physical data centers with virtual ones across Europe, simplifying and reducing the operational costs of its IT estate, as well as reducing energy requirements and helping deliver against its sustainable business strategy.

About Vodafone

For more information, please visit www.vodafone.com, follow us on Twitter at @VodafoneGroup or connect with us on LinkedIn at www.linkedin.com/company/vodafone.

About Microsoft

Microsoft (Nasdaq “MSFT” @microsoft) enables digital transformation for the era of an intelligent cloud and an intelligent edge. Its mission is to empower every person and every organization on the planet to achieve more.

For more information, press only:

Microsoft Media Relations, WE Communications for Microsoft, (425) 638-7777, [email protected]

Vodafone Group Media Relations, [email protected]

Note to editors: For more information, news and perspectives from Microsoft, please visit the Microsoft News Center at http://news.microsoft.com. Web links, telephone numbers and titles were correct at time of publication but may have changed. For additional assistance, journalists and analysts may contact Microsoft’s Rapid Response Team or other appropriate contacts listed at https://news.microsoft.com/microsoft-public-relations-contacts."
Microsoft_News,https://blogs.microsoft.com/blog/2024/01/15/bringing-the-full-power-of-copilot-to-more-people-and-businesses/,,Bringing the full power of Copilot to more people and businesses,"As we kick off a new year, we’re thrilled to see people increasingly using and loving Microsoft Copilot for work and life. Our goal is to empower every person and every organization on the planet to achieve more by bringing Copilot, the everyday AI companion, to millions of people around the world. We have reached another milestone in this mission with more than 5 billion chats and more than 5 billion images to date. As Copilot continues to earn preference and usage, we’re receiving valuable feedback on how to improve. Two examples: First, there are a set of Copilot power users like creators, researchers, programmers and others who want more rapid access to the very latest we have to offer. And second, our Microsoft 365 customers want access to Copilot in the Microsoft 365 apps for personal use.

To help address those needs, today we’re delighted to announce more options for power users, creators and anyone looking to take their Copilot experience to the next level. This begins with the introduction of Copilot Pro, a new premium subscription for individuals that provides a higher tier of service for AI capabilities, brings Copilot AI capabilities to Microsoft 365 Personal and Family subscribers, and new capabilities, such as the ability to create Copilot GPTs. We are also announcing the general availability of our Copilot app for iOS and Android phones. Finally, we’re excited to bring Copilot for Microsoft 365 to more commercial customers by expanding the availability to businesses of all sizes, including small- and medium-sized businesses, starting today.

Introducing Copilot Pro: Supercharge your creativity and productivity

Today we’re announcing the availability of Copilot Pro, a new subscription that delivers the most advanced features and capabilities of Microsoft Copilot to individuals looking to supercharge their Copilot experience. Whether you need advanced help with writing, coding, designing, researching or learning, Copilot Pro brings greater performance, productivity and creativity.

Copilot Pro provides:

A single AI experience that runs across your devices, understanding your context on the web, on your PC, across your apps and soon on your phone to bring the right skills to you when you need them.

Access to Copilot in Word, Excel[i], PowerPoint, Outlook, and OneNote on PC, Mac and iPad for Microsoft 365 Personal and Family subscribers. Priority access to the very latest models – starting today with OpenAI’s GPT-4 Turbo. With Copilot Pro you’ll have access to GPT-4 Turbo during peak times for faster performance and, coming soon, the ability to toggle between models to optimize your experience how you choose. Enhanced AI image creation with Image Creator from Designer (formerly Bing Image Creator) – ensuring it’s faster with 100 boosts per day while bringing you more detailed image quality as well as landscape image format. The ability to build your own Copilot GPT – a customized Copilot tailored for a specific topic – in our new Copilot GPT Builder (coming soon) with just a simple set of prompts.

You can subscribe to Copilot Pro today for $20 per month/per user.

YouTube Video Click here to load media

Expanding Copilot for Microsoft 365 to businesses of all sizes

While Copilot Pro is our best experience for individuals, Copilot for Microsoft 365 is our best experience for organizations. Copilot for Microsoft 365 became generally available for enterprises in November. As we said earlier this year, 40% of the Fortune 100 participated in our Early Access Program, and since GA for enterprise, customers like Visa, BP, Honda, Pfizer, and partners like Accenture, KPMG and PwC are already using Copilot — which means thousands of people across industries and sectors have started working in new ways, with an AI-powered copilot at their side. Today we are excited to announce that Copilot for Microsoft 365 is now available for organizations of all sizes — with no seat minimum. We are also enabling our partners to help every business become AI-powered.

Today’s updates include:

Copilot for Microsoft 365 is now generally available for small businesses with Microsoft 365 Business Premium and Business Standard Customers can purchase between one and 300 seats for $30 per person per month. We’re removing the 300-seat purchase minimum for commercial plans and making Copilot available for Office 365 E3 and E5 customers (A Microsoft 365 license was previously required). Commercial customers can now purchase Copilot for Microsoft 365 through our amazing network of Microsoft Cloud Solution Provider partners. Last month, we also announced eligibility of Copilot for Microsoft 365 for education faculty and staff.

Copilot for Microsoft 365 is even more powerful for organizations because it works across your entire universe of data at work — including emails, meetings, chats, documents and more, plus the web. With natural language prompts like “Tell my team how we updated the product strategy,” Copilot can generate a status update based on the morning’s meetings, emails and chat threads. Copilot is also integrated into the apps millions of people use every day, including Microsoft Teams (which is not available with Copilot Pro). Copilot jump-starts your creativity in Word, analyzes data in Excel, designs presentations in PowerPoint, triages your Outlook inbox, summarizes meetings in Teams – whether you attended or not – and so much more. Backed by enterprise-grade security, privacy, and compliance, and Microsoft’s Customer Copyright Commitment, we can’t wait to see how businesses of all sizes achieve more using AI. Learn more on the Microsoft 365 blog.



Introducing new features in Copilot

As we expand the availability of Copilot to even more people, we continue to offer a great free experience for anyone interested in exploring how Copilot can transform productivity and creativity using AI. Today we’re excited to share additional updates to Copilot. You can get started by visiting copilot.microsoft.com.

Copilot GPTs – Today we’re announcing Copilot GPTs. Copilot GPTs let you customize the behavior of Microsoft Copilot on a topic that is of particular interest to you. A handful of Copilot GPTs will start to roll out beginning today with specific purposes such as fitness, travel, cooking and more. Soon, Copilot Pro users will also be able to create their own Copilot GPTs using Copilot GPT Builder. Stay tuned for more on this experience as we get closer to availability. Copilot mobile app – The Copilot mobile app is now available for Android and iOS. The Copilot app gives you the power of Copilot on the go as your Copilot queries and chats will roam across your phone and PC. The Copilot mobile app includes the same capabilities of Copilot on your PC including access to GPT-4, Dall-E 3 for image creation, and the ability to use images from your phone when chatting with Copilot. Download the app from the Google Play Store or the Apple App Store. Copilot in the Microsoft 365 mobile app – We’re also adding Copilot to the Microsoft 365 mobile app for Android and iOS for individuals with a Microsoft account. This new feature is rolling out over the next month. Access Copilot right inside the app and easily export the content you create to a Word or PDF document. Download the app from the Google Play Store or the Apple App Store.

With today’s announcements, we continue to bring Copilot to more customers with more options that work for them. Whether you’re looking to get started with Copilot for free, want to supercharge your Copilot experience with Copilot Pro or are an SMB or Enterprise customer looking to increase your productivity in new ways with Copilot for Microsoft 365, there’s a Copilot experience for everyone.

[i] Currently in preview, English only

Tags: AI, Copilot Pro, Microsoft 365 Copilot"
Microsoft_News,https://www.microsoft.com/en-us/worklab/how-do-you-ai,,How Do You AI?,"WWhen it comes to using generative AI, everyone will develop their own unique approach. Yes, it’s an all-purpose tool you can use to vanquish tough tasks. But you might get most excited about Microsoft Copilot’s ability to function as a meeting assistant so everyone can stay focused during a Microsoft Teams check-in. Meanwhile, one of your colleagues on the leadership team is most grateful to have some help analyzing and sorting data in quarterly earnings spreadsheets. Your customer service team might be champing at the bit for new Copilot capabilities that help them access key customer information in the field. And your star employee is getting into the habit of asking Copilot to draft an email in their voice. They can ask for something formal or casual. Long or short. They can get quirky and ask it to turn a white paper into a poem.hen it comes to using generative AI, everyone will develop their own unique approach. Yes, it’s an all-purpose tool you can use to vanquish tough tasks. But you might get most excited about Microsoft Copilot’s ability to function as a meeting assistant so everyone can stay focused during a Microsoft Teams check-in. Meanwhile, one of your colleagues on the leadership team is most grateful to have some help analyzing and sorting data in quarterly earnings spreadsheets. Your customer service team might be champing at the bit for new Copilot capabilities that help them access key customer information in the field. And your star employee is getting into the habit of asking Copilot to draft an email in their voice. They can ask for something formal or casual. Long or short. They can get quirky and ask it to turn a white paper into a poem."
Microsoft_News,https://www.microsoft.com/en-us/industry/blog/retail/2024/01/11/microsoft-introduces-new-capabilities-that-help-retailers-bring-ai-to-the-shopper-journey-and-enhance-store-associate-experiences/,,Introducing new AI capabilities in Microsoft Cloud for Retail,"Retail is one of the most dynamic and competitive industries in the world, where customer expectations and preferences are constantly evolving. A recent McKinsey report confirms the retail sector has experienced as much disruption in the past five years as it has in the previous 25.1 Perhaps never before in the history of the industry have we seen every single one of retail’s primary stakeholder groups—customers, suppliers, employees, and investors—simultaneously change their behavior and expectations. According to McKinsey, a retailer’s actions in the next two to three years could position it for success in the next 20.1 In this environment, retailers are turning to the power of generative AI to provide differentiated value across the shopper journey. For example, Walmart announced how they’re using Microsoft’s generative AI technology to build engaging new shopping experiences and provide enhanced productivity to store associates. When the world’s largest retailer decides to make big bets on generative AI, it’s clear the stakes are high and the opportunity to provide value is here.2

Microsoft Cloud for Retail Connect your customers, your people, and your data Discover capabilities

Around the world I’m hearing from retailers who are excited about the potential of AI. The most common question I was asked by retail executives in 2023 was where to start to find the most value. Retailers are looking for ways to begin working with generative AI that will allow them to learn quickly and scale effectively. I’m excited to share new tools that help retailers more easily incorporate AI across the shopper journey. Microsoft has lowered the barriers to building generative AI solutions that improve shopping experiences, support store associates, and enhance retail media campaigns. Through new Microsoft Copilot capabilities in Microsoft products, copilot templates for building applications, and retail data solutions in Microsoft Fabric, Microsoft makes AI implementation more accessible to retailers of all sizes. Retailers can now more easily take the first steps with generative AI.

Let’s look at these new offerings in more detail:

Shopper value

Delight shoppers with more personalized experiences. Retailers can use a copilot template on Azure OpenAI Service to build more individualized shopping experiences across their existing web sites and applications (in public preview).

With applications built using the copilot template, shoppers can engage in helpful and natural conversations that guide them to precisely the goods they need, while saving them time. Generative AI produces experiences that leave shoppers with the confidence they have found the best items. Microsoft Cloud for Retail copilot template pairs the breadth of expressiveness found in a Large Language Model (LLM) with deep knowledge about a retailer’s catalog and expertise. This new approach to commerce comes from advances in generative AI, all built with Responsible AI principles in mind.

Enhance shopping through personalizing marketing with new Copilot capabilities in Microsoft Dynamics 365 Customer Insights (coming soon to public preview).

Our AI-first experience enables marketers to describe the desired marketing outcome in natural language and let generative AI suggest, build, launch, and monitor campaigns in real-time. Transform marketing workflows and improve campaign ROI by uniting business data with Copilot features that deliver outcomes faster and more efficiently. These Copilot capabilities will be available in preview in the first quarter of 2024, with general availability by the third quarter of 2024. Existing Dynamics 365 Customer Insights customers can sign up now for the early access public preview program.

Store associate value

Empower store associates to improve productivity, job satisfaction and customer experiences. Using a copilot template on Azure OpenAI Service, retailers can infuse AI into store operations, better supporting associates (in public preview).

Our copilot template for store operations helps build a generative AI-powered LLM based assistant that enables Q&A from store documentation such as store operating procedures and natural language-based task creation (form filling). Store associates can use natural language to quickly and easily access the information they need in the flow of work, increasing their productivity and efficiency. With this copilot template, retailers can more easily build experiences that enable store employees to quickly get answers to their questions on store operating procedures, HR policies, and benefits. In addition, store associates and managers can save time through natural-language prompt-enabled task creation and assignment.

Using the copilot template, in combination with Microsoft Power Platform and Microsoft Dataverse capabilities, retailers are empowered to seamlessly connect data across multiple lines of business systems to generate AI driven recommendations and actionable solutions that will help store associates make the right decisions.

Consumer brand value

Provide consumer goods brands with tools to auto-generate and edit campaigns with Retail Media Creative Studio (in preview).

Microsoft is introducing generative AI to the Microsoft Retail Media platform (powered by PromoteIQ) through the launch of Retail Media Creative Studio, a comprehensive, end-to-end banner ad creative solution tailored for retail media, available in preview starting in January 2024. With Retail Media Creative Studio, retailers can unlock new revenue with optimized retail media campaigns across multiple retail media channels, such as the retailer’s owned digital properties and across the open web. The solution optimizes banner campaign performance using AI-powered algorithms and delivers a more personalized shopping experience.

The data solutions providing AI value to all

Make the most of retail data to uncover insights that lead to better shopper journeys with retail data solutions in Microsoft Fabric (in public preview).

One of the greatest, if not the greatest, challenges retailers face today is the need to unify data from disparate systems in order to gain insights from it. We are very excited to offer this industry specific set of capabilities in Microsoft Fabric that enables retailers to accelerate time to insight generation by unifying, enriching, and modeling industry data in Fabric. With seamless data harmonization, cross-application analytics, and AI applications, retailers can unlock the full potential of their data and drive their business forward. By using Fabric, retailers can consolidate relevant retail data from multiple systems into a unified, governed hub providing a secure single source of truth for all data and analytics needs. And, with retail data solutions in Fabric, retailers can use the same copy of data without needing to move it from its original source.

Our connector with Sitecore OrderCloud means that data for three important areas: product, customer, and orders, has been mapped to our industry data model, reducing engineering effort and accelerating time to insights.

Across the Microsoft Cloud, retailers now have multiple options when applying AI to key business outcomes across the shopping journey. From building their own solutions to leveraging the copilot templates, Microsoft Cloud for Retail integrates with retailers’ existing systems, seamlessly connecting a retailer’s customers, employees, and data. In each industry, Microsoft builds unique assets to verticalize the Microsoft Cloud and enable a broad partner ecosystem. Built on a foundation of trust and Microsoft’s Responsible AI principles, retailers can safely and securely unlock productivity across their entire business with Microsoft Cloud for Retail.

See it all at NRF 2024 and beyond

According to AI adoption in Retail, the most recent research Microsoft commissioned with The Futurum Group, 87% of retail companies globally have implemented AI in their store operations. Clearly the adoption of AI is increasing as this new technology brings substantive rewards to organizations. Microsoft is here to connect with you, listen to your needs, and support developing your AI strategy. Learn more at the links below and reach out to a Microsoft representative at any time for conversation.

Join us to hear the latest on how Microsoft is helping customers by attending our sessions at NRF 2024 or listening on-demand after the event:

Retail Unlocked: Achieve more with Microsoft: Hosted by Shelley Bransten, Corporate Vice President, Global Retail, Consumer Goods and Gaming industries, Microsoft. Sunday, January 14, 2024, from 1:00 PM to 1:30 PM Eastern Time.

Join this interactive session to hear about one retailer’s AI journey to date. Hosted by Microsoft’s Corporate Vice President, Retail, Consumer Goods & Gaming industries, Shelley Bransten, you’ll also learn about new AI-focused findings from Futurum Research and all new AI capabilities in Microsoft Cloud for Retail that will help power your AI transformation.

Unlocking true customer-centricity: Optimizing touchpoints across the shopper journey with AI: Hosted by Kathleen Mitford, Corporate Vice President, Global Industry Marketing. Monday, January 15, 2024, from 11:45 AM to 12:15 PM Eastern Time.

Generative AI and large language models have captured the attention of executives across industries. While the technology’s use cases seem endless, smart retailers and brands must identify and prioritize the applications of generative AI that will be most valuable to their organization and partner with organizations who will treat their data with the highest privacy standards. Join us to hear how Microsoft is helping organizations large and small maximize their generative AI opportunities safely and responsibly.

Unify your data to unlock AI opportunities: Hosted by Martin Kostal, General Manager, Microsoft Industry Clouds. Tuesday, January 16, 2024, from 1:00 PM to 1:45 PM Eastern Time.

Retailers are swimming in data all day. Even with sophisticated legacy technologies and cutting-edge data science, the majority of that data goes uncollected. Insights stay hidden—often in plain sight. But that’s starting to change. AI tools are enabling retailers to understand their customers, merchandising, supply chains, operations, and workforces better than ever before. Join us to hear about the myriad insights that retailers are drawing from newfound and increasingly precise data sources to run leaner, smarter stores.

Additional Microsoft announcements at NRF 2024

Learn more about implementing AI

1Retail reset: A new playbook for retail leaders, McKinsey & Company.

2IDC Infographic, sponsored by Microsoft, The Business Opportunity of AI, #US51315823, November 2023."
Microsoft_News,https://blogs.microsoft.com/blog/2024/01/09/walmart-unveils-new-generative-ai-powered-capabilities-for-shoppers-and-associates/,,Walmart unveils new generative AI-powered capabilities for shoppers and associates,"Time and money are two of the most valuable resources people have. And one of the most popular ways for Americans to save on both, is shopping online. According to the U.S. Bureau of Labor Statistics, American families spend six hours per week on household planning and shopping. Many of those families do so digitally at Walmart. The world’s largest retailer, famous for its low prices, generated over $82 billion in e-commerce sales in fiscal year 2023 and is steadily growing its active digital customers.

In 2024, the company is further improving the digital shopping experience, building generative AI into its search function to deliver customers a helpful and intuitive browsing experience. Using a combination of Walmart proprietary data and technology and large language models, including those available in Microsoft Azure OpenAI Service, as well as retail-specific models built by Walmart, the new design serves up a curated list of the personalized items a shopper is looking for.

At CES 2024, Walmart President and CEO Doug McMillon and Microsoft Chairman and CEO Satya Nadella introduced the new AI innovations to benefit Walmart customers.

YouTube Video Click here to load media

Study after study shows that AI is driving impact and value across businesses.

McKinsey reports AI will create $400-660 billion in value for the retail and consumer goods industry.

FTI Consulting data shows nearly 80% of online shoppers believe AI personalization can enhance their online experience.

An IDC study commissioned by Microsoft found that for every $1 a retail and consumer packaged goods company invests in AI, it is seeing a return of $3.45.

Generative AI-powered search

Walmart built an all-new generative AI-powered search function across iOS, Android and its own website. The new capability is specifically designed to understand the context of a customer’s query and generate personalized responses. Soon, customers will have a more interactive and conversational experience, get answers to specific questions, and receive personalized product suggestions.

For example, a parent planning a birthday party for a child that loves unicorns. Instead of multiple searches for unicorn-themed balloons, napkins, streamers, etc., the parent can simply ask the question “Help me plan a unicorn-themed party for my daughter.”

One of the reasons why Walmart and other leading retailers are choosing Azure OpenAI Service is the ability to access the most advanced AI models in the world while backed by the enterprise-grade capabilities found in Microsoft Azure including security, compliance and regional availability. Generative AI in retail is particularly exciting as it can help usher in a new way of shopping; shifting from “scroll searching” to “goal searching,” which makes the digital shopping experience more seamless and intuitive.

Don’t forget about the associates!

Both Walmart and Microsoft share an aligned vision around how AI can help organizations and their people be more productive, more satisfied in their work and go on to solve the most pressing problems.

Over the summer, Walmart launched a new tool, giving its 50,000 non-store associates access to its new “My Assistant” app, which was created and built by Walmart and leverages a unique build of Walmart proprietary data, technology and large language models in Azure OpenAI Service. In just a few months, the app has already made a big impact for associates, assisting with a range of tasks, from summarizing long documents to assisting in the creation of new content.

A history of success

This is just the latest evolution in the Walmart and Microsoft relationship.

In 2018, the companies established a strategic partnership to drive Walmart’s digital transformation. As one of Walmart’s preferred and strategic cloud providers, Microsoft has supported Walmart on a variety of different cloud projects. From powering access to electronic health records at its in-store clinics to centralizing, democratizing and optimizing data, the companies have and will continue to collaborate to accelerate innovation.

Other ways to AI

While Walmart’s approach to generative AI uses a combination of large language models, retail-specific models, and their own proprietary data built on top of Azure OpenAI Service, other retailers may have different scenarios that require an alternative approach. That’s why Microsoft offers a broad portfolio of prebuilt, low-code and pro-code solutions that can benefit all retailers and shoppers, no matter where they are on their respective journey.

Visit the Microsoft Cloud for Retail page to learn more.

Tags: AI, Azure OpenAI Service, Microsoft Cloud for Retail"
Microsoft_News,https://news.microsoft.com/source/features/sustainability/how-ai-and-hpc-are-speeding-up-scientific-discovery/,,"Discoveries in weeks, not years: How AI and high-performance computing are speeding up scientific discovery","Computing has already accelerated scientific discovery. Now scientists say a combination of advanced AI with next-generation cloud computing is turbocharging the pace of discovery to speeds unimaginable just a few years ago.

Microsoft and the Pacific Northwest National Laboratory (PNNL) in Richland, Washington, are collaborating to demonstrate how this acceleration can benefit chemistry and materials science – two scientific fields pivotal to finding energy solutions that the world needs.

Scientists at PNNL are testing a new battery material that was found in a matter of weeks, not years, as part of the collaboration with Microsoft to use to advanced AI and high-performance computing (HPC), a type of cloud-based computing that combines large numbers of computers to solve complex scientific and mathematical tasks.

PNNL materials scientist Shannon Lee mixes raw materials to synthesize a new solid electrolyte, one of the promising candidates predicted using AI and HPC tools in the Azure Quantum Elements service. Photo by Dan DeLong for Microsoft.

As part of this effort, the Microsoft Quantum team used AI to identify around 500,000 stable materials in the space of a few days.

The new battery material came out of a collaboration using Microsoft’s Azure Quantum Elements to winnow 32 million potential inorganic materials to 18 promising candidates that could be used in battery development in just 80 hours. Most importantly, this work breaks ground for a new way of speeding up solutions for urgent sustainability, pharmaceutical and other challenges while giving a glimpse of the advances that will become possible with quantum computing.

“We think there’s an opportunity to do this across a number of scientific fields,” says Brian Abrahamson, the chief digital officer at PNNL. “Recent technology advancements have opened up the opportunity to accelerate scientific discovery.”

PNNL is a U.S. Department of Energy laboratory doing research in several areas, including chemistry and materials science, and its objectives include energy security and sustainability. That made it the ideal collaborator with Microsoft to leverage advanced AI models to discover new battery material candidates.

“The development of novel batteries is an incredibly important global challenge,” Abrahamson says. “It has been a labor-intensive process. Synthesizing and testing materials at a human scale is fundamentally limiting.”

Learning through trial and error

The traditional first step of materials synthesis is to read all the published studies of other materials and hypothesize how different approaches might work out. “But one of the main challenges is that people publish their success stories, not their failure stories,” says Vijay Murugesan, materials sciences group lead at PNNL. That means scientists rarely benefit from learning from each other’s failures.

The next traditional scientific step is testing the hypotheses, typically a long, iterative process. “If it’s a failure, we go back to the drawing board again,” Murugesan says. One of his previous projects at PNNL, a vanadium redox flow battery technology, required several years to solve a problem and design a new material.

Vijay Murugesan, material sciences group lead at PNNL, says the Microsoft AI and HPC tools allow scientists to eliminate the time-consuming trial-and-error discovery steps and focus on the best candidates for testing. Photo by Andrea Starr for PNNL.

The traditional method requires looking at how to improve on what has been done in the past. Another approach would be to take all the possibilities and, through elimination, find something new. Designing new materials requires a lot of calculations, and chemistry is likely to be among the first applications of quantum computing. Azure Quantum Elements offers a cloud computing system designed for chemistry and materials science research with an eye toward eventual quantum computing, and is already working on these kinds of models, tools and workflows. These models will be improved for future quantum computers, but they are already proving useful for advancing scientific discovery using traditional computers.

To evaluate its progress in the real world, the Microsoft Quantum team focused on something ubiquitous in our lives – materials for batteries.

Teaching materials science to AI

Microsoft first trained different AI systems to do sophisticated evaluations of all the workable elements and to suggest combinations. The algorithm proposed 32 million candidates – like finding a needle in a haystack. Next, the AI system found all the materials that were stable. Another AI tool filtered out candidate molecules based on their reactivity, and another based on their potential to conduct energy.

The idea isn’t to find every single possible needle in the hypothetical haystack, but to find most of the good ones. Microsoft’s AI technology whittled the 32 million candidates down to about 500,000 mostly new stable materials, then down to 800.

“At every step of the simulation where I had to run a quantum chemistry calculation, instead I’m calling the machine learning model. So I still get the insight and the detailed observations that come from running the simulation, but the simulation can be up to half a million times faster,” says Nathan Baker, Product Leader for Azure Quantum Elements.

AI may be fast, but it isn’t perfectly accurate. The next set of filters used HPC, which provides high accuracy but uses a lot of computing power. That makes it a good tool for a smaller set of candidate materials. The first HPC verification used density functional theory to calculate the energy of each material relative to all the other states it could be in. Then came molecular dynamics simulations that combined AI and HPC to analyze the movements of atoms and molecules inside each material.

Click here to load media

This process culled the list to 150 candidates. Finally, Microsoft scientists used HPC to evaluate the practicality of each material – availability, cost and such – to trim the list to 23 – five of which were already known.

Thanks to this AI-HPC combination, discovering the most promising material candidates took just 80 hours.

The HPC portion accounted for 10 percent of the time spent computing – and that was on an already-targeted set of molecules. This intense computing is the bottleneck, even at universities and research institutions that have supercomputers, which not only are not tailored to a specific domain but also are shared, so researchers may have to wait their turn. Microsoft’s cloud-based AI tools relieve this situation.

Broad applications and accessibility

Microsoft scientists used AI to do the vast majority of the winnowing, accounting for about 90 percent of the computational time spent. PNNL materials scientists then vetted the short list down to half a dozen candidate materials. Because Microsoft’s AI tools are trained for chemistry, not just battery systems, they can be used for any kind of materials research, and the cloud is always accessible.

“We think the cloud is a tremendous resource in improving the accessibility to research communities,” Abrahamson says.

Brian Abrahamson, chief digital officer at PNNL. Photo by Andrea Starr for PNNL.

Today, Microsoft supports a chemistry-specific copilot and AI tools that together act like a magnet that pulls possible needles out of the haystack, trimming the number of candidates for further exploration so scientists know where to focus. “The vision we are working toward is generative materials where I can ask for list of new battery compounds with my desired attributes,” Baker says.

The hands-on stage is where the project stands now. The material has been successfully synthesized and turned into prototype batteries that are functional and will undergo multiple tests in the lab. Making the material at this point, before it’s commercialized, is artisanal. One of the first steps is to take solid precursors of the materials and to grind them by hand with a mortar and pestle, explains Shannon Lee, a PNNL materials scientist. She then uses a hydraulic press to compact the material into a dime-shaped pellet. It goes into a vacuum tube and is heated to 450 to 650 degrees Celsius (842 to 1202 degrees Fahrenheit), transferred to a box to keep it away from oxygen or water, and then ground into a powder for analysis.

For this material, the 10-or-more-hour process is “relatively quick,” Lee says. “Sometimes it takes a week or two weeks to make a single material.”

Then hundreds of working batteries must be tested, over thousands of different charging cycles and other conditions, and later different battery shapes and sizes to realize commercial use. Murugesan dreams of the development of a digital twin for chemistry or materials, “so you don’t need to go to a lab and put this material together and make a battery and test it. You can say, ‘this is my anode and this is my cathode and that’s the electrolyte and this is how much voltage I’m going to apply,’ and then it can predict how everything will work together. Even details like, after 10,000 cycles and five years of usage, the material performance will be like this.”

Microsoft is already working on digital tools to speed up the other parts of the scientific process.

The lengthy traditional process is illustrated by lithium-ion batteries. Lithium got attention as a battery component in the early 1900s, but rechargeable lithium-ion batteries didn’t hit the market until the 1990s.

Today, lithium-ion batteries increasingly run our world, from phones to medical devices to electric vehicles to satellites. Lithium demand is expected to rise five to ten times by 2030, according to the U.S. Department of Energy. Lithium is already relatively scarce, and thus expensive. Mining it is environmentally and geopolitically problematic. Traditional lithium-ion batteries also pose safety issues, with the potential to catch fire or explode.

Many researchers are looking for alternatives, both for lithium and for the materials used as electrolytes. Solid-state electrolytes show promise for their stability and safety.

Surprising results

The newly discovered material PNNL scientists are currently testing uses both lithium and sodium, as well as some other elements, thus reducing the lithium content considerably – possibly by as much as 70 percent. It is still early in the process – the exact chemistry is subject to optimization and might not work out when tested at larger scale, Abrahamson cautions. He points out that the story here is not about this particular battery material, but rather the speed at which a material was identified. The scientists say the exercise itself is immensely valuable, and it has revealed some surprises.

The AI-derived material is a solid-state electrolyte. Ions shuttle back and forth through the electrolyte, between the cathode and the anode, ideally with minimal resistance."
Microsoft_News,https://blogs.windows.com/windowsexperience/2024/01/04/introducing-a-new-copilot-key-to-kick-off-the-year-of-ai-powered-windows-pcs/,,Introducing a new Copilot key to kick off the year of AI-powered Windows PCs,"Today, we are excited to take the next significant step forward and introduce a new Copilot key to Windows 11 PCs. In this new year, we will be ushering in a significant shift toward a more personal and intelligent computing future where AI will be seamlessly woven into Windows from the system, to the silicon, to the hardware. This will not only simplify people’s computing experience but also amplify it, making 2024 the year of the AI PC.

The platform shift driven by AI innovation continues to grow rapidly and powerfully, fundamentally changing the way we use technology across work and life. At Microsoft, we are committed to empowering people and organizations to adapt and thrive in this new age of AI.

Over the last year, we have been at the forefront of this shift, innovating and improving our product experiences with Copilot, your everyday AI companion, at the center. From reinventing the way people search with Copilot in Bing, and unlocking productivity with Copilot for Microsoft 365, to reimagining how people get things done on the PC with Copilot in Windows, we’ve listened to feedback and doubled down to create an experience that helps people every day. We’re also seeing incredible momentum from our silicon partners AMD, Intel and Qualcomm, all of whom have introduced their latest silicon innovations to the world that unlock new AI experiences on the Windows PC. Together, we’re putting new system architectures in place to power new Windows AI experiences bringing together the GPU, CPU, NPU and the cloud.

We are energized by the stories that have been shared on how Copilot has inspired and empowered people across the last year – and we know our work is never done in our relentless pursuit to continue to innovate on behalf of our customers.

The introduction of the Copilot key marks the first significant change to the Windows PC keyboard in nearly three decades. We believe it will empower people to participate in the AI transformation more easily. The Copilot key joins the Windows key as a core part of the PC keyboard and when pressed, the new key will invoke the Copilot in Windows experience to make it seamless to engage Copilot in your day to day*. Nearly 30 years ago, we introduced the Windows key to the PC keyboard that enabled people all over the world to interact with Windows. We see this as another transformative moment in our journey with Windows where Copilot will be the entry point into the world of AI on the PC.

Over the coming days leading up to and at CES, you will start to see the Copilot key on many of the new Windows 11 PCs from our ecosystem partners, with availability beginning later this month through Spring, including on upcoming Surface devices.

We are excited to take the next step on our journey. There’s never been a better time to get started with Copilot today, whether it’s turning your ideas into songs, creating beautiful images and polished drafts to adjusting your PC settings, Copilot is your everyday AI companion for work and life. To learn more visit this link.

As we embark on this new year, we are filled with optimism and excitement. We will continue to build Windows to be the destination for the best AI experiences. This will require an operating system that blurs the lines between local and cloud processing. The year ahead promises to be nothing short of extraordinary!

Disclaimer:

* Timing of Copilot feature delivery and availability varies by market and device. Requires Microsoft account to log in. When Copilot for Windows is not available or enabled on the device, pressing the Copilot key will launch Windows Search.

Editor’s note – Jan. 4, 2023 – The blog was updated to share the latest timing of availability."
Microsoft_News,https://www.microsoft.com/en-us/industry/blog/telecommunications/2024/01/03/generative-ai-provides-a-big-boost-to-the-telecommunications-industry/,,Generative AI provides a big boost to the telecommunications industry,"We’ve moved beyond the hype—generative AI works, and the telecommunications industry is feeling its true impact. Microsoft recently commissioned a study which showed that for every United States dollar that a company invests in AI, it realizes an average return of USD3.50. We just launched a special Work Trend Index report that showed a massive increase in employee productivity; it also showed that 77% of Microsoft Copilot users said that once they used Copilot, they didn’t want to give it up. Those are real benefits that telcos are seeing today, and they are eager to explore what’s next—how can they do more with generative AI and their data investments, their intelligent applications, and their businesses?

Microsoft Azure OpenAI Service Transform your organization with AI-driven solutions Learn more

The big impact of generative AI

Discussions about the potential of generative AI on the telco industry are everywhere. “IDC is projecting that generative AI will add nearly USD10 trillion to global GDP over the next 10 years.”1 Other analysts are projecting telco productivity increases in the billions for customer service, marketing, sales, app development, network insights, and operations. At Microsoft, we’ve already seen the benefits of generative AI across the company. The Microsoft global customer support team streamlined operational efficiency while delivering exceptional customer satisfaction with Copilot in Dynamics 365 Customer Service. There was a 31% increase in first call resolution and a 12% increase in customer satisfaction. Learn more about modernizing your customer service experience with Microsoft Dynamics 365 Customer Service. The Microsoft Customer and Partner Solutions organization used Microsoft Copilot for Sales to simplify workflows and help its sellers more efficiently build relationships with clients.

What does generative AI do for telco?

Generative AI empowers telco to work with vast amounts of data, identify patterns, and generate novel solutions, promising to transform traditional practices and foster industry-wide innovations. By embracing generative AI, telco companies can overcome challenges, unlock new revenue streams, improve operational efficiency, and deliver exceptional customer experiences. It’s a key ingredient in accelerating the transformation from telco to techco. And with so many potential applications for generative AI, it’s important to identify what has worked so far. To provide some inspiration, here are a few success stories that show us generative AI’s potential to transform the industry and drive substantial value.

Elevating customer experiences

Indonesian telco company Telkomsel introduced Veronika—a virtual assistant that integrates Microsoft Azure OpenAI Service. Veronika is rooted in natural language processing and machine learning, and according to Vice President of Customer Journey and Digital Experience at Telkomsel, Danang Andrainto, “Veronika continues to innovate by integrating the best AI technology to infuse intelligence into its functions, resulting in the delivery of solutions that are progressively more accurate.” Veronika recommends telco packages based on customers’ needs, and it can quickly and accurately address customer concerns. Here’s more of the story of Veronika and how generative AI is making it better.

And Veronika isn’t the only one. Bots are becoming more popular and effective in providing a digital-first customer experience. They can handle complex queries, improve customer engagement, and reduce operational costs. They can reduce the average handling time and save millions of dollars per month. These bots can help customers with various tasks, such as checking balances, paying bills, troubleshooting issues, and finding the best deals. They can build personalized scripts for next-best offers based on real-time data and insights. They can enhance end-to-end call center engagements from customer inquiry summarization, providing real-time information to resolve questions for sales agents, to analyze live sentiment, and to suggest personalized scripts for next-best offers; and they can create post-call analyses on agent performances. They can also create customer-sentiment analysis to help monitor and improve customer experiences across multiple touchpoints. Bots are transforming customer care strategies for many businesses around the world.

Bots are helping employees too. South African telco group MTN launched SiYa—an employee bot that can assist workers with inquiries, information on company policies, and employee-to-company interactions. And ultimately, MTN hopes SiYa can help customers with purchases, advice, and service. “By harnessing the power of AI and APIs, we are not only future-proofing our operations but ensuring that our customers, both internal and external, can look forward to a more streamlined, efficient, and data-driven experience,” MTN South Africa CEO Charles Molapisi says.

Aimee is BT Group’s new digital assistant. Kevin Lee, Chief Digital Officer for Consumer Division of BT Group, says, “Our pilots with generative AI with Microsoft are designed to see if we can more rapidly make Aimee the most personal, customer-focused, intelligent digital assistant delivering value through every interaction.” But Lee says he doesn’t want Aimee to replace human-to-human interactions; he wants Aimee to help customers meet their needs more efficiently and accurately. Aimee is meant to be a support, and her role is unlimited.

Accelerate network operation

If we look to the technical side of things, generative AI can improve network operations for operators too. Three UK leveraged Azure Operator Insights by creating and optimizing network configurations, policies, and parameters based on the data collected from the network performance, traffic, and user behavior. Generative AI can learn from the existing network settings and generate new ones that can enhance the network’s efficiency, reliability, and security. For example, generative AI could help design and deploy optimal network slices for different use cases and customers or adjust the network parameters to cope with changing demand and conditions. Generative AI can also help to automate network management tasks like fault detection, diagnosis, and resolution by generating and executing appropriate actions based on the network state and the desired outcomes. It can use natural language processing and generation to enable more human-like interactions between network operators and the network systems, using voice commands to control the network functions or receiving natural language explanations of the network status and its issues. Generative AI applications for network operation include:

Generative AI can be used to optimize Radio Access Network Configuration Optimization parameters based on the network performance data and the operators.

Generative AI can generate and execute network policies, configurations, and actions based on the network data and the operator’s goals.

Organizations can be more efficient

Generative AI can help make knowledge management more efficient with the ability to increase the productivity of HR, finance, legal, and customer service departments. By using bots, organizations can provide faster and more accurate answers to their employees and customers. For example, Finland’s largest telco and tech company, Elisa, has used Microsoft Copilot for Microsoft 365, which helps knowledge workers with various tasks, such as finding documents, scheduling meetings, and creating reports. Katja Bäckström, Elisa’s Senior Vice President, Customer Service and Customer Service with Copilot, says, “With Copilot, traditional data entry is eliminated, and customer data can be accessed directly from customer discussions. Copilot can easily be asked about the latest actions with the customer and a proposal for creating the next agenda. In the end, Copilot improves both the employee experience and the customer experience.”

Multinational tech and telco company Lumen uses Copilot. Lumen’s customer service teams surface relevant policies with Copilot, they summarize tickets, and they easily find repair instructions from manuals. They can quickly create presentations, new business proposals, and statements of work. “Our people are seeing immediate productivity improvements with Copilot, allowing them to focus on more value-added activities each day,” Kate Johnson, president and CEO of Lumen Technologies, Inc. says.

Marketing and sales benefit from generative AI

But can generative AI help your marketing and sales departments?

Generative AI can help create appealing and customized content for different audiences and channels, such as blog posts, social media posts, landing pages, email campaigns, and more. For example, a telco operator could use generative AI to create titles, summaries, keywords, or captions for their online content based on the target audience’s interests and actions.

Generative AI can also help classify and segment customers based on their attributes, desires, preferences, and actions, using data from various sources, like web analytics, customer relationship management platforms, or social media. A telco operator could use generative AI to group their customers into different profiles, for example, such as the innovators, the loyalists, and the value seekers. They could then adjust their messages and offers accordingly.

Generative AI can help recommend appropriate and personalized products or services to customers based on factors such as their previous purchases, web history, and feedback. For example, a telco operator could use generative AI to suggest the best bundle, plan, or add-on for each customer, based on their budget, needs, and usage patterns.

Generative AI can help create interested and qualified leads for the sales team by finding and contacting potential customers who match the ideal customer profile, using data from various sources like third-party databases, social media, or web analytics. For example, a telco operator could use generative AI to create leads for their business solutions by identifying and reaching out to prospects who are searching for similar services, have high intent, and meet the criteria of decision makers.

Amdocs, in partnership with Microsoft, launched a unified Customer Engagement Platform, leveraging the power of generative AI. Integrated with Microsoft Dynamics 365, it is an all-encompassing AI-powered marketing, sales, commerce, and customer service platform serving consumer and enterprise customers on a single, open, telco, and cloud-native platform.

Developer productivity

With GitHub Copilot for Business, 46% of new code is now written by AI, and developer productivity has increased by over 55%. AT&T uses Azure OpenAI Service in a few ways. It moves legacy code into modern code using generative AI, which helps the developers focus on creating modern tools and experiences for workers and customers. AT&T employees can ask generative AI questions about their insurance plans or getting hardware for a new employee. And AI helps with storage problems or computer issues company wide. Read more about AT&T’s developers and generative AI.

GitHub Copilot simplifies the creation and consumption of TM Forum Open APIs by generating the required code that complies to the API guidelines in the development language of your choice.

Accelerate your own generative AI journey with Microsoft

Partner with Azure OpenAI Service to transform your telco organization with AI-driven solutions for enhanced operations, innovative services, and exceptional customer experiences. The service offers many opportunities to explore AI-driven solutions for your organization. We hope to see you at Mobile World Congress 2024 as well. We’ll be there talking about how AI is accelerating the telco industry’s transformation.

About the study

The IDC study, commissioned by Microsoft, is based on results from 2,109 enterprise organizations totaling more than 13 million employees worldwide across 16 countries globally. Through the questionnaire, respondents were identified as the decision maker for AI within their organization.

1Official Microsoft Blog, New study validates the business value and opportunity of AI, November 2023."
Microsoft_News,https://www.microsoft.com/en-us/worklab/podcast/nir-eyal-on-how-to-defeat-distraction-in-an-always-on-world,,Nir Eyal on How to Defeat Distraction,"MOLLY WOOD: Today I’m talking to Nir Eyal, a bestselling author and entrepreneur with expertise in how to make products and services engaging and habit-forming. He has harnessed that same expertise to develop guidelines on how we can maintain focus and tune out the ubiquitous distractions that buffet us all day, every day. Nir has said that being able to control your own attention is the most important skill of the century. And he lays out a process for how to do that in his most recent book, Indistractible: How to Control Your Attention and Choose Your Life. Here’s my conversation with Nir.

[Music]

MOLLY WOOD: For starters, I’d love to get your take on what distraction is and how we can possibly get it under control.

NIR EYAL: The best way to understand what distraction is is to ask yourself, what is the opposite of distraction. Now most people will tell you the opposite of distraction is focus. But that’s not exactly right. The opposite of distraction is traction. They both come from the same Latin root, trahare, which means “to pull.” So traction is any action that pulls you towards what you said you were going to do—things that move you closer to your values and help you become the kind of person you want to become. Distraction is any action that pulls you away from what you plan to do, further away from your values, further away from your goals. Now let’s talk about triggers. We have these two kinds of triggers. External triggers are all the things in your outside environment that tell you what to do next—it’s the pings, the dings, the rings. But it turns out, studies find, even though we tend to blame these things as the source of our distraction, it turns out they only account for 10 percent of our distractions. The vast majority of distraction begins from within. These are called internal triggers. Uncomfortable emotional states that we seek to escape—boredom, loneliness, uncertainty, stress, anxiety. That is the source of 90 percent of our distraction. So now, we have our indistractible model, we have our four steps. Step number one is to master those internal triggers. Step number two, making time for traction. Step number three, hack back the external triggers. And then finally step number four, prevent distraction with pacts. And so using these four steps in concert, anyone can become Indistractible.

MOLLY WOOD: So you’ve worked with companies to devise products and experiences that are habit-forming. But you also stress that we can use technology to master our attention, right? Is there a little bit of contradiction there?

NIR EYAL: You know, the idea is not to negate—because we want to keep the good habits. We want to build products that are engaging, that help people live happier, healthier, more connected lives, right? We want the apps that help us learn a new language or help us exercise more, eat right or save money or connect to loved ones. That’s great. But we also want to break the bad habits that take us off track. This is not a new problem. In fact, part of the research when I first started looking into this psychology of distraction, some of the first mentions of distraction came all the way from Plato. The Greek philosopher talked about akrasia in the Greek, the tendency to do things against our better interest. That’s a 2,500-year-old concept. It can’t be social media’s fault. It can’t be the internet’s fault. It can’t be the technology’s fault, because people have always been distracted from one thing or another. Now, do they play a role? Absolutely. Is it a symptom of a larger problem? Absolutely. And so what we need to do is to stop blaming and shaming and rather look at the root cause of the problem itself. Mankind has always done two things when it comes to the role of technology in our lives. Remember, as Paul Virilio said, when you invent the ship, you invent the shipwreck. You know, there used to be lots of shipwrecks. Today, you almost never hear about shipwrecks. What did we do? Did we stop sailing ships? No, we made ships better. We use technology to improve the last generation of technology. And so that’s what we’re going to do. We’re going to do two things: we’re going to adapt and we’re going to adopt. We’re going to adapt to these technologies by changing our norms, by changing the rules of society. What we’re also going to do is we’re going to adopt new technologies that fix the bad aspects of the last generation of technologies. And that’s exactly what’s going on. Right? We see all these tools today, thousands of apps and websites and devices that actually help us fix this problem of distraction. Part of it is a technologist solution, right, creating new technologies, but we also have a personal responsibility role. And then that’s what Indistractible is for, learning how to better live with these devices, and make sure that we use them as opposed to letting them use us.

MOLLY WOOD: You’ve talked about how with every new innovation that’s introduced, we develop new norms around when and how we use that innovation. But how does that apply to helping us with focus and attention?

NIR EYAL: Sure, so maybe it’s helpful to see how we’ve overcome these challenges in the past. I remember as a kid, I was born in the 1970s, and one thing that’s really profoundly different from the world I grew up in—when I grew up, everyone I knew had ashtrays in their home. People used to collect ashtrays, in fact. My father used to smoke, he gave up smoking, and we still had ashtrays in the house. And I remember people would come to our house, as they did everybody’s house, and adults would light up a cigarette without even asking. That would be unheard of, unconscionable for someone to do that today. But that’s just what people did back then. Until people like my mother took away the ashtrays. And when one of her friends came over and lit up a cigarette without asking, she said, ‘Oh, I’m sorry, we are non-smokers. If you’d like to smoke, kindly go outside.’ So she used what we call in sociology a social antibody. She used this identity moniker to identify herself as somebody who doesn’t do a particular behavior. And so that’s part of what we’re going to see happening when it comes to technology. And I already see this among young people. It’s ironic, because when I talk about technology, people often think, oh, the young people, they’re the ones who are addicted to technology. But actually, they’re the people who are adopting these norms first. When I used to teach at Stanford, the first few years that I taught, everybody was on their phones. In the middle of my lectures, almost the whole class was checking their phones. When I moved to New York, by the end of my time there, almost nobody was on their phones.

MOLLY WOOD: Let’s talk a little more about using technology to help us deal with those menial tasks. How can AI assistants, do you think, give us some of that time away from the phone back, for example?

NIR EYAL: I could see us having an age where we have these AI assistants that can mindfully look at what we’re doing, and help us stay on track, that help us stay aligned with our greater intentions. Because the difference between traction and distraction is intent. The time you plan to waste, as Dorothy Parker said, the time you plan to waste is not wasted time. So if you have planned time in your calendar to watch something online, or to go on social media, or to play a video game, that’s great, there’s nothing wrong with that—as long as it’s done with intent. Conversely, just because something is a work-related task doesn’t mean it’s not a distraction. In fact, I would argue that is the very worst, most harmful kind of distraction, is the distraction you don’t even realize is taking you off track. So if you are checking email rather than working on that big project that you said you would work on, just because it’s a work-related task doesn’t mean it’s not a distraction. It’s a more pernicious distraction, because distraction has tricked you into prioritizing the urgent and easy work at the expense of the hard, important work you have to do to move your life and career forward. So what I could see happening someday is that we have these little AI assistants who know our greater intentions, who know what our schedule should look like, and who help us formulate how we can turn our values into time and then help keep us accountable and say, Hey, I see you’re doing this as opposed to this thing you planned to do. Is that what you really want to do? Is that what’s really on your plan? So maybe there’s like a little accountability buddy that helps keep us on track.

MOLLY WOOD: So even before—long before—this recent explosion of interest in generative AI, you’ve talked about how virtual assistants and AI are a really fruitful area for innovation. What do you think of the potential applications of this tech now, especially around helping us make better decisions and prioritize our time?

NIR EYAL: Yeah. I work a lot in healthcare with various health tech companies to help people do the things that they want to do. It’s a very clear alignment of interests, right? People want to take their medication, they want to exercise, they want to eat healthy—but it doesn’t happen. And the reason it often doesn’t happen is because there’s an intention-action gap—that I intend to do one thing, but I don’t actually do it. So I foresee a day where there will be technologies that help interrupt the trigger and the response to bad habits. So let me give an example. I am sure there will be a device here a few years away, maybe less, where before I eat that french fry, I get a little notification that says, Hey, no problem if you eat that french fry, but you should know it’s going to put you over your calorie allowance for the day.

MOLLY WOOD: So it sounds like you’re not that surprised that generative AI has seized the public imagination, and also that all of these useful applications have appeared.

NIR EYAL: No, actually, I expected this to happen a long time ago. I think it was 2014 or so, 2015, that I was thinking that this revolution with these technologies—that I didn’t predict, of course, all that’s happened with LLMs, but I think I did expect there to be an interface that made it easier for a human being to scale responses. So now that they don’t need to serve just one client at a time, they can serve hundreds, if not thousands of clients at a time, because they have these preformed messages, which makes their throughputs so much higher. There’s still human accountability in the loop, but it’s greatly assisted by the technology. So I think we’re gonna see a lot of that as well.

MOLLY WOOD: How do you think about, for business leaders, adopting this technology, building these AI-powered organizations, which will involve a lot of, in some cases, brand new habits? How do you think about socializing that?

NIR EYAL: I think a big part of it, at least from the user experience perspective, is going to be that we are entering an age of mass customization. So this goes back to my first book, Hooked, around how do you build a habit-forming product. The real linchpin of a habit-forming product is that it gets the user to invest in the product to make it better with use. And that’s something that, really, the social media companies have mastered, the algorithms that the more you use the product, the better and better it becomes. But we do see this in enterprise applications and SaaS applications, and all sorts of products do this. It’s just been very, very expensive to mass customize a product. Well now with AI, and generative AI specifically, that’s going to be a requirement. I think you’re going to be left in the dust if you think that everybody should get the same product no matter who they are, the same product experience—that’s going to change, people are going to expect mass customization. It’s what I call data gossip, that we know that as much as—people, when you ask them, are you okay with people knowing your information? If you couch the question that way, they’ll say, no, that’s terrible. But if you ask them, would you like us to customize your experience to make it easier to use? They say, yeah, absolutely. That sounds great. Show me how. Where do I sign up? Customers are going to require you, they’re going to expect you to improve the product. If they already told you information about themselves and how they like to interact with you, you damn well better customize the experience to make it better for them based on the information they’ve given you.

MOLLY WOOD: Right. And of course, this requires a lot of data transparency and responsibility for companies like Microsoft, and employers as well. So, another key thing we’re exploring this season is how the smart use of things like generative AI can save you time, and what you do with the time you save. In your writing, you’ve specifically identified useless meetings as a productivity trap. How do you think AI can help us avoid those?

NIR EYAL: Yeah. Well, I’ll tell you what I advise. And this came from a pretty extensive study I did around what type of organizations hold effective meetings versus don’t hold effective meetings. The first rule is very simple, and this is something that I learned in high school student council, you would be amazed how many companies don’t do it, which is no agenda, no meeting. Turns out 80 percent of meetings, 80 percent of meetings have no agenda. We’re calling meetings to hear ourselves think. Let’s get together and brainstorm. Well, it turns out the science is pretty convincing that the optimal number of people for a brainstorm session is two or less—that is the optimal number. It turns out that when you sit and actually have the time and attention to think about a problem, what happens is when individuals then submit their ideas, that produces much better results. Why? Because when we call a meeting, without, you know, we call a brainstorming meeting, we get together, we start discussing an idea. What tends to happen, overwhelmingly, is that the loudest, the highest paid, and the most male person dominates the conversation. And we don’t hear everyone’s ideas. To gain consensus, you need two things. You need an agenda, you need to know what we’re going to talk about, and so the person calling the meeting has to do that in advance. That’s definitely something that an AI can help with. The next thing you need to do is a briefing document. A briefing document is when the person who called the meeting shows they did their homework, and they have an opinion after collecting data and doing the analysis that they need to gain consensus around. And so what they do is they say, Okay, please give me your opinion on XYZ. Do that, find the time in your schedule. Send that feedback to me, brainstorm, send me your ideas. I will synthesize them into a briefing document so that when we meet, we can read through this briefing document together and gain consensus. If you require this in your organization, you will eliminate almost all of your unnecessary meetings. Why? Because you’ve made calling meetings more difficult. This is the feedback I get, by the way—oh, that sounds like a lot of work. That’s the point. Because calling meetings today is way too easy. And so people call way too many of these meetings. What you want to do is you want to add friction to the meetings, so that they happen less frequently and are higher quality.

MOLLY WOOD: Or sometimes you’ll create a briefing doc, or have an AI assistant like Copilot help you outline a briefing doc, and discover that sharing the document means you don’t have to have the meeting in the first place.

NIR EYAL: Oh, that’s absolutely right. So that briefing document can be done a million different ways, right? To date, it’s been done manually word by word. But yeah, if there’s an AI that helps you generate this briefing document and helps you get to your conclusion, the whole point is that nine out of 10 times, you didn’t need to call the meeting in the first place.

MOLLY WOOD: With generative AI we’ve entered this world where we can offload a lot of menial tasks. And there’s a base level of work that can happen without us, which means we can take hours off of our calendar. So how should people think about using that extra time? Like, is it okay to schedule in a little Candy Crush? Or do we need to, you know, think of higher-level things that we can be doing?

NIR EYAL: Well, first of all, let’s acknowledge that this is the highest-class problem you could possibly have. Right? So there’s many people, and we just acknowledge that we have tremendous privilege that we live in a day and age that we even need to worry about this problem—ooh, what do I do with my excess leisure time? But it is a problem nonetheless. And so I think the wrong approach is to use these distractions whenever we feel like it. Because what you’re doing when you’re habituating yourself to “every time I feel bored, every time I feel anxious, every time I feel lonely, every time I feel stressed, I need something to take my mind off of that discomfort,” you’re robbing yourself of the ability to deal with that discomfort in a healthy way. But, given that we have more leisure time, historically, than we ever had in human history, figuring out how to wisely spend that leisure time is very important. So what I would advise is to first start with your values. Values are attributes of the person you want to become. Ask yourself, how would the person you want to become spend their time in these three life domains. The first life domain is you. If you can’t take care of yourself, you can’t take care of others, you can’t make the world a better place. So take out your calendar, look at your week ahead and ask yourself, how would the person you want to become spend their time taking care of themselves. And that can include time for prayer, for meditation, for rest, for reading, for painting, for social media. If you want to go on Candy Crush, or you want to play video games, nothing wrong with that. The point here is to schedule it in advance, to put it on your calendar. Then, have time in your schedule for regular engagement with your friendships, it’s very important. Also, of course, with your family, with your extended community—put it in your calendar. And then finally, when it comes to the work domain, this is where we have these two kinds of work. We have reactive work, and we have reflective work. Reactive work is how most distractible people spend their day; they always look to their email to tell them what to do, their phone, their devices are constantly telling them what to do—that’s reactive work, reacting to notifications, reacting to emails, reacting to what your colleagues and boss wants. That’s reactive work. And that has a place in our day, of course, we have to spend some amount of our time reacting to our customers and clients’ needs. But, if you don’t also have time for reflective work—planning, strategizing, creative work, and thinking requires us to do so without distraction. So you’ve got to plan at least some time in your day, even if it’s 30, 45 minutes, maybe an hour of time in your day, for that reflective work. Because if you don’t schedule that time, you’re going to run real fast in the wrong direction.

MOLLY WOOD: Okay, fast-forward three to five years. What do you think will be the most profound change in the way we work?

NIR EYAL: When you’re a hammer, everything looks like a nail. And so I think there will be a real bifurcation between people who learn how to control their time and attention, and people who let their time and attention be controlled by others. So I think there will be a real difference between people who enter the workforce, or who are currently in the workforce, and learn the ability to become what’s called an autodidact—it’s one of my favorite words in the English language. An autodidact is someone who teaches themselves. And what we are seeing with technological progress happening so quickly, it is absolutely essential that we all become better at upskilling. Right? We see this already. If you know how to be an AI prompt engineer, well, you’ve got a superpower. But you had to learn how to do that. And so what I find is that the problem is not that people don’t have the motivation. It’s not that they don’t have the time, they don’t have the ability to focus on the task and get it done. And so I think there will be a real change between the high performers, who are masters of their time and attention, and everyone else. It becomes kind of this multiplier effect of, the better you are at learning new skills, the better you become at learning new skills. That macro skill is the ability to become Indistractible, because that allows you to be able to focus long enough to absorb all this amazing information that, so far, is pretty much free online. You can learn all these amazing skills, you just need the time and attention to put forth to learn them.

MOLLY WOOD: Thanks so much for sharing your time and sharing your great advice on how we should use our time.

NIR EYAL: My pleasure, Molly, thank you.

[Music]

MOLLY WOOD: Thank you again to Nir Eyal, author, entrepreneur, and behavioral design expert. And that’s it for this season of WorkLab, the podcast from Microsoft. Please subscribe and check back for the next season, where we’ll continue to explore what leaders need to know about how to thrive in the new world of work. If you’ve got a question or a comment, drop us an email at worklab@microsoft.com. And check out Microsoft’s Work Trend Indexes and the WorkLab digital publication, where you’ll find all of our episodes along with thoughtful stories that explore how business leaders are thriving in today’s digital world. You can find all of that at microsoft.com/worklab. As for this podcast, rate us, review us, and follow us wherever you listen. It helps out a lot. The WorkLab podcast is a place for experts to share their insights and opinions. As students of the future of work, Microsoft values inputs from a diverse set of voices. That said, the opinions and findings of our guests are their own and they may not necessarily reflect Microsoft’s own research or positions. WorkLab is produced by Microsoft with Godfrey Dadich Partners and Reasonable Volume. I’m your host, Molly Wood. Sharon Kallander and Matthew Duncan produced this podcast. Jessica Voelker is the WorkLab editor."
Microsoft_News,https://www.microsoft.com/en-us/research/blog/research-at-microsoft-2023-a-year-of-groundbreaking-ai-advances-and-discoveries/,,Research at Microsoft 2023: A year of groundbreaking AI advances and discoveries,"It isn’t often that researchers at the cutting edge of technology see something that blows their minds. But that’s exactly what happened in 2023, when AI experts began interacting with GPT-4, a large language model (LLM) created by researchers at OpenAI that was trained at unprecedented scale.

“I saw some mind-blowing capabilities that I thought I wouldn’t see for many years,” said Ece Kamar, partner research manager at Microsoft, during a podcast recorded in April.

Throughout the year, rapid advances in AI came to dominate the public conversation (opens in new tab), as technology leaders and eventually the general public voiced a mix of wonder and skepticism after experimenting with GPT-4 and related applications. Could we be seeing sparks of artificial general intelligence (opens in new tab)—informally defined as AI systems that “demonstrate broad capabilities of intelligence, including reasoning, planning, and the ability to learn from experience (opens in new tab)”?

While the answer to that question isn’t yet clear, we have certainly entered the era of AI, and it’s bringing profound changes to the way we work and live. In 2023, AI emerged from the lab and delivered everyday innovations that anyone can use. Millions of people now engage with AI-based services like ChatGPT. Copilots (opens in new tab)—AI that helps with complex tasks ranging from search to security—are being woven into business software and services.

Underpinning all of this innovation is years of research, including the work of hundreds of world-class researchers at Microsoft, aided by scientists, engineers, and experts across many related fields. In 2023, AI’s transition from research to reality began to accelerate, creating more tangible results than ever before. This post looks back at the progress of the past year, highlighting a sampling of the research and strategies that will support even greater progress in 2024.

Strengthening the foundations of AI

AI with positive societal impact is the sum of several integral moving parts, including the AI models, the application of these models, and the infrastructure and standards supporting their development and the development of the larger systems they underpin. Microsoft is redefining the state of the art across these areas with improvements to model efficiency, performance, and capability; the introduction of new frameworks and prompting strategies that increase the usability of models; and best practices that contribute to sustainable and responsible AI.

Advancing models

Researchers introduced Retentive Networks (RetNet), an alternative to the dominant transformer architecture in language modeling. RetNet supports training parallelism and strong performance while making significant gains in inference efficiency.

To contribute to more computationally efficient and sustainable language models, researchers presented a 1-bit transformer architecture called BitNet.

Microsoft expanded its Phi family of small language models with the 2.7 billion-parameter Phi-2, which raises the bar in reasoning and language understanding among base models with up to 13 billion parameters. Phi-2 also met or exceeded the performance of models 25 times its size on complex benchmarks.

The release of the language models Orca (13 billion parameters) and, several months later, Orca 2 (7 billion and 13 billion parameters) demonstrates how improved training methods, such as synthetic data creation, can elevate small model reasoning to a level on par with larger models.

For AI experiences that more closely reflect how people create across mediums, Composable Diffusion (CoDi) takes as input a mix of modalities, such as text, audio, and image, and produces multimodal output, such as video with synchronized audio.

To better model human reasoning and speed up response time, the new approach Skeleton-of-Thought has LLMs break tasks down into two parts—creating an outline of a response and providing details on each point in parallel.

Advancing methods for model usage

AutoGen is an open-source framework for simplifying the orchestration, optimization, and automation of LLM workflows to enable and streamline the creation of LLM-based applications.

Medprompt, a composition of prompting strategies, demonstrates that with thoughtful and advanced prompting alone, general foundation models can outperform specialized models, offering a more efficient and accessible alternative to fine-tuning on expert-curated data.

The resource collection promptbase offers prompting techniques and tools designed to help optimize foundation model performance, including Medprompt, which has been extended for application outside of medicine.

Aimed at addressing issues associated with lengthy inputs, such as increased response latency, LLMLingua is a prompt-compression method that leverages small language models to remove unnecessary tokens.

Developing and sharing best practices

Accelerating scientific exploration and discovery

Microsoft uses AI and other advanced technologies to accelerate and transform scientific discovery, empowering researchers worldwide with leading-edge tools. Across global Microsoft research labs, experts in machine learning, quantum physics, molecular biology, and many other disciplines are tackling pressing challenges in the natural and life sciences.

Because of the complexities arising from multiple variables and the inherently chaotic nature of weather, Microsoft is using machine learning to enhance the accuracy of subseasonal forecasts.

Distributional Graphormer (DIG) is a deep learning framework for predicting protein structures with greater accuracy, a fundamental problem in molecular science. This advance could help deliver breakthroughs in critical research areas like materials science and drug discovery.

Leveraging evolutionary-scale protein data, the general-purpose diffusion framework EvoDiff helps design novel proteins more efficiently, which can aid in the development of industrial enzymes, including for therapeutics.

MOFDiff, a coarse-grained diffusion model, helps scientists refine the design of new metal-organic frameworks (MOFs) for the low-cost removal of carbon dioxide from air and other dilute gas streams. This innovation could play a vital role in slowing climate change.

This episode of the Microsoft Research Podcast series Collaborators explores research into renewable energy storage systems, specifically flow batteries, and discusses how machine learning can help to identify compounds ideal for storing waterpower and advancing carbon capture.

MatterGen is a diffusion model specifically designed to address the central challenge in materials science by efficiently generating novel, stable materials with desired properties, such as high conductivity for lithium-ion batteries.

Deep learning is poised to revolutionize the natural sciences, enhancing modeling and prediction of natural occurrences, ushering in a new era of scientific exploration, and leading to significant advances in sectors ranging from drug development to renewable energy. DeepSpeed4Science, a new Microsoft initiative, aims to build unique capabilities through AI system technology innovations to help domain experts unlock today’s biggest science mysteries.

Christopher Bishop, Microsoft technical fellow and director of the AI4Science team, recently published Deep Learning: Foundations and Concepts, a book that “offers a comprehensive introduction to the ideas that underpin deep learning.” Bishop discussed the motivation and process behind the book, as well as deep learning’s impact on the natural sciences, in the AI Frontiers podcast series.

Maximizing the individual and societal benefits of AI

As AI models grow in capability so, too, do opportunities to empower people to achieve more, as demonstrated by Microsoft work in such domains as health and education this year. The company’s commitment to positive human impact requires that AI technology be equitable and accessible.

Beyond AI: Leading technology innovation

While AI rightly garners much attention in the current research landscape, researchers at Microsoft are still making plenty of progress across a spectrum of technical focus areas.

Project Silica, a cloud-based storage system underpinned by quartz glass, is designed to provide sustainable and durable archival storage that’s theoretically capable of lasting thousands of years.

Project Analog Iterative Machine (AIM) aims to solve difficult optimization problems—crucial across industries such as finance, logistics, transportation, energy, healthcare, and manufacturing—in a timely, energy-efficient, and cost-effective manner. Its designers believe Project AIM could outperform even the most powerful digital computers.

Microsoft researchers proved that 3D telemedicine (3DTM), using Holoportation TM communication technology, could help improve healthcare delivery, even across continents, in a unique collaboration with doctors and governments in Scotland and Ghana.

communication technology, could help improve healthcare delivery, even across continents, in a unique collaboration with doctors and governments in Scotland and Ghana. In another collaboration that aims to help improve precision medicine, Microsoft worked with industry and academic colleagues to release Terra, a secure, centralized, cloud-based platform for biomedical research on Microsoft Azure.

On the hardware front, Microsoft researchers are exploring sensor-enhanced headphones, outfitting them with controls that use head orientation and hand gestures to enable context-aware privacy, gestural audio-visual control, and animated avatars derived from natural body language.

Collaborating across academia, industries, and disciplines

Cross-company and cross-disciplinary collaboration has always played an important role in research and even more so as AI continues to rapidly advance. Large models driving the progress are components of larger systems that will deliver the value of AI to people. Developing these systems and the frameworks for determining their roles in people’s lives and society requires the knowledge and experience of those who understand the context in which they’ll operate—domain experts, academics, the individuals using these systems, and others.

Engaging and supporting the larger research community

Throughout the year, Microsoft continued to engage with the broader research community on AI and beyond. The company’s sponsorship of and participation in key conferences not only showcased its dedication to the application of AI in diverse technological domains but also underscored its unwavering support for cutting-edge advancements and collaborative community involvement.

Functional programming

Microsoft was a proud sponsor of ICFP 2023, with research contributions covering a range of functional programming topics, including memory optimization, language design, and software-development techniques.

Human-computer interaction

At CHI 2023, Microsoft researchers and their collaborators demonstrated the myriad and diverse ways people use computing today and will in the future.

Large language models and ML

Microsoft was a sponsor of ACL 2023, showcasing papers ranging from fairness in language models to natural language generation and beyond.

Microsoft also sponsored NeurIPS 2023, publishing over 100 papers and conducting workshops on language models, deep learning techniques, and additional concepts, methods, and applications addressing pressing issues in the field.

With its sponsorship of and contribution to ICML 2023, Microsoft showcased its investment in advancing the field of machine learning.

Microsoft sponsored ML4H (opens in new tab) and participated in AfriCHI (opens in new tab) and EMNLP (opens in new tab) , a leading conference in natural language processing and AI, highlighting its commitment to exploring how LLMs can be applied to healthcare and other vital domains.

Systems and advanced networking

Listeners’ choice: Notable podcasts for 2023

Thank you for reading

Microsoft achieved extraordinary milestones in 2023 and will continue pushing the boundaries of innovation to help shape a future where technology serves humanity in remarkable ways. To stay abreast of the latest updates, subscribe to the Microsoft Research Newsletter (opens in new tab) and the Microsoft Research Podcast (opens in new tab). You can also follow us on Facebook (opens in new tab), Instagram (opens in new tab), LinkedIn (opens in new tab), X (opens in new tab), and YouTube (opens in new tab).

Writers, Editors, and Producers

Kristina Dodge

Kate Forster

Jessica Gartner

Alyssa Hughes

Gretchen Huizinga

Brenda Potts

Chris Stetkiewicz

Larry West Managing Editor

Amber Tingle Project Manager

Amanda Melfi Microsoft Research Global Design Lead

Neeltje Berger Graphic Designers

Adam Blythe

Harley Weber Microsoft Research Creative Studio Lead

Matt Corwine

Opens in a new tab"
Microsoft_News,https://www.microsoft.com/en-us/worklab/how-i-prompt-leaders-share-their-favorite-ai-time-savers,,How I Prompt: Leaders Share Their Favorite AI Time-Savers,"Sign up for the WorkLab newsletter to get the latest AI research, insights, and trends delivered straight to your inbox.

Drop a few simple conversational prompts into AI, and the results are pretty astonishing. But these tools also have a deeper potential to transform how work gets done for those who learn how to fully leverage it.

Think of generative AI as a digital assistant that augments your own knowledge and capabilities. If you take a few seconds to give it context and explain your goals, you can create things faster, complete tasks with ease, and lessen your cognitive load.

As you experiment, you’ll develop your own approach to collaboration. To help you get started, we asked 10 leaders here at Microsoft how they use prompts to boost creativity, save time, and stay focused on the most meaningful and rewarding parts of their jobs.









Sumit Chauhan, Corporate Vice President, Office Product Group

When I get in to work in the morning, I’m already behind. There are unread emails and chat messages to catch up on while I’m simultaneously jumping into my first meeting. With Copilot in Outlook, I can type summarize, and boom—I have a pretty accurate rundown of the highlights of a long thread. Or let’s say I have to generate a deck based on documents, emails, previous presentations, what have you. I can go into PowerPoint and say, generate me a deck based on these things, and I get an outline or a draft of a deck. Just that one thing saves me an enormous amount of time.









Jared Spataro, CVP, Modern Work & Business Applications

What makes Copilot feel almost magical is the fact that it has a deep understanding of me, my job, my priorities, and my organization. It knows my entire universe of data at work. I can write:

Quickly summarize the meeting I had at 11 a.m. yesterday.

Who attended?

What decisions were made?

Give me a sense of what you think the next steps should be.

Put that summary into an email to Jun, and propose a time when we’re both free next week to discuss.

Write it in Japanese.









Colette Stallbaumer, General Manager, Microsoft 365 and Future of Work

Time is our most precious resource, and Copilot helps me reclaim some of that time at work. During a busy day, my most frequently used prompts start with “Find me”:

Find me the Q2 news deck that Marta shared in a meeting this week.

Find me the most recent Work Trend Index research document from Grace.

Find me the hybrid work playbook we created in 2021.

No more hunting for specific documents, decks, or emails. Copilot combs through all my folders and files to quickly find what I need—even if it’s a file I haven’t accessed in years. I find it saves me time and helps me stay focused on the strategic and creative work that matters most.









Amy Coleman, CVP, Human Resources & Corporate Functions

Once a week, to keep myself informed and prepare for meetings with global HR partners, I ask Copilot:

What are the top challenges facing global HR organizations this week in September 2023?

What about in Australia, 2023?

Are HR trends in the US for September 2023 different than the HR trends in Germany for September 2023?

Show me HR research across all of our global offices from the past three months, 2023.

Who are the top voices talking about these challenges?

It opens the door to possibilities rather than simply coming to a conclusion.









Jaime Teevan, Chief Scientist & Technical Fellow

When I’m reading an article, I get better summaries when I say, summarize this article for a Microsoft executive with a particular interest in research than when I just ask for a summary. Or if I’m trying to think critically about the article, I might follow up by telling it what I want the reply to look like: What questions should that exec ask of the article? Please include answers to the questions, quoting the article when possible. Basically, I get better replies by including details and direction.









Deb Cupp, President, Americas

I meet with a lot of customers. There are often a lot of ideas generated and action items assigned during these meetings. When I need to send follow-up emails, I rely on Sales Copilot to kick-start the drafting process. I just tell it to generate a response, and it looks at my previous email exchanges with that customer, recent notes from the Teams call, as well as any relevant data from the CRM, and suggests an appropriate response email. I can take that and make some edits of my own before hitting send. These prompts are like my personal shortcuts to staying organized and nailing communication, even on the busiest workdays.









Jon Friedman, CVP, Design & Research

I don’t write code. But I wanted to write JavaScript for an app that ran on mobile devices, so I prompted the AI with all the things I wanted the app to do, and it spit the code back at me. Then I asked, where do I put this code to look at it more carefully? It told me where and helped me troubleshoot errors. I didn’t just ask it to do something for me; I asked it to teach me too. It was like collaborating with a patient programmer.









Kathleen Mitford, CVP, Global Industry Marketing

Prompts like, write a list of… or compare… or give me examples of… give me interesting options and possibilities, and help me to explore creative ideas and build new work habits. Communication and iteration is key at work, and that includes communication with AI. I observe how Copilot responds to my prompts, then I ask it to evaluate its own response, then I ask it to iterate again. It’s like an ongoing dialogue, arrived at by testing and learning continually.









Merrie Williamson, CVP of Azure Infrastructure, Digital & Application Innovation

I am always looking for ways to go deeper in learning about our specific customers. One useful time saver is telling Copilot, highlight key trends and insights in this company’s quarterly earnings report. It’s a quick way to add the additional context I need to drive a great conversation for customer meetings.









Tara Roth, CVP, Microsoft 365 Customer Success Engineering

I love the ability to say, surface key action items for Teams meetings. It’s not always perfect, but it gets you close enough that you can then just quickly edit and add or take away whatever you want. I feel like I can be more attentive in the meeting because I’m not worried about taking notes. I can fully engage with the confidence that Copilot will have captured the key items accurately enough that I can then go modify and send out the summary.







"
Microsoft_News,https://aka.ms/AAl3l7i,,India’s Myntra innovates with generative AI to help shoppers put the right look together,"Bengaluru, Karnataka, INDIA: For someone pushing 40, stepping into a gym for the first time can be a nerve-wracking experience.

As this writer realized, even before self-doubts crept in about their chances of surviving an hour at the gym, the larger looming question was what to wear and not look out of place.

With absolutely no idea what they were looking for, this writer turned to an AI shopping assistant by Myntra, India’s biggest online fashion retailer, and typed, “I’m looking for clothes I can wear to work out in the gym.”

Surprisingly, the AI assistant understood exactly what this writer needed and came up with jerseys that would wick off sweat, compression t-shirts, self-proclaimed comfortable trackpants that wouldn’t restrict movement, shoes that could make you run better, fitness bands and all sorts of gear a newbie couldn’t have imagined they wanted or needed.

With the shopping cart full and the wallet significantly empty, this writer was ready for a new beginning.

What the AI assistant did – convert an abstract user query into actionable results – is game changing for the fashion industry. Conventional search works best with specific keywords – a blue t-shirt from a particular brand, say.

It goes a few steps beyond conventional search. It uses generative AI to respond to more open-ended questions like what to wear for a particular festival or a cricket match or even the trending fashion in a city.

“This is big,” said Arit Mondal, director of product management at Myntra, “Why? Because, this is the first time we have a solution, which is solving the unsolved ‘search’ problem in the fashion, beauty and lifestyle industry. And it’s live for customers at scale.”

For Arit Mondal, director of product management at Myntra, generative AI has helped them solve one of the biggest search problems in the online fashion retail industry. Photo by Selvaprakash Lakshmanan for Microsoft.

Since the beginning of online fashion retail, searching for products has been very similar to searching for any other piece of information online. You try a set of keywords and keep refining your search with different keywords and preset filters.

A search for a branded, blue t-shirt works well because the keywords are already part of the product catalog.

But that’s not always how people shop in the real world. Some shoppers only have a vague idea what they want – for instance, clothes for an upcoming vacation or a rock concert.

The conventional method of searching by keywords fails spectacularly when it comes to the second kind of customer as the search strings they use are not retrievable directly from the information stored in the product catalog.

Until now.

When generative AI – built on large language models (LLMs) that synthesize vast troves of data to generate, text, images and more – first made news last year, the team at Myntra quickly began thinking about how they could leverage it to enhance customer experiences.

When Myntra organized a hackathon in February this year, a group of engineers from the company’s search team decided to use Azure OpenAI Service to solve the abstract search problem and unshackle users from the cuffs of keywords.

The hackathon team at Myntra built a working prototype of the AI shopping assistant over two days. Photo by Selvaprakash Lakshmanan for Microsoft.

They were pleasantly surprised to see how ChatGPT, the generative AI service available through Azure OpenAI Service, could synthesize natural language prompts. They asked ChatGPT about the look of an actor from a recent movie and it could tell it consisted of a bomber jacket, gloves and aviator sunglasses.

“And this is the information that Myntra’s existing catalog didn’t have,” said Swapnil Chaudhari, an engineering manager at Myntra.

Over two days, his team took over a conference room and kept trying new prompts – text that generative AI could understand – to see what results they got. This was new territory – and they didn’t know how far they could push.

“We were surprised to see the results. It was able to answer questions like clothes to wear for regional festivals like Pongal and Onam,” said Pragna Kanchana, a frontend engineer at Myntra.

On a whim, she tried to search in Hindi with sardiyon ke kapde, which in English translates into winter clothes. And it understood it!

The team then got access to Azure OpenAI Service’s playground that let them do much more than was possible with ChatGPT alone.

“Leveraging Azure OpenAI Service, we were able to plug in different large language models in the same prompt and figure out which model worked best for our use case. So, we had a lot of freedom to compare and choose the right model,” explained Santanu Kanchada, a backend engineer in the search engineering team.

The team knew they were on to something big. They wrote the code in a day, and within two days they had a working prototype of a new feature that enabled users to search with natural language.

“If it were not for GPT models, we’d have to first retrain the model using Myntra’s catalog and then wait and check the results with our expectations. But the pre-trained models already available with Azure OpenAI Service were already performing quite well,” added Chaudhari.

Over the next five weeks, multiple teams across engineering and product development fine-tuned both the backend and the user interface for the AI shopping assistant.

“Myntra’s systems are on Azure and deploying Azure OpenAI Service was as seamless as deploying another server and it gave us a secure way of using generative AI,” explained Vindhya Priya Shanmugam, director of engineering at Myntra.

Vindhya Priya Shanmugam, director of engineering at Myntra, found Azure OpenAI Service as a seamless and secure way of deploying their AI shopping assistant. Photo by Selvaprakash Lakshmanan for Microsoft.

Post the hackathon, the search engineering team kept refining the prompts to get useful outcomes for users. One of the problems, for instance, was how to ensure that the response to a user’s query resulted in clothes for only the gender the user is looking for.

In the weeks leading to the launch, they trained the system on Myntra’s catalog and added guardrails so the results were limited to the catalog.

The AI shopping assistant was launched on the Myntra app in late May, just in time for one of their biggest marquee events, End of Reason Sale (EORS). It included sample prompts that gave users an idea of how they could use conversational language rather than keywords.

Since then, Myntra has already seen search queries broaden, offering new opportunities for product discovery. For instance, when someone searches for clothes they can wear to a beach, not only beach wear but also accessories like hats, sunglasses and footwear pop-up.

It has been phenomenal for Myntra.

“Users who shop using the AI shopping assistant are three times more likely to end up making a purchase,” said Mondal. “Because it also helps users discover a complete look from multiple categories of products, we’re seeing that on average they add products from 16 percent more categories than usual.”

While this writer’s fitness transformation journey is still questionable, multiple teams at Myntra are already building new features based on generative AI.

One of them will allow users to choose different categories of products – tops, bottoms and accessories, for example – and see how they look together in an outfit. Myntra plans to further enhance it by introducing voice search and provide personalized results. They are also looking at how they can use generative AI to help the customer support teams.

Click here to load media

Top image: Myntra’s AI shopping assistant powered by Azure OpenAI Service lets shoppers discover a complete look using natural language prompts that can include places, festivals, or other occasions. Photo by Selvaprakash Lakshmanan for Microsoft."
Microsoft_News,https://techcommunity.microsoft.com/t5/microsoft-teams-blog/year-in-review-how-microsoft-copilot-microsoft-teams-and-our/ba-p/4013328,,"Year in review: How Microsoft Copilot, Microsoft Teams, and our partners built a stronger ecosystem","As 2023 winds down, it’s incredible to reflect on all the progress we’ve made across the Microsoft 365 ecosystem this year. Above all, I want to thank our customers for trusting Microsoft Teams to be your tool and platform for collaboration and communication. I’m proud to report that tens of millions more people adopted Teams this year, including the new version released in October. Microsoft Teams now has over 320 million monthly active users.

I also want to share my deep gratitude with the independent software vendors (ISVs), system integrators, and enterprise developers who have partnered to help build our Teams ecosystem. Thanks to your investment, there are now more than 2,000 apps in the Teams store and over 145,000 custom line-of-business (LOB) apps built by enterprises.

This year’s biggest news was the introduction of Microsoft Copilot, your powerful new AI assistant for work. Microsoft Copilot for Microsoft 365 became generally available Nov.1, and we’re ensuring that your investment in Teams provides the foundation for Copilot extensibility, which allows you to augment Copilot with custom skills and bring its capabilities to your apps. Organizations with Copilot for Microsoft 365 can opt into the public preview for extensibility.

As we look forward, I want to share key resources we’ve created for ISVs and enterprise developers so that you can plan how you’ll harness the power of AI by extending Copilot. I also want to highlight a few fantastic Teams apps that can help enterprises improve their end-of-year operations, recognize outstanding employees, and kick off next year with renewed purpose.

Tips for extending Copilot for Microsoft 365 using Microsoft Graph connectors

In 2024, enterprise adoption of Copilot for Microsoft 365 will gain increasing momentum, and enterprise developers and ISVs must prepare accordingly. You can extend Copilot two ways: plugins and connectors. First, we’ll cover Microsoft Graph connectors, which bring information and content from external data sources into Microsoft Graph, enhancing the knowledge layer and grounding Copilot’s responses in more of your unique context. This extensibility option, which is generally available, also helps users discover more of your organization's content across Microsoft 365 experiences, like Microsoft Search.

For example, in early spring 2024, Copilot users will be able to search for and summarize content from Lucidspark's virtual whiteboards and Lucidchart's intelligent diagramming, bringing natural language processing to a new level. Lucid will achieve that new capability by extending Copilot with Graph connectors, making it possible to reason over the various data properties in the whiteboard or diagram and answer complex user questions. Information such as the content of Lucid canvases, the date the Lucid document was created or modified, the author, and other relevant fields will be ingested via Graph connectors to surface rich insights to users. Content ingested from Graph connector data will be linked in Copilot's references, allowing users to link back to the original Lucid whiteboard or diagram.

Visit Microsoft’s new developer portal to learn more about how to get started building Graph connectors, or check out this quick start guide. You can download solutions from the Sample Solution Gallery, and go to the Microsoft 365 Developer YouTube channel for videos on best practices. You can also review the list of all published Graph connectors that have been enabled for use with Copilot.

Tips for extending Copilot for Microsoft 365 with plugins

You can also extend Copilot using plugins. A powerful way to create a plugin is to use Teams message extensions, which can retrieve external data, analyze and summarize information, and allow users to take actions via Adaptive Cards in Teams. Developers can now create message extensions using Teams Toolkit for Visual Studio and Visual Studio Code. For existing message extensions, make sure app manifests are updated.

We have a wealth of resources to help developers build best-in-class plugins and successfully extend Copilot.

How Teams AI library enables intelligent apps

Enterprises and ISVs can also begin their AI journey by using Teams AI library, in public developer preview, to streamline the development of intelligent apps using APIs, controls, and prebuilt code. Ramp, an ISV that automates finances and expense management, used the AI library to map user intent to actions inside the Ramp experience extremely quickly, without requiring custom prompt engineering or manual LLM calls. The API also makes it simple to add actions to Ramp’s Teams app with very little development effort.

The resulting integration with Teams removes friction from traditional financial workflows and unlocks significant productivity gains—ultimately making finance simpler and more efficient.

""Ramp is here to redefine the status quo and make finance simple, so businesses can focus on work that matters,"" says Eric Glyman, CEO of Ramp. ""Simplicity and ease-of-use are at the heart of what our customers love about Ramp—from intelligent routing for the right approvals, to automatically matching receipts to transactions, to maintaining effective controls. By seamlessly integrating with Teams, we make intelligent financial tools available where hundreds of millions of people do their best work every day.""

Ramp has also taken the next step by integrating with Copilot, providing each employee with a finance assistant that can complete expense workflows on their behalf, give instant insight into spending trends, and answer expense policy questions.

Teams apps to improve year-end activities and jumpstart 2024

With the year wrapping up, I’d also like to highlight some Teams apps that can improve recognition programs for outstanding employees in 2023 or help refine business operations for 2024, starting with another look at Ramp.

In addition to accelerating day-to-day tasks, Ramp’s integration with Copilot also fosters more strategic, data-backed thinking and decision-making. With deep insight into the financial inner workings of your business, the Ramp plugin is an invaluable partner to finance teams planning, tracking, and managing budgets as we approach 2024. For example, finance managers planning travel and entertainment budgets can use Ramp to understand how much their company spent on hotels last year and adjust their forecasts based on the data.

Achievers for Teams: Celebrate moments that matter

As the pace of work accelerates, Achievers for Teams helps customers simplify employee engagement by merging the employee experience into the daily flow of work, and by leveraging a tool that employees already use and love—Microsoft Teams. This extends the value of employee engagement strategies and increases a sense of belonging by embedding recognition opportunities throughout daily routines.

“The Achievers for Teams app allows us to bring recognition into the flow of an employee’s normal course of work,” says Michael Cohen, Chief Product Officer at Achievers. “With so many employees spending the bulk of their day in communications tools like Teams, the ability to send and receive recognition from within the application allows us to meet employees where they are and to encourage culture-building without ever leaving the Teams app.”

Organizations that have implemented the Achievers for Teams integration have seen significant increases in the number of recognitions sent and higher overall employee engagement versus those without the integration.

Enterprises can also use Achievers to amplify year-end recognition initiatives, utilizing key functions like celebrating moments that matter where and when they occur by sending social or points-based recognitions within Teams. Points-based recognitions are redeemable for rewards employees actually want. Achievers is an industry leader with a marketplace of over 3 million rewards and 2,500 global brands—with local fulfillment partners that ensure speedy and reliable delivery in over 190 countries, all backed by award-winning customer service.

BHN Rewards: Simplify worldwide gifting to incentivize employees

According to BHN’s 2022 Employee Incentives Report from NAPCO Research, 83 percent of employees say that getting rewards improves their productivity and loyalty. Gift cards and prepaid cards are the most requested option (cited by 90 percent).¹ BHN Rewards for Teams makes it easy to give employees what they want while also simplifying budget controls, international rewarding, and reward tracking.

Users can send rewards during live virtual meetings or in one-on-one chat messages, and the reward announcement can be easily shared to Teams channels as well. The option to deliver rewards publicly—even among remote, hybrid, and global teams—amplifies the impact because colleagues can see and comment on the recognition. Recipients can easily claim their digital gift card or prepaid card with just a few clicks.

With the exponential rise in remote employees and global workforces, delivering end-of-year staff appreciation gifts and honoring top performers has gotten more complicated for a lot of enterprise companies. But with BHN Rewards for Teams, those rewards can be sent on the spot during virtual department meetings or holiday gatherings, making them simple, meaningful, and effective worldwide.

Matter for Teams: Give customizable kudos to revolutionize recognition

Matter for Teams starts by creating a recognition habit called Feedback Friday, where employees are automatically encouraged and guided to provide kudos to their peers. Enterprises can utilize Matter's templating system to create fully customizable kudos templates to match your company’s brand, company values, or special events. Matter’s rewards platform includes gift cards and donations from 1,500+ merchants in 80+ countries, and you can create your own company rewards store for items like merchandise or a PTO day.

“Matter for Teams has made employee recognition and rewards fun and easy to use right where you work,” says Matter CEO Brett Hellman. “Within weeks, 83 percent of employees actively engage in peer-to-peer recognition, all from automatic reminders. This uptake highlights Matter's effectiveness in fostering a culture of appreciation. It's not just about software; it's about revolutionizing how we recognize and reward our teammates.”

Use Matter's analytics tools to understand engagement and recognition patterns. This data can inform HR and management about the effectiveness of recognition strategies, employee morale, and areas needing improvement. When the year ends, you can use Matter’s powerful analytics to find which employees received the most recognition for a particular company value or theme and then reward these employees virtually in your Matter Teams channel or in real time.

Find out more about the apps highlighted above at the Achievers website, the BHN Rewards website, the Lucid website, the Matter website, and Ramp’s website and Teams integration site.



Maximize your investment in Copilot and Teams in 2024

Check out these resources for more on how to get started with Copilot and make the most of your investment in Teams apps:

Extend Copilot for Microsoft 365 by building Teams message extensions and Graph connectors.

Try Copilot Studio, an intuitive and low-code integrated design studio experience, to build plugins or your own enterprise copilots.

Access other Copilot resources like code samples and training videos on Microsoft Learn.

Build collaborative apps for Teams to give customers an experience they’ll love and provide the stepping stone for AI assistants that work alongside Copilot.

We love sharing partner success stories. If you have a story, please contact us.



¹2022 Employee Incentives Report, NAPCO Research and BHN. March 2023."
Microsoft_News,https://blogs.bing.com/search/december-2023/Turn-your-ideas-into-songs-with-Suno-on-Microsoft-Copilot,,Turn your ideas into songs with Suno on Microsoft Copilot,"We are excited to share that that we have partnered with Suno, a leader in artificial intelligence-based music creation to bring their capabilities to Microsoft Copilot. Through this partnership, people will have at their fingertips the ability, regardless of musical background, to create fun, clever, and personalized songs with a simple prompt. Suno has been a leader in AI music technology, pioneering the ability to generate complete songs—lyrics, instrumentals, and singing voices—from a single sentence.

You don’t have to know how to sing, play an instrument, or read music to bring your musical ideas to life. Microsoft Copilot and Suno will do all the hard work for you, matching the song to cues in your prompt. To get started creating your music, simply follow these steps:

Open Microsoft Edge, visit copilot.microsoft.com and ensure you’re signed in with your Microsoft Account

Enable the Suno plugin or click on the Suno logo that says, “Make music with Suno”

Ask Copilot to create a song for you such as, “Create a pop song about adventures with your family”

Jam along to your new tune

Share on social or with your friends and colleagues

We believe that this partnership will open new horizons for creativity and fun, making music creation accessible to everyone. This experience will begin rolling out to users starting today, ramping up in the coming weeks. We can't wait to see (and hear!) what you create."
Microsoft_News,https://www.microsoft.com/en-us/worklab/5-easy-ways-copilot-can-solve-your-work-puzzles,,5 Easy Ways Copilot Can Solve Your Work Puzzles,"Sign up for the WorkLab newsletter to get the latest AI research, insights, and trends delivered straight to your inbox.

This article first appeared in the WorkLab newsletter. Be the first to get our updates by subscribing here.



2023 was a year of rapid advancement in generative AI. We picked up a new vocabulary—prompting, iteration, “usefully wrong.” We reduced digital debt—that pileup of data, emails, meetings, and notifications that keeps us from getting real work done. And we got more productive, creative, and saved time—both individually and as organizations.

Along the way, we learned a lot about how Microsoft Copilot will change work. In a survey of our Early Access Program, 70 percent of Copilot users said it made them more productive, and 68 percent said it improved the quality of their work. Early users said Copilot helped them get their work done quicker: 85 percent said they were able to get to a good first draft faster, and 64 percent said it helped them spend less time processing email.

As a leader at the center of generative AI here at Microsoft, Colette Stallbaumer has been learning how to harness the power of Copilot alongside our customers and partners. Here, the General Manager of Microsoft 365 & Future of Work shares her favorite Copilot tips of the past year.

1. Let Copilot solve the post-meeting muddle.

Too often, no one outlines next steps at the end of a meeting, leaving projects at a standstill. To keep your work moving forward, ask Copilot in Microsoft Teams for a bulleted list of action items, along with who is responsible for each. You can even ask Copilot to draft an email to your colleagues with the list to make sure everyone is up to speed.

2. Get the executive summary—every time.

It can feel impossible to keep up with all the documents, presentations, and emails you need to read every day. To get the TL;DR, ask Copilot to “explain this document/email/deck in three sentences.” In seconds, it will look through the document, find the most important information, and give you a brief overview.

3. Catch up on meetings in a fraction of the time.

Double booked? We know the feeling. If you miss a meeting, ask Copilot in Teams what key points were discussed. Copilot will outline the important takeaways so you can skip watching that recording on 2x speed. And if you’re running late, just ask Copilot, “what did I miss in the meeting so far?” to get a summary of what’s happened.

4. Quickly whip your deck into presentation-ready shape.

You’ve created a PowerPoint presentation based on an array of documents, emails, and spreadsheets. In the Before Times, you’d have to go through the deck slide by slide to make sure everything looked crisp and consistent. Now, just ask Copilot to “make all fonts Segoe UI” or “make all headings size 18-point.” Sometimes it’s the smallest things that save you valuable time.

5. Summarize long email threads.

When you’re coming back from time off, that mountain in your inbox can feel like Everest. Instead of reading each email that came through while you were out, use Copilot to quickly summarize a long email thread by selecting “Summary by Copilot.” It will scan the thread to identify key points and final decisions to help you get up to speed quicker. So go ahead, take that PTO day—you deserve it."
Microsoft_News,https://blogs.microsoft.com/on-the-issues/2023/12/19/trust-privacy-bing-copilot-responsible-ai/,,Enhancing trust and protecting privacy in the AI era,"At Microsoft we want to empower our customers to harness the full potential of new technologies like artificial intelligence, while meeting their privacy needs and expectations. Today we’re sharing key aspects of how our approach to protecting privacy in AI – including our focus on security, transparency, user control, and continued compliance with data protection requirements – are core components of our new generative AI products like Microsoft Copilot.

We create our products with security and privacy incorporated through all phases of design and implementation. We provide transparency to enable people and organizations to understand the capabilities and limitations of our AI systems, and the sources of information that generate the responses they receive, by providing information in real-time as users engage with our AI products. We provide tools and clear choices so people can control their data, including through tools to access, manage, and delete personal data and stored conversation history.

Our approach to privacy in AI systems is grounded in our longstanding belief that privacy is a fundamental human right. We are committed to continued compliance with all applicable laws, including privacy and data protection regulations, and we support accelerating the development of appropriate guardrails to build trust in AI systems.

We believe the approach we have taken to enhance privacy in our AI technology will help provide clarity to people about how they can control and protect their data in our new generative AI products.

Our approach

Data security is core to privacy

Keeping data secure is an essential privacy principle at Microsoft and is critical to ensuring trust in AI systems. Microsoft implements appropriate technical and organizational measures to ensure data is secure and protected in our AI systems.

Microsoft has integrated Copilot into many different services including Microsoft 365, Dynamics 365, Viva Sales, and Power Platform: each product is created and deployed with critical security, compliance, and privacy policies and processes. Our security and privacy teams employ both privacy and security by design throughout the development and deployment of all our products. We employ multiple layers of protective measures to keep data secure in our AI products like Microsoft Copilot, including technical controls like encryption, all of which play a crucial role in the data security of our AI systems. Keeping data protected and secure in AI systems – and ensuring that the systems are architected to respect data access and handling policies – are central to our approach. Security and privacy are principles that are built into our internal Responsible AI standard and we are committed to continuing to focus on privacy and security to keep our AI products safe and trustworthy.

Transparency

Transparency is another key principle for integrating AI into Microsoft products and services in a way that promotes user control and privacy, and builds trust. That’s why we are committed to building transparency into people’s interactions with our AI systems. This approach to transparency starts with providing clarity to users when they are interacting with an AI system if there is risk that they will be confused. And we provide real-time information to help people better understand how AI features work.

Microsoft Copilot uses a variety of transparency approaches that meet users where they are. Copilot provides clear information about how it collects and uses data, as well as its capabilities and its limitations. Our approach to transparency also helps people understand how they can best leverage the capabilities of Copilot as an everyday AI tool and provides opportunities to learn more and provide feedback.

Transparent choices and disclosures while users engage with Microsoft Copilot

To help people understand the capabilities of these new AI tools, Copilot provides in-product information that clearly lets users know that they are interacting with AI and provides easy-to-understand choices in a conversational style. As people interact, these disclosures and choices help provide a better understanding of how to harness the benefits of AI and limit potential risks.

Grounding responses in evidence and sources

Copilot also provides information about how its responses are centered, or “grounded”, on relevant content. In our AI offerings in Bing, Copilot.microsoft.com, Microsoft Edge, and Windows, our Copilot responses include information about the content from the web that helped generate the response. In Copilot for Microsoft 365, responses can also include information about the user’s business data included in a generated response, such as emails or documents that you already have permission to access. By sharing links to input sources and source materials, people have greater control of their AI experience and can better evaluate the credibility and relevance of Microsoft Copilot outputs, and access more information as needed.

Data protection user controls

Microsoft provides tools that put people in control of their data. We believe all organizations offering AI technology should ensure consumers can meaningfully exercise their data subject rights.

Microsoft provides the ability to control your interactions with Microsoft products and services and honors your privacy choices. Through the Microsoft Privacy Dashboard, our account holders can access, manage, and delete their personal data and stored conversation history. In Microsoft Copilot, we honor additional privacy choices that our users have made in our cookie banners and other controls, including choices about data collection and use.

The Microsoft Privacy Dashboard allows users to access, manage and delete their data when signed into their Microsoft Account

Additional transparency about our privacy practices

Microsoft provides deeper information about how we protect individuals’ privacy in Microsoft Copilot and our other AI products in our transparency materials such as M365 Copilot FAQs and The New Bing: Our Approach to Responsible AI, which are publicly available online. These transparency materials describe in greater detail how our AI products are designed, tested, and deployed – and how our AI products address ethical and social issues, such as fairness, privacy, security, and accountability. Our users and the public can also review the Microsoft Privacy Statement which provides information about our privacy practices and controls for all of Microsoft’s consumer products.

AI systems are new and complex, and we are still learning how we can best inform our users about our groundbreaking new AI tools in a meaningful way. We continue to listen and incorporate feedback to ensure we provide clear information about how Microsoft Copilot works.

Complying with current laws, and supporting advancements in global data protection regulation

Microsoft is compliant today with data protection laws in all jurisdictions where we operate. We will continue to work closely with governments around the world to ensure we stay compliant, even as legal requirements develop and change.

Companies that develop AI systems have an important role to play in working with privacy and data protection regulators around the world to help them understand how AI technology is evolving. We engage with regulators to share information about how our AI systems work, how they protect personal data, the lessons we have learned as we have developed privacy, security and responsible AI governance systems, and our ideas about how to address unique issues around AI and privacy.

Regulatory approaches to AI are advancing in the European Union through its AI Act, and in the United States through the President’s Executive Order. We expect additional regulators around the globe will seek to address the opportunities and the challenges that new AI technologies will bring to privacy and other fundamental rights. Microsoft’s contribution to this global regulatory discussion includes our Blueprint for Governing AI, where we make suggestions about the variety of approaches and controls governments may want to consider to protect privacy, advance fundamental rights, and ensure AI systems are safe. We will continue to work closely with data protection authorities and privacy regulators around the world as they develop their approaches.

As society moves forward in this era of AI, we will need privacy leaders within government, organizations, civil society, and academia to work together to advance harmonized regulations that ensure AI innovations benefit everyone and are centered on protecting privacy and other fundamental human rights.

At Microsoft, we are committed to doing our part.

Tags: AI, artificial intelligence, Bing, Copilot, Responsible AI"
Microsoft_News,https://techcommunity.microsoft.com/t5/ai-ai-platform-blog/continuing-to-advance-state-of-the-art-model-and-tooling-support/ba-p/4008407,,Continuing to Advance State of the Art Model and Tooling Support in Azure AI Studio,"In the dynamic world of generative AI, innovation is the driving force propelling us into novel and uncharted territories. New models, new tools and platforms, and new use cases emerge every day, creating a remarkable fusion of creativity and technology and redefining the boundaries of what’s possible. With Azure AI, our goals are to provide the most cutting-edge open and frontier models in the industry, to ensure developers have model choice, to continue to uphold the highest standards in Responsible AI, and to continue to build superior tooling that brings all this together to accelerate the innovation in copilots that we’re seeing.

At Microsoft Ignite, we made over 25 announcements across the Azure AI stack, including the addition of 40 new models to the Azure AI model catalog; new multimodal capabilities in Azure OpenAI Service; the Models as a Service (MaaS) platform in Azure AI Studio and partnerships with Mistral AI, G24, Cohere, and Meta to offer their models in MaaS; and the public preview of Azure AI Studio.

Since Ignite, we’ve continued to add to our Azure AI portfolio. Today, we are excited to announce even more Azure AI capabilities: the availability of Meta’s Llama 2 running in Models as a Service, the preview of GPT-4 Turbo with Vision to accelerate generative AI and multimodal application development, and the addition of even more models in the Azure AI model catalog including our Phi 2 Small Language Model (SLM), among other things.

Now Available: Models as a Service for Llama 2

In Azure AI, you have been able to deploy models onto your own infrastructure for a long time – simply go into the model catalog, select the model to deploy and a VM to deploy it on and you’re off to the races. But not every customer wants to think about operating infrastructure, which is why at Ignite we introduced Models as a Service, which operates models as API endpoints that you simply call, much the way you might call the Azure OpenAI Service.

Today, we’re making Meta’s Llama 2 available in Models as a Service through Azure AI in public preview, enabling Llama-2-7b (Text Generation), Llama-2-7b-Chat (Chat Completion), Llama-2-13b (Text Generation), Llama-2-13b-Chat (Chat Completion), Llama-2-70b (Text Generation), and Llama-2-70b-Chat (Chat Completion).

Watch this video to learn more about Models as Service:

As we bring more models online in Models as a Service, we’ll keep you updated.

Now Available: GPT-4 Turbo with Vision

We are delighted to announce that GPT-4 Turbo with Vision is now in public preview in Azure OpenAI Service and in Azure AI Studio. GPT-4 Turbo with Vision is a large multimodal model (LMM) developed by OpenAI that can analyze images and provide textual responses to questions about them. It incorporates both natural language processing and visual understanding. This integration allows Azure users to benefit from Azure's reliable cloud infrastructure and OpenAI's advanced AI research.

GPT-4 Turbo with Vision in Azure AI offers cutting-edge AI capabilities along with enterprise-grade security and responsible AI governance. When combined with other Azure AI services, it can also add features like video prompting, object grounding, and enhanced optical character recognition (OCR). Customers like WPP and Instacart are using GPT-4 Turbo with Vision and Azure AI Vision today, check out this blog to hear more of their stories.

Available Tomorrow: Fine Tuning for GPT 3.5 Turbo and Other Models

In October 2023, we announced public preview of fine-tuning capabilities for OpenAI models. Starting tomorrow, December 15, 2023, fine-tuning will be generally available for models including Babbage-002, Davinci-002, GPT-35-Turbo. Developers and data scientists can now customize these Azure OpenAI Service models for specific tasks. We continue to push innovation boundaries with these new capabilities and are excited to see what developers build next with generative AI.

Expansion to the Azure AI Model Catalog

While Azure operates our own models as part of the Azure AI services like our Speech, Vision, and Language models, as well as Azure OpenAI, we also realize that customers often need models that we do not operate. Increasingly, we’re seeing customers look to deploy models that have been fine-tuned to specific tasks. To this end, we’ve operated a full model catalog in Azure AI Studio for a long time, and it is well-stocked with a broad variety of models. Today, we’re announcing the addition of six new models. Phi-2 and Orca 2 are available now and other models below are coming soon.

Phi-2. is a small language model (SLM) from Microsoft with 2.7 billion parameters. Phi-2 shows the power of SLMs, and exhibits dramatic improvements in reasoning capabilities and safety measures compared to Phi-1-5, while maintaining its relatively small size compared to other transformers in the industry. With the right fine-tuning and customization, these SLMs are incredibly powerful tools for applications both on the cloud and on the edge. Learn more.

DeciLM. Introducing DeciLM-7B, a decoder-only text generation model with an impressive 7.04 billion parameters, licensed under Apache 2.0. Not only is DeciLM-7B the most accurate 7B base model to date, but it also surpasses several models in its class.

DeciDiffussion. DeciDiffusion 1.0 is a diffusion-based text-to-image generation model. While it maintains foundational architecture elements from Stable Diffusion, such as the Variational Autoencoder (VAE) and CLIP's pre-trained Text Encoder, DeciDiffusion introduces significant enhancements. The primary innovation is the substitution of U-Net with the more efficient U-Net-NAS, a design pioneered by Deci. This novel component streamlines the model by reducing the number of parameters, leading to superior computational efficiency.

DeciCoder. 1B is a 1 billion parameter decoder-only code completion model trained on the Python, Java, and JavaScript subsets of Starcoder Training Dataset. The model uses Grouped Query Attention and has a context window of 2048 tokens. It was trained using a Fill-in-the-Middle training objective. The model's architecture was generated by Deci's proprietary Neural Architecture Search-based technology, AutoNAC.

Orca 2. Like Phi-2, Orca 2 from Microsoft explores the capabilities of smaller LMs (on the order of 10 billion parameters or less). With Orca 2, shows that improved training signals and methods can empower smaller language models to achieve enhanced reasoning abilities, which are typically found only in much larger language models. Orca 2 significantly surpasses models of similar size (including the original Orca model) and attains performance levels similar to or better than models 5-10 times larger, as assessed on complex tasks that test advanced reasoning abilities in zero-shot settings. Learn more.

Mixtral 8x7b. Mixtral has a similar architecture as Mistral 7B but is comprised of 8 expert models in one from a technique called Mixture of Experts (MoE). Mixtral decodes at the speed of a 12B parameter-dense model even though it contains 4x the number of effective parameters.

For more information on other models launched at Ignite in our model catalog, visit here.

Azure AI Provides Powerful Tools for Model Evaluation and Benchmarking

It’s not enough to have a lot of models, customers need to be able to choose which model meets their needs. To that end, Azure AI Studio provides a model benchmarking and evaluation subsystem, which is an invaluable tool for users to review and compare the performance of various AI models. The platform provides quality metrics for Azure OpenAI Service models and Llama 2 models such as Llama-2-7b, gpt-4, gpt-4-32k, and gpt-35-turbo. The metrics published in the model benchmarks help simplify the model selection process and enable users to make more confident choices when selecting a model for their task.

Previously, evaluating model quality could require significant time and resources. With the prebuilt metrics in model benchmarks, users can quickly identify the most suitable model for their project, reducing development time and minimizing infrastructure costs. In Azure AI Studio, users can access benchmark comparisons within the same environment where they build, train, and deploy their AI solutions. This enhances workflow efficiency and collaboration among team members.

Learn more about Model benchmarks here.

Empowering Customers Around the Globe

These groundbreaking advancements not only amplify our capacity to generate diverse and imaginative content but also signal a shift in how we conceptualize AI’s potential. In fact, leading global law firm Dentons, is working with Azure AI to implement Azure OpenAI Service models including GPT-4 and Meta’s Llama 2 into its generative AI application called “fleetAI.” Dentons has over 750 lawyers and business services professionals and is utilizing Azure AI models internally to summarize legal contracts and extract key parts from documents resulting in significant time savings.

“Through the incorporation of a lease report generator, into our fleetAI system, developed with Microsoft Azure's Open AI service, we have revolutionized a time-consuming task that previously took 4 hours, reducing it to just 5 minutes,” said Sam Chen, Legal AI Adoption Manager for Dentons (UKIME). “This significant time saving enables our legal professionals to concentrate on more strategic tasks, thereby enhancing client service and underscoring our dedication to innovation.”

Our Commitment to Inclusive and Responsible AI Development for All

Responsible AI is a key pillar of AI innovation at Microsoft. In October 2023, we announced general availability of Azure AI Content Safety and at Microsoft Ignite 2023, enabled new capabilities to address harms and security risks that are introduced by large language models. The new features help identify and prevent attempted unauthorized modifications and identify when large language models generate material that leverages third-party intellectual property and content. With these capabilities, developers now have tools they can integrate as part of their generative AI applications to monitor content, minimize harm, and lower security risks.

The IDC MarketScape recently looked at AI governance platforms that ensure AI/ML lifecycle governance, collaborative risk management, and regulatory excellence for AI across five key principles: fairness, explainability, adversarial robustness, lineage, and transparency. We are excited to share that Microsoft has been recognized as a leader in the inaugural IDC MarketScape Worldwide AI Governance Platforms 2023 Vendor Assessment. Read our blog to learn more about our placement and how customers are leveraging Azure AI to build and scale generative AI solutions responsibly.

One More Thing: Dark Mode in AI Studio

The user experience in Azure AI Studio matters a lot, and we are creating a more accessible AI ecosystem collaborating with AI developers with disabilities. Today, we’re pleased to announce, “dark mode,” a beloved feature of developers everywhere. Azure AI Studio's dark mode is not only visually appealing - but it also plays a crucial role in enhancing accessibility, making Azure AI Studio more inclusive and comfortable to use for everyone. We hope you get some rest for those eyes and enjoy this new feature as much as we do. To turn on dark mode, go to “Settings” in the app header to easily switch between light and dark themes.

Let’s shape the future of AI together

It has been an exciting year in the world of AI. There is a profound shift underway in the way we interact with applications, search for information, and get help with routine tasks. Copilots or assistants are transforming the way we learn, work, and communicate. We are excited to be at the forefront of this AI evolution to empower developers and data scientists to build with AI confidently for now and in the future.

Resources"
Microsoft_News,https://news.microsoft.com/year-of-ai/,,2023: The year of AI,"2023: The year of AI

The pace of AI innovation in 2023 was astounding — but even more impressive was how people applied this technology to make a real difference in their careers, communities and countries. Here are some of their incredible stories."
Microsoft_News,https://www.microsoft.com/en-us/worklab/podcast/will-ai-make-work-more-human,,Will AI Make Work More Human?,"MOLLY WOOD: Erica Keswin is a business strategist who has worked with the world’s most iconic brands over the last 25 years. She’s an outspoken advocate for a human-first workplace, especially as AI dominates the conversation. In fact, she’s published three bestselling books on the topic. Her latest book, The Retention Revolution, just came out in October. Retention as we know it is a bit outdated, according to Erica. The reasons people stay at a company have really changed. Connection to our work and each other is paramount. So is flexibility, personal development, and even an open door to exit through when the time comes. In today’s episode, I chat with Erica about the human workplace, what that is, how to cultivate one, and why it’s more important now than ever. Here’s my conversation with Erica.

[Music]

MOLLY WOOD: Erica, thanks so much for joining me.

ERICA KESWIN: It’s great to be here.

MOLLY WOOD: So Erica, you have been so prescient on this topic of a human workplace. Your first book, Bring Your Human to Work, was published in 2018, which was of course well before the pandemic, the generative AI boom, quiet quitting—all of these workplace trends we’ve seen over the past few years. Today, in 2023—almost 2024—these books are more relevant now than ever. So let’s start with a definition. What is a human workplace?

ERICA KESWIN: So it’s funny that you go all the way back to 2018, which I love. When I wrote Bring Your Human to Work, people at the time thought I was talking about my dog, Cruiser. And while I would say my dog Cruiser’s a very human dog, I was actually talking about something different, which is about creating a workplace that’s not only good for people but good for business, and how those two things are not mutually exclusive. And if I were to boil it down to one phrase of what it means to create a human workplace, it’s a workplace that honors relationships.

MOLLY WOOD: How does that resonate even more now, would you say, in this era of structured flexible work, Gen Z, and generative AI?

ERICA KESWIN: During the pandemic, many leaders were more human. Some of them it was in their nature, and some of them it was sort of by default. And when we looked at their survey data around employee engagement and job satisfaction, it actually went up during a very stressful time. And so when I think about what those leaders did then and what they need to continue doing, none of it is rocket science. You know, they check in with people, they ask them, how are you really, really doing, and they make sure that people know—especially, this is what Gen Z wants. They want to feel like their leader actually cares about them as a human. And so when I think about the world of generative AI, one of the things that I’m seeing is that generative AI, in addition to being great technology, actually is making, from where I sit, the human skills that much more important.

MOLLY WOOD: You’ve given the example of making that personal connection at work. But how do you think those leaders can start to put this into practice in a really structured way?

ERICA KESWIN: If I were thinking, what would be on my to-do list for 2024 as I think about retention, you know, what employees want, one of the biggest things they want is to develop and grow on the job—up, down, and sideways. And the chapter in my book where I talk about this, it’s called From Ladders to Lily Pads, because long gone are the days where there’s a hundred rungs in the ladder and people stay for 50 years and get a plaque and a pension. And so as leaders, one of the things that we need to think about doing is to be creative about how to help people develop when there aren’t as many rungs going up. We need to think about internal mobility. How do we move them across? How do we possibly even move them down? Sometimes the best new role for somebody might even be outside of your team or outside of your organization. Actually have conversations with employees and ask them, how do you want to grow on the job? And the reason why it’s so important is that if a culture doesn’t have that sense of psychological safety, where people can bring their human to work, they are not going to be open to answering that question.

MOLLY WOOD: I’m curious about this idea of growing down. That’s not something we hear about that often. Can you tell us a little bit more about that and how leaders can shepherd that kind of growth?

ERICA KESWIN: Not everyone, given a certain moment in time in their life, necessarily needs to feel like they’re going up the ladder. You know, there might be a time where someone’s taking care of elderly parents, taking care of kids, wanting to just do something a little bit different. So I profile people in the book that are over-the-moon excited to take a lateral job, even a step back. Or maybe they had an outward-facing role and have decided that they’d rather have an internal-facing role. What I would say in terms of leaders and empathy, whether it’s talking about a job change due to generative AI, or any change—we’re going from two days back in the office to four days. Given the last couple of years, people are on edge. There’s been so much change. So I have a recipe, what I call a recipe for a human leader in this moment, and it cuts across anything that we need to start to communicate. And my recipe—and it’s funny that I even have a recipe because I don’t cook—but my recipe is one part vulnerability for you to say, I also haven’t been down this road before. Even as a leader, generative AI could impact my role. Even I as the boss don’t have this all figured out. So a little bit of vulnerability. The second part of the recipe is empathy to say to people, look, I know this has been challenging for everybody. I know this is not easy. A little bit of empathy. And the third part of the recipe is really important—I mean, they’re all important, but it’s experimentation. That is, hey everybody, we’re making this change and all I can say is that this too may change. This change may change, that we are experimenting and this may not be forever. Because I do feel like regardless of the topic, people are walking around with their shoulders in their ears because they’re so stressed. And so if you approach it with these three pieces, especially the last one, experimentation, I do find that it takes the temperature down.

MOLLY WOOD: One of the things you also talk about in The Retention Revolution is that developing tech intelligence is paramount, but that you can overdo it. And so as organizations and leaders are thinking about how to integrate and train their employees around generative AI, how do they find that balance?

ERICA KESWIN: Yeah, so I talk a lot about finding the sweet spot between tech and connect. That sweet spot is about leveraging it for all of its greatness and then putting that technology in its place. One thing that I did recently, as when my book came out, was to go out to Seattle and participate in an event with Jared Spataro’s organization, who does a lot of the work around the generative AI and Copilot.

MOLLY WOOD: Just to clarify, Jared Spataro’s organization is Microsoft.

ERICA KESWIN: Yeah, and twice a year they have team week, where all 250 people from all over the world, wherever you live, come to Seattle to spend a week together. And it’s not anti-technology, anti-generative AI in any way, shape, or form, but it is taking time to build relationships and to really connect on a human level. Because what we see is that once you leave that week and you go back and you’re using all of your technologies to continue to connect with each other and to move your work and projects forward, your ability to do that is that much stronger, having built the relationships in person.

MOLLY WOOD: The entire thread of your three books, up until The Retention Revolution, really is this idea of humanity, and it is a challenge to leaders. And I wonder how you see generative AI specifically contributing to helping these leaders become better, helping workplaces become more human. I know that feels counterintuitive, but it’s just the theme that keeps coming up over and over, that the humanity cannot be separated from generative AI.

ERICA KESWIN: Again, it’s all new and moving at such a fast pace, but a few quick things that come to mind. One is that, as technology changes or even takes over pieces of a particular job, oftentimes it’s the human pieces that are still there that are taking on an increased importance. So these are the so-called softer skills, or as I like to say, power skills. I like to also say that the soft stuff’s the hard stuff, and sometimes the really important stuff. So I think it’s going to become increasingly important that we invest in helping people develop those human skills. The second thing I would say is that, I was at a conference recently and someone gave the example of, a radiologist is not going to lose her job because of generative AI. A radiologist who doesn’t know how to interact with generative AI will probably lose her job. And so again, if you are thinking about how you as a human interact with any technology, and in particular generative AI, you need more advanced human capabilities to do that well. And that will ultimately be the difference in terms of leadership, and then training the next generation to do the same thing. Fifty percent of managers say they get no training. They get promoted into these manager jobs because they were good at their individual contributor day job. And I think in 2024, we really need to lean into supporting and celebrating these middle managers.

MOLLY WOOD: One of the threads that connects all your work is this importance of feeling a sense of purpose and feeling connected to a greater mission. And if you are offloading to computers the things that computers are good at, and you are exercising your analytical and critical thinking skills and developing within your workplace, it feels like that ought to be positive.

ERICA KESWIN: So I was on an AI panel recently, and I told the story about how in my book I interviewed the CEO of Meetup. And he talks about how when a new person starts, he sends a personal letter or email, that it doesn’t matter what role you’re in, you know, welcome Molly to the firm, we’re so excited to have you. And then he’ll say, your job in fill in the blank X, Y, or Z is so connected to the purpose and mission of Meetup and here’s how. So he is literally connecting the dots between what you are going to do in your job and the purpose and the mission of the organization. When John F. Kennedy went to NASA for the first time and walked into the Houston Space Center and said to the janitor, what do you do? And the janitor said, I’m putting a man on the moon. And so people of all levels and all roles want to feel connected to the purpose and mission of what you do. So my hope is that as generative AI takes over, and all tech takes over certain aspects of a leader’s job, that leader can have more time to connect with his or her employees as humans.

MOLLY WOOD: Let’s talk about retention more broadly. One of the things that you say in the book that I just think is particularly interesting is that leaders should maintain an open door for employees who choose to move on. Can you tell us more about that?

ERICA KESWIN: The whole idea of The Retention Revolution is that the world has changed, and with the new generations, they’re not going to stay in one company for a long time. Going forward, the new generation, they look at their career more as a portfolio. I spent many years as an executive recruiter. And back in the day, if I saw a resume with somebody moving all over the place, it was a big old red flag. These days, not as much. People leave if they don’t feel like they’re growing. People leave if they just want to try something else. There’s not as much of a stigma. So if we know that people are likely going to come and be with us for, as Reid Hoffman calls, you know, the founder of LinkedIn, a tour of duty, then we don’t have to make it when they leave to have this feeling of, okay, Molly, you told me you were leaving, you’re dead to me. Don’t let the door hit you in the behind. Instead, let’s be strategic about how we say goodbye and let’s say goodbye gracefully, and let’s give people opportunities to connect, whether it’s through a podcast, whether it’s through learning and development opportunities, whether it’s through a newsletter, whether it’s letting all of our alumni know that there might be new jobs and maybe they want to come back. There have been a lot of boomerangs at many companies, and as we all know, when people leave they’re also a brand ambassador and they may still buy your products. So The Retention Revolution, if you’re intentional about how you onboard and intentional about how you offboard, the workplace just becomes much more of this virtuous cycle, and the world is heading that way whether we like it or not. And one quick example that I’ll give: there was a study done out of one of the broad legal associations, and they found that the brand-new, bright-eyed and bushy tailed lawyers coming into the firms, only 30 percent of them even have a desire to become a partner.

MOLLY WOOD: One of the things that everyone is grappling with post-pandemic is remoteness, and not every company has the resources to fly people in for in-person gatherings as much as they would want to. Do you have tips for engaging people remotely, and maybe using technology to create that human engagement?

ERICA KESWIN: First of all, I would say yes, not everybody can afford to bring people back as often as others. That being said, I would urge you to try to put some resources toward bringing people together. And it doesn’t have to be everybody, one location. It could be in a certain city, it could be regional, and where there’s a will, there’s a way. This next comment will highlight my, um, advanced Gen X age, but when I was younger, I watched The Love Boat. And on the show, The Love Boat, if listeners don’t know what that is, you could look it up, there was a woman named Julie McCoy and Julie McCoy was a cruise director. And I’m not telling you all to go hire cruise directors, but we cannot leave connection to chance. And I have a podcast that’s called Left to Our Own Devices because, left to our own devices—excusing the cheesy pun—we are not connecting. And so somebody needs to own connection. What I recommend doing is, create a roadmap—map out your organization, figure out where people are, figure out how, when, and where you might bring them together in person. And then when they’re not, think about how, when, and where to bring them together virtually, but in ways that are strategic. So for example, managers are on the front lines of this retention revolution. As a group, they are overworked, they’re having mental health issues, they’re sort of sitting there in the middle, which I believe they’re really in the center and we need to support them.There are organizations where there are communities of managers that come together virtually to support each other. And it costs nothing other than maybe an hour of your time. But unless somebody organizes it, it won’t happen. It’s not leaving that stuff to chance. And making sure that people own it. But it can’t just be sort of in addition to someone’s day job. It has to be valued. And it has to be celebrated and recognized.

MOLLY WOOD: Every org needs a community manager. I love that.

ERICA KESWIN: Yes. A hundred percent. Maybe that’s better than a cruise director, but yes, a hundred percent.

MOLLY WOOD: Alright, one last question for you. What is the single most important way for business leaders to retain great talent?

ERICA KESWIN: Care about them.

MOLLY WOOD: It’s so simple and yet so powerful. Erica Keswin, thank you so much. I encourage every leader everywhere to pick up The Retention Revolution and go all the way back to 2018 for Bring Your Human to Work. Thanks so much for the time. I appreciate it.

ERICA KESWIN: Thank you so much.

[Music]

MOLLY WOOD: Thank you again to Erica Keswin, a workplace strategist and bestselling author who has worked with some of the world’s most iconic brands. That’s it for this episode of WorkLab, the podcast from Microsoft. Please subscribe and check back for the final episode of this season, where I’ll be speaking to Nir Eyal, a bestselling author, entrepreneur, and self-described behavioral designer, about how to build healthy habits and improve productivity with the help of generative AI. That episode comes out right in time for the new year. If you’ve got a question or a comment, drop us an email at worklab@microsoft. com. And check out Microsoft’s Work Trend Indexes and the WorkLab digital publication. There you’ll find all of our episodes, along with thoughtful stories that explore how business leaders are thriving in today’s new world of work. You can find all of that at microsoft.com/worklab. As for this podcast, please rate us, review, and follow us wherever you listen. It helps us out a ton. The WorkLab podcast is a place for experts to share their insights and opinions. As students of the future of work, Microsoft values inputs from a diverse set of voices. That said, the opinions and findings of our guests are their own, and they may not necessarily reflect Microsoft’s own research or positions. WorkLab is produced by Microsoft with Godfrey Dadich Partners and Reasonable Volume. I’m your host, Molly Wood. Sharon Kallander and Matthew Duncan produced this podcast. Jessica Voelker is the WorkLab editor."
Microsoft_News,https://news.microsoft.com/inventive-ways-people-are-using-ai%20,,Inventive ways people are using AI,"Ideas to celebrate

Lisa Vu helped plan a memorable celebration of Diwali, the Hindu festival of lights, for some of her Microsoft colleagues across Australia and New Zealand. The original agenda for the event was “basic” with pre-recorded videos, Vu says, so she used AI as an idea generator to get her creative juices flowing. Microsoft Copilot suggested that the videos be accompanied by virtual rangoli art. Vu put her own spin on the idea by asking participants to use Bing Image Creator to come up with their own interpretations of rangoli — making digital patterns on a screen instead of using the traditional powder, sand or petals — and share them in the event chat. The fun activity drew in people who were there in person as well as those attending virtually. “I find myself more creative, productive and efficient with that little push to get me there,” she says, “rather than trying to figure out all the ideas myself.”"
Microsoft_News,https://www.microsoft.com/en-us/industry/blog/retail/2023/12/11/join-microsoft-at-nrf-2024-and-power-your-ai-transformation/,,Join Microsoft at NRF 2024 and power your AI transformation,"Innovations in technology like AI and generative AI bring an unparalleled opportunity to transform the way we live, play, and conduct business. Microsoft has focused on leading in the era of AI and will be showcasing at the National Retail Federation’s (NRF’s) annual Big Show in New York City, New York, how “Retail unlocked” through AI can unlock the value of your data, unlock new shopping experiences, unlock supply chain optimization, and unlock your store associates’ potential. And ultimately, unlock productivity and growth across your entire retail business.

I invite you to join Microsoft at NRF 2024 to experience the next generation of AI and gain insights on how it’s already transforming retail—and learn about strategies you can use to embrace this wave of innovation.

Connect with Microsoft at NRF

There are many ways you can connect with us in-person at NRF. We look forward to seeing you!

Visit our booth on level three at #4503 .

Conveniently located at the main entrance of the Exhibition Hall, immerse yourself in 29 innovative demos and experiences, meet and collaborate with Microsoft experts and our industry-leading partners on how you can leverage cutting-edge AI retail solutions.

. Conveniently located at the main entrance of the Exhibition Hall, immerse yourself in 29 innovative demos and experiences, meet and collaborate with Microsoft experts and our industry-leading partners on how you can leverage cutting-edge AI retail solutions. Join us for our welcome reception .

Welcome Reception on Sunday, January 12, 2024: Celebrate with our featured retailers and partners with an opportunity to connect over food, drinks, and networking, register now.

. Welcome Reception on Sunday, January 12, 2024: Celebrate with our featured retailers and partners with an opportunity to connect over food, drinks, and networking, register now. Schedule a one-on-one meeting.

Let your account representative know if you would like to schedule some time to meet with our product experts and Microsoft leadership, who are available to strategize and answer all your questions.

Big ideas sessions

We’re very excited to be hosting three sessions this year. We hope you stop by to hear the latest from Microsoft executives, and their featured panel guests. Mark the sessions on your schedule:

Retail Unlocked: Achieve more with Microsoft: Hosted by Shelley Bransten, Corporate Vice President, Global Retail, Consuer Goods and Gaming Industries on Sunday, January 14, 2024, from 1:00 to 1:30 PM EST. Join this interactive session to hear about one retailer’s AI journey to date. Hosted by Microsoft’s Corporate Vice President, Retail, Consumer Goods and Gaming Industries, Shelley Bransten, you’ll also learn about new AI-focused findings from Futurum Research and all new AI capabilities in Microsoft Cloud for Retail that will help power your AI transformation.

Unlocking true customer-centricity: optimizing touchpoints across the shopper journey with AI: Hosted by Kathleen Mitford, Corporate Vice President, Global Industry Marketing on Monday, January 15, 2024, from 11:45 to 12:15 PM EST. Generative AI and large language models have captured the attention of executives across industries. While the technology’s use cases seem endless, smart retailers and brands must identify and prioritize the applications of generative AI that will be most valuable to their organization and partner with organizations who will treat their data with the highest privacy standards. Join us to hear how Microsoft is helping organizations large and small maximize their generative AI opportunities safely and responsibly.

Unify your data to unlock AI opportunities: Hosted by Satish Thomas, Corporate Vice President, Microsoft Industry Clouds on Tuesday, January 16, 2024, from 1:00 to 1:45 PM EST. Retailers are swimming in data every day. Even with sophisticated legacy technologies and cutting-edge data science, the majority of that data goes uncollected. Insights stay hidden—often in plain sight. But that’s starting to change. AI tools are enabling retailers to understand their customers, merchandising, supply chains, operations, and workforces better than ever before. Join us to hear about the myriad insights that retailers are drawing from newfound and increasingly precise data sources to run leaner, smarter stores.

Showcasing transformation with our partners

Let’s shine a special spotlight on our partners and their collaboration with Microsoft at NRF. The remarkable speed at which our partners have incorporated generative AI, utilizing Microsoft 365 Copilot and Azure OpenAI Service, is reshaping the retail landscape. Witness their impressive transformations and explore live demonstrations at our booth. Dive into the innovative solutions presented by partners who are seamlessly integrating Microsoft Cloud for Retail. Join us for engaging demo by 1M Robotics, showcasing autonomous robotics designed to enhance omnichannel, frictionless retail experiences. Along with Adobe, Accenture | Avanade, AiFi, Blue Yonder, and Sitecore, all harnessing the power of the Microsoft platform. Our ongoing collaboration with Sony highlights our commitment to a dynamic ecosystem, where we closely collaborate with partners to envision and bring to life the future solutions that retailers will rely on. And we are excited to welcome the new global payment partnership with Nuve, to deliver leading payment experiences for customers of its products, solutions, and services across many of its key markets.

A big shout-out to all the partners featured in our booth at NRF:

To NRF and beyond

This year’s NRF theme is “Make it Matter,” and we are eager to support what matters to retailers by bringing unique value, productivity, and growth to their business. We’re excited about what we’re accomplishing with our partners and customers in the retail world. Our team has been preparing for months to provide you the best, most informative experience possible at NRF. If you are not able to attend, our sessions will be available on-demand to registrants, and you can get in touch with a Microsoft representative at any time for more information on the ways Microsoft can help your retail business achieve more with insightful, intuitive AI tools.

NRF 2024 Join more than 6,200 brands for three days of learning, collaboration, and discovery Discover more

Learn more"
Microsoft_News,https://news.microsoft.com/2023/12/11/afl-cio-and-microsoft-announce-new-tech-labor-partnership-on-ai-and-the-future-of-the-workforce/,,AFL-CIO and Microsoft announce new tech-labor partnership on AI and the future of the workforce,"AFL-CIO and Microsoft announce new tech-labor partnership on AI and the future of the workforce

New AI alliance will educate workers, incorporate labor’s voice in tech development and help shape policy that supports workers

WASHINGTON — Dec. 11, 2023 — The American Federation of Labor and Congress of Industrial Organizations (AFL-CIO) and Microsoft Corp. on Monday announced the formation of a new partnership to create an open dialogue to discuss how artificial intelligence (AI) must anticipate the needs of workers and include their voices in its development and implementation. This partnership is the first of its kind between a labor organization and a technology company to focus on AI and will deliver on three goals: (1) sharing in-depth information with labor leaders and workers on AI technology trends; (2) incorporating worker perspectives and expertise in the development of AI technology; and (3) helping shape public policy that supports the technology skills and needs of frontline workers.

Building upon the historic neutrality agreement the Communications Workers of America Union (CWA) negotiated with Microsoft covering video game workers at Activision and Zenimax, as well as the labor principles announced by Microsoft in June 2022, the partnership also includes an agreement with Microsoft that provides a neutrality framework for future worker organizing by AFL-CIO affiliate unions. This framework confirms a joint commitment to respect the right of employees to form or join unions, to develop positive and cooperative labor-management relationships, and to negotiate collective bargaining agreements that will support workers in an era of rapid technological change.

“This partnership reflects a recognition of the critical role workers play in the development, deployment and regulation of AI and related technologies,” said AFL-CIO President Liz Shuler. “The labor movement looks forward to partnering with Microsoft to expand workers’ role in the creation of worker-centered design, workforce training and trustworthy AI practices. Microsoft’s neutrality framework and embrace of workers’ expertise signals that this new era of AI can also catalyze a new era of productive labor-management partnerships.”

“By working directly with labor leaders, we can help ensure that AI serves the country’s workers,” said Brad Smith, vice chair and president of Microsoft. “This groundbreaking partnership honors the rights of workers, learns from the advice of labor leaders as we develop technology, and helps us provide people with the skills that will become essential in a new AI era.”

The partnership will deliver on the following goals:

AI education for workers and students: Microsoft will provide formal learning opportunities on the latest and prospective developments in AI, providing labor leaders and workers with critical information and insights on this new technology as it evolves in the future. These will begin with learning sessions that will take place during the winter of 2024 facilitated by Microsoft’s AI experts who will provide access to information about how AI works and where it’s going, outline its opportunities and analyze the potential challenges. These sessions will be augmented by on-demand digital resources that labor leaders and workers can access online. Working with the American Federation of Teachers, Microsoft will explore joint opportunities for career and technical education work that prepares students for high-paying jobs of tomorrow. In addition, they will hold deep-dive and experiential workshops starting 2024 through 2026 that will be tailored to specific careers and roles. Direct feedback from labor leaders and workers: To ensure that the expertise and perspectives of workers inform the work of Microsoft’s AI developers, the partners have developed a mechanism for labor leaders and workers to share experiential insights, concerns and feedback directly to the people who develop this technology. This collaboration will begin with a focus on unions and workers in selected key sectors. This collaboration will start this winter and take the form of Microsoft hosted labor summits. The partners will bring labor leaders and workers together with Microsoft’s key AI product developers, researchers and business leaders for intensive discussions intended to co-design and develop “worker-centered technology.” Joint policy and skills development: As Congress debates future AI and workforce legislation in the Committees of the House and Senate and the bipartisan AI Insight Forums, the AFL-CIO and Microsoft will join forces to propose and support policies that will equip workers with the essential skills, knowledge and economic support needed to thrive in an AI-powered economy. The two organizations will support the expansion of registered apprenticeships, particularly in nontraditional tech occupations, and advocate for funding for Career and Technical Education. On the AI curriculum front, LinkedIn Generative AI content will be tailored to specific sectors most impacted by AI, and Microsoft and the AFL-CIO’s Technology Institute will jointly develop and implement new content and professional learning opportunities to prepare workers for the future workplace.

Both partners acknowledge AI creates a real capacity to enhance workers’ jobs if used to augment work rather than diminish workers’ agency and responsibilities. According to new polling by the AFL-CIO, 70% of workers worry about being replaced by AI. At the same time, a recent Microsoft study of workers found that 70% would delegate as much work as possible to AI to lessen their workloads. To improve work while creating richer possibilities for our lives on the whole, the transition to an AI-assisted future must center workers’ voices. That’s why Microsoft and the AFL-CIO have created this labor-tech partnership — to ensure workers have a voice in the process and that their needs are understood.

About AFL-CIO

The American Federation of Labor and Congress of Industrial Organizations (AFL-CIO) works tirelessly to improve the lives of working people.

We are the democratic, voluntary federation of 60 national and international labor unions that represent 12.5 million working people.

About Microsoft

Microsoft (Nasdaq “MSFT” @microsoft) enables digital transformation for the era of an intelligent cloud and an intelligent edge. Its mission is to empower every person and every organization on the planet to achieve more.

For more information, press only:

Microsoft Media Relations, WE Communications for Microsoft, (425) 638-7777, [email protected]

Isabel Aldunate, AFL-CIO, (202) 262-3628, [email protected]

Note to editors: For more information, news and perspectives from Microsoft, please visit the Microsoft News Center at http://news.microsoft.com. Web links, telephone numbers and titles were correct at time of publication but may have changed. For additional assistance, journalists and analysts may contact Microsoft’s Rapid Response Team or other appropriate contacts listed at https://news.microsoft.com/microsoft-public-relations-contacts."
Microsoft_News,https://blogs.bing.com/search-quality-insights/december-2023/Introducing-Deep-Search,,Introducing deep search,"



Understanding search intent

Finding deeper results

loyalty card programs Japan

best loyalty cards for travelers in Japan

comparison of loyalty programs by category Japan

redeeming loyalty cards in Japan

managing loyalty points with phone apps

Ranking results

Speed

More ways that GPT-4 is used in Bing

Today’s search engines are powerful tools that help us find information on the web, but sometimes they fall short of our expectations. When we have complex, nuanced, or specific questions, we often struggle to find the answers we need. We ourselves know what we’re looking for, but the search engine just doesn’t seem to understand.That's why we created deep search, a new Microsoft Bing feature that provides even more relevant and comprehensive answers to the most complex search queries. Deep search is not a replacement for Bing's existing web search, but an enhancement that offers the option for a deeper and richer exploration of the web.Deep search builds on Bing's existing web index and ranking system and enhances them with GPT-4. GPT-4 is a state-of-the-art generative AI LLM (Large Language Model) that can create natural language text from any input. In the case of deep search, GPT-4 takes the search query and expands it into a more comprehensive description of what an ideal set of results should include.For example, let’s say I’m researching loyalty programs in different countries and search for ""how do points systems work in Japan"". Deep search might generate a more comprehensive description like this:Provide an explanation of how various loyalty card programs work in Japan, including the benefits, requirements, and limitations of each. Include examples of popular loyalty cards from different categories, such as convenience stores, supermarkets, and restaurants. Show a comparison of the advantages and disadvantages of using loyalty cards versus other payment methods in Japan, including current rewards and benefits. Highlight the most popular services and participating merchants.This expanded description captures my intent and expectations more accurately and clearly than a few keywords. It also helps Bing understand what kind of information I am looking for.Some queries are ambiguous. For example, ""how do points systems work in Japan"" could refer to rewards points, as I intended, but could also be seeking information on immigration policy or something else. The expanded description may be right for one of those interpretations but not for all of them. In that case, deep search leverages GPT-4 to find all the possible intents and computes an comprehensive description for each of them. Deep search offers a disambiguation pane where all of these intents are represented. If my research intent was misunderstood, I can select the right one from the disambiguation pane, and the corresponding comprehensive description will be used instead.Bing then goes much deeper into the web with that task in mind, pulling back relevant results that often don't show up in typical search results. Deep search uses a combination of querying techniques to find pages that might match my expanded query, rewriting the query on my behalf, and searching for those variations too.For example, for my earlier loyalty points query, deep search might also try searching for:By doing this, deep search can find results that cover different aspects of my query, even if they don't explicitly include the original keywords. Regular searches on Bing already consider millions of web pages for each search and deep search does ten times that to find results that are more informative and specific than the ones that rank higher in normal search.Once deep search has gathered a wide collection of web pages to review, it then ranks them according to how well they match the comprehensive description. Deep search uses a variety of signals to determine the relevance and quality of each result, considering factors like how well the topic matches, whether it’s at the appropriate level of detail, how credible and trustworthy the source is, how fresh and popular it is, and so on.By doing this, deep search can present a curated list of results and answers that are more likely to answer your question, satisfy your curiosity, or solve your problem.Going deeper takes time, and deep search can take up to thirty seconds to complete. This might seem like a long time compared to normal search, but it can be worth the wait for more specific or comprehensive answers.Deep search is not meant for every query or every user. It's designed for those who have complex questions that require more than a simple answer. Bing will always return regular search results in less than a second and deep search is an optional feature.GPT-4 is already used in many places on Bing, including Copilot, Image Creator from Designer, and already in regular web result ranking where, in January, it powered one of the single biggest relevance improvements in Bing’s history.We’re excited for the potential for deep search to offer yet another significant improvement in search result quality. This is currently an experimental feature that is available to randomly selected small groups of users on Bing worldwide while we are testing and improving it. We would love to hear your feedback and suggestions on how to make deep search better."
Microsoft_News,https://blogs.microsoft.com/blog/2023/12/05/celebrating-the-first-year-of-copilot-with-significant-new-innovations/,,Celebrating the first year of Copilot with significant new innovations,"This year will be remembered as the moment that we, as individuals, began to harness the power of AI in our daily lives. The last 10 months reflect years of AI research, close partnerships, and breakthrough innovations coming together. This culmination is now unifying our product vision to empower every person and every organization on the planet to achieve more.

We started with the introduction of Bing Chat, and the feedback was incredible! Right away, people began to change how they search on the Internet, shop, code, prepare for job interviews, improve their gaming skills, and create beautiful documents and images. We proceeded to incorporate these capabilities into Microsoft 365, Microsoft Edge and Windows, unlocking new scenarios with ever greater context and intelligence for people.

Two weeks ago, we took the significant step to bring together all of this under one brand and one experience that we call Microsoft Copilot, launching http://copilot.microsoft.com and making it accessible to anyone on any device.

We’re thrilled by the impact it is having on the industry and, more importantly, on the lives of hundreds of millions of people. Recent survey data shows that Copilot for Microsoft 365 makes people more productive and faster overall in tasks like searching and writing.

What’s next?

As we set our sights on 2024, we’re committed to bringing more innovation and advanced capabilities to Copilot to provide you with the leading way to benefit from AI. Here are some incredible new features that we have begun testing that you will see roll out soon:

GPT-4 Turbo – Soon, Copilot will be able to generate responses using OpenAI’s latest model, GPT-4 Turbo, enabling you to tackle more complex and longer tasks. This model is currently being tested with select users and will be widely integrated into Copilot in the coming weeks.

New DALL-E 3 Model – You can now use Copilot to create images that are even higher quality and more accurate to the prompt with an updated DALL-E 3 model. These capabilities are available to you now by visiting bing.com/create or by prompting Copilot to create an image.

Inline Compose with rewrite menu – With Copilot, Microsoft Edge users can easily write from most websites. Just select the text you want to change and ask Copilot to rewrite it for you. Coming to all Edge users soon.

Multi-Modal with Search Grounding – We are combining the power of GPT-4 with vision with Bing image search and web search data to deliver better image understanding for your queries. This new capability will be available soon.

Code Interpreter – We are developing a new capability that will enable you to perform complex tasks such as more accurate calculations, coding, data analysis, visualization, math and more. We are gathering feedback on these capabilities from a select set of users and plan to make it widely available soon.

Deep Search – Coming soon to Bing, Deep Search harnesses the power of GPT-4 to deliver optimized search results for complex topics. Activating Deep Search expands search queries into more comprehensive descriptions to deliver more relevant results. More information can be found on our Bing Blog.

To share a sense of the breadth of what Copilot can do for you, we’ve created a list of some of our favorite use cases for you to try right now – inspired* by our community of fans and preview testers.

YouTube Video Click here to load media

Try one of the prompts below and follow your curiosity. Just copy and paste into Copilot at copilot.microsoft.com, in Copilot in Bing or directly from the Copilot tab in Windows 11.

Education How can I design and improve activity plans for elementary school students to experience and learn about different plants? Gaming What are the best methods and tools for stealth and hacking in Starfield? Shopping Explain how to choose a mattress based on firmness level and sleeping preferences. What are the different firmness levels and how do they affect comfort and support? Travel Plan a 4-day itinerary for visiting Paris and Amsterdam. What are the must-see attractions, activities, and restaurants in each city? Culture & Art Analyze Michelangelo’s legacy as an artist and a person. What are the achievements and influences on Michelangelo’s art and life and how did he shape society? Education Explain like I’m five the structure of city-states and the characteristics of civilizations throughout Mesopotamia. History Are depictions of pirates in movies and novels accurate? Design How can I make my living room look more open and refreshing? What are the tips and tricks for choosing and arranging furniture, colors, lighting, and accessories? Education Identify and describe the flowers and plants that attract bees and how I can grow them in my garden. How do you pollinate a garden by hand? Culture & Art Create an image I can use as inspiration for a tattoo. It should be minimalist in design and feature a sun, moon and golden retriever. Jobs How can I get into the semiconductor industry and what are some related fields of study? What are the skills, qualifications, and experiences required? Travel What advice do you have for hiking and sightseeing in Big Four Ice Caves? Science Explain the theory of parallel universes. What is the concept and evidence of parallel universes? Shopping Recommend some DAC (digital-to-analog converter) options for audiophiles. What are the features, benefits, and drawbacks of each option? Culture & Art Who were some of the most influential female musicians of the 1960s and how did they impact culture? Food Suggest some recipe ideas for a vegetarian dinner on a low-carb diet. What are the ingredients and recipes of each dish? Health Create an upper body workout routine for beginners focused on chest and arms using body weight techniques at home. What are the exercises, sets, reps, and rest periods for each session? Tech & Software Design an algorithm to find the majority book preference among a group of friends for a book club. What are the inputs and outputs of the algorithm? Work Discuss how to work effectively with others in a professional work environment. What are the skills and qualities of a good team player? Food What are the best places to eat and drink in Renton, Washington? What are the specialties, prices, and ratings of each place? Jobs What are some tips for someone who has been out of the workforce for a few years but is looking to get back into it? Jobs Compare and contrast the MBA and MHA degrees for a nurse executive. What are the career opportunities and outcomes of each degree? Travel Plan a 5-day summer trip to Hawaii that includes a visit to Diamond Head. Writing Write a congratulatory message for a small gift store’s fifth anniversary. Praise their service and atmosphere and express your gratitude and loyalty as a customer. Writing Write a story about a cat named Babbi who escapes outside and gets scared. How does Babbi escape and how does he return home? Shopping Research and summarize the internet’s reviews about Meta’s Quest 3. What are the features, specs, and pros and cons of the headset? Images Create an image I can put on a holiday card featuring 10 English bulldogs.

*Prompts seen in this post showcase some of our favorite use cases of the consumer version of Copilot, formerly known as Bing Chat, since entering preview in February. All prompts seen below are inspired by popular conversation topics and were generated by Microsoft. No real user prompts are shown above.

Tags: AI, Copilot for Microsoft 365, Copilot in Bing, Microsoft Copilot"
Microsoft_News,https://aka.ms/AAmi78m,,Japan’s Aisin helps people with listening difficulties make sense of what they hear using generative AI,"TOKYO, Japan – Hiromi Soeda always had trouble hearing what people were saying, whether they were her teachers at school or – later – clients at the hair salon where she worked. At home, she struggled to hear her children over domestic noises like a ventilator fan or running water.

Doctors could find nothing wrong with her ears. It was only three years ago that Soeda, now 49, was diagnosed with Auditory Processing Disorder (APD), a form of Listening Difficulty (LiD) where the brain can’t process the words one is hearing.

With low public awareness of the condition in Japan, those with APD say they can feel lonely or isolated, and have trouble keeping a job or simply taking part in daily interactions.

Often, “I’m just nodding and pretending I understand. Sometimes I get the time wrong for meeting people. My friends will say, ‘Are you not listening?’” Soeda said. “They just drift away because they think I can’t keep a promise.”

Earlier this year, Soeda began using YYProbe, an app made by Japan’s Aisin Corp., which turns speech to text and more. While the YYProbe app is used by the wider community of people who are deaf or hard of hearing, a new generative AI-powered summarization feature provided by Microsoft Azure OpenAI Service is particularly helpful for those with APD.

Hiromi Soeda, who has Auditory Processing Disorder, communicates with Minori Oba, who works for Aisin, maker of the app, on a Tokyo street near Aisin’s research office. Photo by Noriko Hayashi for Microsoft.

Generative AI tools are built on large language models (LLMs) that synthesize troves of data to generate text, code, images and more. In addition to generating text, they can also summarize it.

For example, when her mother was hospitalized with Covid-19, Soeda used the app to understand what doctors were telling her. Doctors subsequently discovered her mother had other ailments, including Parkinson’s disease and water in her lungs and had suffered a cerebral infarction.

Soeda used YYProbe on a tablet to follow what doctors were saying, summarize the information and send the transcript to her younger sister.

“It’s much better to read [the text] to follow and help my understanding,” she said. “And if I’m listening and I misunderstand, I can go back and read it again.”

Her mother passed away in July.

Aisin, based in Kariya City, a suburb of Nagoya, is known primarily as a manufacturer of automotive components. Aisin’s research and development team, led by Masaki Nakamura, initially developed YYProbe during the pandemic as a speech-to-text tool for all employees to create business records. As it turned out, Aisin employees who were deaf or hard of hearing found it particularly useful.

The team went on to develop an audio recognition system called YYSystem, which included the YYProbe app, as a tool for wider society which could be used by people who are hard of hearing, the elderly, foreigners or anyone, really, to overcome a communication barrier. YYProbe now has an enterprise version, as well as a free version which has more than 10,000 active monthly users. These include those with listening difficulties, though Nakamura says it’s hard to know the breakdown.

Aisin went with Microsoft Azure AI Speech to build the app because “the accuracy of speech recognition is high,” Nakamura said. Leveraging OpenAI’s ChatGPT technology through Microsoft Azure OpenAI Service, combined with Azure AI Translator, brought summarization and translation abilities.

Masaki Nakamura, who leads the development of YYSystem at Aisin, is constantly adding features based on community feedback. Photo by Noriko Hayashi for Microsoft.

YYSystem is also deployed via counter-top screens at government departments and retail stores and will be used by spectators at the 2025 Deaflympics in Tokyo.

Globally, between two and 10 percent of children have APD, and it is more common in children with other learning or developmental disabilities, according to the World Report on Hearing, published by the World Health Organization in 2021. APD can also afflict older people.

Japan has a fairly well-developed network of schools for people who are deaf or hard of hearing, and it also has legislation to protect those with disabilities from discrimination in the workplace. But because APD is less well-known, it can go undiagnosed for years.

Both people who are deaf or hard of hearing and those with APD are often reluctant to admit they need help, advocates say.

“Japanese people do not like troubling other people,” said Kaori Nasu, president of 4Hearts, an advocacy organization that aims to break down communication barriers – including for people who are deaf or hard of hearing – in Japan. “Sometimes you just give up trying to get involved in the conversation or just keep smiling even though you don’t understand what is being said.”

Those who wear hearing aids often hide them under their hair, she said.

The result is a kind of disempowerment, said Nasu, “That person does not have the information to make a judgement, yes or no. If you can’t judge yes or no, you can’t take action.”

Kaori Nasu, the president of 4Hearts, runs public campaigns to raise awareness about people who face communication barriers. Photo by Noriko Hayashi for Microsoft.

4Hearts runs awareness and empathy workshops in government departments, schools and workplaces. Participants are given ear plugs and headphones with loud static, so they can experience what it’s like to be deaf or hard of hearing, and then come together to think about what they can do.

The community is starting to step out of the shadows.

For example, a group of about 300 members of the deaf community, all employees of another electronics firm, organizes outings to watch a pro volleyball league where YYSystem is hooked up to the arena’s sound system and transcribes the sounds from the venue. “People who cannot hear or [find it] hard to hear can have a fuller experience of viewing sports,” said volunteer Taiyo Akashi.

A Japanese sign-language band named Kokoro Oto performs pop, hip hop and rock at live music venues, offering those who are deaf or hard of hearing a chance to experience live music. When she’s not performing, sign-language vocalist Kuniko Nishimaki, who is deaf, uses the YYProbe app to navigate convenience stores and has used the summarization function to keep up in parent-teacher meetings.

Kuniko Nishimaki, a deaf vocalist for the sign-language band Kokoro Oto, uses the YYProbe app for daily life, from navigating retail stores to summarizing conversations with her children’s teachers. Photo by Noriko Hayashi for Microsoft.

Growing up, Soeda did well in elementary school as she could read what the teacher wrote on the blackboard. Gym class was harder. “I couldn’t understand verbal instructions,” she said. “The teacher would think I was joking around and not being serious.”

In high school, when teaching moved to lecture mode, Soeda struggled. She ended up going to beauty school and began working as a hairdresser in a salon. But loud hair dryers and surrounding clatter made it hard for her to chat with customers, which was part of the job. “The owner of the salon told me it’s not working out,” she said.

Subsequent stints at a noisy manufacturing plant and at a chain restaurant, where she had to wear headphones to get instructions from a supervisor, didn’t last either. She now waits tables at a small restaurant.

Three years ago, Soeda came upon an APD activist on the internet who had been featured on national TV and who had a checklist for APD symptoms. “I did the checklist and thought – this really sounds like me.” That was how Soeda came to be diagnosed by Dr Koji Hirano, an APD expert who wrote a book titled, “I can hear it, but I can’t hear it.”

Today, Soeda runs an online LiD/APD parent support group with 123 members, including doctors and others who work in the field. Since there is no cure, they discuss ways to mitigate the effects, for example, advocating for kids to be able to bring devices into classrooms to help them learn.

They also work with app developers. In May this year, Soeda’s parent support group visited Aisin’s research and development office in Akihabara, the video gaming and anime hub in Tokyo, and met with Nakamura, the developer of YYSystem. Nakamura says he is in constant contact with users and regularly adds features based on their requests – “I don’t actually sleep! I am always writing code!”

Soeda’s group suggested wider line spacing and shorter sentences, as well as different colored text to denote different speakers – changes that have been adopted.

These days, Soeda uses YYProbe for seminars that she runs for her APD support group. And she uses it for fun – when out for drinks with friends at the local izakaya.

“It’s quite noisy inside,” she said. “When we have several people together, I’m in trouble.” The app helps her follow the conversation and translates music, laughter and clapping as simple emoticons on the screen.

In the future, said Nakamura, the app will go beyond text and speech, so users can input as well as generate pictures and videos and graphs to communicate. Generative AI is already making this possible.

Top image: Hiromi Soeda, who has Auditory Processing Disorder, chats using the YYProbe app with Minori Oba, who works for Aisin, maker of the app. Photo by Noriko Hayashi for Microsoft."
Microsoft_News,https://blogs.microsoft.com/blog/2023/12/04/transforming-communications-with-copilot-for-microsoft-365/,,Transforming communications with Copilot for Microsoft 365,"At Microsoft, we’ve asked our communications team to be innovators of AI. To explore and experiment with how we can all use it in our everyday work. We’ve urged the team not to forget their unique expertise and value — the art of communications — but to welcome some science into the process, to be a leader in this new stage of communications.

So, for the last few months we’ve been experimenting with Copilot for Microsoft 365, which is now generally available for enterprises. We’re using Copilot in Teams to story mine with spokespeople and anticipate coverage after interviews. We’re using Copilot in Word to start blogs and draft plans. We’re using chat to test messages, brainstorm and expand our thinking. And Copilot in PowerPoint is helping us create decks that drive clarity and communicate our vision.

We’ve been feeling the impact in our day-to-day but wanted to quantify it — so we did a bit of research ourselves. Using the same methodology featured in our latest Work Trend Index, we surveyed 80 people from our comms and marketing organization and found that— like most knowledge workers —many employees suffer from meeting (70%) and information overload (86%) daily, so it’s not surprising that 80% struggle with having enough focus time each day.

The good news? AI is helping. According to the survey:

86% say Copilot makes them more productive and 81% say it helps them complete tasks faster.

89% say Copilot helps jump-start the creative process and 78% say Copilot improves the quality of their work.

70% say Copilot reduces time spent on tasks they don’t enjoy; specifically, 76% say Copilot reduces mental effort on mundane tasks and 71% say Copilot reduces time spent searching for information.

And the most exciting one for me: 84% say they don’t want to go back to working without Copilot. And I feel the same way. 😊

Now, it’s still early days and the tools aren’t perfect. But to help other communicators consider how AI can improve their work days, here are five ways the team and I are using AI to be more productive, creative, and to make the work we do a little more fun.

1. Meetings and interviews

That meeting overwhelm we feel isn’t just constant back-to-backs; it’s also frequent double-booking and conflicts (if your calendar is anything like mine). Copilot in Teams makes it easier to prioritize your most important meetings and catch up on those you’ve missed — without having to watch the full recording. Some prompts:

Summarize what was discussed in the meeting in short bullet points.

Were there any action items for me?

Were there any unresolved decisions?

During or after a meeting, Copilot can also help you recall what was discussed more accurately, note a great quote or detail for a story, evaluate complex topics, or anticipate coverage following an interview. For example, you can ask:

What was the exact feedback <X> shared about the comms plan that was presented?

The engineer we spoke with shared an interesting anecdote about <X> that I’d like to include in a story I’m working on. Can you remind me exactly what she said?

Put the pros and cons of what the team is discussing about the announcement strategy in a table and recommend a course of action.

After a press interview, ask, “What do you think the reporter will take away from this conversation? Use the transcript as a base document.

2. Message testing

Clarity is key in communications of course, but it’s perhaps even more critical in another setting: the military. Napoleon, the famous general, is known for bringing a corporal to meetings when his generals were presenting war plans. He would ask the corporal, “Having heard these plans, would you know what to do?” If the answer was no, he would ask the generals to re-write their plans.

What does this have to do with AI? I’ve been using Copilot as my corporal to provide fresh perspective. Some examples:

I’ll feed Copilot a blog and ask it to articulate the three key messages; if they’re off, I’ll refine.

I’ll ask Copilot to poke holes in a statement we’re making on a tricky topic, like sustainability or responsible AI. I’ll ask it things like, “If you wanted to disrupt this argument, what would you say?”

With Copilot as my brainstorming partner, I can identify blind spots, sharpen our positions, and expand my thinking so we’re clear and thoughtful in our positionin

3. Preparing spokespeople

To help our spokespeople prepare for press interviews, we’re using Copilot to anticipate questions and develop FAQs. Some example prompts:

Pretend you are a tech reporter. Share the top five questions you would have for me if presented the information in this narrative document: /[X].

Pretend you are a PR person preparing an executive for an interview with a top tech reporter, <X reporter> at <X outlet>. She’s been writing about AI quite a bit. What questions do you think the reporter will ask a tech executive in an interview about how AI will change work?

I’m doing a press interview about <X> what are the top three questions someone unfamiliar with the matter would have on the topic?

Help me draft responses to this list of questions <X>. Answers should be brief, but conversational in tone.

4. Writing comms plans and blogs

Now, many communicators are hired because of their unique ability to write. And as a writer myself, I can tell you that skill isn’t going anywhere — but I’ve found Copilot to be useful in helping me get started, keep going, and refine my content. It’s helping me do what I do best — even better.

Some examples:

In Word, I’ll highlight a paragraph in a plan or blog that I’m getting hung up on and ask Copilot to suggest a few other ways to write it.

Others on my team use Copilot to draft a plan for an upcoming announcement. They’ll give it a brain dump of the elements they want to see in the plan such as what they’re announcing, key messages, timelines, press targets, and spokespeople. Now, it doesn’t produce a full plan end-to-end, but it gives them a solid start.

When I’m at the end of a blog and am stuck for an ending, I like to ask Copilot to write a short, but compelling closing paragraph. And because we’re using Copilot for Microsoft 365, sensitive information, like launch plans and dates, remain protected.

Finally, when the blog or LinkedIn post is done and I’ve used up all my creativity and still need a title or headline, I can ask for five headlines, then jump off from there.

5. Creating presentations

Sometimes the way we present our ideas is just as important as the actual content. So, it’s no surprise that one of my team’s favorite Copilot use cases is turning a Word document, like a PR plan, into a PowerPoint presentation.

Simply open a new presentation in PowerPoint, select the Copilot icon in the ribbon and once the side pane pops up, click “Create presentation from file…” Select the document and let Copilot go to work building a deck.

From there, you can ask Copilot to add an end slide, make all the titles a certain font and color, or ask it to update one of the images to a photograph that’s more to your liking. It’s massively cut down the time it takes my team to build decks — meaning they can focus more on content and less on copy-pasting.

Like any new tool or habit the key is practice, practice, practice. If you already have Copilot for Microsoft 365, you can start experimenting with the prompts above today — or test out some of my communications prompts for Copilot in Bing for free. You can also check out this article on WorkLab that shows you how to write a great prompt.

I’ll keep practicing too — and sharing along the way.

fxs

Tags: AI, Copilot for Microsoft 365, Prompts"
Microsoft_News,https://www.microsoft.com/en-us/industry/blog/healthcare/2023/12/01/how-microsoft-and-nuance-empower-radiologists-with-ai-powered-solutions/,,How Microsoft and Nuance empower radiologists with AI-powered solutions,"The medical imaging profession stands at a pivotal moment. More than half (54%) of radiologists now report feelings of burnout, up from 49% in 2022.1 Up to 44% report that burnout has strong or severe impacts on their lives and well-being. The most recent 2023 American Society of Radiologic Technologists Staffing and Workplace Survey found that vacancy rates topping 18% are at a 20-year high.2 Increasing case volume and complexity—coupled with resource constraints—lead to stress and dissatisfaction as radiologists have to do more with less.

There’s an urgent need to deliver proven, scalable solutions that increase radiology efficiencies, reduce the cognitive burden on radiologists while maintaining the highest standards of reporting quality. That’s why Microsoft and Nuance are committed to creating outcomes-focused AI solutions that streamline radiology workflows.

In our interactive AI Theater at RSNA 2023, we explored the power and potential of advanced AI copilot capabilities. And during our AI Theater presentation, participants experienced how copilots can transform medical imaging by helping automate what radiologists can’t stand, surface what they can’t see, and identify what they can’t miss.

Reducing the cognitive burden and enhancing patient care with AI copilots

With AI-powered automation, radiologists can spend far less time on the tedious, time-consuming tasks that currently take up so much of their day. Instead, as presented in our AI Theater experience, a copilot can amalgamate information from prior reports, AI findings, and natural language captured in the reading room to generate draft reports automatically. As the copilot collects, extracts, and synthesizes relevant data in the background, radiologists can keep their eyes on the image and focus on the quality of their interpretation.

As well as taking on mundane tasks, copilots can support radiologists by enhancing reporting quality and downstream care. AI can monitor images for details that may not be visible or clear to the human eye, helping capture findings that might otherwise go unnoticed. An AI copilot can also assist radiologists by searching the Picture Archiving and Communications System (PACS) or Vendor Neutral Archiving (VNA) for similar images to provide rapid clinical insights.

By providing a vital second pair of eyes, AI can help ensure no findings fall through the cracks. Copilots can catch incidental or subtle findings that could have been easily missed, helping reduce the time to intervention and enhance patient safety.

These copilot experiences can even extend the value of radiology beyond the reading room to support more effective downstream care and patient experience. For example, an AI copilot could act as a companion to patients, providing “patient-friendly” versions of reports and other tools to help people more actively engage with their care.

New AI capabilities and collaborations

As we’ve seen at RSNA 2023, it’s an exciting time to be part of the medical imaging community. We’re thrilled to be playing our part in empowering radiologists by developing new AI capabilities and collaborating with other pioneers in this field. Here’s a recap of the major new developments we announced during the event:

PowerScribe Smart Impression accelerates the adoption of AI in radiology . Nuance shared its progress helping radiologists harness the growing potential of generative AI capabilities for radiology reporting with PowerScribe Smart Impression. Built on the PowerScribe platform used by more than 80% of all radiologists, PowerScribe Smart Impression streamlines radiology workflows and accelerates reporting by automatically creating draft impressions and recommendations using advanced generative AI. Users have noted the natural, accurate wording of draft impressions and how the solution enhances reporting quality by identifying possible omissions, misspellings, or other errors. They also report saving up to a minute per read, which adds up to significant time savings over the course of a busy working day.

. Nuance shared its progress helping radiologists harness the growing potential of generative AI capabilities for radiology reporting with PowerScribe Smart Impression. Built on the PowerScribe platform used by more than 80% of all radiologists, PowerScribe Smart Impression streamlines radiology workflows and accelerates reporting by automatically creating draft impressions and recommendations using advanced generative AI. Users have noted the natural, accurate wording of draft impressions and how the solution enhances reporting quality by identifying possible omissions, misspellings, or other errors. They also report saving up to a minute per read, which adds up to significant time savings over the course of a busy working day. Flywheel collaborates with Microsoft and NVIDIA to accelerate AI development of medical imaging applications . Flywheel, a medical imaging data management platform, launched an AI development solution on Microsoft Azure, integrated with NVIDIA MONAI, to expedite advances in medical imaging AI model development. Flywheel users will also be able to utilize radiology reports with mPower Clinical Analytics, powered by Nuance.

. Flywheel, a medical imaging data management platform, launched an AI development solution on Microsoft Azure, integrated with NVIDIA MONAI, to expedite advances in medical imaging AI model development. Flywheel users will also be able to utilize radiology reports with mPower Clinical Analytics, powered by Nuance. Paige and Nuance transform collaboration among the United States pathologists. Paige, a provider of digital pathology solutions and clinical AI applications, is harnessing the scale and capabilities of Nuance’s PowerShare image-sharing network to create a digital consultation network for pathologists. The network will connect over 14,000 sites, allowing pathologists to collaborate with peers to streamline healthcare operations and reduce the time and costs of diagnosis.

Creating intelligence-infused radiology workflows

The use of AI in radiology isn’t new—but what comes next will be revolutionary, as we create copilot experiences that infuse intelligence into every aspect of the workflow. In this AI-powered future, radiologists will be able to handle growing imaging volumes without compromising quality.

Despite the reports of rising levels of burnout in the profession, it’s been heartening to see the innovation and optimism on display at the RSNA 2023 conference. At Microsoft and Nuance, we’re helping to shape a future where radiologists can work more efficiently and effectively without adding to their cognitive load—all thanks to their AI copilots.

Next steps

Connect with an expert to learn more about AI copilots for healthcare.

Explore Nuance diagnostic solutions.

Discover how you can connect your customers, your people, and your data with Microsoft Cloud for Healthcare.

Intelligent radiology solutions Experience how AI in medical imaging empowers radiologists Explore solutions

1Medscape 2023 Physician Burnout & Depression Report.

2Following 2023 Trends in the Radiologic Technologist Staffing Shortage, AHEConline Blog."
Microsoft_News,https://blogs.microsoft.com/on-the-issues/2023/11/30/uk-ai-skilling-security-datacenters-investment/,,"Our investment in AI infrastructure, skills and security to boost the UK’s AI potential","01.05.2024: This blog was updated to ensure geographical accuracy of build sites.

Today, Microsoft announced a major AI infrastructure and skilling investment supported by a new partnership on security. It will help the UK seize the artificial intelligence (AI) opportunity and ensure that AI innovation and safety progress together while creating jobs, improving services, and protecting public security. Microsoft is committing to more than doubling its datacenter footprint in the UK, training more than one million people for the AI economy and supporting the UK’s growing AI safety and research efforts through partnerships with the government and leading universities.

The investment will cover three key areas:

Capacity: First, Microsoft will invest in the UK’s AI infrastructure. Over the next three years Microsoft will spend £2.5 billion ($3.2bn) to expand its next generation AI datacenter infrastructure, bringing more than 20,000 of the most advanced GPUs to the UK by 2026. The single largest investment in its 40-year history in the country, Microsoft will grow its datacenter footprint across sites in London and Wales and potential expansion into northern England.

This infrastructure investment will help to meet the exploding demand for efficient, scalable and sustainable AI specific compute power and the needs of the private and public sector waiting to take advantage of the latest cloud and AI breakthroughs.

To support research on AI, Microsoft will extend its Accelerating Foundation Models Research (AFMR) program to include prioritized access to GPUs for the UK’s science and research community. AFMR drives interdisciplinary research on AI alignment and safety, beneficial applications of AI, and AI-driven scientific discovery in the natural and life sciences. This new UK effort will aim at harnessing the power of AI to accelerate scientific discovery via multiscale multimodal data generation through prioritized access to Microsoft’s AI tools. This program includes researchers from the UK’s world leading participating universities including Cambridge, Oxford, Imperial College, UCL, Bath, and Nottingham.

Capability: Second, Microsoft will invest in broad-based AI talent and education programs. To support UK workers across the AI economy, Microsoft will make a multi-million-pound investment to train one million people with the skills they need to build and work with AI. This will include expanded training for people looking to start, or move into, a career in AI. Working in partnership with multiple learning and non-profit partners, the program will focus on building AI fluency, developing AI technical skills, supporting AI business transformation, and promoting safe and responsible AI development and use including the first Professional Certificate on Generative AI.

As part of this skilling commitment, Microsoft will also turn all the lessons it has learned in operationalizing responsible AI principles for its own AI engineers and developers, into learning modules for UK customers and partners. This training will help the UK’s AI developer ecosystem to embed safety and security measures into their own systems and processes and takes Microsoft’s training support for responsible AI beyond principles and embeds sound practice into the way AI is developed and integrated across the IT industry.

Finally, to help ensure Microsoft technical trainers are adhering to the ethics and principles of developing AI solutions responsibly they will all complete and attest to Microsoft’s “Responsible Generative AI” training.

Security: Third, Microsoft will invest in strong AI safety and security measures. These will cover both Microsoft’s own infrastructure and support for AI developers and customers deploying and using AI applications. Microsoft will operate its AI services and infrastructure in accordance with industry-leading responsible AI practices. It will integrate the adoption and use of responsible AI principles into its Partner Pledge for its 25,000 UK partners and it will collaborate with the UK Government and AI Safety Institute on the ongoing development of refinements and improvements in this field.

Read the official press release here.

Tags: AI, data center, Responsible AI, United Kingdom"
Microsoft_News,https://news.microsoft.com/2023/11/29/unfccc-partners-with-microsoft-to-use-ai-and-advanced-data-technology-to-track-global-carbon-emissions-and-assess-progress-under-the-paris-agreement/,,UNFCCC partners with Microsoft to use AI and advanced data technology to track global carbon emissions and assess progress under the Paris Agreement,"UNFCCC partners with Microsoft to use AI and advanced data technology to track global carbon emissions and assess progress under the Paris Agreement

DUBAI, United Arab Emirates — Nov. 29, 2023 — Leaders from the United Nations and Microsoft Corp. on Thursday announced a partnership that will enable the UNFCCC to create a new AI-powered platform and global climate data hub to measure and analyze global progress in reducing emissions. This will dramatically simplify the process to validate and analyze climate data submitted by the 196 Parties to the Paris Agreement.

The partnership comes at a critical time, as the world’s governments come together at COP28, organized by the UNFCCC and the COP28 UAE Presidency, to take stock of the slow progress in meeting the climate goals set by the Paris Agreement.

“The world must move faster to reduce carbon emissions. Simply put, you can’t fix what you can’t measure, and these new AI and data tools will allow nations to measure emissions far better than they can today,” said Brad Smith, vice chair and president of Microsoft.

“The Paris Agreement provides the framework for all the world’s nations to reduce greenhouse gas emissions in line with limiting global warming to 1.5 degrees,” said Simon Stiell, UNFCCC executive secretary. “Climate change is a global emergency that goes beyond borders. It will require technology for adaptation and mitigation. Progress also requires collaboration from trusted partners to develop the tools that the framework requires to be delivered. We are happy to work with Microsoft in this effort.”

Aggregating and analyzing carbon data today is time consuming and often done through manual methods. Under the agreement, Microsoft will build a new platform to provide digital support to the UNFCCC’s Enhanced Transparency Framework. This platform will enable advanced analysis of global climate data through the creation of a new global climate data hub and an AI-powered data analytics platform. This will equip UNFCCC and member states with the tools they need to efficiently report and validate progress toward carbon reduction targets. This includes tracking transportation, agriculture, industrial processes, and other sources of carbon emissions. It will also provide UNFCCC and member states with tools to plan carbon reduction strategies using simulations, benchmarks, and data visualizations to help inform targeted actions, saving time and money.

This work will also include the creation of Global Climate Dashboards for publication on UNFCCC website, increasing transparency, accountability, and ultimately informing meaningful climate action.

Microsoft has committed $3 million over two years to help enable the implementation of the Enhanced Transparency Framework and the Global Stocktake mechanisms established by the Paris Agreement.

Enacted in 2015, the Paris Agreement commits countries to reducing emissions to slow the impact of climate change, and to strengthen these commitments over time. Implementation of the Paris Agreement is critical to achieve the Sustainable Development Goals.

Microsoft and the UNFCCC will also partner to host a series of events intended to accelerate climate action in the UNFCCC Pavilion (Blue Zone) at COP28.

About UNFCCC

The UNFCCC secretariat (UN Climate Change) is the United Nations entity tasked with supporting the global response to the threat of climate change. UNFCCC stands for United Nations Framework Convention on Climate Change.

About Microsoft

Microsoft (Nasdaq “MSFT” @microsoft) enables digital transformation for the era of an intelligent cloud and an intelligent edge. Its mission is to empower every person and every organization on the planet to achieve more.

For more information, press only:

Microsoft Media Relations, WE Communications for Microsoft, (425) 638-7777,

[email protected]

UNFCCC, [email protected]

Note to editors: For more information, news and perspectives from Microsoft, please visit the Microsoft News Center at http://news.microsoft.com. Web links, telephone numbers and titles were correct at time of publication, but may have changed. For additional assistance, journalists and analysts may contact Microsoft’s Rapid Response Team or other appropriate contacts listed at https://news.microsoft.com/microsoft-public-relations-contacts."
Microsoft_News,https://blogs.microsoft.com/on-the-issues/2023/11/29/ai-canada-artificial-intelligence-and-data-act/,,AI in Canada: meeting the opportunity,"The era of AI is here, ushering in a transformative wave with potential to touch every facet of our lives and enhance our experiences in unprecedented ways. It is not just a technological advancement; it is a societal shift that is propelling us into a future where innovation takes center stage.

Yet, amid this excitement, a critical mandate remains; as we delve into this AI-powered future, it is imperative that we innovate responsibly, and any progress aligns with human values. With this exciting technological revolution, the role of human oversight cannot be overstated. AI is a tool harnessed by human ingenuity. Our ability to guide, govern, and ensure responsible deployment of AI is paramount. Regulation is crucial to helping ensure that, while we explore AI’s vast potential, we do so responsibly.

Canada stands at the forefront of championing responsible AI governance.

The recent unveiling of a Canadian code of conduct for advanced AI systems and contributions to the historic G7 Hiroshima Process position Canada as a global leader, highlighting Canada’s commitment to responsible AI deployment. Codes of conduct serve as invaluable tools, complementing the ongoing efforts of governments worldwide, as they craft legislative and regulatory frameworks for AI. Codes provide the cornerstone upon which a globally interoperable framework can be built among G7 countries and other allies. Concurrently, the Government of Canada’s proposed Artificial Intelligence and Data Act (Bill C-27) signifies a pivotal moment and embodies a crucial step in responsible regulation.

At Microsoft, we champion the need for robust legislation that navigates the complexities of AI, ensuring we safeguard privacy, civil liberties, and ethical considerations, while nurturing the potential of this revolutionary technology. And in the heart of this transformation, we remain steadfast in our commitment to empower groundbreaking initiatives that demonstrate our nation’s leadership in AI.

And we have already started to see the breakthroughs transpire.

During the pandemic, Canada’s health care sector mitigated the spread of infections, enhanced patient safety, and charted a path toward a future where AI solutions helped to revolutionize health care and improve patient outcomes. By harnessing the power of AI technologies, Canadian health care organizations such as Toronto’s University Health Network (UHN) and BC Cancer are also unravelling hidden insights within vast datasets, leading to breakthroughs in cancer treatments.

The City of Kelowna is developing AI tools to speed up the building permit process by 20-30%, enhancing the overall experience of citizens and government workers alike: citizens who receive frictionless service and government workers whose wellbeing improves from the result of lower churn from data overload and repetitive work.

In partnership with Ontario Power Generation (OPG), we are working to shape a net-zero and environmentally resilient future where AI solutions are instrumental in powering new energy insights, matching local carbon-free sources, reducing emissions, and shaping a sustainable energy landscape.

Across the country, AltaML is partnering with the Government of Alberta and Alberta Wildfire to build Microsoft AI-powered solutions to predict the likelihood of fire in any region, helping to determine how best to deploy scarce resources resulting in $2 million-$5 million in annual savings and helping protect lives.

It makes me particularly proud that Microsoft brought Inuktitut, the language of more than 70% of Nunavut’s population, to Microsoft’s AI-powered Translator. Our work to help preserve cultural heritage with the Government of Nunavut gives tangible expression to Canadian truth and reconciliation.

Ensuring that AI benefits everyone will take collaboration across a diverse set of stakeholders, including policymakers, academics, civil society, and industry to ensure many voices and community interests are considered. Government and industry have a shared responsibility to make certain that Canada’s workforce is equipped with the skills, knowledge, and opportunity to gain jobs and increase livelihoods in an AI economy.

Microsoft is committed to helping people and communities learn how to harness the power of AI through our new AI Skills Initiative, and to continuing to invest in local talent capacity, including by building initiatives such as the Canadian Tech Talent Accelerator, launched in partnership with the DIGITAL, NPower Canada, and CIBC Foundation.

The paper shares our suggestions for the strong regulatory guardrails we believe are needed to see AI shape more prosperous, inclusive, and sustainable communities while prioritizing the safety, security and trust of citizens, governments, and businesses across Canada.

As Microsoft Canada celebrates our part in Canada’s AI-transformative journey, we are also mindful of the road ahead. AI’s potential is vast, and with responsible regulation, it remains a force for good, enriching lives and empowering Canada.

The collaborative partnership between Canada and Microsoft exemplifies the fusion of innovation with ethics, shaping a future where AI serves humanity, enriches the lives of Canadians, and propels our great nation toward a future defined by boundless possibilities. Microsoft is deeply committed to this journey where Canada continues to lead, inspire, and thrive in the digital age.

Read the full paper, “Meeting the opportunity and governing AI in Canada,” here.

Tags: AI, artificial intelligence, Canada, Responsible AI"
Microsoft_News,https://www.microsoft.com/en-us/research/blog/gpt-4s-potential-in-shaping-the-future-of-radiology/,,GPT-4’s potential in shaping the future of radiology,"This research paper is being presented at the 2023 Conference on Empirical Methods in Natural Language Processing (opens in new tab) (EMNLP 2023), the premier conference on natural language processing and artificial intelligence.

Project Project MAIRA

In recent years, AI has been increasingly integrated into healthcare, bringing about new areas of focus and priority, such as diagnostics, treatment planning, patient engagement. While AI’s contribution in certain fields like image analysis and drug interaction is widely recognized, its potential in natural language tasks with these newer areas presents an intriguing research opportunity.

One notable advancement in this area involves GPT-4’s impressive performance (opens in new tab) on medical competency exams and benchmark datasets. GPT-4 has also demonstrated potential utility (opens in new tab) in medical consultations, providing a promising outlook for healthcare innovation.

Progressing radiology AI for real problems

Our paper, “Exploring the Boundaries of GPT-4 in Radiology (opens in new tab),” which we are presenting at EMNLP 2023 (opens in new tab), further explores GPT-4’s potential in healthcare, focusing on its abilities and limitations in radiology—a field that is crucial in disease diagnosis and treatment through imaging technologies like x-rays, computed tomography (CT) and magnetic resonance imaging (MRI). We collaborated with our colleagues at Nuance (opens in new tab), a Microsoft company, whose solution, PowerScribe, is used by more than 80 percent of US radiologists. Together, we aimed to better understand technology’s impact on radiologists’ workflow.

Our research included a comprehensive evaluation and error analysis framework to rigorously assess GPT-4’s ability to process radiology reports, including common language understanding and generation tasks in radiology, such as disease classification and findings summarization. This framework was developed in collaboration with a board-certified radiologist to tackle more intricate and challenging real-world scenarios in radiology and move beyond mere metric scores.

We also explored various effective zero-, few-shot, and chain-of-thought (CoT) prompting techniques for GPT-4 across different radiology tasks and experimented with approaches to improve the reliability of GPT-4 outputs. For each task, GPT-4 performance was benchmarked against prior GPT-3.5 models and respective state-of-the-art radiology models.

We found that GPT-4 demonstrates new state-of-the-art performance in some tasks, achieving about a 10-percent absolute improvement over existing models, as shown in Table 1. Surprisingly, we found radiology report summaries generated by GPT-4 to be comparable and, in some cases, even preferred over those written by experienced radiologists, with one example illustrated in Table 2.

Table 1: Results overview. GPT-4 either outperforms or is on par with previous state-of-the-art (SOTA) multimodal LLMs.

Table 2. Examples where GPT-4 findings summaries are favored over existing manually written ones on the Open-i dataset. In both examples, GPT-4 outputs are more faithful and provide more complete details on the findings.

Another encouraging prospect for GPT-4 is its ability to automatically structure radiology reports, as schematically illustrated in Figure 1. These reports, based on a radiologist’s interpretation of medical images like x-rays and include patients’ clinical history, are often complex and unstructured, making them difficult to interpret. Research shows that structuring these reports can improve standardization and consistency in disease descriptions, making them easier to interpret by other healthcare providers and more easily searchable for research and quality improvement initiatives. Additionally, using GPT-4 to structure and standardize radiology reports can further support efforts to augment real-world data (RWD) and its use for real-world evidence (RWE). This can complement more robust and comprehensive clinical trials and, in turn, accelerate the application of research findings into clinical practice.

Beyond radiology, GPT-4’s potential extends to translating medical reports into more empathetic (opens in new tab) and understandable formats for patients and other health professionals. This innovation could revolutionize patient engagement and education, making it easier for them and their carers to actively participate in their healthcare.

Spotlight: Microsoft research newsletter Microsoft Research Newsletter Stay connected to the research community at Microsoft. Subscribe today Opens in a new tab

A promising path toward advancing radiology and beyond

When used with human oversight, GPT-4 also has the potential to transform radiology by assisting professionals in their day-to-day tasks. As we continue to explore this cutting-edge technology, there is great promise in improving our evaluation results of GPT-4 by investigating how it can be verified more thoroughly and finding ways to improve its accuracy and reliability.

Our research highlights GPT-4’s potential in advancing radiology and other medical specialties, and while our results are encouraging, they require further validation through extensive research and clinical trials. Nonetheless, the emergence of GPT-4 heralds an exciting future for radiology. It will take the entire medical community working alongside other stakeholders in technology and policy to determine the appropriate use of these tools and responsibly realize the opportunity to transform healthcare. We eagerly anticipate its transformative impact towards improving patient care and safety.

Learn more about this work by visiting the Project MAIRA (opens in new tab) (Multimodal AI for Radiology Applications) page.

Acknowledgements

We’d like to thank our coauthors: Qianchu Liu, Stephanie Hyland, Shruthi Bannur, Kenza Bouzid, Daniel C. Castro, Maria Teodora Wetscherek, Robert Tinn, Harshita Sharma, Fernando Perez-Garcia, Anton Schwaighofer, Pranav Rajpurkar, Sameer Tajdin Khanna, Hoifung Poon, Naoto Usuyama, Anja Thieme, Aditya V. Nori, Ozan Oktay

Opens in a new tab"
Microsoft_News,https://www.microsoft.com/en-us/worklab/podcast/s5-e6-eric-horvitz,,"WorkLab: Hard Data, Compelling Stories, Vital Insights","Customer Zero

Our Year with Copilot: What Microsoft Has Learned About AI at Work

Getting AI right requires intention, experimentation, and some unexpected heroes. Here’s how you can apply insights from our experience to your own organization."
Microsoft_News,https://news.microsoft.com/source/features/work-life/a-dai-in-the-life-of-liam-flowers/,,A dAI in the life of Liam Flowers,"Liam Flowers is a marketing program manager for Xbox Experimentation who lives in Seattle with his wife and two 90-pound dogs. In his free time, he paints, creates art and cares for the growing houseplant collection he has had “ever since my wife showed me how to propagate them.”

While Flowers likes using AI tools to help him come up with concepts for his art, he has discovered this year that the tools are indispensable at work. “I’ve got wicked ADHD, and when it comes to keeping my thoughts in order, I will sometimes spit stuff out at Bing Chat to see what it says, and it’s a good vetting process for me,” Flowers says. “Also, I like to be sure I’m remembering correctly, so when Teams intelligent meeting recaps rolled out in the spring, I almost cried. They’ve become hugely important. I used to frantically scribble notes during meetings, but this tool helps me engage fully.”

Flowers, 32, shares a typical day as part of Microsoft’s “A dAI in the life” series, which showcases how AI tools are helping people do more in their personal and professional lives.

9 a.m.

Calls start at work, and there’s lots to keep track of. I use Teams intelligent recap to compose notes and provide bullet lists of action items from each call. Bing Chat — I use the Enterprise version at work — helps me with deeper critical thinking. I am not fast to reply to a lot of things because I like to be thorough, and this tool has replaced a half-dozen others by simply being able to have a discussion.

It’s also unbelievably helpful with review. I have SharePoint Copilot review Word and PowerPoint documents. It can answer questions about them and summarize the content, and it works conversationally, so little prompting knowledge is needed.

12:30 p.m.

I’m currently onboarding into a new role, and I use AI for everything in my training. For example, I’m learning a new data scorecard system for experiments, which is complex stuff. With Bing Chat’s sidebar function in Edge, I can translate grids of dense figures into a story about innovation with just a few prompts.

I’m not a data scientist, so this part of my work used to take the most of my brainpower. Now I get to focus on experience and impact. Bing Chat in the Edge browser deciphers acronyms and metric definitions into plain language, highlighting connections in the data, and can even review others’ work and compare reports I read against the data to look deeper. Here’s an example: “Make a table of all metrics on this page, their definitions, and changes between Control and Treatment.”"
Microsoft_News,https://blogs.microsoft.com/blog/2023/11/17/a-statement-from-microsoft-chairman-and-ceo-satya-nadella/,,A statement from Microsoft Chairman and CEO Satya Nadella,"This blog was updated at 10:15 p.m. on Nov. 21 to reflect the latest statements from Sam Altman and Satya Nadella.

Sam Altman: i love openai, and everything i’ve done over the past few days has been in service of keeping this team and its mission together. when i decided to join msft on sun evening, it was clear that was the best path for me and the team. with the new board and w satya’s support, i’m looking forward to returning to openai, and building on our strong partnership with msft.

Satya Nadella: We are encouraged by the changes to the OpenAI board. We believe this is a first essential step on a path to more stable, well-informed, and effective governance. Sam, Greg, and I have talked and agreed they have a key role to play along with the OAI leadership team in ensuring OAI continues to thrive and build on its mission. We look forward to building on our strong partnership and delivering the value of this next generation of AI to our customers and partners.

Posted Nov. 19, 2023

Satya Nadella: We remain committed to our partnership with OpenAI and have confidence in our product roadmap, our ability to continue to innovate with everything we announced at Microsoft Ignite, and in continuing to support our customers and partners. We look forward to getting to know Emmett Shear and OAI’s new leadership team and working with them. And we’re extremely excited to share the news that Sam Altman and Greg Brockman, together with colleagues, will be joining Microsoft to lead a new advanced AI research team. We look forward to moving quickly to provide them with the resources needed for their success.

Posted Nov. 17, 2023

Satya Nadella: As you saw at Microsoft Ignite this week, we’re continuing to rapidly innovate for this era of AI, with over 100 announcements across the full tech stack from AI systems, models, and tools in Azure, to Copilot. Most importantly, we’re committed to delivering all of this to our customers while building for the future. We have a long-term agreement with OpenAI with full access to everything we need to deliver on our innovation agenda and an exciting product roadmap; and remain committed to our partnership, and to Mira and the team. Together, we will continue to deliver the meaningful benefits of this technology to the world."
Microsoft_News,https://www.microsoft.com/en-us/worklab/podcast/how-copilot-is-transforming-one-global-creative-agency,,How Copilot Is Transforming One Global Creative Agency,"MOLLY WOOD: Today I’m talking to James Thomas, global head of technology at Dentsu Creative, about his organization’s early experience with generative AI at work. Dentsu is one of the world’s largest global creative agencies and was also one of the first to try out Copilot for Microsoft 365 as part of Microsoft’s Early Access Program. James has a report from the front lines. He shares how incorporating generative AI into everyday operations has transformed his team’s workflows. And he talks about what business leaders should keep in mind as they begin getting their hands on this technology too. James, thanks so much for joining us.

JAMES THOMAS: Thank you for having me. It’s great to be here.

MOLLY WOOD: Okay, so Dentsu was one of the first companies to try out Microsoft’s Copilot as part of its Early Access Program. Tell us about it. What has the experience been like for the teams that took it out for a test drive?

JAMES THOMAS: Yeah, so, a huge amount of people wanted to get their hands on it. Unfortunately, we didn’t have that many licenses. But the lucky 300 or so that got access is really a real game changer. A lot of people can’t see themselves going back to how they used to work before. People see the efficiencies. They see the quality of their output being improved and the quality of their collaboration, particularly in creative roles. You know, a lot of time is spent planning—complex production meetings and creative sessions where a lot of notes and a lot of action and next steps are needed to be created, a lot of complex budgetary Excel documents to manage, even just summarizing a long email chain. You know, those savings and efficiencies are huge. It means people can get straight onto the tasks that they’re supposed to do.

MOLLY WOOD: How has AI impacted the creative process at Dentsu?

JAMES THOMAS: So in the actual creative process itself, you know, ideation, we would typically work with a client in what we call a chemistry session, which is, you know, we get everyone in a room, we’ll really just kind of collaborate, come up with some great ideas over a few hours. Typically then what happens is we would go away as an agency and we would come back, you know, days, weeks, sometimes even months later with some creative treatment, visualizations of these ideas, right? And, uh, it’s taken months to even get to that stage. By using Copilot in Teams and DALL-E, we can ideate while we’re in the room with a client. We can sketch down ideas into Word and have ChatGPT expand that out into thought out ideas. We can create visualizations in DALL-E. The hard bit with creative is trying to bring other people on board with the idea you have in your head. And, uh, the more creative the idea, the harder it is to try and get it to people. So the idea of being able to really visualize things very quickly or just take a few lines of copy and suddenly turn that into some kind of proposal is huge. And again, it just means we can get going fast with the client. We know where the dead ends are and we know, right, this is the right idea. And it just helped us to iterate a lot faster. I think a lot of these use cases are ones we hadn’t thought of before. You know, creatives, I think it’s fair to say, were quite apprehensive about this technology when it was becoming more widespread, you know, like, like a lot of us—what does it mean for the future, their work, their jobs, humanity—but, you know, now I think creative people have seen that it’s actually just a tool in their toolkit and it means they can get to their ideas a lot faster. In fact, as the Copilot deployment at Dentsu has shown, yeah, we’ve got a waiting list of thousands. We can’t get these tools in people’s hands fast enough.

MOLLY WOOD: What was that preparation like? Because I do think the creative realm is sort of a space where the easy answer is, we will get all this efficiency and that will allow us more time to be creative. But talk a little bit more about the evolution, like as you started to discover, oh, this works in the process of being creative as well.

JAMES THOMAS: I think everyone is using it in different ways. What we have done really well, thanks to Dominic Shine, our CIO, and Brian Klochkoff, who is enabling all these services at Dentsu in a scaled way, we have really great office hour meetings, town halls, where all of the users are coming together, sharing their own tips and tricks they’ve found. Um, so we’ve really put a lot of work into helping people know how to use it.

MOLLY WOOD: What do you imagine as you go forward and eventually everybody has this, and these efficiencies start to pile on top of each other? What do you imagine that will allow?

JAMES THOMAS: Well, that’s a great question. I think particularly, and I can only really speak for creative, but what we’ve been battling against for quite a few years is that need from CMOs for almost unlimited content—just non-stop content, new versions, new iterations for new channels and everything else. Because of that, and because a lot of the workflows were manual, you could automate some things, but what it meant was creatives were really up against it, overloaded, right? And they were just churning out lots of different iterations and not having the time to spend on the upfront creative idea. The idea of being able to use AI and technology to generate content, generate copy, generate images, it frees up the time that creatives need to be creative. Creativity is not a fast process, usually. You need time, you need space to think through these ideas. But if you know, oh, I’ve got to create a thousand versions of this idea, I don’t have too long to think about the idea in itself. I have to get on and make all these versions. But if I know I can come up with a really great idea, campaign, set of assets that I can take a lot longer to do, and then use generative AI and other technology to help scale that, infinitely almost, then that’s a great place to be. And that’s what everyone wants. Everyone wants the best possible idea.

MOLLY WOOD: Talk a little bit more about the assistance in the creative process. You know, I’ve spoken to people who are using ChatGPT, for example, to brainstorm ideas or, you know, please challenge me on this, or to kind of bat around concepts. I wonder how much of that is happening with you, that actual interaction in the creative process and iterating and maybe using these tools to continue to generate or improve on your ideas.

JAMES THOMAS: No one likes to start with a blank page. You know, it becomes very quick and easy to just throw down a few ideas, get them scaled out into, you know, from one line into a paragraph, from a paragraph into a proposal. But then it also allows you to—because you can get more ideas out, it means you can hopefully get to a better idea quicker. Again, all these things allow for more creativity, and it helps when you’re selling the idea to people because you can be like, look, this is the message, but look, here’s how we tell it to your 10 different audiences.

MOLLY WOOD: You’ve been using this for a while and it, you know, sort of sounds like it’s sunk in for you, but was there a moment when it blew your mind?

JAMES THOMAS: Yeah, I mean, a couple of things that keep wowing me every time is, you know, I spend my life in meetings, on Teams mostly, and the note taking, the transcribing, and the action steps—and also, if you join a meeting late then just kind of recapping what’s happened so far. The accuracy is incredible and I’m back to back in meetings, so unfortunately, quite often I am a little bit late for the next one. I can hit recap meeting and I’ll be up to speed straight away. It’s way more accurate than the meeting notes I take or anyone else I know takes. So that is always a huge one for me. And also, I travel a lot and I get a lot of emails. So catching up on emails is always a pretty daunting task while on the move or coming back from holiday. And now just being able to summarize long email chains in Outlook with Copilot is great. I don’t need to sit through these 30 emails on this one subject. I can get a two-paragraph summary on what’s happened and who’s doing what.

MOLLY WOOD: So let’s talk about advice to business leaders in terms of adopting this and integrating it into an organization, especially in the creative industry, because like you said, there is— [interruption] What happened?

JAMES THOMAS: So that’s my automatic cat timer. And it’s my voice telling my cat it’s dinner time. Quite embarrassing.

MOLLY WOOD: That’s incredible. You really have it all. You have all the toys.

JAMES THOMAS: Yeah, I didn’t know that would get picked up.

MOLLY WOOD: There’s a timer that tells your cat that it’s dinner time in your own voice? Oh my god.

JAMES THOMAS: Yeah.

MOLLY WOOD: Okay, so you’ve given us some really tactical examples so far on how Dentsu leaders are incorporating Copilot into their workflows. What would be your advice for other business leaders who haven’t gotten their hands on it yet? What should they be keeping in mind as they get started?

JAMES THOMAS: We’re a huge holding group. So, you know, there’s equal value in creative as there is in the finance team, as there is in the HR team. Everyone’s using it in a different way, and I think helping to bring people together. Help them to share their findings and their insight on how they’ve been using it, and also sell it to them in the use cases they understand. If you’re talking to a creative part of your business, talk to them about the creative use cases. You know, they might not be so interested in what you can do in an Excel document, but they’ll be very interested in some of the other use cases that are much more specific to their world. So I think maybe tailoring it for your audience will help drive the adoption.

MOLLY WOOD: As you have described it so far, it sort of sounds like these are tools that will allow you to keep up with and succeed in the media world that we live in now, right? Where there are, like you said, different models and different distribution outlets and different ways to get attention. Once you feel caught up, can you imagine how this would also help you create new business models and services?

JAMES THOMAS: Yeah, absolutely. And I think the technology with Microsoft and OpenAI, and what we can do with ChatGPT and DALL-E and how via APIs we can start to plug these things together and build out tools. One thing we launched this year, really to kind of meet this challenge, is what we’re calling the Technical Delivery Center of Excellence. It’s a combination of talent from our India, Brazil, and Poland teams, innovation and generative AI experts and specialists. And we’re really scaling these teams in order to meet the demand of what’s coming. And what’s coming is a lot of custom experiences, a lot of custom platforms and tools. You know, we’re already doing award-winning work. We had two awards at Cannes this year, the top two awards, the Grand Prix awards—one for Scrolling Therapy and one for The Inflation Cookbook, both AI-powered tools. There are so many different products. Also, building custom models and custom algorithms, you know, that’s where a lot of the IP and a lot of the differentiators will come. This technology is going to be available to everyone—brands, agencies. Everyone’s going to be able to get a hold of it, but it’s how you piece it together, how good you are at building a custom model. They say you can give anyone a guitar, but not everyone can play it the same, or play it well, right? Just because you have tools or have access to this stuff doesn’t mean you’re going to be effective with it. So yeah, I think there are so many opportunities if these technologies and experiences can enable more attention and more engagement and ultimately more sales, most of the time, then that’s a good thing for everyone.

MOLLY WOOD: You’re so far ahead of everybody else, right, in adopting these tools and having this early access. And so, I wonder, what do you say to AI skeptics, or people who are reluctant to integrate generative AI into their lives?

JAMES THOMAS: The biggest misconception is that it’s just going to take everybody’s jobs. I mean, obviously AI has been around for a long time, but generative AI in particular, obviously hit the big time because I guess it’s a bit more sexy. It’s a bit more fun. You can go online and turn yourself into Drake and make a song. You know, there are so many fun things that anyone can do. For people to be able to go on and just create content, it’s great. And as a creative, I’m always in this kind of slight battle with myself: I’m a creative first, then a technologist. Anything that can make people creative is a good thing, right? You know, if I can go online, and I might not be the best video editor or photo retoucher ever, but if I can create something and go online and AI can assist me in bringing it to a much higher level, then that’s great. I think everyone should be able to be creative and create the things they have in their mind without technology or skill, to a degree, becoming a blocker. I take advantage of that all the time. As I talked about before, it’s just finding ways for people to be more creative and augment their workflows and make better content, or faster content. But you’re always going to need humans. You’re always going to need the human feel and human touch over this work. And it opens up new opportunities for careers and skill sets and talents as we see people getting into prompt engineering.

MOLLY WOOD: What is, other than feeding your cat, the latest thing that AI has helped you with at work and not at work?

JAMES THOMAS: At work, it’s helped me to deliver incredible work to clients, work that we’d never been able to do without this technology. Personally, it’s enabled me, as I was talking earlier, to create my own content better. I also have a music career I’ve had for a long time, and that makes me have to release other content on a personal note. And yeah, the tools to get that content better, edit it quicker, faster, improve it is great.

MOLLY WOOD: What kind of music do you make?

JAMES THOMAS: All sorts, I work with a lot of big hip-hop artists in the US to film scores to brands. I’ve done a lot. We used to do it full time for a long time as well.

MOLLY WOOD: What do you do with any extra time that AI creates for you?

JAMES THOMAS: Learn about the next thing that’s coming with AI, usually. [Laughs] You know, everyone’s excited about generative AI and where we are right now. My job, and my team’s job, is always to be one step ahead.

MOLLY WOOD: Fast forwarding three to five years, what do you think will be the most profound change in the way we work?

JAMES THOMAS: Uh, wow, that’s a big question. It’s actually really hard to think about where things are going to go. You know, a year ago, we weren’t even thinking about generative AI, really, you know, on the most part, and look where we are now. So, it is hard to say, but I think almost everybody in almost anything they do career-wise, you know, professionally, and as a consumer, will be leveraging AI in their day-to-day work, whether it’s Copilot, whether it’s specialist tools. I think everyone is about to get a lot more efficient, hopefully a lot happier, taking some of the legwork out of some of the mundane tasks, but I can’t see a world now where people aren’t going to be leveraging AI to enhance the way they work and the way they live.

MOLLY WOOD: James Thomas is global head of technology at Dentsu Creative. Thanks so much for the time.

JAMES THOMAS: Thank you so much for the opportunity.

[Music]

MOLLY WOOD: Thank you again to James Thomas. And that’s it for this episode of WorkLab. Please subscribe and check back for the next episode, where I’ll be talking to Microsoft Chief Scientific Officer Eric Horvitz about how leaders can leverage the tremendous potential of AI to best serve humanity. If you’ve got a question or a comment, drop us an email at worklab@microsoft.com, and check out Microsoft’s Work Trend Indexes and the WorkLab digital publication. There you’ll find all of our episodes along with thoughtful stories that explore how business leaders are thriving in today’s new world of work. You can find all of that at microsoft.com/worklab. As for this podcast, please rate us, review, and follow us wherever you listen. It helps us out a ton. The WorkLab podcast is a place for experts to share their insights and opinions. As students of the future of work, Microsoft values inputs from a diverse set of voices. That said, the opinions and findings of our guests are their own and they may not necessarily reflect Microsoft’s own research or positions. WorkLab is produced by Microsoft with Godfrey Dadich Partners and Reasonable Volume. I’m your host, Molly Wood. Sharon Kallander and Matthew Duncan produced this podcast. Jessica Voelker is the WorkLab editor."
Microsoft_News,https://www.microsoft.com/en-us/worklab/the-art-and-science-of-working-with-ai,,The Art and Science of Working with AI,"Get started

OOur research on how to get the most out of AI indicates one overarching rule of thumb: the more detail you give in your prompts, the better the answer will be.ur research on how to get the most out of AI indicates one overarching rule of thumb: the more detail you give in your prompts, the better the answer will be.

HOW I PROMPT What makes Copilot feel almost magical is the fact that it has a deep understanding of me, my job, my priorities, and my organization. It knows my entire universe of data at work. I can write: Quickly summarize the meeting I had at 11 a.m. yesterday.

Who attended?

What decisions were made?

Give me a sense of what you think the next steps should be.

Put that summary into an email to Jun, and propose a time we’re both free next week to discuss.

Write it in Japanese. Jared Spataro Microsoft CVP, Modern Work & Business Applications

If you ask Microsoft Copilot with Graph-grounded chat a simple or open-ended question, it will answer in kind. But if you want more detail and refinement, the question must be more pointed. For instance, if you ask Copilot, what did I miss yesterday? it will offer up a slew of email and chat summaries that you were looped in on. For more precision, be more specific and detailed in the first interaction, e.g., what are my action items from yesterday for the Woodgrove account? That will deliver fine-tuned results that summarize what’s expected of you from meetings, long email threads, disparate chats, and comments in decks and documents.

“With traditional search, people have become so accustomed to being very concise,” says Tara Roth, Corporate Vice President of Microsoft 365 Customer Success Engineering. “You use just a few key words and get a lot of links back, and then do a lot of processing on your own. With prompting, you can be more verbose and descriptive about what you want to get the most accurate and relevant responses.”

Our research shows that there are four key building blocks of a successful prompt: start with the end in mind by explaining what you want Copilot to do; set the stage with any context or details; define any parameters, such as specific dates, documents, or emails that Copilot should look to; and tailor the delivery, or how you want Copilot to present its response.

Anatomy of a Prompt

To get the best response, it’s important to know how to frame and phrase your Copilot prompts. This example, best used in Microsoft Copilot with Graph-grounded chat, highlights the most important things to consider.

HOW I PROMPT Once a week, to keep myself informed and prepare for meetings with global HR partners, I ask Copilot: What are the top challenges facing global HR organizations this week in September 2023?

What about in Australia, 2023?

Are HR trends in the US for September 2023 different than the HR trends in Germany for September 2023?

Show me HR research across all of our global offices from the past three months, 2023.

Who are the top voices talking about these challenges? It opens the door to possibilities rather than simply coming to a conclusion. Amy Coleman Microsoft CVP, Human Resources & Corporate Functions

Get creative and experiment with different styles to hone in on answers that fit your needs. Try specifying tone (neutral, casual, professional) or giving guidance for what kind of language to use, i.e., language a non-technical person could understand. Analogies, poems, and even historical allegories (what is a moment in history I can use to explain the central message in this doc?) can be useful ways to help you process the information.

It’s also helpful to give Copilot a point of view from which to answer. Usually, that involves some explanation about who you are and what you’re trying to achieve so the AI can roleplay: You are a social media manager writing LinkedIn copy. You are a product marketer working on a new campaign. You are a coding tutor who is great at explaining Python to students. You can also ask for a response in the style of a specific persona or approach, like tell me how to solve this problem with the expertise of a Stanford business professor, or teach me about this esoteric company concept in a way a non-technical person could understand.

Another best practice: Ask Copilot to explain how it arrived at a response. “If you ask the model to explain itself, it will produce a better answer,” Teevan says. “It’s similar to how math teachers ask students to show their work—they get better answers from the kids.”

AI excels at imitation—large language models work by mimicking human conversations—so try to give examples of what you’d like the output to look like. Write a catchy slogan for a new brand of toothpaste that whitens teeth and freshens breath, using the following example for inspiration: “Good things never change.”

It’s also useful to think of our relationship with AI through a sports analogy, say researchers Jake Hofman, Dan Goldstein, and David Rothschild, who study AI-augmented cognition at Microsoft. At one end of the spectrum, the researchers say, AI can function like a steroid, giving people a short-term superhuman boost—instantaneous email drafts! quick social media copy!—when they simply offload work to it. In the middle of the spectrum, AI is like a high-quality running sneaker: it can speed up routine, time-consuming tasks (think cleaning and reformatting data), freeing up time and making people more productive in the moment without any long-term consequences. Where AI begins to truly transform work, though, is on the other end of the spectrum, when it serves as a coach, improving people’s own capabilities over time instead of merely assisting them in the moment. With thoughtful design and use, the researchers explain, AI tools can augment people’s innate abilities—leading to unprecedented boosts in productivity."
Microsoft_News,https://blogs.microsoft.com/on-the-issues/2023/11/16/accelerating-sustainability-ai-playbook/,,Accelerating Sustainability with AI: A Playbook,"11.29.2023: This blog was updated to make a cited example more accurate.

Today, Microsoft published a playbook for accelerating sustainability solutions with AI. You can read the foreword below and explore the piece in its entirety here.

AI is an essential tool for accelerating sustainability

Given the urgency of the planetary crisis, society needs to push harder on the AI accelerator while establishing guardrails that steer the world safely, securely, and equitably toward net-zero emissions, climate resilience, and a nature-positive future.

This year the world experienced the impacts of climate change like never before, from devastating wildfires to extreme weather. We are seeing and feeling the impact of climate change in our communities every day, and the science is clear: we need to act at an unprecedented scale and pace to address this crisis. It’s an enormous challenge and an enormous opportunity for the world to accelerate climate progress.

At Microsoft, we believe that for our company to do well, the world also needs to do well. We are at a critical moment for environmental sustainability, and we need government leaders, businesses, and civil society working in tandem. We also need to use every tool at our disposal to aid us in this journey, including AI.

AI is a vital tool to help accelerate the deployment of existing sustainability solutions and the development of new ones – faster, cheaper, and better.

In this paper, we outline the opportunities that AI provides for accelerating sustainability and the actions needed to ensure that we unlock the full potential of AI for sustainability.

AI’s three game-changing abilities

On the journey to net zero, the world has faced many bottlenecks to progress. AI has three unique abilities that can help society overcome key bottlenecks to this progress. These include the ability to:

1) Measure, predict, and optimize complex systems.

2) Accelerate the development of sustainability solutions.

3) Empower the sustainability workforce.

Measure, predict, and optimize complex systems

AI can enable people to discern patterns, predict outcomes, and optimize performance in systems that are too complex for traditional analytic methods. Sustainability practitioners are increasingly using AI’s analytical power for measuring and managing systems. Consider wildfires, which release about 7 gigatons (Gt) of carbon dioxide a year to the atmosphere. Wildfires are difficult to predict because of the complex interplay of many factors, including weather, vegetation, and land use. AI is enabling better wildfire prediction and making better management possible. At Microsoft, we are working with partners to use AI to help communities reduce wildfire risk.

Accelerate the development of sustainability solutions

AI can accelerate the discovery and development of sustainability solutions such as low-carbon materials, renewable energy production and storage, and climate-resilient crops. While AI is already contributing to sustainability-related discoveries, its transformative potential is only beginning to be realized. However, AI’s game-changing potential has already been demonstrated in other sectors. For example, AI was instrumental in accelerating the development of vaccines that mitigated the severity of the COVID-19 pandemic. AI was used to screen candidate messenger RNA (mRNA) molecules, which allowed Moderna to produce an effective COVID-19 vaccine in only six weeks, compared with the four years it would have taken with traditional methods.

Empower the sustainability workforce

AI can empower the sustainability workforce by enabling targeted training and assistance, while amplifying the efforts of sustainability professionals. We are working with partners to use large language models (LLMs) to access and distill the vast archives of sustainability science and policy documents so that sustainability professionals can easily find the information they need to understand and manage complex sustainability challenges.

In Part 1 of this report, we explore each of these three game-changing abilities in more detail.

Given the urgency of the planetary crisis, society needs to push harder on the AI accelerator while establishing guardrails that steer the world safely, securely, and equitably toward net-zero emissions, climate resilience, and a nature-positive future.

Microsoft’s AI & Sustainability Playbook

The global technology, energy, and policy landscape is ripe to be primed to unlock AI’s transformative potential for sustainability. This white paper introduces our five-point playbook for creating the needed enabling conditions.

Invest in AI to accelerate sustainability solutions Develop digital and data infrastructure for the inclusive use of AI for sustainability Minimize resource use in AI operations Advance AI policy principles and governance for sustainability Build workforce capacity to use AI for sustainability

These actions can unleash a flywheel for progress. AI can enable the development and deployment of sustainability solutions that accelerate decarbonization, which can enable the development of more sustainable AI operations, which in turn can enable AI to scale the deployment of more sustainability solutions. In Part 2 of this report, we describe this five-point playbook, summarized here.

Invest in AI to accelerate sustainability solutions

AI has numerous applications that can enhance efficiency, optimize business operations, and provide game-changing breakthroughs to sustainability bottlenecks. AI can help to expedite the integration of renewables onto electric grids, develop energy storage solutions, reduce food waste, foster the creation of high carbon-absorbing materials, and enable accurate weather forecasting weeks or even months in advance of current capabilities.

At Microsoft, through our AI for Good Lab, Microsoft Research’s AI4Science Lab, and Microsoft Climate Research Initiative (MCRI), we are already applying AI to overcome large sustainability bottlenecks. For example, in one MCRI project, we are partnering with researchers at the Massachusetts Institute of Technology (MIT) and University of California, Berkeley (UC Berkeley) to use generative machine learning models to develop new materials and system engineering approaches for applications such as carbon capture. Through the Microsoft Climate Innovation Fund, we are investing in companies like LineVision that are using AI to expand the capacity of transmission lines.

Develop digital and data infrastructure for the inclusive use of AI for sustainability

Data is the foundation on which AI operates, shaping its insights, predictions, and decision-making capabilities. Yet, there are major gaps and accessibility challenges that constrain the development of accurate and representative AI models for sustainability. For example, while AI is critical for optimizing the world’s electricity distribution networks, its use is limited by the availability of detailed, real-time data, which is lacking in many regions. Or, consider biodiversity data, where 80 percent of data in the Global Biodiversity Information Facility (GBIF) comes from just 10 countries.

Even when data exists, it can be inaccessible or difficult to use because it is locked in institutional silos, not digitalized, or in incompatible formats. Data standards, sharing mechanisms, and platforms are needed to increase the usability of sustainability data in AI models.

To use the full potential of AI, sustainability solution providers need access to the internet and compute capacity. The Microsoft Airband Initiative is working with our global ecosystem of partners to bring internet access to 250 million people in unserved and underserved communities around the world by 2025, including 100 million in Africa.

Minimize resource use in AI operations

As the infrastructure needed to support AI models expands, demand for resources such as energy and water will rise. History suggests that innovation can curb that demand. Take datacenters, for example. Between 2010 and 2020, global datacenter workloads increased by approximately 9x, while datacenter electricity demand increased by only 10 percent.

At Microsoft, we are continuously researching and innovating ways to make our datacenters and AI systems ever more energy and water efficient. We are reducing our dependence on freshwater from municipal sources for datacenter cooling and investing in water replenishment in water-stressed basins. We have also been developing advanced cooling methods such as liquid cooling to support AI chips with lower energy and water overheads. We have partnered with the Green Software Foundation to develop and advance carbon-aware software practices, such as software designed to run at times and locations that use the least carbon-intensive electricity sources available. These principles apply to all software workloads, including AI.

Advance AI policy principles and governance for sustainability

AI technologies can have a positive impact on both the environment and society by accelerating sustainable business practices and the energy transition. The infrastructure that hosts the computing power needed to yield these benefits may affect resource use too, such as by increasing power needs while reducing water reliance. Governments have an opportunity to enable the positive impacts of AI by crafting policies that harness its capabilities to benefit and ensure alignment with sustainability outcomes while also mitigating the resource impact that will result from the increased demand for AI.

At Microsoft, we will continue to use our voice to support grid decarbonization and carbon reporting, reduction, and removal policies. In September 2022, we outlined the priorities and principles that guide our advocacy on carbon and electricity policy around the world to accelerate carbon reporting, reduction, and removal and to expand carbon-free electricity. We also intend to expand our advocacy for extending existing sustainability policy frameworks to include AI and aligning government policies to incentivize the use of AI to enable sustainability outcomes.

We also persist in our efforts to strengthen AI governance, helping to ensure trust among users, stakeholders, and the wider public—an indispensable basis for AI’s integral role in advancing sustainability. As the application of AI expands into critical sustainability infrastructure, including power grids and water utilities, the safety, security, and reliability of these AI systems become paramount. We are committed to building and using AI responsibly, as recently outlined in our Governing AI report.

Build workforce capacity to use AI for sustainability

To harness the transformative power of AI for sustainability requires a solid foundation of human capacity to use AI tools.

Building a workforce prepared to use AI for sustainability requires holistic learning pathways that cultivate AI fluency within the context of sustainability. To help people and communities around the world learn how to harness the power of AI, Microsoft recently launched a new AI Skills Initiative. We have also committed to bringing these AI skills to the sustainability workforce. Last year, we partnered with the global nonprofit INCO to launch a new Green Digital Skills certificate program to educate workers and jobseekers on the foundations of sustainability in technology and green design principles and practices. To date, 30,000 people from 140 countries have engaged in the certificate program.

Tracking AI’s impact on the global race to net zero

To ensure that AI is on track to accelerate sustainability progress, it will be essential to continually assess AI’s expected impact on the race to net zero. But this is not an easy task, as it requires projecting a range of interacting and uncertain factors, such as socioeconomic, policy, and technological developments.

Currently, AI compute accounts for only a fraction of the electricity used by datacenters, which collectively use about 1 percent of global electricity supply. How much this increases and how AI growth affects the global race to net zero will depend on many factors. Innovations that drive efficiency gains in both the computing infrastructure and AI operations will have a large impact on future AI energy use. The carbon emissions implications of increased energy demand will depend on the broader policy context in which AI operates and how rapidly electric grids are decarbonized. And finally, AI’s mpact on the global race to net zero depends on how much it enables sustainability solutions.

In Part 3 of this report, we explore what is needed to better assess and track AI’s impact on the global path to net zero. In particular, we highlight the importance of using scenario analysis to help inform and guide AI development for sustainability.

Understanding AI’s impact on the global race to net-zero emissions requires answering three questions:

How much energy is the global expansion of AI compute likely to consume? How fast will the world’s electric grids decarbonize? To what extent will AI enable sustainability solutions?

To use AI effectively to accelerate sustainability, businesses, governments, and civil society must work together to create the enabling conditions while continually monitoring the factors that will determine AI’s impact on the world’s race to net zero.

When we use it ethically and responsibly, AI can be an essential tool to accelerate progress toward sustainability. Together, we have the opportunity to ensure that it does. We invite you to join us in unlocking the accelerating power of AI for sustainability.

Tags: AI, Responsible AI, sustainability"
Microsoft_News,https://blogs.microsoft.com/blog/2023/11/15/microsoft-ignite-2023-ai-transformation-and-the-technology-driving-change/,,Microsoft Ignite 2023: AI transformation and the technology driving change,"As we reach the end of 2023, nearly every industry is undergoing a collective transformation – discovering entirely new ways of working due to AI advancements.

Microsoft Ignite is a showcase of the advances being developed to help customers, partners and developers achieve the total value of Microsoft’s technology and reshape the way work is done.

As we round out the year, there are strong signals of AI’s potential to transform work. Take our latest Work Trend Index. Eight months ago, we introduced Copilot for Microsoft 365 to reduce digital debt and increase productivity so people can focus on the work that is uniquely human. What everyone wants to know now is: Will Copilot really change work, and how? Our research, using a combination of surveys and experiments, shows the productivity gains are real:

70% of Copilot users said they were more productive and 68% said it improved the quality of their work; 68% say it helped jumpstart the creative process.

of Copilot users said they were more productive and said it improved the quality of their work; say it helped jumpstart the creative process. Overall, users were 29% faster at specific tasks (searching, writing and summarizing).

faster at specific tasks (searching, writing and summarizing). Users caught up on a missed meeting nearly 4x faster.

faster. 64% of users said Copilot helps them spend less time processing email.

of users said Copilot helps them spend less time processing email. 87% of users said Copilot makes it easier to get started on a first draft.

of users said Copilot makes it easier to get started on a first draft. 75% of users said Copilot “saves me time by finding whatever I need in my files.”

of users said Copilot “saves me time by finding whatever I need in my files.” 77% of users said once they use Copilot, they don’t want to give it up.

Today, we will make about 100 news announcements that touch on multiple layers of an AI-forward strategy, from adoption to productivity to security. We’ll zoom in on a few key areas of impact below.

Rethinking cloud infrastructure

Microsoft has led with groundbreaking advances like partnerships with OpenAI and the integration of ChatGPT capabilities into tools used to search, collaborate, work and learn. As we accelerate further into AI, Microsoft is rethinking cloud infrastructure to ensure optimization across every layer of the hardware and software stack.

At Ignite we are announcing new innovations across our datacenter fleet, including the latest AI optimized silicon from our industry partners and two new Microsoft-designed chips.

Microsoft Azure Maia, an AI Accelerator chip designed to run cloud-based training and inferencing for AI workloads such as OpenAI models, Bing, GitHub Copilot and ChatGPT.

an AI Accelerator chip designed to run cloud-based training and inferencing for AI workloads such as OpenAI models, Bing, GitHub Copilot and ChatGPT. Microsoft Azure Cobalt, a cloud-native chip based on Arm architecture optimized for performance, power efficiency and cost-effectiveness for general purpose workloads.

a cloud-native chip based on Arm architecture optimized for performance, power efficiency and cost-effectiveness for general purpose workloads. Additionally, we are announcing the general availability of Azure Boost, a system that makes storage and networking faster by moving those processes off the host servers onto purpose-built hardware and software.

Complementing our custom silicon, we are expanding partnerships with our silicon providers to provide infrastructure options for customers.

We’ll be adding AMD MI300X accelerated virtual machines (VMs) to Azure. The ND MI300 VMs are designed to accelerate the processing of AI workloads for high range AI model training and generative inferencing, and will feature AMD’s latest GPU, the AMD Instinct MI300X.

The preview of the new NC H100 v5 Virtual Machine Series built for NVIDIA H100 Tensor Core GPUs, offering greater performance, reliability and efficiency for mid-range AI training and generative AI inferencing. We’re also announcing plans for the ND H200 v5 Virtual Machine Series, an AI-optimized VM featuring the upcoming NVIDIA H200 Tensor Core GPU.

Extending the Microsoft Copilot experience

Over the past year we have continued to refine our vision for Microsoft Copilot, a set of tools that help people achieve more using AI. To go beyond individual productivity, we are extending Microsoft Copilot offerings across solutions to transform productivity and business processes for every role and function – from office workers and front-line workers to developers and IT professionals.

Microsoft is the Copilot company, and we believe in the future there will be a Copilot for everyone and for everything you do. Some of our Copilot-related announcements and updates include:

Microsoft Copilot for Microsoft 365: This month, Copilot for Microsoft 365 became generally available for enterprises. Already customers like Visa, BP, Honda and Pfizer and partners like Accenture, EY, KPMG, Kyndryl and PwC are using Copilot. We continue to bring new value, based on learnings from our Early Access Program and other research channels. The new Microsoft Copilot Dashboard shows customers how Copilot is impacting their organization – with insights like those found in our Work Trend Index. We’re introducing new personalization capabilities that help Copilot offer responses that are tailored to your unique preferences and role. To empower teamwork, new features for Copilot in Outlook help you prep for meetings, and during meetings, new whiteboarding and note-taking experiences for Copilot in Microsoft Teams keep everyone on the same page. And customers who need it can now use Copilot during a meeting without transcription retention. When you give Copilot a seat at the table, it goes beyond being your personal assistant to helping the entire team – check out the Microsoft 365 blog for updates across the suite including PowerPoint, Excel, Microsoft Viva and more.

This month, Copilot for Microsoft 365 became generally available for enterprises. Already customers like Visa, BP, Honda and Pfizer and partners like Accenture, EY, KPMG, Kyndryl and PwC are using Copilot. We continue to bring new value, based on learnings from our Early Access Program and other research channels. The new Microsoft Copilot Dashboard shows customers how Copilot is impacting their organization – with insights like those found in our Work Trend Index. We’re introducing new personalization capabilities that help Copilot offer responses that are tailored to your unique preferences and role. To empower teamwork, new features for Copilot in Outlook help you prep for meetings, and during meetings, new whiteboarding and note-taking experiences for Copilot in Microsoft Teams keep everyone on the same page. And customers who need it can now use Copilot during a meeting without transcription retention. When you give Copilot a seat at the table, it goes beyond being your personal assistant to helping the entire team – check out the Microsoft 365 blog for updates across the suite including PowerPoint, Excel, Microsoft Viva and more. Microsoft Copilot Studio: AI transformation begins by tapping into an organization’s unique data and workflows. Microsoft Copilot Studio is a low-code tool designed to customize Microsoft Copilot for Microsoft 365 by integrating business-critical data and build custom copilots for internal or external use. Copilot Studio works with connectors, plugins and GPTs, allowing IT teams to steer Copilot to the best data sources for specific queries.

AI transformation begins by tapping into an organization’s unique data and workflows. Microsoft Copilot Studio is a low-code tool designed to customize Microsoft Copilot for Microsoft 365 by integrating business-critical data and build custom copilots for internal or external use. Copilot Studio works with connectors, plugins and GPTs, allowing IT teams to steer Copilot to the best data sources for specific queries. Microsoft Copilot for Service: The newest copilot to provide role-based support helps businesses accelerate their AI transformation of customer service. Copilot for Service includes Microsoft Copilot for Microsoft 365 and helps extend existing contact centers with generative AI. In customer interactions, agents can ask Copilot for Service questions in natural language and receive relevant insights based on data sources from knowledge repositories, leading to faster and smarter resolutions.

The newest copilot to provide role-based support helps businesses accelerate their AI transformation of customer service. Copilot for Service includes Microsoft Copilot for Microsoft 365 and helps extend existing contact centers with generative AI. In customer interactions, agents can ask Copilot for Service questions in natural language and receive relevant insights based on data sources from knowledge repositories, leading to faster and smarter resolutions. Copilot in Microsoft Dynamics 365 Guides: Combining the power of generative AI and mixed reality, this copilot helps frontline workers complete complex tasks and resolve issues faster without disrupting workflow. Available first on HoloLens 2, the hands-free copilot will help service industry professionals use natural language and human gestures to offer interactive guidance through content and holograms overlaid on the equipment.

Combining the power of generative AI and mixed reality, this copilot helps frontline workers complete complex tasks and resolve issues faster without disrupting workflow. Available first on HoloLens 2, the hands-free copilot will help service industry professionals use natural language and human gestures to offer interactive guidance through content and holograms overlaid on the equipment. Microsoft Copilot for Azure: This is an AI companion for IT that simplifies day-to-day IT administration. More than just a tool, it is a unified chat experience that understands the user’s role and goals, and enhances the ability to design, operate and troubleshoot apps and infrastructure. Copilot for Azure helps IT teams gain new insights into their workloads, unlock untapped Azure functionality and orchestrate tasks across both cloud and edge.

This is an AI companion for IT that simplifies day-to-day IT administration. More than just a tool, it is a unified chat experience that understands the user’s role and goals, and enhances the ability to design, operate and troubleshoot apps and infrastructure. Copilot for Azure helps IT teams gain new insights into their workloads, unlock untapped Azure functionality and orchestrate tasks across both cloud and edge. Bringing Copilot to everyone: Our efforts to simplify the user experience and make Copilot more accessible to everyone starts with Bing, our leading experience for the web. Bing Chat and Bing Chat Enterprise will now simply become Copilot. With these changes, when signed in with a Microsoft Entra ID, customers using Copilot in Bing, Edge and Windows will receive the benefit of commercial data protection. Over time, Microsoft will also expand the eligibility of Copilot with commercial data protection to even more Entra ID (formerly Azure Active Directory) users at no additional cost. Copilot (formerly Bing Chat and Bing Chat Enterprise) will be out of preview and become generally available starting Dec. 1. Learn more here.

Reinforcing the data and AI connection

AI is only as good as the data that fuels it. That’s why Microsoft is committed to creating an integrated, simplified experience to connect your data to our AI tools.

Microsoft Fabric is part of that solution. Available now, Microsoft Fabric reshapes how teams work with data by bringing everyone together on a single, AI-powered platform that unifies all those data estates on an enterprise-grade data foundation.

Copilot in Microsoft Fabric also integrates with Microsoft Office and Teams to foster a data culture to scale the power of data value creation throughout the organization. We’ve made more than 100 feature updates since Build and expanded our ecosystem with industry leading partners, and have over 25,000 customers including Milliman, Zeiss, London Stock Exchange and EY using it today.

Unlocking more value for developers with Azure AI

We continue to expand choice and flexibility in generative AI models to offer developers the most comprehensive selection. With Model-as-a-Service, a new feature in the model catalog we announced at Microsoft Build, pro developers will be able to easily integrate the latest AI models, such as Llama 2 from Meta and upcoming premium models from Mistral, and Jais from G42, as API endpoints to their applications. They can also customize these models with their own data without needing to worry about setting up and managing the GPU infrastructure, helping eliminate complexity.

With the preview of Azure AI Studio, there is now a unified and trusted platform to help organizations more easily explore, build, test and deploy AI apps – all in one place. With Azure AI Studio, you can build your own copilots, train your own, or ground other foundational and open models with data that you bring.

And Vector Search, a feature of Azure AI Search, is now generally available, so organizations can generate highly accurate experiences for every user in their generative AI applications.

The new GPT-3.5 Turbo model with a 16K token prompt length will be generally available and GPT-4 Turbo will be in public preview in Azure OpenAI Service at the end of November 2023. GPT-4 Turbo will enable customers to extend prompt length and bring even more control and efficiency to their generative AI applications.

GPT-4 Turbo with Vision is coming soon to preview and DALL·E 3 is now available in public preview in Azure OpenAI Service, helping fuel the next generation of enterprise solutions along with GPT-4, so organizations can pursue advanced functionalities with images. And when used with our Azure AI Vision service, GPT-4 Turbo with Vision even understands video for generating text outputs, furthering human creativity.

Enabling the responsible deployment of AI

Microsoft leads the industry in the safe and responsible use of AI. The company has set the standard with an industry-leading commitment to defend and indemnify commercial customers from lawsuits for copyright infringement – the Copilot Copyright Commitment (CCC).

Today, Microsoft takes its commitment one step further by announcing the expansion of the CCC to customers using Azure OpenAI Service. The new benefit will be called the Customer Copyright Commitment. As part of this expansion, Microsoft has published new documentation to help Azure OpenAI Service customers implement technical measures to mitigate the risk of infringing content. Customers will need to comply with the documentation to take advantage of the benefit.

And Azure AI Content Safety is now generally available, helping organizations detect and mitigate harmful content and create better online experiences. Customers can use Azure AI Content Safety as a built-in-safety system within Azure OpenAI Service, for open-source models as part of their prompt engineering in Azure Machine Learning, or as a standalone API service.

Introducing new experiences in Windows to empower employees, IT and developers

We continue to invest in and build Windows to empower people to navigate the platform shift to AI. We are thrilled to introduce new experiences in Windows 11 and Windows 365 for IT and employees that unlock new ways of working and make more AI accessible across any device. To further our mission of making Windows the home for developers and the best place for AI development, we announced a host of new AI and productivity tools for developers, including Windows AI Studio.

Announcing NVIDIA AI foundry service

Aimed at helping enterprises and startups supercharge the development, tuning and deployment of their own custom AI models on Microsoft Azure, NVIDIA will announce their AI foundry service running on Azure. The NVIDIA AI foundry service pulls together three elements – a collection of NVIDIA AI Foundation models, NVIDIA NeMo framework and tools, and NVIDIA DGX Cloud AI supercomputing and services – that give enterprises an end-to-end solution for creating custom generative AI models. Businesses can then deploy their models with NVIDIA AI Enterprise software on Azure to power generative AI applications, including intelligent search, summarization and content generation.

Strengthening defenses in the era of AI

The threat landscape has evolved dramatically in recent years, and at Microsoft Ignite we are introducing new technologies across Microsoft’s suite of security solutions to help defenders make the world a safer place.

Microsoft Sentinel and Microsoft Defender XDR (previously Microsoft 365 Defender) will be combined to create the industry’s first Unified Security Operations Platform, with embedded Security Copilot experiences. With built-in generative AI, it’s a single, powerful experience focused on protecting threats at machine speed and aiding defenders by simplifying the complexity of their environment.

Additionally, the expansion of Security Copilot embedded within Intune, Purview and Entra will help IT administrators, compliance units and identity teams simplify complex scenarios. In Entra, identity administrators can quickly troubleshoot identity access. In Purview, data security alerts deliver rich context to help resolve problems faster. In Intune, IT administrators can use “what if” analysis to keep business running while improving governance and compliance.

And that’s just a snapshot of what we’ll be announcing at Ignite. As a reminder, you can view keynote sessions from Satya Nadella, Rajesh Jha and Jared Spataro, Charlie Bell and Vasu Jakkal, and Scott Guthrie live or on-demand.

Plus, you can get more on all these announcements by exploring the Book of News, the official compendium of all today’s news, and the product blogs below.

RELATED:

Watch the keynotes and get all the latest photos, videos and more from Microsoft Ignite

The online event for Microsoft Ignite

With a systems approach to chips, Microsoft aims to tailor everything ‘from silicon to service’ to meet AI demand

Introducing new Copilot experiences to boost productivity and elevate customer experiences across the organization

Simplify IT management with Microsoft Copilot for Azure – save time and get answers fast

Introducing Microsoft Copilot Studio and new features in Copilot for Microsoft 365

Announcing general availability of vector search and semantic ranker in Azure AI Search

GPT-4 Turbo with Vision on Azure OpenAI Service

How Azure AI Content Safety helps protect users from the classroom to the chatroom

Elevating the developer experience on Windows with new AI tools and productivity tools

Microsoft unveils expansion of AI for security and security for AI at Microsoft Ignite

Tags: AI, Azure AI Content Safety, Azure AI Studio, Microsoft 365, Microsoft Copilot, Microsoft Fabric, Microsoft Ignite 2023, Microsoft Security Copilot, Model-as-a-Service"
Microsoft_News,https://news.microsoft.com/source/features/ai/in-house-chips-silicon-to-service-to-meet-ai-demand/,,"With a systems approach to chips, Microsoft aims to tailor everything ‘from silicon to service’ to meet AI demand","“Microsoft is building the infrastructure to support AI innovation, and we are reimagining every aspect of our datacenters to meet the needs of our customers,” said Scott Guthrie, executive vice president of Microsoft’s Cloud + AI Group. “At the scale we operate, it’s important for us to optimize and integrate every layer of the infrastructure stack to maximize performance, diversify our supply chain and give customers infrastructure choice.”

Optimizing every layer of the stack

Chips are the workhorses of the cloud. They command billions of transistors that process the vast streams of ones and zeros flowing through datacenters. That work ultimately allows you to do just about everything on your screen, from sending an email to generating an image in Bing with a simple sentence.

Much like building a house lets you control every design choice and detail, Microsoft sees the addition of homegrown chips as a way to ensure every element is tailored for Microsoft cloud and AI workloads. The chips will nestle onto custom server boards, placed within tailor-made racks that fit easily inside existing Microsoft datacenters. The hardware will work hand in hand with software – co-designed together to unlock new capabilities and opportunities.

The end goal is an Azure hardware system that offers maximum flexibility and can also be optimized for power, performance, sustainability or cost, said Rani Borkar, corporate vice president for Azure Hardware Systems and Infrastructure (AHSI).

“Software is our core strength, but frankly, we are a systems company. At Microsoft we are co-designing and optimizing hardware and software together so that one plus one is greater than two,” Borkar said. “We have visibility into the entire stack, and silicon is just one of the ingredients.”

Rani Borkar, corporate vice president for Azure Hardware Systems and Infrastructure (AHSI) at Microsoft. Photo courtesy of Microsoft.

At Microsoft Ignite, the company also announced the general availability of one of those key ingredients: Azure Boost, a system that makes storage and networking faster by taking those processes off the host servers onto purpose-built hardware and software.

To complement its custom silicon efforts, Microsoft also announced it is expanding industry partnerships to provide more infrastructure options for customers. Microsoft launched a preview of the new NC H100 v5 Virtual Machine Series built for NVIDIA H100 Tensor Core GPUs, offering greater performance, reliability and efficiency for mid-range AI training and generative AI inferencing. Microsoft will also add the latest NVIDIA H200 Tensor Core GPU to its fleet next year to support larger model inferencing with no increase in latency.

The company also announced it will be adding AMD MI300X accelerated VMs to Azure. The ND MI300 virtual machines are designed to accelerate the processing of AI workloads for high range AI model training and generative inferencing, and will feature AMD’s latest GPU, the AMD Instinct MI300X.

By adding first party silicon to a growing ecosystem of chips and hardware from industry partners, Microsoft will be able to offer more choice in price and performance for its customers, Borkar said.

“Customer obsession means we provide whatever is best for our customers, and that means taking what is available in the ecosystem as well as what we have developed,” she said. “We will continue to work with all of our partners to deliver to the customer what they want.”

Co-evolving hardware and software

The company’s new Maia 100 AI Accelerator will power some of the largest internal AI workloads running on Microsoft Azure. Additionally, OpenAI has provided feedback on Azure Maia and Microsoft’s deep insights into how OpenAI’s workloads run on infrastructure tailored for its large language models is helping inform future Microsoft designs.

“Since first partnering with Microsoft, we’ve collaborated to co-design Azure’s AI infrastructure at every layer for our models and unprecedented training needs,” said Sam Altman, CEO of OpenAI. “We were excited when Microsoft first shared their designs for the Maia chip, and we’ve worked together to refine and test it with our models. Azure’s end-to-end AI architecture, now optimized down to the silicon with Maia, paves the way for training more capable models and making those models cheaper for our customers.”

The Maia 100 AI Accelerator was also designed specifically for the Azure hardware stack, said Brian Harry, a Microsoft technical fellow leading the Azure Maia team. That vertical integration – the alignment of chip design with the larger AI infrastructure designed with Microsoft’s workloads in mind – can yield huge gains in performance and efficiency, he said.

“Azure Maia was specifically designed for AI and for achieving the absolute maximum utilization of the hardware,” he said.

Meanwhile, the Cobalt 100 CPU is built on Arm architecture, a type of energy-efficient chip design, and optimized to deliver greater efficiency and performance in cloud native offerings, said Wes McCullough, corporate vice president of hardware product development. Choosing Arm technology was a key element in Microsoft’s sustainability goal. It aims to optimize “performance per watt” throughout its datacenters, which essentially means getting more computing power for each unit of energy consumed.

These servers inside a datacenter in Quincy, Washington, are the first to be powered by the Microsoft Azure Cobalt 100 CPU. Photo by John Brecher for Microsoft.

“The architecture and implementation is designed with power efficiency in mind,” he said. “We’re making the most efficient use of the transistors on the silicon. Multiply those efficiency gains in servers across all our datacenters, it adds up to a pretty big number.”

Custom hardware, from chip to datacenter

Before 2016, most layers of the Microsoft cloud were bought off the shelf, said Pat Stemen, partner program manager on the AHSI team. Then Microsoft began to custom build its own servers and racks, driving down costs and giving customers a more consistent experience. Over time, silicon became the primary missing piece.

The ability to build its own custom silicon allows Microsoft to target certain qualities and ensure that the chips perform optimally on its most important workloads. Its testing process includes determining how every single chip will perform under different frequency, temperature and power conditions for peak performance and, importantly, testing each chip in the same conditions and configurations that it would experience in a real-world Microsoft datacenter.

The silicon architecture unveiled today also lets Microsoft not only enhance cooling efficiency but optimize the use of its current datacenter assets and maximize server capacity within its existing footprint, the company said.

For example, no racks existed to house the unique requirements of the Maia 100 server boards. So Microsoft built them from scratch. These racks are wider than what typically sits in the company’s datacenters. That expanded design provides ample space for both power and networking cables, essential for the unique demands of AI workloads.

A custom-built rack for the Maia 100 AI Accelerator and its “sidekick” inside a thermal chamber at a Microsoft lab in Redmond, Washington. The sidekick acts like a car radiator, cycling liquid to and from the rack to cool the chips as they handle the computational demands of AI workloads. Photo by John Brecher for Microsoft.

Such AI tasks come with intensive computational demands that consume more power. Traditional air-cooling methods fall short for these high-performance chips. As a result, liquid cooling – which uses circulating fluids to dissipate heat – has emerged as the preferred solution to these thermal challenges, ensuring they run efficiently without overheating.

But Microsoft’s current datacenters weren’t designed for large liquid chillers. So it developed a “sidekick” that sits next to the Maia 100 rack. These sidekicks work a bit like a radiator in a car. Cold liquid flows from the sidekick to cold plates that are attached to the surface of Maia 100 chips. Each plate has channels through which liquid is circulated to absorb and transport heat. That flows to the sidekick, which removes heat from the liquid and sends it back to the rack to absorb more heat, and so on.

The tandem design of rack and sidekick underscores the value of a systems approach to infrastructure, McCullough said. By controlling every facet — from the low-power ethos of the Cobalt 100 chip to the intricacies of datacenter cooling — Microsoft can orchestrate a harmonious interplay between each component, ensuring that the whole is indeed greater than the sum of its parts in reducing environmental impact.

Microsoft has shared its design learnings from its custom rack with industry partners and can use those no matter what piece of silicon sits inside, said Stemen. “All the things we build, whether infrastructure or software or firmware, we can leverage whether we deploy our chips or those from our industry partners,” he said. “This is a choice the customer gets to make, and we’re trying to provide the best set of options for them, whether it’s for performance or cost or any other dimension they care about.”

Microsoft plans to expand that set of options in the future; it is already designing second-generation versions of the Azure Maia AI Accelerator series and the Azure Cobalt CPU series. The company’s mission remains clear, Stemen said: optimize every layer of its technological stack, from the core silicon to the end service.

“Microsoft innovation is going further down in the stack with this silicon work to ensure the future of our customers’ workloads on Azure, prioritizing performance, power efficiency and cost,” he said. “We chose this innovation intentionally so that our customers are going to get the best experience they can have with Azure today and in the future.”

Related resources:

Read more: Microsoft delivers purpose-built cloud infrastructure in the era of AI

Read more: Azure announces new AI optimized VM series featuring AMD’s flagship MI300X GPU

Read more: Introducing Azure NC H100 v5 VMs for mid-range AI and HPC workloads

Learn more: Microsoft Ignite

Top image: A technician installs the first server racks containing Microsoft Azure Cobalt 100 CPUs at a datacenter in Quincy, Washington. It’s the first CPU designed by Microsoft for the Microsoft Cloud. Photo by John Brecher for Microsoft."
Microsoft_News,https://blogs.windows.com/msedgedev/2023/11/13/ai-powered-edge-holiday-season/,,"From shopping to entertaining, AI-powered Microsoft Edge helps you tackle the holiday season, while preserving the joy of it","This time of year can be magical, nostalgic, and joyful. So much time spent with family and friends, celebrating, and making new memories. It is a great time to reflect on what the season is all about, which is spending time with those we love. But let’s be honest, it can also be stressful. Most of us keep a growing list of to-dos. There is a lot of pressure to create perfect moments. Not to mention the added stress of rising inflation, and our ever-evolving budget racing to keep up. And with online shopping becoming so prevalent, we are worried about getting a great deal while protecting our sensitive data online.

Microsoft Edge is here to help you recapture the essence of the holidays, giving you the tools to tackle your to-do list with ease so you can focus more on joy and connection this season.

Remember, if you’re running a Windows PC, you already have Microsoft Edge installed, so check it out and see why Microsoft Edge is the smarter way to browse. For those who want to try Microsoft Edge and are on a macOS, mobile or Linux device, download it and let us know what you think!

Check out how Edge is your AI-powered assistant this holiday season.

A smarter way to find the perfect gift at the right price

It is no secret that shopping online is the status quo. The convenience of shopping in the comfort of your home, and the multitude of choices, makes it all very appealing. But it’s not all rosy. More choices mean it can be very overwhelming to choose the right product at the best price. It gets even more difficult knowing what will fit our needs and what reviews to trust. All of this diminishes the convenience – and joy – of online shopping. Due to our powerful set of built-in features, Edge and Bing are here to help put the joy back into shopping, by making it easier for you to discover or find what you need in less time, all while experiencing the thrill of scoring great deals. With that in mind, I’m excited to announce the latest features available in Edge and Bing:

In September, we announced Copilot in Microsoft Shopping and today I’m pleased to share it is now rolling out and will be widely available soon, just in time to make your holiday shopping easier. Copilot in Microsoft Shopping is designed to be your own personal shopper and help you find what you need in less time. You can give it prompts like “what are some gift ideas for teenage boys?” and Copilot will ask you a set of intelligent questions to help narrow down ideas for gifts for your nephew. Coming soon, you’ll also be able to simply share a picture of the product you’re looking for, and Copilot will guide you to the right match. This experience is available on PC to start and will be coming to mobile soon. To access Copilot in Microsoft Shopping, simply open your Edge browser, then in the address bar enter https://bing.com/shop/ai to get started. Copilot in Microsoft Shopping is available on any browser, but to unlock the best experience (and savings!), we recommend Microsoft Edge.



and today I’m pleased to share it is now rolling out and will be widely available soon, just in time to make your holiday shopping easier. Copilot in Microsoft Shopping is designed to be your own personal shopper and help you find what you need in less time. You can give it prompts like “what are some gift ideas for teenage boys?” and Copilot will ask you a set of intelligent questions to help narrow down ideas for gifts for your nephew. Coming soon, you’ll also be able to simply share a picture of the product you’re looking for, and Copilot will guide you to the right match. This experience is available on PC to start and will be coming to mobile soon. To access Copilot in Microsoft Shopping, simply open your Edge browser, then in the address bar enter https://bing.com/shop/ai to get started. Copilot in Microsoft Shopping is available on any browser, but to unlock the best experience (and savings!), we recommend Microsoft Edge. It’s not just the overwhelming number of choices on the internet that makes online shopping so challenging. Knowing what reviews and product ratings to trust can be time-consuming. In June, we announced Review Summaries and today I’m pleased to say that it’s now widely available. Edge and Bing can do the work for you and help you shop with confidence, giving you a quick look at top insights and popular opinions about the product. To access Review Summaries, simply click on the Copilot icon from the Edge sidebar and ask it to summarize what people are saying about an item online.

Stay safer while you shop online

While we all enjoy the convenience and choices that shopping online offers, the flip side of this is it results in transactions using our private information, especially our credit cards. Microsoft Edge is loaded with security features and advanced controls designed to keep even the most tech-savvy users safer from online threats.

Let’s start with our newest feature, Edge Secure Network . This feature gives you security protection that is smart enough to automatically turn on when you need it most. Edge Secure Network uses VPN technology to stop third parties and bad actors from accessing your sensitive information, so you can make purchases online, fill out forms, and keep your browsing activity away from prying eyes. A lot of us are probably traveling this season and sometimes accessing open Wi-Fi networks at airports or coffee shops. Edge Secure Network will turn on in those instances and even when you visit a website that isn’t secured by HTTPS. To get started, sign into Microsoft Edge with your personal Microsoft account, and toggle on Edge Secure Network in Browser Essentials. This feature is built-in to the browser and free to use.

. This feature gives you security protection that is smart enough to automatically turn on when you need it most. Edge Secure Network uses VPN technology to stop third parties and bad actors from accessing your sensitive information, so you can make purchases online, fill out forms, and keep your browsing activity away from prying eyes. A lot of us are probably traveling this season and sometimes accessing open Wi-Fi networks at airports or coffee shops. Edge Secure Network will turn on in those instances and even when you visit a website that isn’t secured by HTTPS. To get started, sign into Microsoft Edge with your personal Microsoft account, and toggle on Edge Secure Network in Browser Essentials. This feature is built-in to the browser and free to use. With Password Health indicator and Password Monitor , we aim to give you peace of mind. These two features combined can help you keep an eye on potentially leaked log-in information and let you know if the password you’re setting on retailer sites this holiday season is strong enough. This is so valuable because, let’s face it, many of us have racked up quite a list of log-in credentials over the years. At Microsoft Edge, we want to provide tools that give you peace of mind and help you keep your credentials safer, while still enjoying the efficiencies that online shopping has to offer.

indicator and , we aim to give you peace of mind. These two features combined can help you keep an eye on potentially leaked log-in information and let you know if the password you’re setting on retailer sites this holiday season is strong enough. This is so valuable because, let’s face it, many of us have racked up quite a list of log-in credentials over the years. At Microsoft Edge, we want to provide tools that give you peace of mind and help you keep your credentials safer, while still enjoying the efficiencies that online shopping has to offer. Say you’re wanting to check your bank account after a particularly long grocery and holiday shopping spree. But you’re so tired from trying to juggle work, kids, and holiday prep that you add an extra letter to your bank’s URL. A lot of scammers hope you do just that, standing up fraudulent sites with that misspelled URL and giving them an opportunity to steal your personal/financial information and/or trick you to buy false products. This is called typo squatting. Website typo protection keeps you safe from landing on a malicious site by suggesting the website you intended to visit. Now you can rest assured that you will get to the site you wanted to visit, with added peace of mind.

keeps you safe from landing on a malicious site by suggesting the website you intended to visit. Now you can rest assured that you will get to the site you wanted to visit, with added peace of mind. Lastly, one of the most tedious things we do online when shopping or booking travel is filling out all the information needed to check out. It takes precious time away from an already extensive to-do list and time with our loved ones. Autofill in Edge has gotten much smarter and can help you get through those holiday travel bookings much faster. As you’re filling out your traveler details to book your flight, Autofill can now suggest completions when you type the first few characters in an online form field, so your saved info such as your passport number, frequent flyer account, and more can be quickly filled just by pressing right arrow or tab. Just go to Edge Settings > Profile to securely store and easily access your info.

Invitations, recipes, and all you need to entertain this holiday season

The best part of the holidays is spending time and making memories with our loved ones. And if you want to add party planner to your list of duties this season, with a little help, let Microsoft Edge spark your creativity, and save you time.

Copilot in Edge is your holiday planning assistant, helping you get through your to-do list in less time so you can enjoy the season. For example, if you are hosting a party, it is most likely that you’ll need to send an invite, but it may feel daunting in the context of everything you have to get done. With Copilot in Edge, you can create a wow-worthy AI-generated image to add to your holiday party email invite. Simply access Copilot from the sidebar and give it your prompt to get started. Once you have your image ready, you can save a copy and email it to attendees or share on social media. Your guests will be delighted once they receive it, and your one-of-a-kind image will set the perfect, personalized tone for your upcoming soiree.

is your holiday planning assistant, helping you get through your to-do list in less time so you can enjoy the season. For example, if you are hosting a party, it is most likely that you’ll need to send an invite, but it may feel daunting in the context of everything you have to get done. With Copilot in Edge, you can create a wow-worthy AI-generated image to add to your holiday party email invite. Simply access Copilot from the sidebar and give it your prompt to get started. Once you have your image ready, you can save a copy and email it to attendees or share on social media. Your guests will be delighted once they receive it, and your one-of-a-kind image will set the perfect, personalized tone for your upcoming soiree. For that same party, Copilot in Edge can help you finalize many other details. For example, need the perfect mocktail recipe to go with your dinner menu? Copilot in Edge has your back. Let’s say you are researching recipes that will work for your party. You can ask Copilot in Edge “what are some mocktails that would pair best” and Copilot will give you suggestions and find recipes for you. And every good dinner party needs the right music – Copilot will also help you build the perfect playlist for your gathering. With the help of Copilot in Edge, your dinner party will have every last detail sorted out, and only you will know that Edge and the power of AI allowed you to plan and prepare, smarter and more efficiently.

can help you finalize many other details. For example, need the perfect mocktail recipe to go with your dinner menu? Copilot in Edge has your back. Let’s say you are researching recipes that will work for your party. You can ask Copilot in Edge “what are some mocktails that would pair best” and Copilot will give you suggestions and find recipes for you. And every good dinner party needs the right music – Copilot will also help you build the perfect playlist for your gathering. With the help of Copilot in Edge, your dinner party will have every last detail sorted out, and only you will know that Edge and the power of AI allowed you to plan and prepare, smarter and more efficiently. Lastly, I wanted to share one of our latest features that has become an instant crowd favorite on social media. That feature is split screen. Let’s face it, we never stop multitasking, and the holidays are probably the time of year that tests our multi-tasking limits. We recently launched split screen and since then, the feedback has been overwhelmingly positive. This tool allows you to simultaneously work on multiple tasks across two, side-by-side screens in one browsing tab with Microsoft Edge, helping boost your productivity and multitask more efficiently. That recipe you found with the help of Copilot? You can view it on one side, while on the other open a Word document in Edge to allow you to create a running grocery list for later. You can also view shopping pages side by side as you research the perfect decorations for your holiday gathering. All designed with you and your productivity in mind. To try split screen, simply select the split screen icon from the tool bar to get started.

We hope these tools and features help you tackle your to-do list with more ease, and most importantly, joy this holiday season. To learn more, visit https://aka.ms/holiday-shopping-edge and please continue to send us your feedback as we work to create web experiences and tools to give you a smarter way to browse."
Microsoft_News,https://news.microsoft.com/source/features/ai/4-misconceptions-about-ai/,,4 misconceptions about AI,"Myth 4: AI is inherently biased and should be avoided

It’s true that AI can be biased, from large language models trained on internet opinions to models built with data that reflect societal bias to products made by developers with preconceived beliefs.

But Allison encourages people to use AI as informed consumers who learn how the systems are built and understand the principles of companies building them. She says it’s important that developers train AI systems on diverse and representative datasets and use fair and unbiased algorithms. Microsoft AI customers can learn about the company’s practice of responsible AI by design and its work in building responsible AI systems that adhere to principles of fairness, reliability and transparency.

“We all had to learn at some point that not everything on the internet is true, and we have to do the same with AI,” Allison says. “Learn its biases. Learn its shortcomings. Learn its strengths and figure out how to use AI in your own life and make it a tool that serves you.”

Images created by Bing Image Creator. Images like these can be used as a starting point for designers and others to create illustrations. Photo of Karmel Allison, by Mark Maryanovich Photography, was added."
Microsoft_News,https://news.microsoft.com/europe/features/improving-lives-with-ai-and-digital-and-financial-inclusion-in-kenya-one-smartphone-at-a-time,,"Improving lives with AI, digital and financial inclusion in Kenya, one smartphone at a time","Supporting ‘financial resilience’

Founded in 2011 in Kenya, M-KOPA has expanded into Uganda, Nigeria and Ghana and is currently beginning operations in South Africa. By 2022, it had deployed more than $1 billion in credit with a focus on providing solutions that give people access to the digital world and help them financially in a way that is affordable and sustainable.

Nancy Sangoro, director of customer experience and retail at M-KOPA. Photo by Jenkins Kuyoh for Microsoft.

Nancy Sangoro, director of customer experience and retail at M-KOPA says, “Our mission is to make financing for everyday essentials affordable to everyone.”

That financing gives M-KOPA customers access to essential products they need to improve their lives, she says.

“When I think about the challenges that a lot of customers face, I can group them into two. One is financial resilience … Most customers are incapable of dealing with unforeseen emergency situations. Through our upgrade products like health insurance, these customers are able to deal with unforeseen emergencies.”

She says that M-KOPA has issued about 204,000 customers with health insurance policies.

“The second challenge relates to access to credit,” she says. “Eighty-two percent of our customers have reported that by being able to access credit, they’ve been able to expand their businesses and grow their income investing the excess funds in essentials like food, rent and education, which essentially improves their quality of life.”

Nicholas Njama, 44, a taxi driver in Nairobi, learned about M-KOPA at a critical moment in the fall 2022. His smartphone had broken, and he couldn’t afford to buy a new one. “I rely on my smartphone because many of my clients are in India and they need to be able to reach me for when they are here,” he says. “I was losing business.”

“A friend told me about M-KOPA and I applied for a phone,” he says. The company requires an initial deposit, typically about 20% of the cost of the phone. “I couldn’t have gotten a loan from a regular bank, and the payments were small enough.”

The M-KOPA app makes payments easy for clients and collects data for the company. Photo by Jenkins Kuyoh.

Once he paid it off, he had a credit line, and he took out loans to pay off school fees for his two children. One loan was 9,000 shillings, and the payback is 75 shillings a day (around 50 cents). The interest charges amount to about 2,000 shillings, according to an M-KOPA spokesperson.

“M-KOPA helped me because I was weighed down with school fees and I was carrying a balance,” he says. “I have one kid in high school and the other one in the second year of university.”

Njama, like many M-KOPA clients, stays with the company because it has become a trusted source of help to get ahead.

M-KOPA has been growing rapidly. And while part of M-KOPA’s mission is to help foster entrepreneurship, it also creates thousands of jobs. In Kenya alone, it has over 12,400 sales representatives and employees, many of whom are sales reps whose pay is based on commission for finding new clients.

Empowering women

Sangoro of M-KOPA says that female customers are more likely than their male counterparts to increase their spending on education and health. She says they are also more likely to report an improvement in their quality of life because they tend to save more and use earnings to support their families. Because of these trends, Sangoro says, M-KOPA is offering new opportunities to increase women’s financial access.

“One out of three of our customers are women, and two in five of our sales agents are also women,” she says.

Ruth Njuguna is an M-KOPA sales agent in the low-income community of Kawangware. Photo by Jenkins Kuyoh for Microsoft.

Ruth Njuguna, 27, is one of those sales agents. She sells phones where she lives, in the low-income community of Kawangware, about 15 kilometers, or 9 miles, west of Nairobi’s business center.

Unemployment there is high and daily income averages less than 300 shillings, or about $2, daily.

After losing her smartphone more than a year ago, a friend told her about M-KOPA. “Being able to get a good quality smartphone and having access to it at such a low price appealed to me,” she says. The low payments made it more attractive than settling for what she could afford at a regular smartphone store.

She later joined M-KOPA as a direct sales representative, selling M-KOPA smartphones in her community and earning a commission in return. The customers who buy an M-KOPA smartphone and make timely payments on it get access to cash loans. She says her clients have included ride share app drivers and people running businesses through social media apps who need smartphones to operate.

“I like my job and I like seeing how my clients’ lives improve,” she says."
Microsoft_News,https://news.microsoft.com/source/features/work-life/a-dai-in-the-life-of-janet-kim/,,A dAI in the life of Janet Kim,"Janet Kim is a senior communications manager for Microsoft who lives in Bothell, Washington, with her husband, two “very active and energetic” sons and her mother, who flies back and forth from Texas to help with the boys. Kim, 39, says she was surprised when AI was able to help with the challenge of having three generations living together.

Kim mainly uses Bing Chat to help her plan trips that her family will enjoy. The tool has given “excellent recommendations that were perfect for kids” for trips to Hawaii, when Kim was on a budget and was looking for free or low-cost activities, and the Joshua Tree National Park, when the family had a tight timeline.

She shares a typical day as part of Microsoft’s “A dAI in the life” series, which showcases how AI tools are helping people do more in their personal and professional lives."
Microsoft_News,https://news.microsoft.com/apac/features/ocbcs-new-generative-ai-chatbot-is-boosting-the-banks-productivity-across-departments-and-locations#new_tab,,OCBC’s new generative AI chatbot is boosting the bank’s productivity across departments and locations,"In her job at OCBC’s contact center in Singapore, Denise Law must respond to what are sometimes convoluted, lengthy emails from customers.

Sifting through those emails, figuring out what customers need and writing effective responses can take considerable time for Law, who also manages the center’s chatbot for personal banking inquiries.

That work has gotten a little easier lately with the help of a generative AI chatbot OCBC has been piloting with its employees that allows them to ask questions and get help with everything from communications to coding. The tool will be rolled out bank-wide in November.

Law has been using the chatbot to quickly identify what customers are asking for in their emails — how to check a bank balance or get a fee waiver, for example — and provide answers. If she’s not satisfied with the response, she can ask the chatbot to come up with a more succinct or empathetic answer.

“It helps me to break down the sentences and the questions and craft the response to best help the customer,” Law said. “I can actually give instruction on how I want the response to be improved so it doesn’t sound like a robotic reply.”

Law also uses the tool to refine answers to FAQs for the bank’s personal banking customer service chatbot on the corporate website, translate the occasional Chinese word she is not familiar with and draft responses to customer complaints that can be used by her colleagues as templates. The tool saves time, she says, and has improved communication with customers.

“It’s very fast and it can generate the responses quickly,” Law said. “That allows me to manage more interactions and also ensures consistency in responses, which ultimately leads to enhanced customer service.”

‘Interesting use cases’

Singapore is an Asian financial hub and OCBC is the island state’s second biggest bank by assets.

OCBC decided to develop the tool around March 2023, about four months after the launch of ChatGPT, OpenAI’s large language model-based chatbot. Like people worldwide, the bank’s employees were intrigued by ChatGPT, and senior leaders saw potential for the technology to help them in their daily work.

“We took an exploratory approach to understand the capabilities and risks of ChatGPT — wanting to see if we could harness its benefits in a safe and secure environment,” said Bryan Lee, managing director of Group Technology Architecture at OCBC.

OCBC built the chatbot in its private Microsoft Azure environment, which provides access to OpenAI’s models, including ChatGPT, along with Azure’s infrastructure and security. Since most of the bank’s employees were already using Microsoft Teams, the bank opted to embed the chatbot in Teams’ secure and controlled environment, with risk controls in place built by an in-house engineering team, Lee said.

After an initial proof of concept phase, the company introduced the tool at an internal event in May, where around 200 employees asked to sign up for the subsequent pilot. As the pilot got underway over the next few months, OCBC and Bank of Singapore employees across departments and locations — from Singapore to Hong Kong, Malaysia and Indonesia — eagerly got onboard. Bank of Singapore is OCBC’s private banking subsidiary. By September, close to 1,000 employees were using the chatbot on a regular basis, Lee said.

The company trained employees on how to use the chatbot and began holding workshops for people to share their experiences with it. The group leading the project had envisioned the technology being used primarily to generate content and help with coding, Lee said, but employees quickly found other uses to help them in their daily tasks.

Front office managers were using the chatbot to research various types of industries to better connect with their clients. Contact center employees used it to summarize calls from customers and identify key issues. Marketing and communications teams were using the tool to create content for newsletters, and human resources staff tapped it to create job description templates.

“They came back with a lot of interesting use cases that we were just very surprised by,” Lee said.

Megan Wong, business manager at Bank of Singapore, enthusiastically signed on for the proof of concept testing as soon as her manager told her about it. Wong has used the chatbot to summarize large documents into key points, draft email invites for client events and come up with campaign names for an internal presentation.

“Sometimes trying to be creative is not so easy, but this technology gives you ideas,” Wong said. “It saves my time trying to come up with something fancy. It can generate more options better and faster than I can.”

An AI evolution

OCBC was an early adopter of analytics and AI capabilities, creating its first analytics team in the late 1990s and hiring Donald MacDonald, now head of its Group Data Office, in 2004 to develop the bank’s marketing analytics infrastructure.

Back then, MacDonald said, analytics was largely focused on consumer banking. As OCBC built up its infrastructure over the years, it began applying analytics and AI to other areas of the organization, such as corporate banking, compliance and operations.

OCBC’s use of AI and machine learning reached an inflection point about five years ago, MacDonald said, as growth and adoption of those technologies accelerated. The bank developed a chatbot for customer service inquiries and another chatbot named Buddy to help employees with HR-related issues. It launched programs to develop digital skills in employees and began providing postgraduate AI scholarships.

Then in 2018, OCBC established an AI lab to develop in-house AI capabilities, becoming the first bank in Singapore to do so.

“We started the lab with just three people,” MacDonald said, “but it very quickly got a lot of traction because we were able to go beyond marketing analytics, which was really our core competency before, and start working on areas like financial crime and fraud detection and generate some very impressive benefits.”

For example, the bank’s anti-money laundering efforts previously used a system that would generate more than 10,000 alerts a month. Investigators would spend about 45 minutes reviewing each alert, MacDonald said, and the majority were false positives. The bank developed an AI model that prioritizes alerts and automatically closes or hibernates lower-risk ones.

Over the past year, MacDonald said, OCBC has focused increasingly on generative AI to improve employee productivity. The bank’s OCBC Wingman tool, launched in May 2023, helps developers by tracking code as they write it and automatically generating additional lines of code — boosting productivity by an estimated 20 to 30%, MacDonald said. Generative AI is also being trialed at the bank’s contact center to summarize and transcribe sales calls, saving employees from having to listen to hundreds of calls daily to identify sales anomalies.

Similarly, MacDonald said, the new generative AI tool is helping employees across departments to be more productive and improve customer experiences. Contact center employees typically take a training course to become certified letter writers, he said, but tests showed that the tool could provide a useful first draft that a certified writer can then refine as needed.

“I think that’s a great example of where it just makes people more productive at what they were already doing,” MacDonald said. “It’s a tool that’s very flexible and can handle a wide range of use cases.”

Employees seem to agree — a recent survey of pilot participants found that 93% were satisfied with the chatbot overall and 72% reported productivity improvements since they started using it.

The question he gets most often from employees about the chatbot, MacDonald said, is when it will be available to them.

“People are really looking forward to getting it and are excited by it, which is fantastic.”

Click here to load media

Top image: Denise Law, who works in OCBC’s contact center in Singapore, is among employees using the bank’s new generative AI chatbot. Photo by Ore Huiying for Microsoft."
Microsoft_News,https://blogs.microsoft.com/?p=52561257,,"Startups to access high-performance Azure infrastructure, accelerating AI breakthroughs","Today Microsoft is updating its startup program to include a free Azure AI infrastructure option for high-end GPU virtual machine clusters, for use in training and running large language models and other deep learning models.

Y Combinator (YC) and its community of startup innovators will be the first to access this offering in private preview to a limited cohort. YC has an unmatched reputation as a pioneering startup accelerator helping launch transformative companies including Airbnb, Coinbase and Stripe. Now YC startups will have the technical resources they need to quickly prototype and bring to market cutting-edge AI innovations. Our close collaboration with YC provides valuable insights into the infrastructure needs of early-stage AI companies, ensuring our offering delivers optimal value to additional startups going forward.

“With the overwhelming infrastructure requirements needed to do AI at scale, we believe that providing startups with high-performance capabilities tailored for demanding AI workloads will empower our startups to ship faster,” said Michael Seibel, Managing Director of Y Combinator.

We are also working with M12, Microsoft’s venture fund, and the startups in M12’s portfolio which will gain access to these dedicated supercomputing resources to further empower their AI innovations. Over time, our vision is to partner with additional startup investors and accelerators, with a goal of working with the ecosystem to lower the barrier to training and running AI models for any promising startup.

Microsoft Azure offers cloud-based scalable AI infrastructure, built for and with the world’s most sophisticated AI workloads, from delivering the largest and most complex AI models including GPT-4 and ChatGPT through Azure OpenAI Service to developers to infuse AI capabilities into many apps. Azure AI infrastructure is fueling groundbreaking innovations. Infrastructure requirements to do AI at scale are often overwhelming, but with Azure’s global infrastructure of AI-accelerated server offerings with networked graphics processing units (GPUs), startups building advanced AI systems will be able to leverage these high-performance capabilities to accelerate innovation.

On top of world-class infrastructure, we will also provide tools to simplify deployment and management through Azure Machine Learning. This enables easy low-code or code-based training of custom models and fine-tuning of frontier and open-source models, simplified deployment and optimizations like Low Rank Adaptation, DeepSpeed and ONNX Runtime (ORT). Further, startups can deploy AI solutions with peace of mind knowing all deployments are secure and backed by Microsoft’s principles for Responsible AI.

Empowering startups to build transformative solutions powered by AI

AI is transforming industries and startups are leading that innovation, creating new business and societal value quicker than many thought possible. According to a recent KPMG survey, the near-term demand is real, with 75% of U.S. CEOs stating that generative AI is a top investment priority, 83% anticipating an increase in generative AI investment by more than 50% in the next year, and 45% saying investment will at least double. For startups, this represents a once-in-a-generation opportunity to bring groundbreaking impact to a market hungry for change.

To help startups meet this opportunity, last year we introduced Microsoft for Startups Founders Hub – designed to help founders speed development with free access to GitHub and the Microsoft Cloud as well as unique benefits including free access to $2,500 of OpenAI credits to experiment and up to $150,000 in Azure credits that startups can apply to Azure OpenAI Service. Startups also receive 1:1 advice from Microsoft AI experts to help guide implementation. The Microsoft Pegasus Program, an extension of Founders Hub, links enterprise customers with startup solutions for immediate deployment. Seventy-five percent of Pegasus startups have landed deals with Fortune 1000 companies via increased reach across Azure Marketplace.

Startups using Azure AI to develop cutting-edge solutions for today’s problems

Whether you have a product in market or just an idea, Microsoft provides startups with the tools they need to rapidly build and scale AI solutions. Already, we are seeing the results of empowering startups to innovate with AI to improve customer support, detect and address health conditions and advance immersive gaming experiences. Here are just a few examples of the cutting-edge innovation happening now:

Commerce.AI dramatically increases call center productivity with Azure OpenAI Service

Commerce.AI uses Azure OpenAI Service and Azure AI Services to make call centers more efficient. Azure Cognitive Services uses a Commerce.AI model to transcribe interactions in real time, including into multiple languages. After the call, Azure OpenAI Service creates a summary with customer contact information, topics of conversation and embedded sentiment analysis. The system selects next steps and follow-up action items from pre-generated options, and the customer service agent exports the information to Microsoft Dynamics 365 in one quick step.

Inworld: The next-generation AI character engine for immersive gaming

Inworld, a Silicon Valley startup, is a fully integrated character engine that goes beyond language models to give users complete control over AI non-player characters (NPCs). With Inworld, users can customize their characters’ knowledge, memory, personality, emotions and narrative role. Inworld uses Azure AI technologies like Azure OpenAI Service to power its advanced natural language understanding and generation.

BeeKeeperAI is helping catch rare childhood conditions early

AI tooling company BeeKeeperAI enables AI algorithms to run in a private and compliant way in healthcare environments. The company is pioneering an effort to leverage confidential computing to train an algorithm for predicting a rare childhood condition using real patient health records. By encrypting both the data and algorithm and using Microsoft Azure’s confidential computing, the company has enabled the algorithm to analyze identifiable health information in a secure, sightless manner.

YouTube Video Click here to load media

Calling all startup founders — Start building the future today The AI landscape is developing at breakneck speed, and Microsoft is ready to assist startups in seizing this opportunity. If you’re a startup founder evaluating partners, we invite you to join us at Microsoft for Startups Founders Hub and discover how we can accelerate your immediate success.

Tags: AI, Azure AI, Azure OpenAI Service, M12, Microsoft for Startups Founders Hub, startups"
Microsoft_News,https://www.microsoft.com/en-us/worklab/with-copilot-every-meeting-is-a-digital-artifact,,"With Copilot, Every Meeting Is a ‘Digital Artifact’","Over the past few years, flexible work and innovations in digital meetings have reshaped the way we collaborate. We can meet across locations and time zones, allowing us to include people who otherwise would have been left out. We can dig through a transcript to refresh our memory of a conversation. Now, generative AI is driving another fundamental shift, changing what a meeting is in the first place.

A meeting is no longer an ephemeral, one-time event. Think of it instead as a “digital artifact” that you can interrogate in powerful ways.

“A meeting has become less a point in time and almost a knowledge object that I can query, that I can ask questions of,” says Jared Spataro, Corporate Vice President of Modern Work & Business Applications at Microsoft. “It’s a whole new way of thinking about human interaction.”

And it comes at a critical moment: Since February 2020, people are in three times more Microsoft Teams meetings and calls per week. According to Microsoft’s 2023 Work Trend Index, they see inefficient meetings as their top productivity disruptor.

With Copilot in Teams, people can consult a meeting and interact with it after the fact—even if they couldn’t attend—allowing everyone to reclaim time for creative and focused work so they can truly thrive. Here’s how it works.

Get more out of the meeting you’re in

Generative AI lets you extract more intelligence from a meeting that’s happening right now. In real time (as long as the meeting is being recorded), you can ask Copilot to analyze, organize, and synthesize the discussion, doing so in a chat interface visible solely to you.

If you’re having challenges jumping into the conversation, you might ask Copilot, “Rephrase what she just said, I didn’t quite understand it.” Or, “What would be a good question to ask this presenter?” If you were multitasking and missed something, you can ask Copilot to repeat it. If you need a table with the ideas discussed and their pros and cons, or a list of action items, Copilot can generate one.

Copilot can also help ensure that everyone is included: If you’re the meeting host, you can ask Copilot, “Who hasn’t had a chance to speak?” or “Who was cut off?” In short, it opens up new ways to actively engage with a meeting in progress and helps you see the bigger picture.

Get up to speed on meetings you missed

Most of us can’t attend every meeting we’re invited to. Sometimes two meetings are scheduled at once. Sometimes you’re on vacation or picking up your kids from school. Right now, when you have to miss a meeting, you might catch up by reading through the transcript or watching the recording. Copilot takes you a step further, letting you dynamically interact with the digital record of the conversation to get answers to what you need to know, faster.

Copilot can give you a full recap, or it can answer questions like: “What topics did people discuss?” “What decisions did they make?” and “Did anyone mention my name?” But it can also analyze and report on mood and sentiment. “Was that an easy decision?” “How did the group feel about that?” Or “Did anybody dissent?”

“You can get such a fine-grained analysis of human interactions that it really opens your eyes,” Spataro says. “It used to be that a meeting happened, and it was over, and people maybe took sketchy notes. These days, that very full interaction can be looked at from many different angles.”

Humans have gathered together to share information, generate ideas, and make decisions for thousands of years. Copilot will unlock a new level of efficiency and awareness: people can design meetings that work for the way they work now—and leaders everywhere can empower their teams to make the most of this transformative technology."
Microsoft_News,https://news.microsoft.com/10-ai-terms/,,10 AI terms everyone should know,"2. Machine learning

If artificial intelligence is the goal, machine learning is how we get there. It’s a field of computer science, under the umbrella of AI, where people teach a computer system how to do something by training it to identify patterns and make predictions based on them. Data is run through algorithms over and over, with different input and feedback each time to help the system learn and improve during the training process — like practicing piano scales 10 million times in order to sight-read music going forward. It’s especially helpful with problems that would otherwise be difficult or impossible to solve using traditional programming techniques, such as recognizing images and translating languages. It takes a huge amount of data, and that’s something we’ve only been able to harness in recent years as more information has been digitized and as computer hardware has become faster, smaller, more powerful and better able to process all that information. That’s why large language models that use machine learning — such as Bing Chat and ChatGPT — have suddenly arrived on the scene."
Microsoft_News,https://news.microsoft.com/source/features/work-life/a-dai-in-the-life-of-omar-smith/,,A dAI in the life of Omar Smith,"10 a.m.

Join a Microsoft Teams video call with my colleagues. I brainstorm ideas for the campaign and use Teams intelligent recap to generate a summary of our discussion and then put the recap emails and personal notes in Microsoft Loop to help us collaborate.

11 a.m.

Take a break and play with my puppy. Ask Bing to create a fun caption to pair with a photo I captured of him playing. I gave Bing some examples of rappers that we like, and here’s the response it gave me: “Tobi is my right hand, my go-to / He’s always by my side, he’s loyal and true / He’s more than just a dog, he’s family / He’s got me feeling some type of way, he’s the real MVP.” The suggestion was a little lengthy and not totally in my tone of voice, but it gave me a great foundation to tweak it.

12 p.m.

Make some lunch and play a bit on my Xbox. I know Bing can make recommendations based on my chat history, so I ask it to help me brainstorm what my in-game persona should be in Starfield. I end up creating a Space Ronin with alien DNA, and Bing helps me come up with a name for my spaceship and helps me craft my own backstory with sci-fi references that fits within the context and lore of Starfield, so I can have an idea of what choices I want to make in my playthrough. It also tells me about an unlockable outfit that I didn’t even know was part of Starfield and that perfectly matches my in-game aesthetic, so that’s cool to discover.

4 p.m.

I check the analytics of a social campaign I’m working on and ask Bing Chat Enterprise to give me some insights and recommendations on how to improve it, then build on them in my retrospective exercise before sharing with my manager and partners.

5 p.m.

I wrap up work and turn to school. Ask Bing for relevant scholarships I qualify for, for the master’s program I’m enrolled in, and get Bing’s help to format a paper in the APA style, since I’m more used to using MLA style from my undergrad years.

6 p.m.

Cook dinner using a recipe that Bing suggested based on what I told it I have in my fridge and pantry — salmon, tomatoes, onions, sweet potatoes and spinach — using my new air fryer. I check my Bing search history and go back to a discussion from two weeks ago so I can ask a clarifying question about a trick to air-fry salmon with sweet potatoes.

7 p.m.

Ask Bing to suggest some good movies to watch with my girlfriend, or a new drama or love-reality TV show. We settle on its reality dating show suggestion.

Read more stories in Microsoft’s “A dAI in the life” series and share your story.

Story as told to Microsoft Source writer Susanna Ray.

Lead photo by Scott Eklund/Red Box Pictures; other images provided by Omar Smith."
Microsoft_News,https://www.microsoft.com/en-us/worklab/podcast/linkedin-vp-aneesh-raman-on-why-adaptability-is-the-skill-of-the-moment,,LinkedIn VP on Why Adaptability Is the Skill of the Moment,"MOLLY WOOD: Today, I’m having a great conversation with Aneesh Raman, vice president at LinkedIn and head of the company’s Opportunity Project, which focuses on building a more dynamic and equitable global labor market. He’s here to tell us one simple thing: jobs are changing all around you, even if you aren’t changing jobs. And this is a guy who knows a little something about changing jobs. He formerly worked as a CNN war correspondent, and a speechwriter for President Obama. He’s now focused on how tech innovations are transforming the way we work, but also how they’re creating and expanding opportunities for people without standard career paths and educational backgrounds. Here’s my conversation with Aneesh.

[Music]

MOLLY WOOD: So you have had a remarkable set of careers—journalist, author, speechwriter for the president, advisor to the governor of California, now an executive at LinkedIn. Has there been, could you say, a through line to all of these tasks and jobs?

ANEESH RAMAN: Up until recently, it was hard for me to articulate a through line. And that was hard for me, just personally, because I found it hard to explain my career. It was a classic squiggly line career, but across every job, explanatory storytelling was core to what I did. That was true as a reporter, it was true as a speechwriter, it was true in all the roles I had in tech and with Governor Newsom—I am a storyteller.

MOLLY WOOD: Well, a squiggly line is kind of an increasingly common career path. Let’s talk a little more about that—how much jobs really are changing, and how we should deal with that.

ANEESH RAMAN: Yeah, I mean, I want to repeat it, because I want people to really hear it: jobs are changing on you, even if you’re not changing jobs. So here I am, this very extreme example of someone who has not just changed jobs but changed careers, from journalist to speechwriter to tech executive. And so it can be easy to say, well, that’s someone else. But everyone is a version of me, even if you don’t realize it, because the way the technology has changed, what we do at work has already had an impact. Twenty-five percent of the skills required to do jobs have changed over the past eight years, by our data. But 65 percent will change by 2030—65 percent of the skills required for a job will change by 2030. That’s basically a new job.

MOLLY WOOD: Tell me what that means. Like, I’m doing a job right now, I think I know how to do it, and 65 percent of that is going to be totally different.

ANEESH RAMAN: Yeah, in your day-to-day, think about just, you know, look back maybe a decade, how you’re using tools differently. How we started using email, and we started using the instant communication tools that weren’t there a decade ago. How that meant that what we needed to meet about was different. How businesses had to change to adapt to the internet age and e-commerce. So we have been in a state, really, since the internet age took hold, of constant change. Now, the speed of that change has been measured. And so we could feel it perhaps year over year, it felt kind of incremental, we could walk our way through the way our job was changing. I think AI is going to speed all that up. And so it means we’ve all got to be a lot more focused on how we’re going to do lifelong learning, how we’re going to keep track of what are the new and better tools we can be using? How we’re going to keep track of what are the ways we have to upskill?—ahead of where the business that we’re working at is going, or the team that we’re leading needs to go. And again, I just go back to skills-first, because it’s really the only way you can get your head around it. You can’t just cut and paste job descriptions if you’re a company, you can’t just wait to get your manager’s job if you’re an individual. Because all of this stuff that is underneath a job—the tasks are changing. And so the key takeaway, I think, for us all is just adaptability is the best way to have agency right now. I think in a moment of big change like we’re living through now, the thing we all most want is not just a way to understand it but a way to manage it. And at the core of that right now is just going to be building that muscle of adaptability.

MOLLY WOOD: It sounds like you’re talking to everybody in an organization, without question, that this is going to have to be you know, bottom up, but I do wonder how you manage through that. As a business leader.

ANEESH RAMAN: I think it starts with communication. I mean, people are really nervous right now. They’re really anxious right now. As I described, I now see myself as a storyteller, and I think storytelling is a must-do right now for everyone, to give a vision for where this technology is going to take your team or your company, and in a direction that includes the people you’ve got, and the support you’re going to give, to upskill the people you’ve got. So I think it’s really important for us all to bring that kind of energy to how we are communicating out to teams, because this is one of those moments, those early days of a big shift, where the story sets the tone, and the tone sets the direction, and over time, the direction becomes self-fulfilling and inevitable. And I think there are a lot of reasons for us all to be thoughtful about AI, to really think about intent as it’s built, to think about the responsibility that needs to be built into AI. But it’s important for us all to also see what’s possible because of AI. The aspirational other end of this, that we think of at LinkedIn as a world of work that’s more human, not less. Because people skills are going to come more to the center of individual career growth, and people-to-people collaboration is going to come into the center more for company growth. For leaders, you’ve got to start with communicating clearly, compassionately, and empathetically with your teams. And then I think it’s really building a culture of learning. That’s like the most important thing because there is no universal answer to where this is going. There’s no way to know, except to know where it’s going next. And so I go back to that adaptability is the best way to have agency. How are your teams talking about the latest AI tools? How are your teams learning together, growing together? How are you encouraging team members to think about tours of duty and skills transferability? All of those things are really important right now.

MOLLY WOOD: Well, and a culture of learning is also a culture of training, and a culture of time and patience. Like, it seems to me that what we’re talking about in large part is a leadership structure that says, We want to help you develop these skills, as opposed to set an expectation that you will spend all your nights and weekends learning about this when you’re not on the job. And that could really change workdays, I would imagine.

ANEESH RAMAN: Employers are going to become educators more and more. And the good news for employers is that—and employees—a lot of that is going to be on the job. One of the things I like to ask the audience at any panel I’m at is, to think about the job that they’re doing right now and raise their hand if more than half of what they do in their job is based on what they learned in college or the degree they got. And very few, if any, hands go up. Then I say, raise your hand if most of what you do in your job is stuff you learned on the job or in previous jobs, and almost every hand goes up. So the idea of learning on the job is not new. It’s going to get faster and more complicated now, but a lot of this is going to be just how in our day-to-day jobs we’re starting to upskill and learn—not something we do separate from work but within work. I’m a good example. I am someone who writes a lot, as my job. And I have been working with ChatGPT a lot to help me get through a first draft, to help me refine positioning, to debate with me what core themes are. That is now embedding into my workflow, and I’m getting really good at prompting. So that’s the kind of learning I think that companies want to encourage, and that people should feel excited about. Because, again, I really think AI will be a tool. And humans have built and perfected tools over millennia, to help us do more of what we love, and to help us do the work that we love to do better.

MOLLY WOOD: Okay, talk to me more about debating. Tell me more about the prompts that get you to engage in a back and forth. Are you really doing that? It’s super cool.

ANEESH RAMAN: Yeah, I mean, I did a post recently on LinkedIn about how I think philosophy, and the study of philosophy, is going to become this “it skill” across all these different areas of how AI is going to affect work, about social cohesion, ethics, lifelong learning, resilience. And as I was building that—you know, there are a bunch of different ways you could describe philosophy as relevant to the changes hitting work. And so I sort of did this starter, and I prompted it with assigning it who it was—you are a speechwriter helping me out. I am—described what I’m working on—thinking about a post that talks about philosophy and its role in the age of AI. Some notes, but really, I was trying to get to what do I think are the core themes, the core takeaways for people? And I had a couple. I asked it for ideas, it had a couple, some were good, some were not. And it was in that back-and-forth that I was able to really articulate these different ways that I think the study of philosophy will help us. That’s just one example. As you think about any sort of content you’re doing, any sort of meeting that you’re leading, any sort of moment where you are trying to inspire new thought—a lot of that work is really hard at the front end, because you’re taking this kind of abstract idea and trying to get it to paper. And I have found that AI is helping me speed up that front process so I can spend more time on the stuff I love most and that I think I am, as a human, best positioned to do.

MOLLY WOOD: You have talked about how it’s important to think about skills as kind of naturally dividing into three buckets. Can you tell us—you’ve given us some examples, but can you tell us more about what those buckets are?

ANEESH RAMAN: Yeah, I think, you know, for me to come up here and say, AI is a big deal, which I think it is, and that it’s going to change, you know, how we work and how we live—it’s going to change how we work and how we live in different ways based on your sector or function. That’s like a lot to manage. It’s a really complex, nuanced moment of big change. So I like to also offer up what I think is the best way to feel some agency, something actionable in managing that, and I think that is skills. And here’s why. Probably the biggest impact of AI on work is that I think it’s going to force us to redefine jobs—not as titles, but as a set of tasks. So if you take your job, and you put aside your title, and you think about, let’s say, the top dozen tasks that you do on any given day—what you can do now is break those tasks into three buckets. The first is, tasks that AI is ready to do almost fully for you: summarizing meeting notes, even writing code in some instances. The second bucket are tasks that you’re going to do with AI, and prompting is the best example of that. And then the third are tasks that require your unique skills, your people skills, creativity, collaboration. So everyone can do that math. And if your job or your team or your workforce is heavy on that first or second bucket, that’s a good indication that it’s time to upskill. And then everyone should be thinking about that third bucket, where we have the most competitive skill set, which is the people skills. So again, like, you could break jobs into tasks, and then with a skills-first mindset, we can all—starting today—know where we’re at and what we need to do to feel agency right now.

MOLLY WOOD: There has been, kind of, talk of skills-based hiring and, you know, skills-based management for a long time. And it’s been very—it’s hard to implement, it is actually you know… It’s so obvious and necessary, and it opens a ton of doors for a ton of different kinds of employees. And it is sort of anathema to how companies operate right now. Talk to me about the level of change that this will require in the adaptability in companies.

ANEESH RAMAN: So the first thing I always concede about skills is that it does feel early. It feels hard to scale. It feels hard to define. It is not as easy to filter for skills as you filter for degrees. But I promise everyone that it is easier than any other way that exists to figure out what is going to happen to work, to your job, to your team in the age of AI, and how you can take advantage of the opportunities that are emerging. Winston Churchill has this quote about democracy that basically says, democracy is the worst, except for everything else. Name me any way that we currently judge potential in people that isn’t skills first, and I’ll show you how it’s either broken or going to break over time. Those ways may be easy now, because the systems exist around them. But they’re not going to be effective going forward. And so then I think, as a company, you have two choices: to sort of ignore that reality and to stay focused on systems that are easy now, or to do the work now to test and learn and build the systems around skills first that make you an adaptive company with an adaptive workforce later. And the big reason for hope that didn’t exist before out in the broader conversation is that, while AI is an accelerant for why people have to think in a skills-first way, it is also going to be a tool that helps us build the systems around skills first. It helps us build taxonomies to connect to job descriptions that are linked to LinkedIn profiles and the skills people have in ways that are dynamic and that are keeping track of trends across the labor market. That’s what’s held skills-first thinking back, is the human need to do all of that. And now we’ve got a tool to build those systems. But it’s really, to me, the only way forward.

MOLLY WOOD: I mean, I think we’re all going to have to learn how to devise the ideal prompts to get the most out of AI. But actually, Jared Spataro, Microsoft’s Corporate Vice President of Modern Work and Business Applications, has suggested that there is crossover between people who are good at prompting and doing all the setup and preparation and context setting and information sharing that you’re describing, and people who are also good managers.

ANEESH RAMAN: And I also think the people part of managing is going to become more and more important, because a lot of what it is to manage that the tools and that AI could help us now do in terms of tracking budgets, and making sure priorities are aligned, and all these things that we might be able to now through a tool be able to have visibility on and track against. It’s going to then open up the space and open up the need for managers to be focused on the people part of managing, and that goes to the people skills that I really think are going to come to the center of the labor market—empathy, collaboration, listening, and leading by listening.

MOLLY WOOD: You know, there’s obviously a lot of demand for AI experience and people who are good at prompting. But LinkedIn’s June 2023 executive confidence index shows that 72 percent of US executives agree that soft skills are even more valuable than those AI skills. And I think by soft skills, we mean what’s traditionally been called people skills, right? Communication, creativity, adaptability. Why do you think those skills are so valuable now? And how do you teach that?

ANEESH RAMAN: Soft skills have always been core skills. Because they are skills we uniquely do as humans. If you think back millennia, not just centuries, and two or more people doing something together—buying or selling, investing, building, hiring, executing—it’s all that happened before technology around that. How did I build a relationship with you, talk about the product I have in a way that was something you wanted to buy? How do I collaborate? How do I empathize with where you’re at, so when I communicate with you it’s something that lands with you and isn’t just me talking over you or at you—all of those things. What’s interesting is that over the past few decades, because of the internet age, when we think about workforce development, so much effort has been, understandably, on technical skills, computer science degrees, coding boot camps, educated and credentialed—technical skills. We now, I think, you’re going to have to do that for soft skills. And that is a big new challenge for us, in terms of workforce development. Again, I think AI will help—help define soft skills in an aggregate way. Help us do credentialing based on contextualizing skills, like I do on my profile. Millions of skills are getting added every year on LinkedIn profiles, where members are saying, these are the skills I used to do this work. What does it mean to communicate? And where did you do it that led to a deliverable that you can show? At one level, I think you’ll see a little bit of a recalibration where all of this funding and energy went to the engineering departments on college campuses, I think the humanities will have a bit of a renaissance. But also, again, the shelf life of a degree is shrinking pretty dramatically. So, how soft skills are applied to this changing world of work is going to change. And I think that’s going to mean workforce development, not just going into college, but after college and across your career, it’s going to have to account for soft skills now as a core skill for us to identify and credential.

MOLLY WOOD: I love this idea. I think, you know, it’s particularly a conversation when you talk about, for example, women coming back into the workforce, or hiring veterans, or just more equitable hiring overall. You are, I should say, speaking as someone who is a Harvard grad and a Fulbright scholar, and it sounds like you’re kind of saying you want the importance of those titles to fade into the background over time.

ANEESH RAMAN: Well, I would say I would like them to be less relevant to how I succeed or how anyone succeeds in their career. Because I think they are not in and of themselves an issue, but representations of a labor market that has really required pedigree signals to get ahead. And we know that pedigree signals often come from privilege. What I am excited about with skills-first thinking is that we can finally put an objective dataset underneath the labor market so that people match talent and opportunity in a more efficient and equitable way. If you look at the history of work, for most of human history you inherited work, you did what your parents did. That’s wildly inefficient and unequal. Then you had these industrial revolutions, and they opened up new opportunities for work. And over time, college especially, but higher ed and education generally was meant to be the mechanism of mobility. No matter what station I was born into, I could learn my way into new and better jobs. That model has had a bunch of challenges hit it over time, not just least of which is the cost of college, but also the way that curriculum is developed. It’s really hard to tether that to the changing dynamics of work, to make sure that as you develop curriculum, when you’re done, it’s still relevant to where work is and is going. And all of that means I think that we’ve got this opportunity now to take the guesswork out of work, to put skills at the base of it. And with that, college will still be an important credential, but create other ways, other credentials for people to come into and across the labor market. And to really, you know, challenge some of these baked-in inequities, the gender inequities in the labor market, a lot of the roles that have the people skills associated with them are often undervalued and underpaid, because we have focused so much of value around the technical skills. I think that’s going to shift. If you look at home healthcare workers, as an example, a profession that is a very high-skilled profession that we will start to, I think, better describe as high-skilled. So I think there’s a great equalizing effect, a great democratization of economic opportunity that’s about to happen, spurred by the age of AI.

MOLLY WOOD: Let it be. Lord, let it be. [Laughter] We tend to have these conversations anytime a new technology comes along, that’s going to enable greater efficiency, but it feels really transformative now to be talking about these skills in such a different way.

ANEESH RAMAN: Well, as a storyteller, my first reaction is, we can’t just say, let it be, we have to say, make it be. And I think right now, the story really matters. Our ability to articulate a vision for AI that will democratize access to economic opportunity will make it more likely that the people who are around the systems of workforce development start to align it in that direction. But I’ll take you even one step further than just equalizing opportunity in the labor market, in terms of how I see the potential for AI. You know, a lot of the discussion about AI has been on how it will help reduce the drudgery of our day, the repetitive tasks we do that are not fun. But I think some of the most powerful impacts of AI will come in reducing the barriers in how we communicate with each other. One of the most important skills in the world is communicating to someone else in a way that isn’t just about you talking at them with a focus on what you’re saying, but talking with them with a focus on what they’re hearing. That is tremendously difficult to do. Because it requires understanding where the other person is at, and bringing empathy to how you communicate. That becomes impossibly difficult to do as you think about divides across geography and culture and language and sector and function and market. All of these barriers have existed for some time now that make it really difficult to talk human to human. And I think AI is going to help us all get better at that. It’s going to help us, in real time, break down those barriers to communication that I think will lead to higher quality conversations and more meaningful collaborations. What’s exciting to me about that is that if we’re able to do that in the world of work, it’s pretty easy to see how that can extend out into society, and into a world where we are bringing greater humanity into how we all live. And that’s my real hope here. And I think it’s important to say that that’s not inevitable. And that that will require us being really deliberate with the intent of AI that is being built and the responsibility that we have to build into it. But that it’s also possible. And if we can believe it’s possible, it’s amazing the degree to which that can affect how we approach the early days of this big shift, and how that can actually make it much more likely that that’s where things end up.

MOLLY WOOD: Yeah, I hope so too. Okay, well, before I let you go, let me bring this back to you. You are using AI a lot. So how is it saving you time? And what are you doing with the time it saves you?

ANEESH RAMAN: The time I am saving with AI in terms of the tasks I would be doing if I didn’t have AI—which are generally that first draft, first cut first outline—I’m now able to spend a lot more time on the creative part of how do you perfect the language? And how do I think about how it sounds when I’m saying it out loud? And I find that really enjoyable. Because I found, and I’ve always found, the first draft, the first outline, the first how do I take an idea and start to think about the logic flow? necessary but not fun. And I, you know, would have feared if I told you that there was something that would help me with that, that maybe I’d lose something in terms of, you have to slog your way through that. And that’s how you get to the fun of the creative crafting. But no, that’s not what happens. You actually just get to dive right into the fun.

MOLLY WOOD: Aneesh Raman, vice president at LinkedIn and head of the company’s Opportunity Project—the guy who’s going to make it be. Thank you so much for the time.

ANEESH RAMAN: Make it be with you and everyone else. Thanks so much for having me.

[Music]



MOLLY WOOD: And that’s it for this episode of WorkLab, the podcast from Microsoft. Please subscribe and check back for the next episode, where I’ll be talking to James Thomas, Global Head of Technology at Dentsu Creative about how full integration of AI is transforming organizations. If you’ve got a question or comment, drop us an email at worklab@microsoft.com. And check out Microsoft’s Work Trend Indexes and the WorkLab digital publication, where you’ll find all of our episodes, along with thoughtful stories that explore how business leaders are thriving in today’s new world of work. You can find all of that at microsoft.com/worklab. As for this podcast, please rate us, review, and follow us wherever you listen. It helps us out a ton. The WorkLab podcast is a place for experts to share their insights and opinions. As students of the future of work, Microsoft values inputs from a diverse set of voices. That said, the opinions and findings of our guests are their own, and they may not necessarily reflect Microsoft’s own research or positions. WorkLab is produced by Microsoft with Godfrey Dadich Partners and Reasonable Volume. I’m your host, Molly Wood. Sharon Kallander and Matthew Duncan produced this episode. Jessica Voelker is the WorkLab editor."
Microsoft_News,https://blogs.microsoft.com/blog/2023/11/02/new-study-validates-the-business-value-and-opportunity-of-ai/,,New study validates the business value and opportunity of AI,"As AI becomes more woven into society, its economic impact will be significant, and organizations are just starting to understand the extent of what’s possible. For companies to invest in AI though, it must make good business sense. Business leaders and decision makers need to understand the industry and line-of-business use cases that are best positioned to drive value within their organizations, what the return on investment will be, what time to value to expect, and how to get started. In short, they need help demystifying the business case for AI.

To help companies understand the opportunities AI can unlock, Microsoft commissioned a study through IDC that provides unique insights into how AI is being used to drive economic impact for organizations. IDC surveyed over 2,000 business leaders and decision makers from around the world who are responsible for bringing AI transformation to life within their organizations. The study, which builds on the results from Microsoft’s Work Trend Index focused on workplace productivity, examines how companies are monetizing their AI investments, from generating new revenue streams to delivering differentiated customer experiences, to modernizing internal processes. Key findings from this study show*:

71% of respondents say their companies are already using AI

92% of AI deployments are taking 12 months or less

Organizations are realizing a return on their AI investments within 14 months

For every $1 a company invests in AI, it is realizing an average return of $3.5X

52% report that a lack of skilled workers is their biggest barrier to implement and scale AI

The study illustrates that AI has demonstrable business value, and we are seeing this surface in core use cases within areas like employee experience, customer engagement and internal business processes, and how AI can help bend the curve on innovation. With generative AI, that value gets exponentially greater, as we’ve seen in the past year with generative AI technologies from OpenAI such as ChatGPT.

“IDC is projecting that generative AI will add nearly $10 trillion to global GDP over the next 10 years.** Calculating the value of new investments in GenAI requires building the business case by simulating potential cost and responsible value realization,” said Ritu Jyoti, Group Vice President AI and Automation for IDC.

This wave of innovation has accelerated the pace of AI adoption in ways that are changing and augmenting how we work and live, and Microsoft customers are increasingly embracing AI opportunities for business transformation.

Enrich employee experiences: Employees in every industry are dealing with an increasing volume of digital debt and administrative burdens that slow down productivity and get in the way of meaningful work. To address this challenge, AI is being used to bring together unstructured data like social media, product details and customer engagement to better tailor communications, enable more intelligent insights and solve problems faster. Additionally, employees are using Azure OpenAI and Microsoft Copilot in Microsoft 365 to augment their copywriting capabilities for things like presentations, website content, case studies, blogs, press releases, search engine optimization and digital art.

Reinvent customer engagement: With the heavy competition for customer acquisitions and retention, organizations have struggled to keep pace with the increasing amount of customer signals, and to deliver personalized service to customers in real-time. To drive greater customer loyalty, organizations are applying the AI capabilities of Dynamics 365 in contact centers for real-time assistance and guidance on suggested responses. Employees are also using AI to summarize conversations, guide on next steps, and get coaching feedback. Azure-powered virtual assistants are being used to deliver all kinds of hyper-personalized experiences across different verticals like healthcare for processing claims and entertainment for sports fans. Salespeople are using Viva Sales to help nurture leads and close deals.



Reshape business processes: Companies have pockets of valuable information scattered throughout their organization that can be difficult for employees to locate and use holistically. By finding and making connections across this information, AI can surface integrated insights that help to predict and accelerate workloads. This is particularly evident in cybersecurity, where employees are using AI insights to identify bad actors more quickly and better protect both employees and intellectual property. AI is also being used in manufacturing and operations, to create digital replicas of their supply chain environments so they can run simulations and optimize workflow management, resulting in enhanced supply chain efficiency.

Bend the curve on innovation: This is an exciting concept as companies in every industry look to regain an edge. Organizations can deploy AI to stay ahead of changing business dynamics, and to exceed customer expectations. By not having to modernize every underlying system to achieve these results, and by putting AI directly in the hands of developers with GitHub Copilot, organizations can operate with agility and accelerate innovation. Teams can leverage AI to help scale production and speed to market while being able to focus on higher-value activities.

IDC survey data confirms that businesses are eager to adopt AI technology, with 71% of survey respondents currently using AI tools in their organizations, and 22% planning to do so within the next 12 months. However, even with this momentum and positive outlook for what AI can help them achieve, organizations are facing challenges when it comes to implementation. A shortage of skilled employees is holding companies back from accelerating their AI-based innovations, with 52 percent of those surveyed reporting a lack of skilled workers needed to implement and scale AI initiatives across business functions as the top blocker.

To help address the skilling gap, Microsoft has already engaged over 6 million people globally in learning activities in the last 12 months and has ambitions to provide skills to everyone using our AI technology. We have also empowered our ecosystem of more than 400,000 partners worldwide with the skills needed to implement AI technology responsibly and to deliver greater customer value.

No matter where you are in your cloud and AI transformation journey, Microsoft can help. To learn more about how customers across industries are shaping their AI transformation with Microsoft, please visit the Microsoft Cloud blog which shares real-world examples of business impact being driven by AI, as well as resources and skilling opportunities you can use to build your readiness to lead the era of AI.

About the study

The IDC study, commissioned by Microsoft, is based on results from 2,109 enterprise organizations totaling more than 13 million employees worldwide across 16 countries globally. Through the questionnaire, respondents were identified as the decision maker for AI within their organization.

Source: *IDC Infographic, sponsored by Microsoft, The Business Opportunity of AI, IDC #US51315823, November 2023. **Generative Artificial Intelligence: A New Chapter for Enterprise Business Applications, IDC Perspective #US50471523, March 2023.

Tags: AI"
Microsoft_News,https://news.microsoft.com/europe/features/a-future-facing-minister-a-young-inventor-and-a-shared-vision-an-ai-tutor-for-every-student/,,"A future-facing minister, a young inventor and a shared vision: An AI tutor for every student","Since the age of 14, when he found his textbooks tedious, Pativada had actually been dreaming of ways to learn faster and more efficiently. His first app summarized text to create flash cards. Now he thinks the app he is developing with the U.A.E. Ministry of Education is fulfilling those teenage dreams.

Quddus Pativada, 20, is the founder and CEO of ASI, a startup that is creating an AI tutor. Photo by Chris Welsch for Microsoft.

“A tutor really gives a student a leg up outside of class,” he says. “I mean, even I had a tutor in high school, and I saw the difference it made. We want to make that kind of help accessible to every student.”

The Ministry of Education and Pativada see what has become known as the U.A.E. AI Tutor as a way to provide students with 24/7 assistance as well as help level the playing field for those families who cannot afford a private tutor. At the same time, the AI Tutor would be an aid to teachers, they say. “We see it as a tool that will support our teachers,” says Aljughaiman. “This is a supplement to classroom learning.”

ASI is building the U.A.E. AI Tutor with Microsoft’s AI capabilities including Azure OpenAI Service and Azure Machine Learning. The app, which functions in Arabic and English, is designed to teach as many teachers do – by answering one question with information and more questions, drawing the student deeper into the subject matter by responding to the student at the student’s level.

Pativada says that his team, using Azure OpenAI’s GPT-4 API and a custom variant of the U.A.E.’s Falcon model, has altered it so that it is personalized for each user and that it aligns with the U.A.E. curriculum and standards.

“We developed a model that was able to steer responses of a larger model like GPT-4 and personalize them to the student,” he says.

“Students can be confident they’re using a tool that understands the same content they study, and it references it,” he says.

Saif Hassan Ibrahim, 16, uses a closed beta prototype of the U.A.E. AI Tutor in Dubai. Photo by Chris Welsch for Microsoft.

Saif Hassan Ibrahim, 16, is an Emirati high school student who has been using a closed beta version of the U.A.E. AI Tutor for four months. He participated in the U.A.E.’s largest national science competition three times with projects to fight climate change, winning prizes each time. He says that even in the sophisticated research involved in his most recent project, the AI tutor has been invaluable in helping him grow as a scientist.

“I basically synthesized a novel material that efficiently processes carbon dioxide in a single step and explored its use in a new model for CO2 capture facilities,” he explains.

He says that what surprised him was as the AI tutor got to “know” him, it worked with him as a “copilot” at his level.

“Over time, as you basically engage with the responses to questions,” he says, “it seems to adapt to you and your understanding level. … It formulates questions in an order that aligns with the knowledge I already possess, allowing me to learn at my current pace.”

Soon, a small cohort of students will test a closed beta version of the AI tutor for the U.A.E. schools. That app uses U.A.E. curriculum, is bilingual in English and Arabic, and all data collected from its use will be housed in the U.A.E., where Microsoft has a datacenter. “That’s exactly why we are partnering with Microsoft. Microsoft is our trusted partner when it comes to data,” says Aljughaiman.

Microsoft will be announcing the availability of the Azure OpenAI Service in the cloud region of the U.A.E. later this year. The U.A.E. Ministry of Education and other organizations in the Emirates will be able to leverage the power of Azure’s cutting-edge generative AI capabilities with local data residency, meeting local requirements.

For the U.A.E., the priority is to help students and give teachers a tool they can use to help students achieve excellence. “The key thing is to provide support to the students,” she says."
Microsoft_News,https://www.microsoft.com/en-us/worklab/how-copilot-turns-everyone-into-a-manager,,How Copilot Turns Everyone Into A Manager,"This article first appeared in the WorkLab newsletter. Be the first to get our updates by subscribing here.



Earlier this year, we launched an early access program for Microsoft 365 Copilot. In the months since, tens of thousands of people have started using it as a regular part of their workday. And we’ve learned something surprising: more experienced people managers are having an easier time adapting to the new technology than their less experienced counterparts.

That’s not what we expected. As Jared Spataro, Microsoft’s Corporate Vice President of Modern Work & Business Applications recently pointed out, we assumed that younger digital natives would take more readily to a new way of working. But it turns out that Copilot transforms everyone into a manager—and those skills are essential to getting the full value of the technology.

Sure, Copilot automates some of the more routine, mundane aspects of work, finding that deck your co-worker shared in that meeting the other day. Where users are finding the most value, though, is assigning Copilot more complex and nuanced tasks, like writing an email from scratch in a tone that’s tailored to a specific audience, or analyzing a dataset and suggesting an appropriate visualization format.

In that sense, Copilot has capabilities akin to those of a very well-qualified but early-in-career employee. To tap into its full potential, you need the skills that most people develop as they grow into roles where they direct the work of others. You need to think like a manager.

Those skills include:

Breaking down work into smaller pieces

Assigning work in a way that clearly defines expectations and provides the necessary context and parameters

Evaluating the work that comes in, reviewing it, and offering feedback

Effectively moving forward with decisions and deliverables

Senior leaders are typically more well-versed in these management techniques than early-in-career employees, which means that getting your organization ready for generative AI isn’t about developing your employees’ technology skills. It’s about developing your employees’ people skills—foundational leadership and management capabilities.

Train them, offer them how-to guides, and, crucially, give them opportunities to lead, whether formally or informally. That’s going to be essential in this new era—and organizations that get their employees ready will be the ones that reap the benefits."
Microsoft_News,https://news.microsoft.com/2023/10/31/siemens-and-microsoft-partner-to-drive-cross-industry-ai-adoption/,,Siemens and Microsoft partner to drive cross-industry AI adoption,"Siemens and Microsoft partner to drive cross-industry AI adoption

Companies introduce Siemens Industrial Copilot, a generative AI-powered assistant, designed to enhance human-machine collaboration and boost productivity.

Companies will work together to build additional copilots for manufacturing, infrastructure, transportation, and healthcare industries.

Leading automotive supplier, Schaeffler AG, is an early adopter of Siemens Industrial Copilot.

In addition, the Siemens Teamcenter app for Microsoft Teams will be generally available in December 2023 and accelerate innovation across the product lifecycle.

Microsoft and Siemens are deepening their partnership by bringing the benefits of generative AI to industries worldwide. As a first step, the companies are introducing Siemens Industrial Copilot, an AI-powered jointly developed assistant aimed at improving human-machine collaboration in manufacturing. In addition, the launch of the integration between Siemens Teamcenter software for product lifecycle management and Microsoft Teams will further pave the way to enabling the industrial metaverse. It will simplify virtual collaboration of design engineers, frontline workers, and other teams across business functions.

“With this next generation of AI, we have a unique opportunity to accelerate innovation across the entire industrial sector,” said Satya Nadella, Chairman and CEO, Microsoft. “We’re building on our longstanding collaboration with Siemens and bringing together AI advances across the Microsoft Cloud with Siemens’ industrial domain expertise to empower both frontline and knowledge workers with new, AI-powered tools, starting with Siemens Industrial Copilot.”

“Together with Microsoft, our shared vision is to empower customers with the adoption of generative AI,” says Roland Busch, CEO of Siemens AG. “This has the potential to revolutionize the way companies design, develop, manufacture, and operate. Making human-machine collaboration more widely available allows engineers to accelerate code development, increase innovation and tackle skilled labor shortages.”

A new era of human-machine collaboration

Siemens Industrial Copilot will allow users to rapidly generate, optimize and debug complex automation code, and significantly shorten simulation times. This will reduce a task that previously took weeks to minutes. The copilot ingests automation and process simulation information from Siemens’ open digital business platform, Siemens Xcelerator, and enhances it with Microsoft’s Azure OpenAI Service. Customers maintain full control over their data, and it is not used to train underlying AI models.

Siemens Industrial Copilot promises to boost productivity and efficiency across the industrial lifecycle. Using natural language, maintenance staff can be assisted with detailed repair instructions and engineers with quick access to simulation tools.

The vision: Copilots for all industries

The companies envision AI copilots assisting professionals in various industries, including manufacturing, infrastructure, transportation, and healthcare. Numerous copilots are already planned in the manufacturing sectors, such as automotive, consumer package goods and machine building.

Schaeffler AG, a leading automotive supplier, is among the first in the automotive industry to embrace generative AI in the engineering phase. This helps its engineers to generate reliable code for programming industrial automation systems such as robots. In addition, the company intends to incorporate Siemens Industrial Copilot during their own operations, aiming to significantly reduce downtimes, and also for their clients at a later stage.

”With this joint pilot, we’re stepping into a new age of productivity and innovation. This Siemens Industrial Copilot will help our team work more efficiently, reduce repetitive tasks, and unleash creativity. We’re excited to partner with Siemens and Microsoft on this project,” says Klaus Rosenfeld, CEO of Schaeffler Group.

Generative AI facilitates virtual collaboration

To bring virtual collaboration across teams to the next level, Teamcenter for Microsoft Teams will be generally available beginning December 2023. This new app uses the latest advances in generative AI to connect functions across the product design and manufacturing lifecycle such as frontline workers to engineering teams. It connects Siemens’ Teamcenter software for product lifecycle management (PLM) with Microsoft’s collaboration platform Teams to make data more accessible for factory and field service workers. This will enable millions of workers who do not have access to PLM tools today to contribute to the design and manufacturing process more easily as part of their daily work.

Siemens will share more details on Siemens Industrial Copilot at the SPS expo in Nuremberg, Germany, in November 2023.

Siemens AG

Siemens AG (Berlin and Munich) is a technology company focused on industry, infrastructure, transport, and healthcare. From more resource-efficient factories, resilient supply chains, and smarter buildings and grids, to cleaner and more comfortable transportation as well as advanced healthcare, the company creates technology with purpose adding real value for customers. By combining the real and the digital worlds, Siemens empowers its customers to transform their industries and markets, helping them to transform the everyday for billions of people. Siemens also owns a majority stake in the publicly listed company Siemens Healthineers, a globally leading medical technology provider shaping the future of healthcare. In addition, Siemens holds a minority stake in Siemens Energy, a global leader in the transmission and generation of electrical power.

In fiscal 2022, which ended on September 30, 2022, the Siemens Group generated revenue of €72.0 billion and net income of €4.4 billion. As of September 30, 2022, the company employed around 311,000 people worldwide. Further information is available on the Internet at www.siemens.com.

Siemens global Website

Discover Siemens as a strong partner, technological pioneer and responsible employer.

About Microsoft

Microsoft (Nasdaq “MSFT” @microsoft) enables digital transformation for the era of an intelligent cloud and an intelligent edge. Its mission is to empower every person and every organization on the planet to achieve more.

For more information, press only:

Florian Martens

Siemens AG

+49 162 2306627

[email protected]

Bernhard Wardin

Siemens AG

+49 173 3270510

[email protected]

Microsoft Media Relations

WE Communications for Microsoft

(425) 638-7777

[email protected]"
Microsoft_News,https://news.microsoft.com/source/features/work-life/a-dai-in-the-life-of-miri-rodriguez/,,A dAI in the life of Miri Rodriguez,"Miri Rodriguez is a storyteller for a Microsoft sales team focused on the health and public sector industries, and she runs her own wellness business and blog. She lives in Miami with her husband and has two sons in college.

AI tools help her consider different viewpoints and be more inclusive as she writes in English and Spanish for different groups around the world. “I have my own biases and experiences as a Latina immigrant woman who grew up in Venezuela,” Rodriguez says, “and Bing Chat helps me remove those biases by giving me context about what’s happening in different parts of the world so I can consider the right words for my specific audiences.”

She also recalls spending too much time last year reading reports just to find one relevant insight. “Now AI can scan and summarize for me,” she says, “so I have more time to focus on the creative aspects of my work, as well as more time for myself and my family.”

Rodriguez, 45, shares a typical day as part of Microsoft’s “A dAI in the life” series, which showcases how AI tools are helping people do more in their personal and professional lives."
Microsoft_News,https://news.microsoft.com/europe/features/a-job-creation-program-brings-new-ai-skills-to-thousands-of-young-south-africans/,,A job-creation program brings new AI skills to thousands of young South Africans,"Like Phakitso Mohale, the young people who complete programs at tech companies tend to get jobs right away. Naidoo says, however, that even in some other kinds of jobs, the exposure to AI will have a carry-on effect.

“Even if a person worked in a warehouse, but they were comfortable with AI programs, that’s going to be very important – how things are stacked, unpacked and connected to the consumer,” he says. “They’re going to come back and open up other warehousing solutions elsewhere with that experience.”

Adam Craker is the CEO of IQbusiness, which was one of the first 10 South African companies to join YES in 2019. He is an enthusiastic champion of the program. IQBusiness is a management consulting service for the banking, financial services, health insurance and telecommunications industries. More than 200 of the about 1,100 employees of IQBusiness are former YES participants.

“The one-year program is a very structured immersion into consulting, training, technology training, exposure to clients and project evaluation,” Craker says, adding that more than 95% of IQbusiness apprentices, through its YES-aligned intern program, end up with jobs in the company. It is “a very important part of our growth in terms of talent coming into the company.”

IQbusiness helped develop the YES program, and data and data analysis are key to its success, Craker says. “Having a feedback mechanism is really important,” he says. “We don’t want to be just standing still, we want to improve the program every year.”

Every YES participant receives a smartphone with a dedicated app that provides the trainings they are required to complete during the first six months of the apprenticeship. It also has tools for giving feedback on how satisfied the apprentice is with his or her placement.

Kgomotso Sekhu works as a data analyst at Nedbank, one of South Africa’s largest banks. Photo by Chris Welsch for Microsoft.

Preparing for success in many ways

The trainings go beyond Microsoft’s tech offerings.

“There was also etiquette training,” recalls Kgomotso Sekhu, 29, with a laugh. She was in the first program in 2019. “We were even taught how to use a fork and knife in a restaurant, how to place your glass and your plate. I still remember it every time I go to a restaurant.”

Sekhu grew up in a village in Hammanskraal, a region north of Pretoria. She says she is the first member of her family to graduate from college; she has a degree in mathematics from the University of Pretoria. She spent her apprenticeship at Nedbank, one of South Africa’s largest. Now she is a data analyst in the bank’s private wealth division.

Malcolm MacDonald is the chief information officer at YES, in charge of tech strategy and how the data gathered from the YES app and training modules is used. He says the training is key to the success of the program “because we want to produce people at the end of this program who are imminently hirable.”

He says learning the basics of AI is a key part of that.

“We want every alumni of this program to be adding value where they are by being more efficient through AI,” he says."
Microsoft_News,https://blogs.microsoft.com/on-the-issues/2023/10/27/uk-ai-safety-summit-responsible/,,Progress with our AI commitments: an update ahead of the UK AI Safety Summit,"Today, Microsoft is sharing an update on its AI safety policies and practices ahead of the UK AI Safety Summit. The summit is part of an important and dynamic global conversation about how we can all help secure the beneficial uses of AI and anticipate and guard against its risks. From the G7 Hiroshima AI Process to the White House Voluntary Commitments and beyond, governments are working quickly to define governance approaches to foster AI safety, security, and trust. We welcome the opportunity to share our progress and contribute to a public-private dialogue on effective policies and practices to govern advanced AI technologies and their deployment.

Since we adopted the White House Voluntary Commitments and independently committed to several other policies and practices in July, we have been hard at work to operationalize our commitments. The steps we have taken have strengthened our own practice of responsible AI and contributed to the further development of the ecosystem for AI governance.

The UK AI Safety Summit builds on this work by asking frontier AI organizations to share their AI safety policies – a step that helps promote transparency and a shared understanding of good practice. In our detailed update, we have organized our policies by the nine areas of practice and investment that the UK government is focused on. Key aspects of our progress include:

We strengthened our AI Red Team by adding new team members and developing further internal practice guidance. Our AI Red Team is an expert group that is independent of our product-building teams; it helps to red team high-risk AI systems, advancing our White House Commitment on red teaming and evaluation. Recently, this team built on OpenAI’s red teaming of DALL-E3, a new frontier model announced by OpenAI in September, and worked with cross-company subject matter experts to red team Bing Image Creator.

We evolved our Security Development Lifecycle (SDL) to link our Responsible AI Standard and integrate content from within it, strengthening processes in alignment with and reinforcing checks against governance steps required by our Responsible AI Standard. We also enhanced our internal practice guidance for our SDL threat modeling requirement, accounting for our ongoing learning about unique threats specific to AI and machine learning. These steps advance our White House Commitments on security.

We implemented provenance technologies in Bing Image Creator so that the service now discloses automatically that its images are AI-generated. This approach leverages the C2PA specification that we co-developed with Adobe, Arm, BBC, Intel, and Truepic, advancing our White House Commitment to adopt provenance tools that help people identify audio or visual content that is AI-generated.

We made new grants under our Accelerate Foundation Models Research program, which facilitates interdisciplinary research on AI safety and alignment, beneficial applications of AI, and AI-driven scientific discovery in the natural and life sciences. Our September grants supported 125 new projects from 75 institutions across 13 countries. We also contributed to the AI Safety Fund supported by all Frontier Model Forum members. These steps advance our White House Commitments to prioritize research on societal risks posed by AI systems.

In partnership with Anthropic, Google, and OpenAI, we launched the Frontier Model Forum. We also contributed to various best practice efforts, including the Forum’s effort on red teaming frontier models and the Partnership on AI’s in-development effort on safe foundation model deployment. We look forward to our future contributions to the AI Safety working group launched by ML Commons in collaboration with the Stanford Center for Research on Foundation Models. These initiatives advance our White House Commitments on information sharing and developing evaluation standards for emerging safety and security issues.

Each of these steps is critical in turning our commitments into practice. Ongoing public-private dialogue helps us develop a shared understanding of effective practices and evaluation techniques for AI systems, and we welcome the focus on this approach at the AI Safety Summit.

We look forward to the UK’s next steps in convening the summit, advancing its efforts on AI safety testing, and supporting greater international collaboration on AI governance.

Tags: AI, AI safety policies, ChatGPT, OpenAI, Responsible AI, United Kingdom"
Microsoft_News,https://cloudblogs.microsoft.com/dynamics365/bdm/2023/10/25/microsoft-business-applications-launch-event-introduces-wave-of-new-ai-powered-capabilities-for-dynamics-365-and-power-platform/,,Microsoft Business Applications Launch Event introduces new AI capabilities,"Today, at the Microsoft Business Applications Launch Event, we kicked off the 2023 release wave 2 for Microsoft Dynamics 365 and Microsoft Power Platform, a six-month rollout of new and enhanced capabilities scheduled for release between October 2023 and March 2024.

This release wave introduces hundreds of new features across Microsoft Power Platform applications, including enhanced capabilities for governance, administration, and professional development. Updates for Dynamics 365 include innovation to help employees be more productive, create exceptional customer experiences and deepen relationships, and drive meaningful growth across the business. This release also features new AI capabilities in Copilot—which more than 130,000 organizations have now experienced—that help to improve insights, save time, and enhance creativity across Dynamics 365 and Microsoft Power Platform.

Tune in to the launch event, live or on-demand, for a concise overview of the release wave, as well as a firsthand look at how organizations like Nestlé, Kodak Alaris, Northern Trust, Centrica, Spark NZ, Domino’s Pizza UK and Ireland, and Suffolk are adopting these capabilities to drive transformative changes in their businesses.

Some of the themes at the event include:

A new era of AI-powered customer service and field service

Transforming enterprise resource planning (ERP) with AI

Enhancing customer experience through AI-driven transformation

Leading a new era of AI-generated low-code app development with Microsoft Power Platform

A new era of AI-powered customer service and field service

As a frontline for customer loyalty, service agents and field teams need access to information and insights to understand customer needs and respond appropriately. New Copilot capabilities for Microsoft Dynamics 365 Customer Service and Microsoft Dynamics 365 Field Service will help reduce time spent on common tasks, as well as introduce enhancements to the Customer Service workspace. Updates include improved inbox functionality, a redesigned voice experience, enhanced collaboration through Microsoft Teams, and integrated diagnostics for administrators—all aimed at boosting agent productivity and operational efficiency.

During the session led by Jeff Comstock, Corporate Vice President, Customer Service, we demonstrated how Copilot assists customer service and field service processes, including customer self-service, across various channels.

We also revealed how customers like Northern Trust Corporation, a leading wealth and asset management institution, can use Copilot to assist the client services team with tasks ranging from account reviews and case investigations to post-resolution wrap-ups. Northern Trust Corporation has not only gained recognition for its innovative financial services, but also for its unwavering commitment to customer service. With Dynamics 365 Customer Service as a steadfast component of its journey, the latest capabilities in release wave 2 can help the client service teams at Northern Trust be even more efficient, effective, and customer-focused, streamlining its workflow and enhancing its ability to provide timely and accurate support to clients.

The session also delved deeper into the field service domain, where Centrica, a global energy services company, effectively manages its sizable workforce of 12,000 field operatives on site by harnessing the new capabilities of Dynamics 365 Field Service, streamlining processes from task assignments to issue resolution.

To learn more about release wave 2 capabilities for Dynamics 365 Customer Service and Field Service, visit the release planner.

Transforming ERP with AI

The new release wave harnesses AI, automation, and analytics to help organizations drive greater operational efficiency across finance, supply chain, and operations—capabilities that enhance visibility, automate processes, extend coverage, and deliver a more integrated experience across departments.

Updates to Microsoft Dynamics 365 Finance include the general availability of extended planning and analysis, which brings together operational and financial planning to continuously plan, act, and analyze. In addition, the general availability of business performance analytics streamlines financial reporting by centralizing data from multiple business processes and in an easy-to-use interface.

Updates to Microsoft Dynamics 365 Supply Chain Management include improvements in demand planning, as well as procure-to-pay processes. Copilot will now suggest actions that can help purchasing agents make better decisions in response to new and updated information that affects open purchase orders.

At the launch event, Georg Glantschnig, Vice President, AI ERP, showcased how Domino’s Pizza UK and Ireland is improving its demand planning accuracy by using AI. These new features have greatly enhanced its capacity to serve more customers by precisely planning food requirements, thereby reducing food waste, and improving environmental sustainability through more efficient facility operations. Additionally, the process of fulfilling purchase orders has also seen a remarkable enhancement, thanks to Copilot.

We also demonstrated how New Zealand’s largest telecommunications and digital services provider, Spark NZ, is transforming its finance and supply chain operations with Microsoft Dynamics 365. It can now automate many of its financial processes—including vendor invoice processing, automatic revaluation of foreign currency transactions, transaction reconciliation, billing, and complex tax calculations. Human resources can also streamline processes, from hiring to self-service vacation time requests and tracking.

See the release plans for Dynamics 365 Finance, Supply Chain Management, Project Operations, and Human Resources.

Enhancing customer experience through AI-driven transformation

With Microsoft Dynamics 365 Sales, Microsoft Dynamics 365 Customer Insights, and Copilot you can use data and insights that used to be hidden, unlock capabilities previously out of reach, and reach new levels of productivity and collaboration.

The new release wave introduces a variety of solutions to help marketers and sales professionals use Copilot to deepen their understanding of their target customer base, streamline engagement processes, and push the boundaries in crafting exceptional customer experiences.

In the closing keynote session, Lori Lamkin, Corporate Vice President, Customer Experience, demonstrated how Kodak Alaris, a global technology company, effectively used Copilot within Dynamics 365 Sales and Customer Insights. Taking advantage of the new AI capabilities, it tapped into previously hidden data to target its customer base, unlocking capabilities that were once out of reach. Using Copilot, it was able to create unique personalized content to keep customers informed about its services and effortlessly establish new levels of productivity and customer connection, attracting new businesses like never before.

For more details, review the release plans for Dynamics 365 Sales and Dynamics 365 Customer Insights.

Leading a new era of AI-generated low-code app development with Microsoft Power Platform

Copilot in Power Platform ushers in a new era of AI-assisted low-code development. Copilot features in release wave 2 make it even easier to quickly create solutions.

At the launch event, Sangya Singh, Vice President, Power Pages, showcased how Copilot plays a vital role in democratizing development, enabling a broader audience—both citizen and professional developers—to create innovative solutions using natural language.

Through the lens of Suffolk, one of America’s largest construction companies, we demonstrated how Microsoft Power Automate helped them streamline critical material request processes, enabling teams to use Copilot in Power Automate to build flows by describing what they need.

We also showcased how Microsoft Power Apps can help Suffolk facilitate efficient coordination of construction status updates, and how the generative answers capability in Microsoft Power Virtual Agents can search industry resources for answers, reducing manual research. We also demonstrated how Microsoft Power Pages improves collaboration with multiple partners on construction projects, and how Microsoft Power BI can help Suffolk visualize safety data at construction sites across the globe, highlighting the trends, causes, and outcomes of incidents and near misses so that preventative actions can be easily identified and implemented.

In addition to enhancing daily business operations, Copilot within Microsoft Power Platform has significantly improved the governance and administrative experience, expediting the development of these applications.

Visit the Microsoft Power Platform release planner for more details.

Tune in to the Microsoft Business Applications Virtual Launch Event

Microsoft Business Applications Launch Event Tune in live or on-demand for a concise overview of the release wave. Watch now

Watch the launch event on-demand for in-depth insights and demonstrations of the new capabilities across Dynamics 365 and Microsoft Power Platform. You can also delve into several deep-dive presentations on topics including Microsoft Dynamics 365 Business Central, responsible AI practices, and a fireside chat that explores the latest features in this release wave.

Don’t forget to explore the detailed release plans for Dynamics 365 and Microsoft Power Platform to stay informed about what’s new and on the horizon.

We also invite you to learn more about the latest AI innovation at Microsoft Ignite 2023, taking place in Seattle from November 14 through November 17, 2023, with online sessions available live and on-demand on November 15 and November 16. Register today."
Microsoft_News,https://news.microsoft.com/a-dai-in-the-life/,,A dAI in the life: Simple AI tricks for getting more out of each day,"AI is probably already a part of your day, helping navigate your trip to work, recommending movies you’ll like or predicting words when you’re texting friends.

But some of the latest tools can help you do even more. You can use AI to get dinner recipes for what’s in your fridge, advice on how to train your puppy, or a summary of an important meeting so you can focus on your coworkers instead of taking notes.

Welcome to Microsoft’s “A dAI in the life,” where people are sharing stories of how they’re using AI in their personal and professional lives. Take a peek through their daily diaries for tips and tricks that might be helpful, productive and fun."
Microsoft_News,https://news.microsoft.com/source/features/work-life/a-dai-in-the-life-of-liam-flowers/,,A dAI in the life of Liam Flowers,"Liam Flowers is a marketing program manager for Xbox Experimentation who lives in Seattle with his wife and two 90-pound dogs. In his free time, he paints, creates art and cares for the growing houseplant collection he has had “ever since my wife showed me how to propagate them.”

While Flowers likes using AI tools to help him come up with concepts for his art, he has discovered this year that the tools are indispensable at work. “I’ve got wicked ADHD, and when it comes to keeping my thoughts in order, I will sometimes spit stuff out at Bing Chat to see what it says, and it’s a good vetting process for me,” Flowers says. “Also, I like to be sure I’m remembering correctly, so when Teams intelligent meeting recaps rolled out in the spring, I almost cried. They’ve become hugely important. I used to frantically scribble notes during meetings, but this tool helps me engage fully.”

Flowers, 32, shares a typical day as part of Microsoft’s “A dAI in the life” series, which showcases how AI tools are helping people do more in their personal and professional lives.

9 a.m.

Calls start at work, and there’s lots to keep track of. I use Teams intelligent recap to compose notes and provide bullet lists of action items from each call. Bing Chat — I use the Enterprise version at work — helps me with deeper critical thinking. I am not fast to reply to a lot of things because I like to be thorough, and this tool has replaced a half-dozen others by simply being able to have a discussion.

It’s also unbelievably helpful with review. I have SharePoint Copilot review Word and PowerPoint documents. It can answer questions about them and summarize the content, and it works conversationally, so little prompting knowledge is needed.

12:30 p.m.

I’m currently onboarding into a new role, and I use AI for everything in my training. For example, I’m learning a new data scorecard system for experiments, which is complex stuff. With Bing Chat’s sidebar function in Edge, I can translate grids of dense figures into a story about innovation with just a few prompts.

I’m not a data scientist, so this part of my work used to take the most of my brainpower. Now I get to focus on experience and impact. Bing Chat in the Edge browser deciphers acronyms and metric definitions into plain language, highlighting connections in the data, and can even review others’ work and compare reports I read against the data to look deeper. Here’s an example: “Make a table of all metrics on this page, their definitions, and changes between Control and Treatment.”"
Microsoft_News,https://news.microsoft.com/source/features/work-life/a-dai-in-the-life-of-janet-kim/,,A dAI in the life of Janet Kim,"Janet Kim is a senior communications manager for Microsoft who lives in Bothell, Washington, with her husband, two “very active and energetic” sons and her mother, who flies back and forth from Texas to help with the boys. Kim, 39, says she was surprised when AI was able to help with the challenge of having three generations living together.

Kim mainly uses Bing Chat to help her plan trips that her family will enjoy. The tool has given “excellent recommendations that were perfect for kids” for trips to Hawaii, when Kim was on a budget and was looking for free or low-cost activities, and the Joshua Tree National Park, when the family had a tight timeline.

She shares a typical day as part of Microsoft’s “A dAI in the life” series, which showcases how AI tools are helping people do more in their personal and professional lives."
Microsoft_News,https://news.microsoft.com/source/features/work-life/a-dai-in-the-life-of-omar-smith/,,A dAI in the life of Omar Smith,"10 a.m.

Join a Microsoft Teams video call with my colleagues. I brainstorm ideas for the campaign and use Teams intelligent recap to generate a summary of our discussion and then put the recap emails and personal notes in Microsoft Loop to help us collaborate.

11 a.m.

Take a break and play with my puppy. Ask Bing to create a fun caption to pair with a photo I captured of him playing. I gave Bing some examples of rappers that we like, and here’s the response it gave me: “Tobi is my right hand, my go-to / He’s always by my side, he’s loyal and true / He’s more than just a dog, he’s family / He’s got me feeling some type of way, he’s the real MVP.” The suggestion was a little lengthy and not totally in my tone of voice, but it gave me a great foundation to tweak it.

12 p.m.

Make some lunch and play a bit on my Xbox. I know Bing can make recommendations based on my chat history, so I ask it to help me brainstorm what my in-game persona should be in Starfield. I end up creating a Space Ronin with alien DNA, and Bing helps me come up with a name for my spaceship and helps me craft my own backstory with sci-fi references that fits within the context and lore of Starfield, so I can have an idea of what choices I want to make in my playthrough. It also tells me about an unlockable outfit that I didn’t even know was part of Starfield and that perfectly matches my in-game aesthetic, so that’s cool to discover.

4 p.m.

I check the analytics of a social campaign I’m working on and ask Bing Chat Enterprise to give me some insights and recommendations on how to improve it, then build on them in my retrospective exercise before sharing with my manager and partners.

5 p.m.

I wrap up work and turn to school. Ask Bing for relevant scholarships I qualify for, for the master’s program I’m enrolled in, and get Bing’s help to format a paper in the APA style, since I’m more used to using MLA style from my undergrad years.

6 p.m.

Cook dinner using a recipe that Bing suggested based on what I told it I have in my fridge and pantry — salmon, tomatoes, onions, sweet potatoes and spinach — using my new air fryer. I check my Bing search history and go back to a discussion from two weeks ago so I can ask a clarifying question about a trick to air-fry salmon with sweet potatoes.

7 p.m.

Ask Bing to suggest some good movies to watch with my girlfriend, or a new drama or love-reality TV show. We settle on its reality dating show suggestion.

Read more stories in Microsoft’s “A dAI in the life” series and share your story.

Story as told to Microsoft Source writer Susanna Ray.

Lead photo by Scott Eklund/Red Box Pictures; other images provided by Omar Smith."
Microsoft_News,https://news.microsoft.com/source/features/work-life/a-dai-in-the-life-of-miri-rodriguez/,,A dAI in the life of Miri Rodriguez,"Miri Rodriguez is a storyteller for a Microsoft sales team focused on the health and public sector industries, and she runs her own wellness business and blog. She lives in Miami with her husband and has two sons in college.

AI tools help her consider different viewpoints and be more inclusive as she writes in English and Spanish for different groups around the world. “I have my own biases and experiences as a Latina immigrant woman who grew up in Venezuela,” Rodriguez says, “and Bing Chat helps me remove those biases by giving me context about what’s happening in different parts of the world so I can consider the right words for my specific audiences.”

She also recalls spending too much time last year reading reports just to find one relevant insight. “Now AI can scan and summarize for me,” she says, “so I have more time to focus on the creative aspects of my work, as well as more time for myself and my family.”

Rodriguez, 45, shares a typical day as part of Microsoft’s “A dAI in the life” series, which showcases how AI tools are helping people do more in their personal and professional lives."
Microsoft_News,https://blogs.microsoft.com/blog/2023/10/23/innovating-with-responsibility-how-customers-and-partners-are-bridging-data-ai-and-trust-with-the-microsoft-cloud/#new_tab,,"Innovating with responsibility: How customers and partners are bridging data, AI and trust with the Microsoft Cloud","For the past decade, we have been on a journey with our customers to help them achieve digital transformation, which is business transformation empowered by cloud technology. With increasing excitement around generative AI — both for its potential and the impact it is already having — organizational leaders are eager to prioritize adoption that takes advantage of this next wave of AI transformation. At Microsoft, we are working with our customers to pragmatically assess and develop responsible, secure AI strategies focused on maximizing their investment while yielding desired business outcomes. With our differentiated copilot capabilities, customers can take advantage of the latest advancements in generative AI across the services they already know and love; and with the confidence they are building upon the most integrated, comprehensive and trusted cloud in the industry. Together with our unmatched partner ecosystem — from the ISVs helping shape industries to the digital natives that are disrupting them — we are building generative AI solutions that will unlock productivity and innovation opportunities for organizations everywhere. In many cases, we are co-innovating and co-developing custom AI solutions directly with our customers. As I look back on the past quarter, I am humbled by what we have achieved together and the incredible effort by organizations across industries to embrace AI transformation.

Organizations like 3M, Prada Group and Campari have been testing copilot features in Dynamics 365 and Power Platform firsthand, while General Motors, Visa, KPMG , AGL, Data #3, Bupa, NAB, Powerlink Queensland, Rest Super and Suncorp are now part of the Microsoft 365 Copilot Early Access Program. Our collaboration with IBM is helping clients accelerate the deployment of generative AI with its new Azure OpenAI Service offering, and we are enabling thousands of organizations like PepsiCo, Vodafone and Voya Financial with Azure cloud services through our expanded partnership with Oracle. To empower employees across 34 countries, Grupo Bimbo developed a solution with an integrated copilot in two weeks to help prevent non-compliance and save time when asking questions about company policies. All of Microsoft’s AI-powered copilots are backed by our Copilot Copyright Commitments to extend IP and legal protection to enterprise customers who use these services, building upon our AI Customer Commitments.

Helping healthcare professionals and providers focus on patient care and support through secure data automation and training

By securely centralizing its data in an AI-powered intelligent data platform on Azure, Mercy is able to use generative AI to help patients schedule appointments more efficiently and better understand their lab results. Mayo Clinic is deploying Microsoft 365 Copilot to ease the burden of administrative demands on healthcare providers so they can focus on patient care, while Duke Health is partnering with Microsoft to responsibly and ethically harness the potential of generative AI and the Microsoft Cloud to redefine the healthcare landscape. To speed up care and improve patient experiences, MultiCare has automated its medication reconciliation process and increased efficiency by 175% with help from Microsoft and partner 3Cloud . By consolidating data such as lab results, medications and plan coverage in the cloud, Blue Shield of California is making services more accessible to members while reducing the cost of care. With help from Healthanea , France-based insurance company AXA is connecting hospitals, pharmaceuticals, health tech solutions and insurers to provide patients with reliable and accurate health information while protecting sensitive health data through the Microsoft Cloud for Healthcare. Paige and Microsoft are collaborating to transform patient care by building the world’s largest image-based AI to detect cancer with higher accuracy. To ensure patient confidentiality and automate threat reporting, Hamad Medical Corporation is working with Mannai to proactively detect and respond to cyber threats while providing real-time visibility to its executives. Sanofi is improving training and collaboration for employees in different locations with HoloLens 2 — saving two weeks of training time for its production line operators and meeting increased demand for pharmaceuticals.

Empowering government workers, non-profit volunteers, students and teachers to expand social impact and save costs with data and AI

Working with AltaML , the Government of Alberta has built an AI-powered tool to help firefighting duty officers become more confident in predicting and sustainably managing the risk of wildfires, creating the potential to save up to $3 million in annual operating costs. In the U.K., Aberdeen City Council is making it easier for workers to access social care data within minutes to provide faster and more accurate service to vulnerable citizens while saving more than $2 million annually on manual data collection. To help ensure seamless service to citizens and prevent cyberattacks to critical infrastructure like traffic light systems and utilities, the City of Brampton is helping its IT team improve its cybersecurity maturity and reduce attack alerts by 70% with help from partner Difenda . To quickly scale the creation of thousands of audiobooks and reduce volunteer labor, nonprofit Project Gutenberg is making its e-books more accessible to people with visual impairments by using text-to-speech capabilities in Azure AI and Microsoft Fabric. German-based Nationalpark Bayerischer Wald is using AI to help research students pre-classify wildlife images in two days instead of 30 — saving 95% on the cost of wildlife monitoring and distance measurement. Working with teachers to offer more individualized support to students, New York City Public Schools has developed a secure, custom AI-powered teaching assistant on Azure OpenAI to answer questions and give real-time feedback.

Providing financial services employees and customers with AI capabilities for more meaningful and personalized interactions

Ally Financial launched a proprietary platform as its foundation for generative AI innovation across the company, including live summarization of customer service calls so employees can spend more time focusing on customer interactions. With Azure OpenAI, Swiss investment firm Vontobel is boosting employee productivity in programming and data analysis, while automatic payments company Sem Parar is responding intelligently and contextually to customer inquiries to help them resolve their questions more quickly. Emirates NBD is empowering more than a thousand developers with its coding assistant leveraging the capabilities of GitHub Copilot X, while automating repetitive tasks and content generation for employees using Microsoft 365 Copilot. MetLife is helping pet parents access health records and connect with veterinary technicians more easily through its app built with AI-powered search and machine learning capabilities. With a focus on making financial services more accessible in Qatar, CWallet has saved $1 million by building its secure and compliant fintech platform on Azure to meet data regulations in the Middle East, and now plans to explore AI capabilities to simplify customer transactions.

Equipping manufacturing workers with AI-driven data and insights to improve customer support and streamline complex operations

Using Azure OpenAI, electrical equipment manufacturer ABB is integrating generative AI into its platform and applications to provide industry executives, specialists and engineers with real-time insights for better decision making and increased productivity. To reduce waiting time for customers, Dubai-based BMW Group importer AGMC is building an AI solution to more quickly locate and transport vehicles from its largest service center. By creating a scalable AI platform in Azure, Swedish steel manufacturer Epiroc is helping automate complex processes for its global employees to ensure consistent quality of its products, increase efficiency and reduce waste. Printer and imaging company Lexmark has improved its technician support efficiency by 20% with AI-driven predictive modelling, contributing to a 20% increase in customer satisfaction ratings. Xiaomi has developed an AI service bot with Power Virtual Agents to handle customer questions more efficiently and is better using Azure Translator to quickly generate product manuals in multiple languages. Indian textile company Arvind is leveraging the integrated AI capabilities of Power Apps to reduce sampling errors by 90%, production errors by 70% and order turnaround time by 30%.

Enhancing employee productivity and providing customers with AI-enhanced solutions across professional services

Lumen Technologies is empowering employees across organizations with Microsoft 365 Copilot, making it easier for customer service teams to access repair manuals and helping sales teams summarize actionable steps from customer communications. In France, consulting firm Arthur D. Little is unifying its complex, unsorted data while maintaining data confidentiality and maximizing human capital — helping its consultants prepare for client meetings faster and curate presentation content in 50% less time. Jacobs Solutions is making it easier for staff to access and share high-quality data by integrating Microsoft Fabric with its end-to-end platform for seamless data management and advanced AI capabilities. INSPIRE Environmental is reducing costs and client turnaround time for image analysis of complex ocean data using Azure AI and machine learning. By leveraging Azure OpenAI, Orca Security is speeding up response times to customers and increasing data security while meeting regulatory compliance, Amadeus is working with Microsoft and Accenture to assist corporate travelers with trip logistics through its interactive assistant — as well as building a plug-in for Microsoft 365 Copilot, and professional services firm Atera is helping IT technicians focus on high value work while improving efficiency by 10x with its AI-powered platform.

Today’s AI advancements have also generated new opportunities for digital natives to build upon their cloud-first strategies and shape the future of industry. To combat and identify cyber financial crime behaviors, SymphonyAI developed an AI assistant to help investigators securely and automatically collect, collate and summarize financial and third-party information. By applying AI capabilities across thousands of interactions each day, CallMiner is unlocking insights that empower organizations with a better understanding of the customer journey. Striving to be a leader in empathetic personal intelligence, Inflection AI is developing an AI chatbot that helps people accelerate development while reducing downtime. Building upon its cloud-based solution on Azure, Elastic is giving customers more focused answers to search queries by combining internal company knowledge with context from actual documents. With Azure OpenAI and Azure Cognitive Services, DeepBrain AI is cutting down chatbot development time and reducing manual processes while increasing language understanding and translation capabilities; while Commerce.AI has already started driving up to 50% increases in productivity for clients with its consumer sentiment analytics solutions.

We have a collective opportunity to put generative AI to work to help solve the biggest challenges facing organizations, industries and society today. Microsoft is helping customers and partners prioritize work and pragmatically innovate with generative AI to meet their most pressing business needs. From our unwavering commitment to building products responsibly and securely to how we engage with our customers and partners, I am proud of the trust we have forged along the way. Whether you are leveraging our copilot capabilities across the Microsoft Cloud, working with our partners to apply industry-specific cloud and AI solutions or seeking to co-innovate and co-develop to build custom solutions, I look forward to working alongside you to accelerate your AI transformation.

Tags: AI, AI Customer Commitments, Azure, Azure AI, Azure OpenAI Service, Copilot Copyright Commitments, Digital Natives, HoloLens 2, ISV, Microsoft 365 Copilot, Microsoft AI, Microsoft Cloud, Microsoft Cloud for Healthcare, Microsoft Cloud Partner Program, Microsoft Copilot, Microsoft Dynamics 365 Copilot, Microsoft Fabric, Microsoft Partners, Microsoft Power Platform, Microsoft Security, Power Virtual Agents"
Microsoft_News,https://news.microsoft.com/apac/features/ask-ai-guru-genpact-turns-to-generative-ai-to-help-employees-learn,,Ask AI Guru: Genpact turns to generative AI to help employees learn,"TN Senthil Kumar, a Bengaluru-based IT project lead for a global company, was facing a challenge many managers deal with – how to manage friction within his team.

He turned to higher-ups for help and got some useful tips: Pre-define the team members’ activities. Focus on goals. Refrain from massaging egos.

The source of this wisdom wasn’t a person, at least not directly. It was a generative AI chatbot called AI Guru rolled out in July by Kumar’s employer, NYSE-listed Genpact Ltd., as part of its internal learning platform.

Since then, Kumar says, “I’ve asked AI Guru so many things.”

AI Guru helped his team with the IT migration to a new enterprise platform, including generating test cases for hiring and onboarding – and yes, AI Guru gave him sound management advice too.

Generative AI, built on large language models (LLMs) that synthesize vast troves of data to generate text, images and more, hit the news late last year and is seen as the biggest technological leap since the web browser and smartphones. Businesses are rolling out generative AI tools to assist employees in doing everything from writing computer code to drafting emails.

At Genpact, the focus is on boosting employee learning and development, a crucial component when your business is professional services.

Genpact, which last year booked revenue of USD$4.4 billion from a global roster of clients, is using Microsoft Azure OpenAI Service and Azure AI Services to scale up the development of courses, pull content from its own experts and constantly update materials. Most recently, it rolled out a digital twin of Genpact experts available to be consulted 24/7, so time-pressed senior executives can quickly get answers.

“There is the whole concept of collective intelligence,” said Kunal Dureja, who leads Genpact’s learning technologies and is based in Gurugram, the corporate hub on the edge of New Delhi. “People learn with each other. If you look at how we curate content, everywhere you see there is the element of the power of the team as opposed to having just one point of view.”

Genpact started in 1997 with 20 employees as a subsidiary of GE that handled the US conglomerate’s finance and accounting functions globally. It now employs over 115,000 people in over 30 countries.

Piyush Mehta, Genpact’s chief human resources officer, remembers the early days of the company when they hired fresh graduates and swiped people from other industries like airlines and hotels. “The joke was that there used to be a sign outside the office that said ‘Trespassers will be recruited’,” he said.

Genpact’s success depends on its employees keeping abreast of the latest in digital technology, domain and process expertise to serve its clients globally. “We didn’t have a choice,” said Mehta, who is based in Gurugram. “We had to skill and reskill across the board if we wanted to grow.”

Today, Genpact hires 40,000 to 50,000 entry-level employees each year, all of whom also need training.

Like many others, Genpact used to rely on a mix of on-the-job learning and training programs run by vendors, in scheduled classroom settings, with a real-life guru.

But the old-fashioned way of signing up for physical classes, at scheduled times, just wasn’t keeping up. Vendor content was often generic and outdated and class times inflexible.

In 2019, the company decided to put most of its learning online. Mehta and Genpact’s then chief innovation officer, Gianni Giacomelli, were tasked full time with building a platform. They called it Genome, to reflect the idea that learning was part of the company’s DNA.

They identified 40 skills most important for growth, ranging from accounts payable and data literacy to commercial negotiation. Using email analysis from Microsoft Viva Insights, they identified “master gurus,” people with 20 years’ experience or more who were sought out within the company for these skills. (The exception was Europe, where laws do not allow such meta data harvesting of emails.)

These master gurus were recruited to curate courses, add Genpact specific content and answer questions on online forums; their answers are then rated. Peers review each other’s work at the end of each course. Today, between 40 and 50 percent of course content comes from internal expertise. Tasks people do as part of their everyday jobs are curated and indexed and become part of a body of knowledge to be drawn from.

The platform has grown rapidly. There are over 50,000 learners on Genome every month. The most popular course by far this year, not surprisingly, has been an introduction to generative AI: 60,000 employees have taken it. Storytelling is the next most popular course, particularly with sales and marketing teams, followed by people management, which has evolved rapidly in the age of hybrid teams. Next come role-specific courses like supply chain, fraud and accounts payable.

The number of skills has doubled from the initial 40 to 80, and there are 600 gurus and master gurus to, as Shalini Modi, global leader for learning and employee experience, puts it, “take you from darkness to light.”

Before starting a course, learners rate themselves on proficiency – 1 for beginner, 4 for proficient – so they get content that’s right for them. They are also recognized in various ways – virtual badges they can post on their LinkedIn profiles, a shout-out of the top ten Genome learners from CEO Tiger Tyagarajan at global town halls, and ultimately, deeper engagement and enhanced prospects for career development.

The impact on retention is tangible. Those who’ve enrolled for training on Genome, said Mehta, are twice as likely to stay with the company as those who have not.

By early 2023, Genome had exponentially boosted learning at Genpact. But there remained a bottleneck – the number of master gurus. That’s where generative AI came in.

In July, the Genome team rolled out a chatbot called AI Guru, a digital twin of all the gurus collectively, powered by OpenAI’s GPT-3.5 via Azure OpenAI Service, available around the clock. Trained on three years’ worth of course content and questions and answers from the company’s intranet hosted on Microsoft SharePoint, AI Guru is now available to several thousand senior learners globally.

“Today it’s a learning companion,” said Prashant Shukla, who heads learning and content management for Genome. “The next step is guiding people on skills they should be learning. In future, we look at this as a coach for specific roles. For a first-time manager who needs constant coaching – they can talk to it.”

As of mid-September, 400 people had asked AI Guru 1,500 questions, including Kumar’s on how to more effectively manage his team.

“This has actually given time back to everyone,” said Crina Ilie, who leads Genpact human resources for EMEA, based in Bucharest, and is a Master Guru for People Leadership. “It used to take 15 to 20 minutes to compose a response to a forum question. Now it’s instant.”

Ilie, who has been involved in the design of Genome from the beginning, is enthusiastic about the technology but clear that human interaction is still important. There are some things AI Guru cannot replace.

“As much as we love technology, we are still human beings,” she said. “It’s good to experience some cohort learning and building leadership is easy when sharing the same space, time, food and drink. I think, you know, this is priceless.”

And as much as AI Guru can do the work of real-life gurus, she noted, it can only disseminate what’s already known. It cannot, for example, divine the future of work.

That will still require humans to figure out.

Top image: TN Senthil Kumar, an IT project lead at Genpact, with co-worker Sridhar Gnanasekaran at their office in Bengaluru. Photo by Selvaprakash Lakshmanan for Microsoft."
Microsoft_News,https://news.microsoft.com/apac/features/at-the-university-of-hong-kong-a-full-embrace-of-generative-ai-shakes-up-academia#new_tab,,"At The University of Hong Kong, a full embrace of generative AI shakes up academia","Hong Kong – Leon Lei, who teaches data science in the faculty of education at The University of Hong Kong (HKU), recently produced a textbook – in 30 hours.

Using a mix of generative AI and other tools, Lei turned transcripts and slides from a series of online classes he taught during pandemic lockdowns into text (15 hours), then edited and compiled it into a 10,000-word course book (another 15 hours). He also converted chapters to mind maps – diagrams which show concepts in visual form – and created video clips.

“Students have diverse learning styles,” said Lei, who is running AI clinics across the university on using AI tools for teaching. “Some want to listen, watch. Some want a mind map first. Before this, I didn’t have time to explore.”

Generative AI is causing teachers to rethink how they teach and how they can prepare students for the future. Administrators are reframing what universities should be teaching that future employers will want.

“When did we last have this kind of shake-up?” said Pauline Chiu, associate vice president for teaching and learning at HKU. “We’ve got the attention of teachers, parents, students. It’s an opportunity to reinvent our teaching. Now that’s a big positive.”

Generative AI tools – built on large language models (LLMs) that synthesize massive troves of data to generate text, code, images and more – are seen as the biggest technological leap since the web browser and smart phones. But while the technology is powerful, it can deliver imperfect results and learning institutions have been grappling in the last few months over how to deploy it responsibly – if at all.

The advent of generative AI is raising bigger questions on what sort of future universities should be preparing students for. “What should we be teaching in university alongside it? What do future employees need? What kind of other human skills do we need to be teaching? How do you collaborate with other human beings, what about relationship building?” said Chiu.

HKU, a research-led comprehensive university founded in 1911, is the oldest university in Hong Kong and known for its medical school. It’s ranked as the top university in Hong Kong and 35th globally, according to the Times Higher Education World University Rankings 2024.

HKU initially instituted a ban earlier in the year on using generative AI tools. “We knew it was temporary,” said Chiu. In February, a task force made up of staff, students and technologists began meeting weekly to discuss the implications of the new technology.

When Microsoft Azure OpenAI Service, powered by OpenAI’s GPT, became generally available in January, the university’s IT department acted first. “We said AI is the future,” said Flora Ng, chief information officer and university librarian. “It is what we need to pursue to enhance research, teaching and learning.”

HKU was already using Microsoft’s solutions and the IT department made an unusual decision to go ahead and fund Azure OpenAI Service to staff only from April to June, so they could test it out and understand the impact of generative AI. Usually, new IT funding involves tender documents with detailed requirements and buy-in from various departments – which can take months.

In this case, “nobody knew what the total requirements should be,” said Ng. “Our IT department said we will take a risk; we’re going to fund it. The strategy for me was to quickly adopt, then if it fails, to pivot.”

In June, the HKU senate officially endorsed a generative AI policy that established it as a “fifth literacy” for students, alongside oral, written, visual and digital literacy. At the end of August, HKU and seven other universities in Hong Kong announced they were making Azure OpenAI Service available to all staff and students, with few restrictions, when the new school semester started in September.

“Our stance is to embrace it,” said Chiu, adding that it’s up to teachers if they wanted to limit use for their courses or certain assignments.

“There may be situations in which we want students to learn the basics by limiting the use of generative AI,” said Chiu. “But it will be up to the teachers to make that decision.”

The university has rolled out several generative AI chatbots, built with Azure OpenAI Service. An IT helpdesk chatbot answers simple queries, freeing staff up to deal with more complicated issues. Another chatbot deals with administrative questions, such as how to sign up for a course, and another one on undergraduate course selection.

Staff and students can also access a more general HKU chatbot for teaching and learning.

Early usage statistics have been encouraging. In the first 20 days, since it was launched on September 1, more than 10 percent of the student population of 36,400 have used the general HKU chatbot. About 17 percent of the staff population of 13,100 have done the same. The IT helpdesk chatbot in turn received 1,276 inquiries between August 21 and September 13.

To protect user data and privacy, the chatbots do not keep any data on queries. “We don’t look at what they ask. We don’t keep any records,” said Ng.

Students are taught basic generative AI literacy in AI workshops run by HKU’s Teaching and Learning Innovation Centre. They learn that results are not always perfect, but that the HKU chatbot can be a good idea generator. Nor is it a search engine; it’s a language synthesizer. They are told to always check original sources for accuracy. And so on.

The big concern, of course, is that students become too reliant on generative AI to complete assignments without really understanding the materials. However, HKU teachers will not be relying on AI detection tools because they aren’t accurate or reliable today. There is a possibility of false negatives and false positives, which could lead to a student being wrongly accused of cheating.

Instead, teachers are asked to reinvent assessment, said Cecilia Chan, director of HKU’s Teaching and Learning Innovation Centre. “Exactly what do we want the student to learn?” said Chan. “Think about the learning process, outcomes and experience, that is what is important.”

A teacher could, for example, ask for a skills demonstration or an oral presentation instead of an essay. Or they could ask the chatbot to generate a number of essays and ask students to critique them. Are there factual errors? Students could add their opinions and maybe generate an essay plan. It’s a sort of reverse engineering of an essay, where “you can still have all the learning objectives of an essay,” said Chan.

A student could be asked to demonstrate competency through hands-on work at different stations like in the medical school’s Objective Structured Clinical Exam, stuff that AI cannot do.

Chan said she herself uses generative AI tools “like a personal assistant,” including to answer the many emails she gets asking her for interviews and to speak at conferences. To those who worry about relying on it too much, she offers a comparison.

“Can you imagine life without one of these?” she asks, waving her smartphone. “That’s what we are getting used to.”

Students are already figuring all this out for themselves.

Lai Yan Ying, also known as Cheri, is a fourth-year student majoring in linguistics. She said she wouldn’t use it for writing an essay but thinks it’s fair to use it to generate ideas, such as questions for recent research project where she interviewed someone about their experience learning English.

“I don’t think we can just use ChatGPT for everything,” said Lai. “Sometimes, I just prefer to go to a library and grab a book.”

For Yan Wing Lam, a fourth-year engineering major, generative AI is less of a mind shift, “In engineering, we are quite into AI already. It’s just like a tool to me.”

When Lai and Yan both worked on a recent project together, they encountered both the promise and the limitations of the tool. For a course called Digitizing Cultural Heritage in Greater China, they decided to use OpenAI’s DALL·E 3 image generator via Azure OpenAI Service on the HKU chatbot to create pictures of Chinese mythical creatures – with their instructor’s blessings.

They were only partially successful.

A prompt for “blue dragon with horns and claws” successfully brought forth a picture of Qing Long, an azure dragon god in Chinese mythology. However, it took a few tries to generate a usable picture of Chi Ru, a fish with a human face.

Attempts to conjure up a likeness of Xiang Liu, a nine-headed monster snake, kept returning pictures of single-headed snakes. Lai ended up making her own digital drawing of Xiang Liu, which took about half an hour, versus just seconds using DALL·E 3.

The four-person team got an A on the project.

Top image: Leon Lei, who teaches data science in the faculty of education, is using generative AI tools to create mind maps and short videos for students with different learning styles. Photo by Lam Hei Chun for Microsoft."
Microsoft_News,https://news.microsoft.com/source/features/ai/azure-ai-content-safety-in-azure-ai-platform/,,How Azure AI Content Safety helps protect users from the classroom to the chatroom,"Earlier this year, South Australia’s Department for Education decided to bring generative AI into its classrooms. But before they opened the doors, one question loomed large: how to do it responsibly?

The core concern revolved around helping to protect students from potentially harmful or inappropriate content that may be reflected in the output of a large language model, given its training on vast and unfiltered expanses of the internet, said Simon Chapman, the department’s director of digital architecture.

“What’s available with the public versions of generative AI is extremely limited for education,” he said. “There are no guardrails around how students might interact with it.”

Fast forward to today, and the department is wrapping up a pilot of EdChat, an AI-powered chatbot. Nearly 1,500 students and 150 teachers across eight secondary schools tested the bot’s ability to help research everything from cellular division to the plot of John Steinbeck’s “Of Mice and Men.”

The department is still evaluating the results, Chapman said. But the Microsoft system it used as its guardrails received high marks: Azure AI Content Safety, an AI-powered platform to help organizations create safer online environments.

Azure AI Content Safety provides guardrails that made it possible for the South Australia Department for Education to deploy EdChat in a pilot project across eight schools. The AI-powered chatbot can help students do research and educators do lesson planning. Photo courtesy of South Australia Department for Education.

EdChat’s built-in safety features blocked inappropriate input queries and filtered harmful responses, allowing teachers to focus on the technology’s educational benefits rather than content oversight, he said.

“We wouldn’t have been able to proceed at this pace without having the content safety service in there from Day 1,” Chapman said. “It’s a must-have.”

Microsoft today announced the general availability of Azure AI Content Safety within the Azure AI platform, which uses advanced language and vision models to help detect hate, violence, sexual and self-harm content. When the models detect potentially harmful content, they mark it with an estimated severity score. That allows businesses and organizations to tailor the service to block or flag content based on their policies.

Initially introduced as a part of Azure OpenAI Service, Azure AI Content Safety is now a standalone system. That means customers can use it for AI-generated content from open-source models and other companies’ models as well as for user-generated content as part of their content systems, expanding its utility, Microsoft said."
Microsoft_News,https://www.microsoft.com/en-us/worklab/how-i-prompt-leaders-share-their-favorite-ai-time-savers,,How I Prompt: Leaders Share Their Favorite AI Time-Savers,"Sign up for the WorkLab newsletter to get the latest AI research, insights, and trends delivered straight to your inbox.

Drop a few simple conversational prompts into AI, and the results are pretty astonishing. But these tools also have a deeper potential to transform how work gets done for those who learn how to fully leverage it.

Think of generative AI as a digital assistant that augments your own knowledge and capabilities. If you take a few seconds to give it context and explain your goals, you can create things faster, complete tasks with ease, and lessen your cognitive load.

As you experiment, you’ll develop your own approach to collaboration. To help you get started, we asked 10 leaders here at Microsoft how they use prompts to boost creativity, save time, and stay focused on the most meaningful and rewarding parts of their jobs.









Sumit Chauhan, Corporate Vice President, Office Product Group

When I get in to work in the morning, I’m already behind. There are unread emails and chat messages to catch up on while I’m simultaneously jumping into my first meeting. With Copilot in Outlook, I can type summarize, and boom—I have a pretty accurate rundown of the highlights of a long thread. Or let’s say I have to generate a deck based on documents, emails, previous presentations, what have you. I can go into PowerPoint and say, generate me a deck based on these things, and I get an outline or a draft of a deck. Just that one thing saves me an enormous amount of time.









Jared Spataro, CVP, Modern Work & Business Applications

What makes Copilot feel almost magical is the fact that it has a deep understanding of me, my job, my priorities, and my organization. It knows my entire universe of data at work. I can write:

Quickly summarize the meeting I had at 11 a.m. yesterday.

Who attended?

What decisions were made?

Give me a sense of what you think the next steps should be.

Put that summary into an email to Jun, and propose a time when we’re both free next week to discuss.

Write it in Japanese.









Colette Stallbaumer, General Manager, Microsoft 365 and Future of Work

Time is our most precious resource, and Copilot helps me reclaim some of that time at work. During a busy day, my most frequently used prompts start with “Find me”:

Find me the Q2 news deck that Marta shared in a meeting this week.

Find me the most recent Work Trend Index research document from Grace.

Find me the hybrid work playbook we created in 2021.

No more hunting for specific documents, decks, or emails. Copilot combs through all my folders and files to quickly find what I need—even if it’s a file I haven’t accessed in years. I find it saves me time and helps me stay focused on the strategic and creative work that matters most.









Amy Coleman, CVP, Human Resources & Corporate Functions

Once a week, to keep myself informed and prepare for meetings with global HR partners, I ask Copilot:

What are the top challenges facing global HR organizations this week in September 2023?

What about in Australia, 2023?

Are HR trends in the US for September 2023 different than the HR trends in Germany for September 2023?

Show me HR research across all of our global offices from the past three months, 2023.

Who are the top voices talking about these challenges?

It opens the door to possibilities rather than simply coming to a conclusion.









Jaime Teevan, Chief Scientist & Technical Fellow

When I’m reading an article, I get better summaries when I say, summarize this article for a Microsoft executive with a particular interest in research than when I just ask for a summary. Or if I’m trying to think critically about the article, I might follow up by telling it what I want the reply to look like: What questions should that exec ask of the article? Please include answers to the questions, quoting the article when possible. Basically, I get better replies by including details and direction.









Deb Cupp, President, Americas

I meet with a lot of customers. There are often a lot of ideas generated and action items assigned during these meetings. When I need to send follow-up emails, I rely on Sales Copilot to kick-start the drafting process. I just tell it to generate a response, and it looks at my previous email exchanges with that customer, recent notes from the Teams call, as well as any relevant data from the CRM, and suggests an appropriate response email. I can take that and make some edits of my own before hitting send. These prompts are like my personal shortcuts to staying organized and nailing communication, even on the busiest workdays.









Jon Friedman, CVP, Design & Research

I don’t write code. But I wanted to write JavaScript for an app that ran on mobile devices, so I prompted the AI with all the things I wanted the app to do, and it spit the code back at me. Then I asked, where do I put this code to look at it more carefully? It told me where and helped me troubleshoot errors. I didn’t just ask it to do something for me; I asked it to teach me too. It was like collaborating with a patient programmer.









Kathleen Mitford, CVP, Global Industry Marketing

Prompts like, write a list of… or compare… or give me examples of… give me interesting options and possibilities, and help me to explore creative ideas and build new work habits. Communication and iteration is key at work, and that includes communication with AI. I observe how Copilot responds to my prompts, then I ask it to evaluate its own response, then I ask it to iterate again. It’s like an ongoing dialogue, arrived at by testing and learning continually.









Merrie Williamson, CVP of Azure Infrastructure, Digital & Application Innovation

I am always looking for ways to go deeper in learning about our specific customers. One useful time saver is telling Copilot, highlight key trends and insights in this company’s quarterly earnings report. It’s a quick way to add the additional context I need to drive a great conversation for customer meetings.









Tara Roth, CVP, Microsoft 365 Customer Success Engineering

I love the ability to say, surface key action items for Teams meetings. It’s not always perfect, but it gets you close enough that you can then just quickly edit and add or take away whatever you want. I feel like I can be more attentive in the meeting because I’m not worried about taking notes. I can fully engage with the confidence that Copilot will have captured the key items accurately enough that I can then go modify and send out the summary.







"
Microsoft_News,https://www.microsoft.com/en-us/worklab/what-we-mean-when-we-say-ai-is-usefully-wrong,,What We Mean When We Say AI is “Usefully Wrong”,"This article first appeared in the WorkLab newsletter. Be the first to get our updates by subscribing here.



When you brainstorm with a person, their throwing-spaghetti-at-the-wall suggestions aren’t usually The Thing. They’re ideas, points of view—puzzle pieces that may fit together or may not. They stimulate your creative juices, helping you get to The Thing. The same is true of AI: Ask Copilot for 20 suggestions for a catchy presentation title, and bam! You have a list of relevant suggestions in seconds. They won’t all be that just-right idea you’re looking for, but often one or two will spark real inspiration—leading you toward a title you’d never come up with on your own.

At Microsoft, we like to say that this is when AI is “usefully wrong.” It’s a different, more collaborative way of working with technology—one that upends our long-held assumptions about what computers can and can’t do. We’re used to one interaction with a computer: put in a query, get an answer. With AI, the answer isn’t the final word; the magic is in the conversation, the back and forth. And it’s up to people to build on, combine, or transform the content into something original and meaningful.

Wharton professor and AI expert Ethan Mollick calls generative AI “alien intelligence.” Because it synthesizes ideas and information in novel ways, it’s inherently weird—so it can often propose some unconventional ideas. To harness that divergent thinking, you need to be open-minded and curious. AI can offer up content that is unexpected, surprising, or just plain weird. Don’t let that discourage you. Instead, embrace the challenge to come at a problem from a different perspective.

It’s crucial to check that any AI-generated content is complete and correct. AI isn’t a replacement for your own creativity or judgment; it’s a tool that can enhance and augment those innately human skills. Don’t blindly accept or follow AI suggestions; instead, evaluate them carefully and objectively. Ask yourself: Is this content relevant and appropriate? How can I improve or refine it? How can I add my own voice or style to it?

AI’s suggestions are a puzzle that’s nearly finished—it just needs your expertise to be complete."
Microsoft_News,https://blogs.microsoft.com/on-the-issues/2023/10/05/responsible-ai-governance-japan/,,​Advancing AI governance in Japan,"“Don’t ask what computers can do, ask what they should do.”

That is the title of the chapter on AI and ethics in a book I coauthored with Carol Ann Browne in 2019. At the time, we wrote that “this may be one of the defining questions of our generation.” Four years later, the question has seized center stage not just in the world’s capitals, but around many dinner tables.

As people use or hear about the power of OpenAI’s GPT-4 foundation model, they are often surprised or even astounded. Many are enthused or even excited. Some are concerned or even frightened. What has become clear to almost everyone is something we noted four years ago – we are the first generation in the history of humanity to create machines that can make decisions that previously could only be made by people.

Countries around the world are asking common questions. How can we use this new technology to solve our problems? How do we avoid or manage new problems it might create? How do we control technology that is so powerful? These questions call not only for broad and thoughtful conversation, but decisive and effective action.

All these questions and even more will be critical in Japan. Few countries have been more resilient and innovative than Japan the past half century. Yet the remainder of this decade and beyond will bring new opportunities and challenges that would put technology at the forefront of public needs and discussion.

In Japan, one of the questions that’s being asked is how to manage and support a shrinking and aging workforce. Japan will need to harness the power of AI to simultaneously address population shifts and other societal changes while driving its economic growth. This paper offers some of our ideas and suggestions as a company, placed in the Japanese context.

To develop AI solutions that serve people globally and warrant their trust, we’ve defined, published, and implemented ethical principles to guide our work. And we are continually improving engineering and governance systems to put these principles into practice. Today we have nearly 350 people working on responsible AI at Microsoft, helping us implement best practices for building safe, secure, and transparent AI systems designed to benefit society.

New opportunities to improve the human condition

The resulting advances in our approach to responsible AI have given us the capability and confidence to see ever-expanding ways for AI to improve people’s lives. By acting as a copilot in people’s lives, the power of foundation models like GPT-4 is turning search into a more powerful tool for research and improving productivity for people at work. And for any parent who has struggled to remember how to help their 13-year-old child through an algebra homework assignment, AI-based assistance is a helpful tutor.

While this technology will benefit us in everyday tasks by helping us do things faster, easier, and better, AI’s real potential is in its promise to unlock some of the world’s most elusive problems. We’ve seen AI help save individuals’ eyesight, make progress on new cures for cancer, generate new insights about proteins, and provide predictions to protect people from hazardous weather. Other innovations are fending off cyberattacks and helping to protect fundamental human rights, even in nations afflicted by foreign invasion or civil war.

We are optimistic about the innovative solutions from Japan that are included in Part 3 of this paper. These solutions demonstrate how Japan’s creativity and innovation can address some of the most pressing challenges in various domains such as education, aging, health, environment, and public services.

In so many ways, AI offers perhaps even more potential for the good of humanity than any invention that has preceded it. Since the invention of the printing press with movable type in the 1400s, human prosperity has been growing at an accelerating rate. Inventions like the steam engine, electricity, the automobile, the airplane, computing, and the internet have provided many of the building blocks for modern civilization. And like the printing press itself, AI offers a new tool to genuinely help advance human learning and thought.

Guardrails for the future

Another conclusion is equally important: it’s not enough to focus only on the many opportunities to use AI to improve people’s lives. This is perhaps one of the most important lessons from the role of social media. Little more than a decade ago, technologists and political commentators alike gushed about the role of social media in spreading democracy during the Arab Spring. Yet five years after that, we learned that social media, like so many other technologies before it, would become both a weapon and a tool – in this case aimed at democracy itself.

Today, we are 10 years older and wiser, and we need to put that wisdom to work. We need to think early on and in a clear-eyed way about the problems that could lie ahead.

We also believe that it is just as important to ensure proper control over AI as it is to pursue its benefits. We are committed and determined as a company to develop and deploy AI in a safe and responsible way. The guardrails needed for AI require a broadly shared sense of responsibility and should not be left to technology companies alone. Our AI products and governance processes must be informed by diverse multistakeholder perspectives that help us develop and deploy our AI technologies in cultural and socioeconomic contexts that may be different than our own.

When we at Microsoft adopted our six ethical principles for AI in 2018, we noted that one principle was the bedrock for everything else – accountability. This is the fundamental need: to ensure that machines remain subject to effective oversight by people and the people who design and operate machines remain accountable to everyone else. In short, we must always ensure that AI remains under human control. This must be a first-order priority for technology companies and governments alike.

This connects directly with another essential concept. In a democratic society, one of our foundational principles is that no person is above the law. No government is above the law. No company is above the law, and no product or technology should be above the law. This leads to a critical conclusion: people who design and operate AI systems cannot be accountable unless their decisions and actions are subject to the rule of law.

In many ways, this is at the heart of the unfolding AI policy and regulatory debate. How do governments best ensure that AI is subject to the rule of law? In short, what form should new law, regulation, and policy take?

A five-point blueprint for the public governance of AI

Building on what we have learned from our responsible AI program at Microsoft, we released a blueprint in May that detailed our five-point approach to help advance AI governance. In this version, we present those policy ideas and suggestions in the context of Japan. We do so with the humble recognition that every part of this blueprint will benefit from broader discussion and require deeper development. But we hope this blueprint can contribute constructively to the work ahead. We offer specific steps to:

Implement and build upon new government-led AI safety frameworks.

Require effective safety brakes for AI systems that control critical infrastructure.

Develop a broader legal and regulatory framework based on the technology architecture for AI.

Promote transparency and ensure academic and public access to AI.

Pursue new public-private partnerships to use AI as an effective tool to address the inevitable societal challenges that come with new technology.

More broadly, to make the many different aspects of AI governance work on an international level, we will need a multilateral framework that connects various national rules and ensures that an AI system certified as safe in one jurisdiction can also qualify as safe in another. There are many effective precedents for this, such as common safety standards set by the International Civil Aviation Organization, which means an airplane does not need to be refitted midflight from Tokyo to New York.

As the current holder of the G7 Presidency, Japan has demonstrated impressive leadership in launching and driving the Hiroshima AI Process (HAP) and is well positioned to help advance global discussions on AI issues and a multilateral framework. Through the HAP, G7 leaders and multi-stakeholder contributors are strengthening coordinated approaches to AI governance and promoting the development of trustworthy AI systems that champion human rights and democratic values. Efforts to develop global principles are also being extended beyond G7 countries, including organizations like the Organization for Economic Cooperation and Development (OECD) and the Global Partnership on AI.

The G7 Digital and Technology Ministerial Statement released in September 2023 recognized the need to develop international guiding principles for all AI actors, including developers and deployers of AI systems. It also endorsed a code of conduct for organizations developing advanced AI systems. Given Japan’s commitment to this work and its strategic position in these dialogues, many countries will look to Japan’s leadership and example on AI regulation.

Working towards an internationally interoperable and agile approach to responsible AI, as demonstrated by Japan, is critical to maximizing the benefits of AI globally. Recognizing that AI governance is a journey, not a destination, we look forward to supporting these efforts in the months and years to come.

Governing AI within Microsoft

Ultimately, every organization that creates or uses advanced AI systems will need to develop and implement its own governance systems. Part 2 of this paper describes the AI governance system within Microsoft – where we began, where we are today, and how we are moving into the future.

As this section recognizes, the development of a new governance system for new technology is a journey in and of itself. A decade ago, this field barely existed. Today Microsoft has almost 350 employees specializing in it, and we are investing in our next fiscal year to grow this further.

As described in this section, over the past six years we have built out a more comprehensive AI governance structure and system across Microsoft. We didn’t start from scratch, borrowing instead from best practices for the protection of cybersecurity, privacy, and digital safety. This is all part of the company’s comprehensive Enterprise Risk Management (ERM) system, which has become a critical part of the management of corporations and many other organizations in the world today.

When it comes to AI, we first developed ethical principles and then had to translate these into more specific corporate policies. We’re now on version 2 of the corporate standard that embodies these principles and defines more precise practices for our engineering teams to follow. We’ve implemented the standard through training, tooling, and testing systems that continue to mature rapidly. This is supported by additional governance processes that include monitoring, auditing, and compliance measures.

As with everything in life, one learns from experience. When it comes to AI governance, some of our most important learning has come from the detailed work required to review specific sensitive AI use cases. In 2019, we founded a sensitive use review program to subject our most sensitive and novel AI use cases to rigorous, specialized review that results in tailored guidance. Since that time, we have completed roughly 600 sensitive use case reviews. The pace of this activity has quickened to match the pace of AI advances, with almost 150 such reviews taking place in the last 11 months.

All of this builds on the work we have done and will continue to do to advance responsible AI through company culture. That means hiring new and diverse talent to grow our responsible AI ecosystem and investing in the talent we already have at Microsoft to develop skills and empower them to think broadly about the potential impact of AI systems on individuals and society. It also means that much more than in the past, the frontier of technology requires a multidisciplinary approach that combines great engineers with talented professionals from across the liberal arts.

At Microsoft, we engage stakeholders from around the world as we develop our responsible AI program – it’s important to us that our program is informed by the best thinking from people working on these issues globally and to advance a representative discussion on AI governance. It is for this reason that we’re excited to participate in upcoming multistakeholder convenings in Japan.

This October, the Japanese government will host the Internet Governance Forum 2023 (IGF) centered on the theme “The Internet We Want – Empowering All People.” The IGF will include critical multistakeholder meetings to advance international guiding principles and other AI governance topics. We’re looking forward to these and other meetings in Japan to learn from others and offer our experiences developing and deploying advanced AI systems, so that we can make progress toward shared rules of the road.

As another example of our multistakeholder engagement, earlier in 2023, Microsoft’s Office of Responsible AI partnered with the Stimson Center’s Strategic foresight hub to launch our Global Perspectives Responsible AI Fellowship. The purpose of the fellowship is to convene diverse stakeholders from civil society, academia, and the private sector in Global South countries for substantive discussions on AI, its impact on society, and ways that we can all better incorporate the nuanced social, economic, and environmental contexts in which these systems are deployed. A comprehensive global search led us to select fellows from Africa (Nigeria, Egypt, and Kenya), Latin America (Mexico, Chile, Dominican Republic, and Peru), Asia (Indonesia, Sri Lanka, India, Kyrgyzstan, and Tajikistan) and Eastern Europe (Turkey). Later this year, we will share outputs of our conversations and video contributions to shine light on the issues at hand, present proposals to harness the benefits of AI applications, and share key insights about the responsible development and use of AI in the Global South.

All this is offered in this paper in the spirit that we’re on a collective journey to forge a responsible future for artificial intelligence. We can all learn from each other. And no matter how good we may think something is today, we will all need to keep getting better.

As technology change accelerates, the work to govern AI responsibly must keep pace with it. With the right commitments and investments that keep people at the center of AI systems globally, we believe it can.

Tags: AI, ChatGPT, Japan, OpenAI, Responsible AI"
Microsoft_News,https://www.microsoft.com/en-us/worklab/podcast/microsoft-deputy-cto-sam-schillace-on-how-ai-will-shift-our-productivity-paradigm,,Sam Schillace on How AI Will Shift Our Productivity Paradigm,"MOLLY WOOD: His trailblazing breakthroughs in collaborative software and engineering leadership have led him to his current role as Microsoft CVP and Deputy CTO, where he focuses on consumer product culture and the next phase of productivity, which are two topics that are pretty near and dear to our hearts on the WorkLab podcast. Here’s my conversation with Sam.

[Music]

MOLLY WOOD: So lots of people are saying that AI tools like the Bing Chat chatbot, Microsoft 365 Copilot are game changers for how we work. What are your thoughts on that?

SAM SCHILLACE: Yes and no. I find a lot of parallels to the beginning of the internet in the current moment. If you’re a practicing entrepreneur, programmer, or whatever, you could see that the world was going to change a lot. It wasn’t entirely clear which things were going to matter. Nobody knew what a social network was going to be. We didn’t have smartphones yet. It was hard to build websites, we didn’t really have the cloud yet… I mean, you can go on and on, right? I kind of feel like we’re in that moment with AI, like, clearly the world is going to change. Clearly, this is a very powerful and important programming tool. Clearly, there’s a lot of stuff to be done and a lot of new capabilities that are reachable now. But I still think it’s kind of early days, like we’re still trying to figure out how to put the pieces together. Yes, it’s going to massively change a lot of things. I don’t think we entirely know how yet. And I think we have a lot of both programming practices and tool chain to build still before we really understand it deeply.

MOLLY WOOD: You’ve written about and observed that as platforms emerge, we have a tendency to get stuck in old paradigms. We just use tools or programs the same way we always have, even though there’s technology that lets us do so much more. Can you talk a little bit about that, and how it’s tended to play out over time, and what it tells us about our current AI moment?

SAM SCHILLACE: I mean, I think it’s a very natural place to be. It’s hard to jump more than one or two jumps at a time conceptually, for anyone, for good reasons, right? So, you take a thing that is working and you iterate a little bit, you mutate it a little bit. And so I think that’s a natural thing to do to begin…

MOLLY WOOD: Well, you have a personal example. You founded a start-up decades ago that created what became a whole new kind of always-on interactive document. But at first, you and your colleagues, and even early users, couldn’t really get the full potential out of it. Can you talk about that evolution?

SAM SCHILLACE: Yeah, originally, it’s really just a copy of the desktop. It took a few new affordances from the New World. It took ubiquity, you know, so it was always on, always there. And we did collaboration, because that was a new capability that you could have, because you’re connected, it kind of took advantage of this. But we didn’t completely reinvent what a document was. Now that we’re used to these documents being more virtualized and abstracted, now we’re ready to go another step and maybe think about them not being static anymore. Maybe they’re fluid, maybe they’re something you talk to, maybe there’s just actually a live thing that reconfigures how it looks and what’s inside—it’s fuzzier, things like that. And that’s a beginning of taking what we have now and adding one or two pieces of the affordances of the next platform, which is the AI platform. What happens is, you know, companies work through that, engineers work through that one step at a time. You do one thing and it makes sense, and then you do another thing, and it makes sense. And then you kind of build on those. So I think that’s the other thing that happens a bit, is like, you try things that are new to the platform, and then you find problems that are new to the platform, and then you have to go solve those problems. And that’s how the solutions sort of evolve.

MOLLY WOOD: You are, I believe, one of the earliest users of Microsoft 365 Copilot, which is in a, no pun intended, pilot phase. Can you talk a little bit about how you’re seeing maybe a similar evolution, how it’s already maybe starting to change the way that you think about documents or—you know, you’re in such a perfect position to imagine where it could go in the future.

SAM SCHILLACE: Yeah, there’s this really interesting thing going on. I think we’re actually kind of at the beginning of the second version of the computer industry entirely. The first version of it was largely about syntax and these fixed processes, because we had to teach the computers to do stuff. But now we’re moving to this more semantic realm, where the computer can have context, it can know what you’re doing, it can actually help you instead of you, the person, helping the computer, which is a lot of what we do. A lot of what we do, even though we think computer is a tool for us, we are really helping the computer do stuff, and like, if you don’t think that’s true, tell me how often you spend time trying to fix the formatting, you know, not understanding why it’s not working right, or whatever. So I think the natural next set of evolution for the copilots is in that direction of fluidity, in the direction of helping, away from these fixed static artifacts and more towards, well what do you need? What are you trying to do? Oh, I need to do this presentation, or brainstorm this thing with me. Oh, I need to cross back and forth between what we thought of as application boundaries—I need to go from Word to Excel, I need to build some, you know, decision or some process, I need to work with my team. I think that’s where we’re heading. Right now, if I gave you a document and I said, this can never be shared in any way—you can’t email it, you can’t collaborate on it, you can’t put it on the web—it would just be this weird, anachronistic—like, why is that? Why would I want that? You know, documents are for sharing, collaborating. Non-online documents seem very anachronistic now. I think non-smart applications and documents are going to seem anachronistic in exactly the same way, in not very long. Like, why would I work with something that you can’t just tell it what I want?

MOLLY WOOD: Well, as documents and AI tools like Copilot get smarter, what sort of new capabilities are unlocked?

SAM SCHILLACE: We do these interesting things right now that are just a tiny little baby step in this direction. So we’ve been working on this project that we call internally, the Infinite Chatbot. So it’s a chatbot, like any other copilots, and it just has a vector memory store that we use it with. And so these things are very, very long-running. Like, we have one that’s been in existence for six months that’s teaching one of the programmers music theory, and he talks to it every morning and it gives him ideas for what he can practice in the evening.

MOLLY WOOD: Oh, wow. So it’s not just that it remembers what you’ve asked it before, it remembers about you.

SAM SCHILLACE: Well, it can see all the conversation, it can see the timestamps and remembers anything you told it. And the way that the system works is, it’ll pull relevant memories up, based on what it infers your intention to be moment to moment in a conversation. But one of the things we like to do with these that works really, really well is, you tell it, I’m working on this technical system, I want to describe the architecture to you, and then we’re going to write a paper together. And so they’ll interview you. You can set them up, you know, you can control their personalities and their memories and stuff. And you set them up to be interviewers. And so they’ll interview you, they’ll talk to you and ask you questions about this technical system for a while. And that’s of course recorded, it’s got a chat history, so you can see all of it. But that chat history has populated that bot’s memory. And so the next person can come in and just ask questions. And so that’s now a live document. So you can ask them, like, give me an outline of this architecture. So that’s like a very small baby step. I think where we want to take that is you have more of a canvas that you’re sitting and looking at that, rather than a linear flow, you can just say, show me this, show me that. So that, to me, feels like the beginning of a live document. A friend of mine was talking about, she has a bunch of information about her father’s medical history and status, her elderly father, and it’s not really a linear fixed thing. It’s more like a cloud of related ideas and facts. There’s his actual medical stuff, and there’s maybe how he’s doing day to day, or maybe there’s like some diet stuff mixed in there, his caregivers. And you might want to look through different lenses at that, right, you might want to be able to talk to that document about like, well, he’s coming over, what’s a dinner we should have that we haven’t had for a while that will fit with his medical diet, or I need to talk to his, you know, let me review his blood pressure over the last two weeks with his practitioner, if he’s got the right permissions for that. So that kind of thing, it’s less of a static linear list of characters that never changes and more of a, if you will, like a semantic cloud of ideas that you can interact with that can get presented in different ways.

MOLLY WOOD: I don’t know how much of a sci-fi fan you are, but what you’re saying makes me think of the intelligent interactive handbook called “A Young Lady’s Illustrated Primer” in Neal Stephenson’s novel…

SAM SCHILLACE: Yes, The Diamond Age. Absolutely. It’s one of our North Stars.

MOLLY WOOD: It is?

SAM SCHILLACE: Yeah.

MOLLY WOOD: Because that’s what it sounds like. Apologies, listeners, if you have not read this, but you definitely should, because it gives you a sense of what we could be talking about here, this level of intelligence, the adaptation—a book that tells the reader a story, but can also respond to your questions and incorporate your suggestions. And it’s all super personalized in real time. And so, Sam, I think what you’re talking about with these live documents is the ability to, in a business setting, abstract away the time-consuming acts of creation, like, I don’t want to spend my time figuring out how to create a chart, right?

SAM SCHILLACE: Right. You want to express goals. So when I was talking about syntax versus semantics, that’s also expressing process versus expressing intention and goal. Syntax is about, I’m going to tell you how to do this thing one step at a time. That’s very tedious. You know, think about a simple example of driving to the store. If you had to specify in advance all of the steps of turning the wheel and pressing on the gas, and you know, it’s brittle, it takes forever to specify that—it’s very difficult. What you want to be able to say is, I want to drive my car to the store. And you want that for business, right? You don’t want to have to specify a business process, you want to be able to specify business intent. But the thing about the primmer from The Diamond Age, I joke with people with these high, stateful copilots, the stateful bots, I need to have a sign behind me that says it’s been this many days since I’ve accidentally proposed something I heard about in science fiction first. Because we’re constantly, like, there’s a thing in The Matrix about, now I know kung fu. And we actually do that, like, we have multiple agents that have different memories. And you can take the memory from one of them and give it to another one and read or read-write for, and then that agent now knows both what it was trained on plus what that new memory has in it. There’s things like that.

MOLLY WOOD: You have taken a stab, a little bit, at publishing the process of refinement that could occur. You’ve got the Schillace’s Laws, a set of principles for large language model AI. One of them is, ask smart to get smart.

SAM SCHILLACE: Sure. So, first of all, somebody else called those “laws,” and I probably would have called them Schillace’s “best guesses at the current moment about writing code with these things.” But that’s a little bit hard to fit on a postcard. They’re just things we have observed trying to build software in the early stages of this transformation. Ask smart to get smart, one of the interesting things about these LLMs is they’re big, it’s big and high-dimensional in a way that you’re not used to. And so you might ask a simple question like, oh, explain to me how a car works, and you’ll get a simplified answer because it’s sort of matching on that part of its very large space. And if you want to get a better answer out of it, you have to know how to ask a better question, like, okay, explain to me the thermodynamics of internal combustion, you know, as it relates to whatever, whatever. And I think that’s an interesting hint in the direction of what skills are going to be important in the AI age. I think you need to be able to know enough to know what you don’t know, and to know how to interrogate something in a space that you’re not familiar with to get more familiar with it. I think, you know, anyone who’s gone through college kind of understands that—you get to college, and the world is gigantic, and there’s all this stuff going on, and you don’t know any of it. You get these classes, you’re kind of swimming in deep water, and you have to develop these skills of making order out of that, and figuring out where the rocks are that you can stand on, and what questions you can ask, and what things you don’t even know, and all that stuff. So I think that’s—it’s fundamental to these systems, and I think a lot of people are not getting good results out of programming these because they’re expecting the model to do all the work for them. And it can’t make that inference—you have to navigate yourself to the right part of its mental space to get what you want out of it. So that’s the ask smart to get smart.

MOLLY WOOD: I feel like that gets to a trust factor at work, too, which is you want to believe that the employee who’s interacting with this has asked three times—I’m actually a big fan of ask three times and then triangulate the answer from that in real life, and when dealing with AI. But that in order to feel confident that the strategy you might be building on top of some of these agents is accurate.

SAM SCHILLACE: Yeah, I mean, I think there’s lots of examples starting to emerge of, you need to have good critical thinking or mental hygiene skills. There’s an example of the lawyer who got sanctioned, I think we all know about this guy. So some lawyer used ChatGPT to file his case, it made up a bunch of cases. So, first of all, he didn’t check, which is a mistake. Second of all, when the judge challenged him, he doubled down on it, and you know, elaborated, which was also—that’s a good counter example of maybe putting too much trust and not using your critical thinking, right? The systems aren’t magic, they’re not—maybe they’ll be magic eventually; they’re not magic yet.

MOLLY WOOD: I think there’s this sense that, oh, this will save us all this time. But you still have to invest the time up front to get the product that you need.

SAM SCHILLACE: Well, and there’s different things, right? Some of it is saving time, and some of it is getting new things to be even capable, right? Both can be happening in a situation, and only one can be happening in a situation. It may be that you’re much more capable of something, and maybe you can reach for a design point that you wouldn’t have been able to manage before because you couldn’t have kept all the points in your head, or something like that. Or, you know, I’ve got an old house in Wisconsin, it’s got a lot of spring water on the property, so it’s a good candidate for geothermal. I don’t know anything about geothermal, but I know enough about it to know which questions to ask. And I’ve been slowly designing a system, you know, with an AI helping me. I didn’t get to say, here’s my house, please design my geothermal system, but I am getting to explore the space and do this new capability.

MOLLY WOOD: What do you think this does tell us about where employees and business leaders and managers should focus their efforts? What skills should we be developing in the workplace to make sure that these kinds of interactions are happening? Because it’s a big shift in thinking, you know, from how to interact with a dumb document to how to interact with a smart document, that’s a big leap.

SAM SCHILLACE: It is a big shift. Again, this is one of those things, it’s going to be hard to predict more than a little way down the road, right? There’s going to be a lot of changes that happen over time. What we know right now, I think a little bit, is critical thinking is important, right? Being able to know what you don’t know, being able to ask questions in an environment where you have low information and extract information. And be aware of things like biases and preconceptions that prevent you from getting good results out of a system like that, I think is useful, that kind of open-mindedness, growth mindset stuff. I think growth mindset is going to be much more important now than it’s ever been. I think, you know, trying to not be attached to status quo. It’s hard to get away from it. But I think having that mindset is really important. One of the things that I really like a lot and try to live as much as I can every day is, when we are confronted with disruptive things—and this is certainly a very disruptive thing—our egos are challenged, our worldviews are challenged. When your worldview is challenged, you kind of have this very stark choice of either I’m wrong or it’s wrong. And most people choose the it’s wrong path. And we’re good at telling stories, so we tend to tell these stories about why something isn’t going to work. I call these why not questions. There’s a lot of these why not stories—it’s not factually correct, it’s not smart, it made this mistake, I can jailbreak it. Those are all true, they’re real. But that doesn’t mean it’s never going to work. They’re just problems to be solved. So the questions that I like to ask, and I think everybody should ask, to answer your question is, don’t ask the why not questions, ask what if. What if is a better question—what if this works? What does the world look like if this works? And if the what if question is compelling, then you work through the why not problems to get there. So what if I could transform my business in a certain way? What if I didn’t need to make this kind of decision? What if this process, which is very manual, could be automated with an LLM? Would that change my business? How would it change my business? That would be amazing. Okay, well, now I need to trust this thing. I need to be compliant, I need to do this and that—now I can do the why not. But the what if is the place to start.

MOLLY WOOD: Yeah, that’s the place to start today. As you’re starting to think about how to implement this, don’t jump to the end. I love it. I mean, you have said that actually, creative, interesting ideas almost always look stupid at first.

SAM SCHILLACE: Absolutely. They really do. One of my flags is if people call it a toy, you know, oh, that’s a toy. That’s never gonna work, or whatever. That’s always like, oh, that’s interesting. Like, that’s probably not a toy. Anything people dismiss as being unrealistic or being a toy, I’m almost always like, that’s okay. I can take a look at that, see what's going on there.

MOLLY WOOD: So, big picture, before I let you go—what mindset should business leaders have when they’re looking ahead to a future with AI?

SAM SCHILLACE: You know, there’s not really much of a prize for being pessimistic and right; there’s not much of a penalty for being optimistic and wrong. So, the real prize is in the corner of the box that’s labeled optimistic and right. And the real penalty is pessimistic and wrong. So, you know, you can kind of do the game theory on this—the right place to be is optimistic and, you know, try lots of things. If you can, experiment a lot, have that what if mentality, and assume things are solvable rather than the other way.

MOLLY WOOD: Sam, thank you so much for joining me.

SAM SCHILLACE: Thank you. Glad to be here.

MOLLY WOOD: Thank you again to Sam Schillace, CVP and Deputy CTO at Microsoft. And that’s it for this episode of WorkLab, the podcast from Microsoft. Please subscribe and check back for the next episode, where I’ll be talking to Christina Wallace, a Harvard Business School instructor, a serial entrepreneur, and author of the book The Portfolio Life. We’ll talk about how leaders need to rethink skills and career growth in the age of AI. If you’ve got a question or a comment, please drop us an email at worklab@microsoft.com, and check out Microsoft’s Work Trend Indexes and the WorkLab digital publication, where you’ll find all of our episodes, along with thoughtful stories that explore how business leaders are thriving in today’s digital world. You can find all of that at microsoft.com/worklab. As for this podcast, please rate us, leave a review, and follow us wherever you listen. It helps us out a ton. WorkLab is produced by Microsoft and Godfrey Dadich Partners and Reasonable Volume. I’m your host, Molly Wood. Sharon Kallander and Matthew Duncan produced this podcast. Jessica Voelker is the WorkLab editor. Thanks for listening."
Microsoft_News,https://blogs.bing.com/search/october-2023/DALL-E-3-now-available-in-Bing-Chat-and-Bing-com-create-for-free,,"DALL-E 3 now available in Bing Chat and Bing.com/create, for free!","We’re excited to share that DALL-E 3, the latest and most capable text-to-image model from OpenAI, is now generally available to everyone within Bing Chat and Bing.com/create—for free! The DALL-E 3 model from OpenAI delivers enhancements that improve the overall quality and detail of images, along with greater accuracy for human hands, faces, and text in images.

Since launching Bing Image Creator, over 1 billion images have been generated, helping inspire people’s creativity. We’ve seen Bing Image Creator make illustrated stories, thumbnails for social media content, PC backgrounds, design inspirations, and so much more. And today, we’re excited for you to take your creativity even further.

The promise of DALL-E 3

DALL-E 3 is a breakthrough in text-to-image generation, powered by a deep neural network that can produce realistic and diverse images from natural language prompts. DALL-E 3 builds on the success of previous models, such as:

Relevance and prompt following: DALL-E 3 follows the user’s prompt with even more precision and reliability than any previous models. For the best results, we recommend providing greater level of detail in the prompt—the more information, the more refined the final image will be.

Coherence: DALL-E 3 generates images that are even more photorealistic than other models for a varied set of prompts. The images are not only visually appealing, but also logically consistent with the prompt.

Aesthetics: DALL-E 3 generates images that are not only realistic, but also creative and artistic. The images can be uniquely styled with flair that meets your creativity.

Ensuring safety with more realistic images

We understand the risks and challenges of synthetic media, and we take safety and ethics seriously. Bing Image Creator has two main features to ensure this:

Content Credentials accompany all AI-generated images created by Bing Image Creator, featuring an invisible digital watermark adhering to the C2PA specification. This watermark includes the time and date it was originally created and confirms the provenance of the image as AI-generated.

The content moderation system, which removes any images that are harmful or inappropriate. We have trained our system to follow our terms of service and community guidelines, and to avoid images that contain nudity, violence, hate speech, or illegal activities.

Try Bing Image Creator today

We invite you to try Bing Image Creator today and see for yourself what DALL-E 3 can do for you. You can access it through Bing Chat or Bing.com/create.

We hope you enjoy using Bing Image Creator and have fun creating amazing images with DALL-E 3.

Try asking Bing Chat to “create an image of a golden doodle jumping into a pile of leaves, action photography.”

Ask Bing Chat to ""generate an image of a mystified child discovering an unusual bird that does not exist, over the shoulder shot, midday, detailed.“

Ask Bing Chat to ""create a scuba diver standing in the middle of a vast desert scratching their head with a lost look on their face.”

Ask Bing Chat to ""generate a vast landscape made of cotton candy, filled with glowing animals made of neon threads.”"
Microsoft_News,https://cloudblogs.microsoft.com/powerplatform/2023/10/03/the-ai-revolution-supercharging-low-code-with-the-power-platform-community/,,Supercharging low-code with the Power Platform community,"Welcome to the second Microsoft Power Platform Conference! Since the first conference, there has been a seismic shift in how we build low-code solutions. With Copilot in Power Platform, we are now in the era of AI-assisted low-code development. As such, this year’s conference is focused on helping the Power Platform community maximize their use of AI.

With advanced AI enhancing low-code development, more than 126,000 organizations have experienced Copilot in Power Platform. These new copilot capabilities make it easier than ever to get started with Microsoft Power Platform, thereby democratizing development for an even wider audience.

Over the past year, as we’ve seen rapid growth in Microsoft Power Platform—our monthly active Power Platform community members has grown to more than 5.2 million. This expanding community will play a pivotal role in shaping Microsoft Power Platform’s AI-driven future. To further aid the community’s growth, I’m excited to announce advancements in copilot, incredible designer updates for Power Automate, and automated environment routing to accelerate maker onboarding.

Power Platform Turn great ideas into impactful solutions Get started

Drive organization-wide innovation with Copilot in Power Platform

New Copilot capabilities in Power Pages are making it much easier to build data-driven websites. With a few sentences and clicks, developers can use Copilot in Power Pages to create websites and multi-step forms.

Using natural language to describe the website they want to build, developers can tell Copilot in Power Pages to generate a sitemap and homepage with various layouts and site themes. They can further refine and modify the website using Copilot in the normal point-and-click design studio. Lastly, makers can effortlessly design and build intuitive multi-step forms with just a few words. The Copilot experience simplifies website creation into fewer steps, providing a significant productivity boost.

We have also evolved the Copilot control in Power Apps, enabling makers to fully customize their AI-assistants and extend their Copilot through Power Virtual Agents. For example, makers can now directly add websites and unstructured content to their Copilot control, in addition to structured data sources, exponentially boosting the capabilities of the embedded copilot. Every app can now have a powerful Copilot! This is possible due to the seamless integration of Copilot control with Power Virtual Agents’ generative actions.

Enable faster development with the new Power Automate flow designer

Together with improvements to next-generation AI in Power Automate, we’re fueling faster development by enabling Copilot by default and making the version three designer generally available.

Today, tens of thousands of users are using the new designer in public preview. They’re more satisfied with the authoring experience and are creating flows with Copilot that are 50 percent more likely to run in production than those built without AI assistance. Based on user feedback, we’ve further refined Copilot in Power Automate by expanding its ability to populate more parameters in the flows and actions it generates.

Streamline governance and security for your makers with automation in Managed Environments

We’re expanding on Managed Environments with a set of capabilities to help automate routing of makers to their own development environments, so people can easily get started with the full capabilities of the platform in a way that’s manageable at scale.

managed environments Learn more

Environment routing allows admins to automatically place makers in their dedicated developer environments rather than the shared default environment. This ensures that makers start building in a scalable and governable manner from the beginning. Once makers are ready to deploy a new or updated solution, they can securely push it to a production environment via Power Platform pipelines. Pipelines automate in-product application lifecycle management (ALM) and ensure IT is informed of upcoming deployments with approval workflows and GitHub-based auditing.

IT can go a step further by having Copilot generate deployment notes and descriptions of all applications in Managed Environments, ensuring compliance with security practices at scale. Lastly, advisor in Managed Environments offers proactive recommendations and inline actions, helping administrators stay ahead of security threats at scale.

Extending the Power Platform community

Last year at Microsoft Power Platform Conference (MPPC), we announced the Power Up program, a three-month guided curriculum with self-paced learning, hands-on labs, instructor-led sessions, and more to help citizen developers build key skills in low code to advance their careers. Building on the successful launch of the Power Up program, which attracted more than 22,000 participants from more than 180 countries, we are excited to announce our latest expansion. In response to community feedback and to promote collaborative learning, this year, we are introducing group learning opportunities.

But that’s not all—we have an exciting invitation. If you’re passionate about Microsoft Power Platform and eager to make a difference, we invite you to join our Super Users group. Super Users play a crucial role in enhancing our community by answering questions, creating educational content, and providing valuable support. In return, Super Users enjoy exclusive benefits, including access to monthly meetings with Microsoft and expert badges.

For those interested, please join the Power Up and Super User programs.

What’s next

Thank you to the community members, customers, and partners who joined us this year for the Microsoft Power Platform Conference! Please register for Microsoft Ignite, November 14–17, 2023 to learn about even more great new capabilities coming to the platform.

For those who wish to follow the Power Platform Conference remotely, please join the Power Platform LinkedIn Community."
Microsoft_News,https://www.microsoft.com/bing/?OCID=artprompt_sidebar_SimplePromptstoTryonBing_mcrsft_bing%20,,Your Everyday AI Companion,"At Microsoft, we take our commitment to responsible AI seriously. Copilot is being developed in accordance with our AI principles. We are working with our partner OpenAI to deliver an experience that encourages responsible use. For example, we have and will continue to partner with OpenAI on foundational model work, we have designed the Copilot user experience to keep humans at the center, and we have developed a safety system that is designed to mitigate failures and avoid misuse with things like content filtering, operational monitoring and abuse detection, and other safeguards. The waitlist process is also a part of our approach to responsible AI. We'll be taking user feedback from those with early access to Copilot to improve the tool before making it broadly available. Visit the Bing blog for the latest on our learnings and progress.

Responsible AI is a journey, and we'll continually improve our systems along the way. We're committed to making our AI more reliable and trustworthy, and your feedback will help us do so.

To learn more about how to use Bing responsibly, please see our Terms of Use and Code of Conduct."
Microsoft_News,https://blogs.bing.com/search/september-2023/Bing-Preview-Release-Notes-New-Experiences-Powered-by-Bing-Image-Creator,,Bing Preview Release Notes: New experiences powered by Bing Image Creator,"Visual Search in Bing Chat Enterprise: We launched Visual Search in Bing Chat in July, and now it’s also available in Bing Chat Enterprise. Visual Search gives Bing Chat Enterprise the ability to understand the context of an image, interpret it, and answer questions about it.

For example, what if you’re travelling to Hong Kong and you’re not sure if the power adapter you brought for your laptop will work? Take a picture of it with your phone, open Bing Chat Enterprise in Edge mobile, upload the image and ask, “Will this plug shape work in Hong Kong?”"
Microsoft_News,https://blogs.microsoft.com/bayarea/2023/09/28/san-francisco-a-natural-home-for-our-fifth-ai-co-innovation-lab/,,San Francisco: A natural home for our fifth AI Co-Innovation Lab,"San Francisco: A natural home for our fifth AI Co-Innovation Lab

Around the world, Microsoft AI Co-innovation Labs offer startups and established companies alike a place to collaborate and build, develop, prototype, and test new solutions. We opened our first lab in Redmond in 2017, followed by labs in Munich, Shanghai, and Montevideo. Today these labs are accelerating the development of new products for new use cases and growing the ecosystem of AI-driven solutions. Today, we’re extremely excited to announce the opening of our fifth lab, in San Francisco.

The labs are a place to more deeply understand and experiment with AI development tools. They’re about quickly applying emerging technologies to emerging needs with tangible business impacts.

“AI is one of the defining technologies of our time, and Microsoft is committed to empowering every person and organization, whether a large enterprise or startup, to achieve more with AI,” says Christopher Young, Executive Vice President, Business Development, Strategy and Ventures, Microsoft. “It has been incredible to see the pace of development and innovation coming from the Bay Area and we’re looking forward to working with companies of all sizes, across all industries, to bring their AI ideas and projects to life in the AI Co-Innovation Lab.”

The San Francisco lab is the latest launch in a series of programs and investments from Microsoft that help companies of all sizes take advantage of this new era of AI. Azure OpenAI Service, which became generally available earlier this year, enables companies to apply the most advanced AI models, backed by the unique supercomputing and enterprise capabilities of Azure, to innovate in new ways. Microsoft also supports the startup community through programs like Microsoft for Startups, where more than 5,000 AI-first startups are leveraging our platform to advance their innovations and their businesses, and the Microsoft for Startups Founders Hub, a global platform which helps startups accelerate innovation by providing access to industry-leading AI services, expert guidance, and the essential technology needed to scale their company.

With the rapid adoption of AI and generative AI across industries, there are countless companies, including startups, in the Bay Area looking for an open and collaborative space to experiment with AI tools, and the lab is a place where they can go to engage with a team of engineers and technology experts—and there are numerous examples of this type of experimentation and collaboration in action in our labs.

Sony Semiconductor Solutions Group’s (“SSS”) vision AI platform, AITRIOS™, sets out to democratize vision AI by simplifying the process to deploy and scale computer vision and edge sensing solutions across industries including retail, logistics, smart city, and more. As a strategic partner of ours, SSS is involved in our labs in Tokyo, Shanghai, Munich, and Redmond and is now joining us in the San Francisco lab.

“The Co-Innovation Labs is a place for customers and partners to test minimum-viable products (MVPs) and develop cutting-edge solutions with Sony’s resources and Microsoft’s support,” says Mark Hanson, VP of Technology & Business Innovation and Head of Marketing for System Solution Business Development at SSS-A.

Artificial, an M12 portfolio company, is a digital platform start-up in the lab orchestration and execution space. They will join us in San Francisco after completing a successful proof of concept in the Redmond lab, where they used Azure OpenAI Service to integrate ChatGPT into their current platform. The integration unlocks the ability for scientists and non-programmers to use natural language instead of needing coding expertise to create orchestration methods that execute scientific laboratory tasks such as operating many instruments in a process and moving specimens around a lab to generate results.

“Working with Microsoft, we developed a functional, end-to-end proof of concept for the non-programmers in the lab, which we are now commercializing,” Artificial CEO David Fuller told me. “For us, the Redmond lab experience rapidly accelerated our vision to orchestrate science using natural language.”

Another lab partner and M12 portfolio company is Space and Time. The company gives its customers the ability to use natural language, rather than complex SQL queries, to access Web3 data—which means the data is more accessible and, ultimately, more usable. It also has a next-generation AI chatbot and worked with us in the lab to integrate a vector search database to improve its chatbot’s ability to return accurate results.

“Before working with Microsoft, we had a 50-60% accuracy rate against our own prompts and expected query results. Now, we hear from our customers that it’s in the order of 80-90% accuracy,” said Scott Dykstra, Chief Technology Officer at Space and Time. “Working with them also accelerated the delivery of the solution by months.”

The lab spaces are so important as places for true collaboration and partnership, but also as spaces for us at Microsoft to get feedback on how to best apply our technology to right-now problems.

So, if you’re in San Francisco and you’re interested in an efficient and compact engagement designed to accelerate or otherwise enhance what you’re doing—join us! There’s no cost to participate. All you need is to be an Azure user or interested in becoming one; an AI use case and business plan; a committed engineering team ready to collaborate; and a desire to solve hard problems with transformative results.

We can work with you on any part of the stack; we can help connect you with other partners; or create a new product or refine your go-to-market strategy. Together, we’ll grow the AI ecosystem, promote the rapid deployment of more AI solutions and learn from each other along the way.

It’s easy to apply, just visit: https://aiotlabs.microsoft.com/p/apply/sprint and to learn more about Microsoft Co-Innovation Labs around the world—including our next one opening in Kobe, Japan, later this year, visit: https://aiotlabs.microsoft.com/en."
Microsoft_News,https://www.microsoft.com/en-us/industry/blog/energy-and-resources/2023/09/28/the-era-of-ai-transformative-ai-solutions-powering-the-energy-and-resources-industry/,,The era of AI: Transformative AI solutions powering the energy and resources industry,"Energy and resources companies face the tremendous challenge of providing secure and reliable energy for 8.1 billion people and growing while moving toward a carbon-free world. Under pressure to adapt quickly to changing demands, regulations, and technologies, the energy sector is turning to AI to accelerate the energy transition and operate more efficiently, safely, and sustainably.

Today’s headlines are dominated by news about AI, from the latest discussions about Microsoft Copilot to ways that AI paves the way for a sustainable energy future. The use of AI is increasing the availability and efficiency of renewable energy sources such as solar, wind, hydroelectric, and biomass which now account for approximately 30 percent of electricity generated worldwide1

The World Economic Forum underscores the role AI plays in the energy transition and estimates that every 1 percent additional efficiency in demand creates USD1.3 trillion in value between 2020 and 2050 due to reduced investment needs.2

Microsoft partners with organizations across the energy and resources sector on solutions to drive workforce transformation, improve operational efficiencies, accelerate net-zero, and increase energy innovation and growth opportunities. We work with customers and partners on:

Enhancing safety and security by using facial recognition, anomaly detection, and robotics to prevent accidents, protect workers, and secure facilities.

Increasing operational and energy efficiency by using data analytics, machine learning, and the Internet of Things (IoT) to optimize supply chains, monitor and control assets, forecast demand, and balance power grids.

Curbing greenhouse gas emissions by leveraging computer vision, natural language processing, and deep learning to detect leaks, monitor flaring, and track carbon footprints.

Improving customer service and engagement through chatbots, recommender systems, and sentiment analysis to provide personalized experiences, offers, and feedback.

Leveraging AI to accelerate the energy transition

Our customers in power and utilities, oil and gas, and mining are transforming their workforce and operations to achieve more with less. These innovators are using digital technologies, data analytics, and automation to improve efficiency, safety, and sustainability. Investments include upskilling their employees, fostering innovation, and collaborating with Microsoft to create value for their customers and stakeholders.

Several industry leaders are at the forefront of leveraging data and AI to accelerate the energy transition, including:

Ontario Power Generation (OPG) teamed with Microsoft to develop an AI-powered chatbot for employees called ChatOPG. The chatbot is designed to provide information, answer questions, and act as a personal assistant at work. Adopting AI technology has helped OPG drive operational efficiencies by improving productivity, safety, and performance among employees.

Global mining company BHP is accelerating time to value with Microsoft AI and machine learning, using real-time plant data from the copper concentrators and Microsoft Azure Machine Learning to make hourly predictions. These predictions are then used to create machine learning–assisted recommendations for its Escondida operations team. As grade declines at existing mines and fewer new copper deposit discoveries are made, next-generation technologies like AI, machine learning, and data analytics will be used to unlock more production and value from our existing mines to help meet the increasing demand for copper and other minerals to support batteries and new energy generation.

Boliden is taking advantage of Azure to bring scalability and flexibility to its mining operations, combine cloud computing power, and work locally with mobile devices. Teams get real-time updates using the Boliden camera network without losing valuable time manually watching video streams. Site managers, inspectors, and analysts now get a deeper view of site performance and can focus on business development activities.

To replace some of their manual processes, E.ON introduced virtual inspections of power lines with drone images and AI. Together with their three distribution system operators, they developed their own virtual inspection solution using Microsoft Azure data and AI services. Drones are used to take pictures, and AI analyzes the images, sorts them, and evaluates them to make the maintenance process safer and more efficient.

Using an AI and machine learning solution built on Azure paired with IoT technology, Shell automatically identifies safety hazards and alerts service champions to quickly respond to and eliminate potential problems. In addition to protecting lives, having fewer accidents reduces operating costs and environmental impact.

Snam is using Microsoft AI and IoT technology to support data collection and strengthen security across its European pipeline network. In addition, the organization is using Azure Machine Learning for a deeper understanding of key equipment to improve proactive maintenance activities and boost energy efficiency.

Partnering on AI innovation

Our extensive, global partner ecosystem is fundamental to accelerating innovation across the energy sector. While technology is an enabler, collaboration is the true foundation for addressing the world’s complex energy challenges. Microsoft is actively working with partners SLB, Cognite, Bentley, and many others to accelerate ideation and the development and deployment of AI-driven, sustainable energy solutions. You can find out more about our partnerships in my June blog.

SLB was named Energy and Resources Partner of the Year for revolutionizing its DELFI platform built on Azure Data Manager for Energy and leveraging high-performance computing and AI to optimize simulation workflows for energy exploration, development, and carbon storage. Through our strong partnership and collaboration, SLB and Microsoft enable customers to spend less time on operations and more time focusing on addressing the growing energy demand crisis the world is facing.

Cognite, a finalist for the Energy and Resources Partner of the Year award, builds on the power of the Microsoft Cloud and its generative AI capabilities to simplify access to complex, industrial data and enable actionable insights. Cognite Data Fusion built on Microsoft Azure uses AI to automate the ingestion, consolidation, contextualization, and access to operational, engineering, and IT data from multiple sources to create data models and build new analytics dashboards, digital solutions, and digital twins.

Through digital twins and the power of data, AI, and advanced analytics, Bentley Systems helps energy companies better understand and optimize their operations. With AI, energy organizations can build mission-critical solutions to analyze images, identify patterns, do predictive analytics, and isolate anomalies to solve complex problems crucial to sustaining the environment and growing economies. Azure provides the platform for Bentley to unify data into a digital twin and apply AI, helping energy companies generate better insights, reduce costs, and increase efficiency.

The promise of generative AI for energy and resources industry transformation

Last week we announced Microsoft’s vision to deliver Copilot, your everyday AI companion—to help people and businesses be smarter, more creative, more productive, and more connected to the world around them. We believe that together with our customers and partners, Microsoft can help power your teams, businesses, and processes, to empower every person and every organization to do their very best work and to achieve more.

In the energy and resources industry, generative AI has the potential to create new solutions and optimize existing processes by enhancing predictive maintenance models which evaluate the current status of equipment and machinery, whether it’s a power line, trucks at a mining site, or offshore wind turbines. The AI models can proactively make predictions based on usage trends and consequently inform maintenance teams of potential equipment failures in advance which help energy companies optimize maintenance schedules, minimize equipment downtime, reduce costs, and ensure a safe and reliable energy supply.

AI and machine learning can be used to improve the security of energy grids by preventing cyberattacks before they happen by using data analytics to identify patterns in energy data that may be indicative of a breach. AI can also empower and enable field workers to identify high-risk tasks and help prevent serious injuries by analyzing large data sets on work sites, schedules, and historical incidents. AI models can be used to predict future supply chain information such as forecasting demand for specific products and optimizing inventory levels, and there are countless more examples around service desk scenarios, customer care and support, and internal knowledge assistants.

As AI technology continues to rapidly evolve, Microsoft is committed to the advancement of AI driven by ethical principles and making sure AI systems are developed responsibly and in ways that maintain trust. Our AI solutions and technology development align with Microsoft’s AI Principles—fairness, reliability and safety, privacy and security, inclusiveness, transparency, and accountability—along with Microsoft’s Responsible AI Standard in partnership with responsible AI experts across the company.

I hope you’re as excited as I am by the latest AI innovations across the energy and resources sector.

Resources

Microsoft AI Explore how Microsoft is empowering the world to achieve more with AI. Learn more

1AI paves the way for a sustainable energy future, Journal of Petroleum Energy Future, February 2023.

2Artificial intelligence is critical enabler of the energy transition, Word Economic Forum in collaboration with BloombergNEF and Deutsche Energie-Agentur, September 2021."
Microsoft_News,https://blogs.bing.com/search/september-2023/Expanding-Our-AI-Partnership-with-Meta-(1),,Expanding Our AI Partnership with Meta,"Last week, we shared our vision for how we’re unifying our AI copilot experiences to help people navigate any task. As part of this vision, Bing is central to these experiences by ensuring they are grounded in the latest web data and information available.In addition to copilots across the portfolio of Microsoft products, we are a platform company that provides the tools and services needed for others to succeed in their AI ambitions. Which is why today, we're thrilled to announce that we’ve begun to work with Meta to integrate Bing into Meta AI’s chat experiences enabling more timely and up-to-date answers with access to real-time search information. Bing’s integration extends to Meta AI and a few of Meta’s other AIs available to message with in WhatsApp, Messenger, and Instagram.Today’s announcement builds on our partnership with Meta to accelerate innovation in the era of AI. We’re excited to expand on this to continue to help deliver powerful, useful AI experiences into the products people use most. Read more about today’s announcements here - Yusuf Mehdi, Corporate Vice President and Consumer Chief Marketing Officer"
Microsoft_News,https://news.microsoft.com/2023/09/28/mayo-clinic-to-deploy-and-test-microsoft-generative-ai-tools/,,Mayo Clinic to deploy and test Microsoft generative AI tools,"Mayo Clinic to deploy and test Microsoft generative AI tools

ROCHESTER, Minn., and REDMOND, Wash. — Sept. 28, 2023 — Mayo Clinic, a world leader in healthcare known for its commitment to innovation, is among the first healthcare organizations to deploy Microsoft 365 Copilot. This new generative AI service combines the power of large language models (LLMs) with organizational data from Microsoft 365 to enable new levels of productivity in the enterprise.

Mayo Clinic is testing the Microsoft 365 Copilot Early Access Program with hundreds of its clinical staff, doctors and healthcare workers.

“Microsoft 365 Copilot has the ability to transform work across virtually every industry so people can focus on the most important work and help move their organizations forward,” said Colette Stallbaumer, general manager, Microsoft 365. “We’re excited to be helping customers like Mayo Clinic achieve their goals.”

Generative AI has the potential to support Mayo Clinic’s vision to transform healthcare. For example, generative AI can help doctors automate form-filling tasks. Administrative demands continue to burden healthcare providers, taking up valuable time that could be used to provide more focused care to patients. Microsoft 365 Copilot has the potential to give healthcare providers valuable time back by automating tasks.

Mayo Clinic is one of the first to start working with Copilot tools to enable staff experience across apps like Microsoft Outlook, Word, Excel and more. Microsoft 365 Copilot combines the power of LLMs with data in the Microsoft 365 apps, including calendars, emails, chats, documents and meeting transcripts, to turn words into a powerful productivity tool.

“Privacy, ethics and safety are at the forefront of Mayo Clinic’s work with generative AI and large language models,” said Cris Ross, chief information officer at Mayo Clinic. “Using AI-powered tech will enhance Mayo Clinic’s ability to lead the transformation of healthcare while focusing on what matters most — providing the best possible care to our patients.”

As a leader in healthcare, Mayo Clinic is always looking for new ways to improve patient care. By using generative AI and LLMs, Mayo Clinic will be able to offer its teams new timesaving tools to help them succeed.

About Mayo Clinic

Mayo Clinic is a nonprofit organization committed to innovation in clinical practice, education and research, and providing compassion, expertise and answers to everyone who needs healing. Visit the Mayo Clinic News Network for additional Mayo Clinic news.

About Microsoft

Microsoft (Nasdaq “MSFT” @microsoft) enables digital transformation for the era of an intelligent cloud and an intelligent edge. Its mission is to empower every person and every organization on the planet to achieve more.

For more information, press only:

Microsoft Media Relations, WE Communications for Microsoft, (425) 638-7777, [email protected]

Samiha Khanna, Mayo Clinic, (507) 266-2624, [email protected]

Note to editors: For more information, news and perspectives from Microsoft, please visit the Microsoft News Center at http://news.microsoft.com. Web links, telephone numbers and titles were correct at time of publication but may have changed. For additional assistance, journalists and analysts may contact Microsoft’s Rapid Response Team or other appropriate contacts listed at https://news.microsoft.com/microsoft-public-relations-contacts."
Microsoft_News,https://news.microsoft.com/2023/09/27/microsoft-and-mercy-collaborate-to-empower-clinicians-to-transform-patient-care-with-generative-ai/,,Microsoft and Mercy collaborate to empower clinicians to transform patient care with generative AI,"Microsoft and Mercy collaborate to empower clinicians to transform patient care with generative AI

Multiyear alliance creates foundation for innovation and deeper insights with data

REDMOND, Wash., and ST. LOUIS — Sept. 27, 2023 — Microsoft Corp. and Mercy are forging a long-term collaboration using generative AI and other digital technologies to give physicians, advance practice providers and nurses more time to care for patients and improve the patient experience. This work represents what’s next in healthcare for applying advanced digital technologies to the delivery of care to consumers.

“With the latest advances in generative AI, this moment marks a true phase change where emerging capabilities can help health care organizations address some of their most pressing challenges, create needed efficiency and transform care,” said Peter Lee, corporate vice president of research and incubations at Microsoft. “Mercy has a reputation for ongoing innovation and — through our years working together — has been a leader in the industry in creating an intelligent data platform on which to launch this kind of transformation. This is just the beginning, and it’s inspiring to see Mercy’s leadership adopting these tools to empower physicians, providers, nurses and all clinicians to improve patient care.”

Mercy plans to use Microsoft Azure OpenAI Service to improve care in several immediate new ways:

Patients will have the information to better understand their lab results and engage in more informed discussions about their health with their provider through the help of generative AI-assisted communication. Patients will be empowered to get answers in simple, conversational language.

Mercy will apply generative AI when taking patient calls for actions like scheduling appointments. Beyond the initial call, the AI solution will provide recommendations for additional follow-up actions to make sure all the patient’s needs are met during a single interaction, limiting the need for follow-up calls.

A chatbot for Mercy co-workers will help quickly find important information about Mercy policies and procedures, and locate HR-related answers such as information on benefits or leave requirements. By helping nurses and co-workers find the information they need more quickly, they can spend more time on patient care.

“Because of all the investments we have made together with Microsoft in the past few years, including the use of Microsoft’s secure cloud, we are better positioned to perform real-time clinical decision-making that ultimately improves patient care,” said Joe Kelly, Mercy’s executive vice president of transformation and business development officer. “With Microsoft, we are exploring more than four dozen uses of AI and will launch multiple new AI use cases by the middle of next year to transform care and experiences for patients and co-workers. This is predictive, proactive and personalized care at its best.”

As Mercy’s preferred platform for ongoing innovation, the Microsoft Cloud provides the health system with a trusted and comprehensive platform to improve efficiency, connect and govern data, impact patient and co-worker experience, reach new communities, and build a foundation for ongoing innovation. By securely centralizing and organizing data in an AI-powered intelligent data platform built on Azure, Mercy is uniquely positioned to deliver on evolving clinician and patient expectations more quickly. For example, Mercy can tap into secure data insights to reduce many unnecessary patient days in the hospital by giving care teams smart dashboards and better visibility into the factors that impact how soon patients can return home. Additionally, Microsoft’s modern work solutions will help Mercy co-workers improve productivity and communication so they can spend more time improving patient care and experience.

“Mercy and Microsoft are creating a new path for health systems in which we are working shoulder to shoulder to combine our 200-year heritage in health care and Microsoft’s extensive expertise in cloud and AI to enhance care for the patients we serve and improve the working experience for our physicians, advanced providers, nurses and all co-workers,” said Steve Mackin, Mercy’s president and CEO. “By using technology in new and secure ways, we innovate better health care for all.”

The organizations recently brought together Mercy’s engineering teams and senior leaders with Microsoft leaders, engineers and industry experts for a hackathon to co-imagine and begin to co-innovate around the generative AI use cases in development. Additionally, Microsoft and Mercy are working together to showcase Mercy’s solutions in the Microsoft Technology Center (MTC) in Chicago in 2024. The showcase will highlight transformational clinical experiences and demonstrate what the future of health care could look like using Microsoft technology.

About Mercy

Mercy, one of the 20 largest U.S. health systems and named the top large system in the U.S. for excellent patient experience by NRC Health, serves millions annually with nationally recognized quality care and one of the nation’s largest Accountable Care Organizations. Mercy is a highly integrated, multi-state health care system including more than 40 acute care, managed and specialty (heart, children’s, orthopedic and rehab) hospitals, convenient and urgent care locations, imaging centers and pharmacies. Mercy has 900 physician practices and outpatient facilities, more than 4,000 physicians and advanced practitioners and more than 45,000 co-workers serving patients and families across Arkansas, Kansas, Missouri and Oklahoma. Mercy also has clinics, outpatient services and outreach ministries in Arkansas, Louisiana, Mississippi and Texas.

About Microsoft

Microsoft (Nasdaq “MSFT” @Microsoft) enables digital transformation for the era of an intelligent cloud and an intelligent edge. Its mission is to empower every person and every organization on the planet to achieve more.

For more information, press only:

Microsoft Media Relations, WE Communications for Microsoft, (425) 638-7777, [email protected]

Bethany Pope, Mercy, (314) 251-4472 office, [email protected]

Joe Poelker, Mercy, (314) 525-4005 office, (314) 724-6095 mobile, [email protected]

Note to editors: For more information, news and perspectives from Microsoft, please visit the Microsoft News Center at http://news.microsoft.com. Web links, telephone numbers and titles were correct at time of publication but may have changed. For additional assistance, journalists and analysts may contact Microsoft’s Rapid Response Team or other appropriate contacts listed at https://news.microsoft.com/microsoft-public-relations-contacts."
Microsoft_News,https://blogs.windows.com/windowsexperience/2023/09/26/the-most-personal-windows-11-experience-begins-rolling-out-today/,,The most personal Windows 11 experience begins rolling out today,"Just last week, we announced exciting innovation coming not just on Windows, but across Surface, Microsoft 365, Bing and the new Microsoft Copilot. Starting today, there is even more product innovation available for our customers in the September Windows update.

Ready to upgrade or buy a new PC but not sure how to make the shift quickly and easily? Windows Backup is there to support you every step of the way. In a hurry to make a healthy meal plan for the week and finding the time to do so is challenging? Copilot in Windows can make building the plan and creating the shopping list a breeze. Want to unleash your inner creative and brand that side hustle you’ve been thinking about? Powerful creator tools make it easier and faster to bring your ideas to life. And there’s more. We’re expanding our voice access capabilities and bringing natural voices to Narrator ensuring Windows is accessible by default, and we’re making it even easier to stay secure with features like Passkey adoption and enhanced security features for IT pros and the businesses they protect.

Personalized AI experiences from Windows

We spend a lot of time on our PCs, and time is valuable. That’s why Windows is on a mission to make the things you do every day easier, faster and effortless with new features like Copilot in Windows.

Introducing Copilot in Windows – the intelligent assistant at your fingertips

We’re harnessing the power of AI to assist you in work, creation and play with the preview of Copilot in Windows¹. Designed to accelerate your tasks, reduce friction and save you time, it can also provide you with personalized answers, inspiration and task assistance.

Whether you need help with summarizing a web page, composing an email to your daughter’s new teacher, changing your settings to dark mode or generating an image for that unique idea in your head, Copilot in Windows can assist you. Need to enable Bluetooth or connect a new pair of headphones? Copilot can help. Not sure of the best way to capture a screenshot? Ask Copilot to do it for you. Copilot in Windows can change the way you use your PC and inspire you to try new things that you may not have thought of before. It is where productivity and creativity meet.

To get started, look for the Copilot icon on the taskbar or simply press WIN + C to launch Copilot in Windows using the same Microsoft account (MSA) or Microsoft Entra ID (formerly Azure Active Directory) account that you use to sign in on Windows.

Unleash your creativity with AI-enhanced tools in Paint

We’re excited to announce that we are updating our most popular inbox apps like Paint, Snipping Tool, Photos and more with AI capabilities optimized for digital creation.

To enhance your work with even greater creativity, we’re bringing layers and intuitive background removal to Paint. But that’s not all: the Paint Cocreator preview² will become available to Windows Insiders starting today with general availability for all customers in the coming weeks. Cocreator unleashes your creativity by simply inputting a text prompt, selecting a style and generating a unique image. You can then use the array of other tools in Paint to further refine your creation, whether it’s adding layers or drawing on top.

To access these enhancements, simply search for “Paint” in your search box or app list, and you’re ready to create, design and express yourself like never before.

Save time and produce your video with less effort using Microsoft Clipchamp

When it comes to storytelling with video, editing matters just as much as the scenes themselves. Microsoft Clipchamp can help you make it all come together with enhanced AI tools like Auto Compose. This new feature built into Clipchamp will help you get a head start on editing with just a few simple questions on the type of video you are developing. From there, Clipchamp will provide recommended scenes, edits and a narrative for you – all based on your input and creative assets and a few simple clicks. When your work is complete, easily save it to OneDrive or Google Drive, send to your social channels like Tik Tok, Instagram and LinkedIn, or upload to YouTube.

To get started, just search for the Clipchamp app right from Search on your Taskbar.

Snipping Tool gets an AI upgrade

Earlier this year, we announced the addition of screen recording capabilities in Snipping Tool. Now, along with recording visuals from your screen, you can also capture sound using audio and mic support, all within Snipping Tool. Need to record a tutorial on YouTube or record an online class? Snipping tool now makes it easier than ever to get it done.

To utilize the screen recorder feature, simply press Win + Shift + R or Print Screen.

To help further streamline your workflow with Snipping Tool, we are introducing two new text actions – text extraction and redaction.

Whether you need to extract specific content from an online article, a video call or any other source, you can effortlessly scan and copy text directly into other documents using text extraction. Using the copied text, you can perform web searches or easily incorporate it into your Word documents and PowerPoint presentations.

Moreover, protecting your privacy and sensitive information is paramount and with text redaction, we help you take that extra step to secure your confidential information. You can completely black out any text you don’t want to show – such as an email address within your screenshots or a category of information. Quick redaction makes maintaining privacy faster without any manual effort on your part.

To get started, navigate to the ”text actions” mode after snipping your screen.

Find and edit your favorite photo memories with ease

We’ve added new functionality to our Photos app to make finding, sharing and editing photos easier.

Today, we are launching background blur and enhanced search capabilities within the Photos app. Looking for that favorite set of photos from a trip but can’t quite remember where you placed them? Enhanced search capabilities make finding specific photos saved in OneDrive³ easier than ever. Now, with our enhanced search capabilities, finding specific images in the Photos app, especially those backed up in OneDrive, is easier.

Simply type in keywords and objects you remember from the image to quickly locate the photos and memories you’re seeking. Whether you’re searching by objects, locations or dates, the Photos app streamlines the process, presenting you with relevant photos in an instant.

Need to make a few edits to the photo background? Background blur offers you a way to effortlessly enhance image resolution and achieve stylish blur effects. And, when you are ready to share, the new slideshow feature offers you an easy way to relive those memories and share with your friends and family.

Windows Backup

It’s never been easier to move to your next PC

We know that when you buy a new PC you want to spend your time using the device, not setting it up. That’s why we’re making moving your important details to your new Windows 11 PC easier than ever before with Windows Backup.

Using Windows Backup, you can select your preferred backup options across most files, apps, settings and credentials4. When you move to a new Windows 11 PC, you’ll have the option to restore content from any of your backed up PCs, directly from the cloud, by logging in using your Microsoft account6. Windows Backup will make sure that everything is where you left it on your old PC5 – just how you like it. And, if you need more than 5 GB of free cloud storage, it’s easy to increase with an upgrade to a Microsoft 365 subscription7.

For even greater set-up simplicity, sign into Microsoft Edge with your Microsoft account where you can opt to sync your browsing history, favorite websites, passwords and other browser data to make moving from one device to the next seamless.

Accessible by default

Voice access expansion

Tools like Voice access have made it possible to set up and navigate your PC easily using your preferred inputs, like voice, and based on your needs. Starting today, Voice access works in more places8, including during log-in so you can get started with voice from step one. You can now dictate complex and non-standard words through the new spelling experience, and the corrections functionality will fix words that were recognized incorrectly.

To activate, search for Voice access in your app list to start setting up.

Natural languages in Narrator

Last year, we introduced three new voices8 to make listening more natural and enjoyable when using Narrator. Now, we are expanding to support even more languages, including Spanish, Portuguese, French, German, Mandarin Chinese, Japanese, Korean and English (U.K., India).

To start using Narrator, press Win + Ctrl + Enter.

Easier than ever to stay secure

Windows 11 offers an unprecedented range of security benefits to protect your information and your PC to keep it secure. And we are investing in even more new experiences like Passkeys, Smart App Control and Adaptive Dimming, all designed to make it easier to stay protected.

You only need to smile to sign in – replace passwords with passkeys

With the integration of Passkeys, Windows 11, with Windows Hello, will make it even more difficult for hackers to steal your passwords. Passkeys are the cross-platform future of secure sign-in management and eliminate the need for passwords. A passkey creates a unique, unguessable credential and allows you to sign in using your face, fingerprint or device PIN. Passkeys on Windows 11 will work on multiple browsers including Edge, Chrome, Firefox and others.

Learn more about Passkeys and how to develop yours.

Presence sensing improvements to increase security and reduce energy use

Reducing energy usage is becoming increasingly more important and today, we are announcing another way to conserve energy with Adaptive Dimming. If your PC presence sensor detects you are no longer paying attention, it will slowly dim your screen and save energy. This can also serve as an alert to refocus, keeping you in the flow.

Wake on Approach, Lock on Leave, and Adaptive Dimming are all powered by presence sensors and starting today, if your PC has this sensor, you can enable these important features all within your startup experience or in Settings. This means you have control over these features – both turning them on or off and the information collected. This functionality will also extend to external monitors if offered by the manufacturer.

The security feature updates don’t stop there. We know that our business customers expect a secure PC environment for their employees and today we are rolling out additional features to add that extra layer of protection.

Windows Hello for Business can eliminate the need for passwords

Windows Hello for Business can protect user identities by removing the need to use passwords from day one. Your IT manager can now set a policy for Microsoft Entra ID-joined PCs to remove the password requirement when accessing secured company resources. Once the policy is set, it will remove passwords both for device unlock as well as in-session authentication scenarios.

Empowering IT professionals with Config Refresh

We know mistakes happen and teams can change important settings or tamper with the registry settings that IT wants to reset. Config Refresh is designed to allow settings in the PolicyCSP on a Windows 11 device to be reset every 90 minutes by default, or every 30 minutes if desired. And, in situations where helpdesk may need to reconfigure a PC while troubleshooting, Config Refresh can also be “paused” for a period of time, after which it will be re-enabled. Starting today, Config Refresh is available to our Windows Insiders and coming soon to all customers.

Securing applications with Intune

Another feature designed to help with malicious apps is Intune with App Control for Business (formerly Windows Defender Application Control). Many organizations cite application control as one of the most effective means of defending against executable file-based malware and with this feature, apps must earn trust before running in order to enable a more secure PC environment for employees.

Customers using Microsoft Intune (sold separately) to manage their PCs are now able to configure App Control for Business in the admin console, including setting up Intune as a managed installer.

Commercial productivity

Windows 365 Boot streamlines access to your Windows 365 Cloud PC

As an industry-leading solution, Windows 365 empowers a more flexible workforce with a fully managed solution that securely streams your Windows experience — including your personalized apps, content and settings — from the Microsoft Cloud to any device on a Windows 365 Cloud PC.

In May we announced the preview of Windows 365 Boot, and today it becomes generally available. Windows 365 Boot lets employees log directly into their Windows 365 Cloud PC and designate it as the primary Windows experience on their device. This means that when they power on their device, Windows 365 Boot takes them to their Windows 11 login experience and directly into their Cloud PC with no additional steps in-between, saving them time and keeping them secure.

Seamlessly switch between your PC and Cloud PC

Whether your employees are full-time, contractors, shift workers or seasonal staff, Windows 365 Switch provides the flexibility to transition between their Cloud PC and local desktop.

With a familiar swipe gesture, shortcut keys or a simple mouse click on the taskbar, it is easier than ever for employees to securely access their personalized apps, content, data and settings on whichever device they choose to work from.

Windows 365 maintains secure access and data policy controls between personal and corporate environments, which is great for organizations looking to enable Bring-Your-Own-PC scenarios, onboard employees within minutes, reduce management and security headaches, and ensure your workforce is always up and running.

Mobile Application Management (MAM) for Windows

In addition to employees switching between their local and cloud PCs, we know that there are also times when organizations want to empower employees with access to company information on a personal PC, all while balancing their security needs.

Whether an employee needs to borrow a family member’s computer to quickly make some edits to a Word doc or write out an email that would be time consuming on their phone, Mobile Application Management for Windows makes this possible. Employees can now access organizational resources through Microsoft Edge from an unmanaged device, all while giving IT the ability to control the conditions under which the resources can be accessed.

AI-powered recommendation in File Explorer and Start

We are bringing AI-powered recommendations to File Explorer and the Start menu for our business customers running Windows PCs in their organization. These recommendations are designed to help you quickly and easily find the most relevant files for you based on your usage.

Introducing Instant Games in the Microsoft Store on Windows

With customers and developers at the heart of everything we do, we are pleased to introduce experiences, features and tools that make it easier to explore and access content even faster in the Microsoft Store on Windows. Starting today in preview, users can take advantage of Instant Games, a new experience that allows you to jump in and instantly play your favorite casual game directly from the Microsoft Store on Windows without the need to download and install on your Windows device. We’ve partnered with game publishers to be able to bring this experience to our collection of casual games. Find out how developers can participate.

Coming this month, through the Microsoft Store on Windows, users will also have the option to select specific drives and locations for game installations, keeping their library organized just the way they prefer. We’ve also made it even easier for users to explore Game Pass subscriptions and discover the latest games and offers with a new page in the Microsoft Store on Windows. To extend the experiences that users have grown to love, we are redesigning collections, enabling performance improvements and providing richer search engine results on the Apps webpage in the Microsoft Store, offering users new ways to discover more content on their Windows device.

More experiences to love

Windows is committed to bringing new innovation to the experiences you already know and love, and there is even more coming.

The new Outlook on Windows – available for free on any Windows device

– available for free on any Windows device A new Settings home tab, where you can manage all of your Microsoft account services, storage and recommended settings – all in one place

Auto Color Management for improved color accuracy and better gradients

for improved color accuracy and better gradients Improvements to the volume mixer in Quick Settings allowing customization of audio on a per-app basis

Dynamic Lighting – now generally available

– now generally available For our developers, we are announcing the general availability of tools recently announced at Build ’23. Dev home – a productivity companion for developers on Windows, and Dev Drive, a new storage volume delivering performance and security for developer workloads WinGet configuration – delivering fast and reliable machine setup New experimental features in Windows Subsystem for Linux such as Auto Memory reclaim, Disk space reclaim and new networking modes.



Ready to move to Windows 11 or purchase a new PC?

Learn more about the latest devices from Surface and our incredible OEM partners.

Acer:

Acer’s Swift Edge 16 features a thin and light design equipped with hardware to enable current AI experiences. The AI-powered capabilities of select AMD Ryzen 70040U Series processors help free up your processor to perform other workloads and keep your system running fast. AI-enabled noise reduction and Windows Studio Effects can also help you look and sound your best.

ASUS:

With the ROG Zephyrus G14, announced earlier this year, you can create customizable animations on the lid, thanks to the AniMe Matrix display. With NVIDIA’s GeForce RTX 40 Series Laptop GPUs inside, speed ups are extensive. You’ll see an increase in frame rates in games and faster rendering in creative apps. AI features complete tasks faster, while videos encode and export faster. AI also enables two-way noise cancellation, making streams, chats and recordings clearer than ever.

Dell:

The Dell Latitude 9440 is a powerful work companion. The 2-in-1 features 13th Gen Intel Core processors built on the Intel vPro Platform, memory options up to 32 GB and new mini-LED backlit keyboard technology. Made with recycled and machined aluminum, this laptop looks sleek, whether you’re using it in tent, stand or tablet mode.

HP:

With either the latest processors from AMD or Intel, the HP Pavilion Plus 14 is a sustainably made laptop that will power you through your day. The 5MP camera, with noise reduction technology, enables you to log in fast via Windows Hello. On select AMD versions, AMD Ryzen AI – a dedicated AI engine built into AMD’s processor – unlocks the video conferencing features of Windows Studio Effects.

Lenovo:

Lenovo’s Legion Pro 7i is a powerhouse gaming laptop with plenty of AI-enabled features, thanks to NVIDIA’s GeForce RTX 40 Series Laptop GPUs and AI technology from Lenovo. Experience higher FPS and AI-tuned cooling features, which help keep you competing at your best. This laptop comes with three months of Xbox Game Pass Ultimate, so you can access over 100 high-quality games, with new games added all the time.

Samsung:

The Galaxy Book3 Pro 360 from Samsung is a power-packed laptop with the latest 13th Gen Intel Core i7 processor with 1TB built-in storage and up to 2TB expandable storage via a microSD card, enabling smooth performance and plenty of space. This laptop, and other laptops running Windows 11, enable seamless phone-to-PC connectivity. With Phone Link, send and receive text messages, get notifications and make phone calls from your PC.

How to take advantage of the new innovation

We are committed to delivering continuous innovation to Windows 11 with the goal of providing you with the best experiences year-round.

Today, Copilot in Windows and many of the new features such as Windows Backup1, voice access for log in and effortless text corrections, and Passkey secure sign in to replace passwords for apps and websites will start to become available. Windows 11 devices will get new functionality at different times, as we gradually roll out some of these new features over the coming weeks initially using our controlled feature rollout (CFR). Eligible devices running Windows 11, version 22H2, have the option to enable access now by opening Settings (Settings > Windows Update) and turning on ”Get the latest updates as soon as they’re available.” We anticipate broad availability of most new features by the November 2023 security update release for all devices9.

If you haven’t moved to Windows 11 yet, now is the time. Just use Windows Backup, then select a great device that suits your needs best. The home to new Copilot experiences from Microsoft is a Windows 11 PC.

////////

Screens simulated, subject to change, feature availability and rollout timing may vary.

1 Copilot in Windows will start to release in preview to select global markets as part of our latest update to Windows 11. The initial markets for the Copilot in Windows preview include North America and parts of Asia and South America. It is our intention to add additional markets over time.

2Requires Microsoft account. Additional subscription may be required. Timing of feature delivery varies by device. Feature availability may vary by market. Available at launch in the U.S., Canada, Germany, France, Australia, U.K. and Italy. English inputs only for now. 50 credits available for initial use of Paint Cocreator. One credit applied per use. Credit system subject to change once preview is complete.

³Available for photos stored in OneDrive (home or personal) accounts.

4 Windows can back up most files, settings and apps from PCs running Windows 10 and higher. Restore is available on Window 11, version 22H2 and higher. Geographic restrictions may apply. Backup is available for Microsoft Accounts from any supported device running Windows 10 or higher. Restore is available on devices running Windows 11 22H2 or higher when connected to a network during new device setup. Backup and Restore are available globally with the exception of mainland China.

5When you open apps for the first time on your new Windows 11 PC, some will reinstall when you first open them. Other apps may require you to reinstall them manually from the original app provider.

6Using Windows Backup to restore to a Windows 11 PC requires you to sign in during initial device setup with the same Microsoft account you used for Windows 10 PC backup.

7Requires Microsoft account. Up to 5GB of Microsoft Storage is included. Data transfers exceeding 5GB require an active Microsoft subscription or trial.

8Hardware dependent. Requires Windows PC with microphone capability.

9Timing of feature delivery varies by device. Feature availability may vary by market.

Editor’s note – Sept. 26, 2023 – The section above about the Paint Cocreator preview was edited to indicate Windows Insiders will begin to receive the new feature starting tomorrow. Also, the second footnote above was updated to correct the number of credits available for initial use of Paint Cocreator."
Microsoft_News,https://news.microsoft.com/source/features/digital-transformation/how-metlife-pet-app-keeps-animals-healthy-soothing-wallets-worries-pet-parents/,,How the MetLife Pet app keeps animals healthy – while soothing the wallets and worries of pet parents,"If you’re caring for a toddler or a tabby or a toy poodle, you’ve probably faced what Jim DeMarco calls “a fundamental rule of parenting.”

“That rule,” says DeMarco, the father of four children and one cat, “is children and animals seem to get sick or get hurt after 5 o’clock on Friday afternoons, when the doctor’s office is closed.”

Those episodes can mean painful waits with whiny little ones at urgent care clinics. For parents without health insurance, such visits typically cost $100 to $200. But for pet owners, a trip to the emergency vet may run $1,500 or higher.

Not long ago, DeMarco faced that very dilemma. His cat, Mr. Darcy, had started scratching himself nearly nonstop, causing his skin to bleed. The family’s regular veterinary office was closed. But DeMarco happened to be part of a team developing a health and wellness app for pets.

Jim DeMarco and Mr. Darcy. (Photo courtesy of Jim DeMarco.)

As it turned out, that solution would spare his wallet, save his weekend and soothe Mr. Darcy’s itch. Soon, it would solve similar issues for thousands of other pet parents.

DeMarco, director of industry digital strategy at Microsoft, had spent months collaborating on the app with Microsoft engineers and with technologists and executives at MetLife, a New York City-based financial services company that provides insurance for people and pets.

Among the app’s features is a digital library stocked with hundreds of articles about pet care – like how to relieve fireworks fear or the lowdown on dog lumps. The library uses Azure Cognitive Search, an AI-powered search platform that helps each user uncover content for the precise needs of their pet, based on species, age and breed.

As Mr. Darcy scratched furiously and meowed in misery, DeMarco prepped for a pricey ride to the emergency vet. But when he grabbed his smart phone, the answer was right on his screen.

Mr. Darcy was very itchy. (Photo courtesy of Jim DeMarco.)

“Ah! I have the MetLife Pet app!” DeMarco said at the time. He had recently purchased a MetLife Pet insurance policy for Mr. Darcy – and downloaded the pet app – to trial the features as part of his job.

“I searched the knowledge base on the app and found out we were dealing with cat anxiety,” DeMarco recalls. His wife bought a bottle of pheromone spray at the pet store that calmed Mr. Darcy within minutes. Not seeing an emergency vet saved the family about $200, they estimated.

Launched in 2022, MetLife’s digital pet ecosystem offers a one-stop shop for all things fur baby. App users can submit and track insurance claims, maintain vaccination records, and find nearby vets, groomers or trainers.

The app, which is available to people with MetLife Pet insurance policies, has amassed more than 120,000 active users. Users can sign up for MetLife pet insurance through their employee benefits (if available) or purchase a policy directly.

“We focus on nose-to-tail wellness,” says Brian Jorgensen, CEO of MetLife Pet Insurance. “The app does that in a way core pet insurance never could.”

MetLife Pet CEO Brian Jorgensen, right, with his wife and their dog, Baxter. (Photo courtesy of Brian Jorgensen.)

Where pet insurance provides consumers with a tool to financially withstand big-dollar items like accidents and serious illnesses, the MetLife Pet app is built to make daily pet care even easier, Jorgensen says.

“We want to simplify the process wherever we can and reduce any level of concern, any level of challenge that the pet parent might face,” Jorgensen says.

“With the app, we try to take as much pressure off pet parents and give them confidence that the only thing they need to do is focus on their pet.”

At home, Jorgensen and his family care for Baxter, a pit bull mix, “who is the sweetest boy in the world,” and Sally, “a small, yellow dog of unknown provenance, who is the pack leader of the family,” he says.

For years, pet parents like Jorgensen and DeMarco have shared a common headache: tracking their animals’ health records.

The Jorgensens’ other dog, Sally. (Photo courtesy of Brian Jorgensen.)

Moving to a new city means finding a new vet, which may require multiple communications with the former vet to obtain those records. Worse, current records are typically unavailable when pet parents are forced to whisk their animals to an emergency clinic after hours.

The MetLife Pet app enables users to upload and access pet health records, ensuring they’re always at the ready. That feature relies on Azure Form Recognizer, an AI service that applies advanced machine learning to automatically extract key text from documents.

Making pet records portable follows a trend that consumers enjoy in their own health care – the rise of electronic health records, which can be shared among various providers, says Mike Dorris, a principal customer success account manager at Microsoft. He served as the project manager during the app’s development.

Recently, Dorris’ daughter, Makayla, 21, purchased a MetLife Pet policy, following her adoption of an 8-month-old kitten named Cosmo. Makayla downloaded the MetLife Pet app and took Cosmo, a Chantilly-Tiffany, to a local vet for spaying and vaccinations. She then used the app to upload her claims and the vaccination records.

Makayla Dorris and Cosmo. (Photo courtesy of Mike Dorris.)

No doubt, it’s easier for families (especially the animals!) if veterinary advice can be administered remotely. In fact, about 70% of vet visits made by pet parents can be effectively addressed via telemedicine calls, according to data collected by AskVet, a California-based company offering virtual health and wellness care for pets.

MetLife also gives app users the ability to communicate with vets around the clock through their mobile devices. The app connects pet parents to the AskVet global network of more than 80 vets and veterinary technicians plus trainers, behaviorists and nutritionists.

Some people use that feature to get free veterinary advice or to obtain second opinions following their pets’ diagnoses. Others use it to ask quality-of-life questions about older pets.

“Vets and animal hospitals are overwhelmed and overbooked. So if we can reassure someone that what they’re describing doesn’t sound like an emergency, that they can call their vet in the morning, we will do that,” says Crissy Allstott, AskVet’s chief veterinary officer.

“Of course, if someone feels strongly that something is off, that their pet may be having an emergency, we would never tell them not to take their pet to the ER. Because you know your pet best,” she adds.

The MetLife Pet chat is crucial for people who live hundreds of miles from the nearest vet’s office. In some cases, virtual vets have stayed on the line with pet parents during long, stressful rides to the closest animal ER.

“It’s such a hard time for them. It’s very emotional. It is for us as well. But it’s so rewarding to be able to go through that with them, to help somebody at the lowest point,” Allstott says.

“It’s amazing how, even via a chat, you can make a bond with someone,” she adds. “But it happens. And it happens pretty quickly. It’s powerful.”

Top photo courtesy of MetLife."
Microsoft_News,https://blogs.windows.com/windowsexperience/2023/09/22/a-new-wave-of-innovation-with-edge-your-ai-powered-browser/,,"A new wave of innovation with Edge, your AI-powered browser","Updated Nov. 15, 2023: To simplify the user experience and make Copilot more accessible to everyone, Bing Chat and Bing Chat Enterprise will now simply become Microsoft Copilot. For more information: https://aka.ms/BingIgnite

It’s been such an exciting year for Edge and Bing. We’ve worked diligently to bring you rich, AI-powered innovation to help you find, create and achieve beyond what you ever thought possible.

Yesterday, we announced another iteration of AI-powered features across Bing and Edge, and today, I’m eager to tell you more. Like advancements in shopping, to help you find what you need at the best price, and new ways help you get more done with browser actions, Tab Auto-grouping, Inline Compose and PDF view in Bing Chat on the Microsoft Edge mobile app. And because we need smarter ways to get more done at work, we’re excited to tell you more about Bing Chat Enterprise on the Microsoft Edge mobile app. All these innovations are powered by AI to help you browse smarter.

Remember, if you’re running a Windows PC, you already have Microsoft Edge installed, so check it out. For those who want to try Microsoft Edge and are on a macOS, mobile or Linux device, download it and let us know what you think![1]

Now, more about our announcements from yesterday’s event:

Shop smarter online

For the past two and a half years we’ve built shopping features into Edge to ensure you get the best deals possible right in the browser. Price history, price comparison and built-in coupons allow you to shop with confidence and ease – all while saving you money in the process. In fact, in the last year, shoppers have been offered more than $4 billion in savings on Microsoft Edge. Yesterday, we announced even more new shopping features. With Copilot in Microsoft Shopping, you have your very own personal shopper, powered by AI, helping you find what you’re looking for at the best price and in less time. Simply ask Copilot in Microsoft Shopping to help you find a product, and it will reply with intelligent questions to help narrow down your choices and guide you to the product that fits your needs. Coming soon, you’ll also be able to simply share a picture of the product you’re looking for and Copilot will guide you to the right match. This will come in handy this holiday season, when my kids text me photos of their wish list! This experience will be available soon on both mobile and desktop to facilitate your shopping experience from your preferred device. Although Copilot in Microsoft Shopping works on any browser, we recommend using Edge for the best experience.

Achieve more than you ever thought possible

For many of us, the holiday season can also mean more to do. Yesterday, we rolled out a new wave of AI-powered innovation to help you boost your productivity and get through your to-do list in less time.

Recently, we told you how to use Copilot in Edge to perform actions and save you time, like play a movie or group related tabs. Coming soon, you’ll be able to tell Copilot to send an email. That’s right. Simply open Copilot in Edge, give the prompt to draft a note and Copilot will open Outlook and write the email for you. All you need to do is review and hit send.

We’re also excited to announce that we’re expanding the capabilities within Compose in Copilot to help you write from most websites in the Edge browser. For example, if you’re working on a blog and having trouble landing the right words, Edge has you covered. Coming soon, with Inline Compose in Edge, you can highlight anything that you’d like to improve, and use the Rewrite menu to try on different tones – like Enthusiastic or Professional, or help with writing a longer post.

We know that a big part of our to-do lists each day happen on-the-go, which is why we’re making sure to bring AI-powered innovation to your mobile device. Coming soon to the Microsoft Edge mobile app, you will be able to ask Copilot questions like “what are the key takeaways of this report?” All you need to do is open Copilot on Edge mobile and give the prompt.

Productivity and organization go hand in hand. Yesterday, we announced Tab Auto-grouping in Edge, which uses AI to group your tabs based on specific topics or categories. Simply navigate to the tab icon on the top left, and click on group similar tabs, and Copilot will group your tabs, leaving your browser window, and mind, less cluttered.

Empowering organizations, safely

Just two months ago, we unveiled Bing Chat Enterprise, which offers AI-powered web chat with commercial data protection. Corporate customers of all sizes have been rapidly adopting the service, so employees can experience greater efficiency in their workday while protecting confidential data.

Yesterday, we announced that Bing Chat Enterprise is now available on the Edge mobile app. Let’s say you are on a business trip. You have a few ideas for a customer proposal that’s going into a competitive bid. Simply use your phone to ask Bing Chat Enterprise to shape your quick bullet points into a paragraph with a formal business tone. Now you can send customer-ready wording back to your teammate to incorporate into the bid, ahead of the deadline. What’s best about Bing Chat Enterprise is that it is designed for confidential information, so you and your organization can rest easily knowing that your data is protected. All of this is available at no additional cost to customers with Microsoft 365 E5, E3, A5 or A3 (faculty users), Business Premium or Business Standard licenses. Learn more about Bing Chat Enterprise .

More ways to browse smarter with Edge

Beyond yesterday’s announcements, there is a lot more AI-powered innovation to discover in Edge. For example, see why Designer in Edge makes us the first and only browser with an integrated AI-powered graphic design app. Or, how Edge can help you find what you’re looking for within web pages in less time with smart find, the new AI-powered update to Find on Page. And how Edge is leveraging the power of AI to keep you safer online with smart features like Website Typo protection, which helps you avoid malicious sites that exploit URL typos in the address bar. Learn more about our AI-powered features.

These are just a few examples of how Edge with the power of AI can help you find, create and achieve beyond what you ever thought possible. We hope these new tools and features in Microsoft Edge help you do just that. Please continue to send us your feedback and enjoy smarter browsing with Edge.

[1] You can share your feedback from the browser window by going to … menu > Help and feedback > Send feedback"
Microsoft_News,https://www.microsoft.com/en-us/microsoft-365/blog/2023/09/21/announcing-microsoft-365-copilot-general-availability-and-microsoft-365-chat/,,Announcing Microsoft 365 Copilot general availability and Microsoft 365 Chat,"Updated November 15, 2023: To simplify the user experience and make Copilot more accessible to everyone, Bing Chat and Bing Chat Enterprise will now simply become Microsoft Copilot. Learn more.

Today at an event in New York, we announced our vision for Microsoft Copilot—a digital companion for your whole life—that will create a single Copilot user experience across Bing, Edge, Microsoft 365, and Windows. As a first step toward realizing this vision, we’re unveiling a new visual identity—the Copilot icon—and creating a consistent user experience that will start to roll out across all our Copilots, first in Windows on September 26 and then in Microsoft 365 Copilot when it is generally available for enterprise customers on November 1.

To summarize today’s announcements, here is the product line-up for commercial customers:

Microsoft Copilot in Windows will be available on September 26. It will empower you to create faster and complete tasks with ease and lessen your cognitive load—making once-complicated tasks simple. We’ve made accessing the power of Copilot seamless as it’s always right there for you on the taskbar or with the Win+C keyboard shortcut, providing assistance alongside all your apps. Copilot in Windows will feature the new Copilot icon, the new Copilot user experience, Bing Chat, and will be available to commercial customers for free.

will be available on September 26. It will empower you to create faster and complete tasks with ease and lessen your cognitive load—making once-complicated tasks simple. We’ve made accessing the power of Copilot seamless as it’s always right there for you on the taskbar or with the Win+C keyboard shortcut, providing assistance alongside all your apps. Copilot in Windows will feature the new Copilot icon, the new Copilot user experience, Bing Chat, and will be available to commercial customers for free. Bing Chat Enterprise builds on Microsoft Copilot and adds commercial data protection—so you can be confident your business data is protected and will not leak outside the organization. With Bing Chat Enterprise, chat data is not saved, Microsoft has no eyes-on access, and your data is not used to train the large language models (LLM). Bing Chat Enterprise is available as a standalone for $5 per user per month and is included in Microsoft 365 E3 and Microsoft 365 E5.

builds on Microsoft Copilot and adds commercial data protection—so you can be confident your business data is protected and will not leak outside the organization. With Bing Chat Enterprise, chat data is not saved, Microsoft has no eyes-on access, and your data is not used to train the large language models (LLM). Bing Chat Enterprise is available as a standalone for $5 per user per month and is included in Microsoft 365 E3 and Microsoft 365 E5. Microsoft 365 Copilot is your AI assistant at work. It builds on Bing Chat Enterprise but is in a class all its own. It includes enterprise-grade security, privacy, compliance, and responsible AI to ensure all data processing happens inside your Microsoft 365 tenant—using technology Microsoft 365 customers have relied on for years. Microsoft 365 Chat is the new hero experience for Microsoft 365 Copilot and goes far beyond simple questions and answers. It combs across your entire universe of data—all your emails, meetings, chats, documents, and more, plus the web—to solve your most complex problems at work. And it’s integrated into the Microsoft 365 Apps millions of people use every day—Word, Excel, PowerPoint, Outlook, Teams, and more. Already used by tens of thousands of enterprise users in our Early Access Program (EAP) including customers at companies like Visa, General Motors, KPMG, and Lumen Technologies, Microsoft 365 Copilot will be generally available for enterprise customers for $30 per user per month on November 1.

Read on for more details about today’s announcements in Microsoft 365 Copilot, Bing Chat Enterprise, and Copilot in Windows.

Microsoft 365 Copilot—your AI assistant at work

In March, we showed you how Copilot can unlock productivity and unleash creativity in the apps that millions of people use every day—Word, Excel, PowerPoint, Outlook, and Teams. Today, we unveiled a new, hero experience in Microsoft 365 Copilot: Microsoft 365 Chat. You saw a glimpse of Microsoft 365 Chat in March, then called Business Chat, but rapid advancements over the last few months have taken it to a whole new level. It’s a powerful new capability in Microsoft 365 Copilot that goes far beyond simple questions and answers to tame the complexity, eliminate the drudgery, and reclaim time at work. Like an assistant, it has a deep understanding of you, your job, your priorities, and your organization. It can find whatever you need in your files (even the files you forgot existed), connect the dots across all your content and context at the speed of light, and even integrate with the apps you use to run your business. Preview customers can access it today on Microsoft365.com or in Teams when signed in with their work account. In the future, you’ll be able to access it wherever you see the Copilot icon when signed in with your work account.

Microsoft 365 Copilot Unlock productivity and unleash creativity in the apps millions of people use every day across work and life. Learn more

Enterprise customers should call their Microsoft account representative to purchase Microsoft 365 Copilot beginning on November 1. EAP customers will have the first opportunity to deploy Copilot across their organizations when it is generally available. In addition, we have expanded our EAP to a select group of consumers and small business customers, and are excited to learn more as we scale.

Over the past few years, the pace and volume of work have only increased. On a given workday, our heaviest users search for what they need 18 times, receive over 250 Outlook emails, and send or read nearly 150 Teams chats.1 Teams users globally are in three times more meetings each week than they were in 2020.2 And on Windows, some people use 11 apps in a single day to get their work done. Microsoft 365 Chat will help everyone lift the weight of work.3

Learn to work in a whole new way with Copilot Lab

We also announced Copilot Lab to help everyone learn to work iteratively with AI and get the most out of Microsoft 365 Copilot. Just as customers turned to Microsoft in the shift to remote and flexible work, they are relying on us to help people build new work habits for a new AI-powered era of productivity. And we want to help. With Copilot Lab, you can learn to turn a good prompt into a great one, share your favorite prompts with coworkers, and get inspired as we all learn how to work in a whole new way together. Once it’s generally available, Copilot Lab will be integrated into Microsoft 365 Copilot and accessible via a website to all Microsoft 365 Copilot users.

Unlock productivity and unleash creativity with Microsoft 365 Copilot

We’re continuing to add new Copilot experiences in the Microsoft 365 apps. All updates will be generally available for commercial customers in November unless noted as “coming soon.”

Copilot in Outlook helps you stay on top of your inbox and create impactful communication in a fraction of the time.

Now you can:

Ask Copilot to summarize an email thread to get key information with annotations that help you quickly jump to the source of the summarized content, and suggested action items, replies, and follow-up meetings.

Choose “Sound like me” to match your unique writing style and voice when you’re using Copilot to draft an email.

to match your unique writing style and voice when you’re using Copilot to draft an email. Follow a Teams meeting that you could not attend live, directly from Outlook on your own time. When the meeting starts, Teams notifies participants to record it. When the recording is ready, Copilot notifies you in Outlook.

Copilot in Word transforms every part of the writing process to make you more creative and efficient.

Now you can:

Ask Copilot for a summary of any document to share as a recap or quickly get up to speed, and Copilot will now deliver a more in-depth bulleted summation with all the information you need.

Ask Copilot to “ rewrite ” a paragraph, then scroll through a series of options to see what fits best. You can then adjust the rewrite tone to make it more neutral, casual, or professional.

” a paragraph, then scroll through a series of options to see what fits best. You can then adjust the rewrite tone to make it more neutral, casual, or professional. Refine a prompt by asking Copilot to do things like “make answer more concise” or “add a column in the table for the project owner.”

Save time on formatting by asking Copilot to generate a table from your copy.

Copilot in Excel enables anyone to analyze and visualize data like a data analyst.

Now you can:

Work with Copilot in Excel to help analyze, format, and edit your data to gain deeper understanding and insights.

Quickly add a formula column, highlight key data with a prompt like “make all cells red where the value is under 1000,” filter and sort your data, and ask questions to instantly uncover key insights.

Use Copilot to access advanced analytics; create powerful, professional visualizations, generate forecasts, and save time sorting through data with Python in Excel.

Copilot in Loop unlocks the power of shared thinking, helping teams cocreate, stay up to date, and pick up where others left off.

Now you can:

Iterate with Copilot collaboratively as a team, cocreating prompts and reviewing earlier interactions to edit and improve on work together.

Ask Copilot to generate a quick table on the page to help organize team projects. You can easily turn the table into a Loop component to share with teammates wherever they’re working—in Teams, Outlook, Microsoft Whiteboard, and Word on the web.

Quickly catch up where your teammates left off by asking Copilot for a summary of a page or asking open-ended questions like “What key assignments were made since I was last on this page?”

Generate a recap for a teammate that you’re handing work off to, so they can get up to speed on any updates or changes.

Save time writing code with Copilot-suggested Code blocks that pop up automatically using the context of your work.

Copilot in OneNote helps you stay organized, prepared, and ready to take action.

Now you can:

Gain deeper insights on your notes by asking comprehensive questions like: “What are the pros and cons of this process?”

Quickly generate summaries of your OneNote content.

Type just a few sentences and get a Copilot-generated paragraph, bulleted list, or organized section.

Make your writing clearer and more effective with a quick Copilot edit.

Copilot in Stream helps you find the insights and information you need from a video—in the Microsoft Stream web app or anywhere Stream videos work across Microsoft 365 apps—in seconds.

Now you can:

Get a quick summary of the video with a transcript of the relevant spots you need to review.

Ask Copilot open-ended questions—“What was the discussion outcome?” “How did the site walkthrough go?”—to quickly understand outcomes and key points.

Ask Copilot to identify when people, teams, or topics are discussed, then jump right to that point in the video.

Ask Copilot for suggested follow-ups or actions from a video you missed.

Copilot in OneDrive helps you find all the insights and information you need—without ever opening a file.

Now you can:

Ask Copilot open-ended questions related to an individual file or get a summary of the content.

Bing Chat Enterprise—be confident using generative AI at work

In July, we introduced Bing Chat Enterprise. As organizations adopt AI, they want to be confident that their data is protected. Bing Chat Enterprise adds commercial data protection, ensuring that sensitive business data is never seen by anyone, that the queries are never stored, and user input is never used to train the foundation models.

Today, we also announced that Bing Chat Enterprise is now available in the Microsoft Edge mobile app and we’re bringing support for multimodal visual search and Image Creator to Bing Chat Enterprise. Boost your creativity at work with the ability to find information using images and creating them while protecting sensitive enterprise data.

Bing Chat Enterprise is already part of Microsoft 365 E3 and E5, Business Standard, and Business Premium, which means more than 160 million people already have access.

Copilot in Windows

In May, we announced that Copilot was coming to Windows 11. Copilot in Windows—in preview starting September 26—empowers you to create faster, complete tasks with ease, and lessens your cognitive load—making once complicated tasks, simple. We’ve made accessing the power of Copilot seamless as it’s always right there for you on the taskbar or with the Win+C keyboard shortcut providing assistance alongside all your apps, on all screen sizes at work, school, or at home.

Managing Copilot in windows Learn more

And we’re empowering IT admins with controls to decide when they deploy Copilot in Windows to their enterprise and who has access. To help bring Copilot to more people across more organizations, we are excited to announce that Windows 365 Boot and Windows 365 Switch will also be available in this update, making it easier than ever to get a full, secure, personalized Windows 365 Cloud PC with Copilot—on any device. Microsoft was recently recognized as a Leader in Gartner® Magic Quadrant™ for Desktop as a Service (DaaS).

Building responsibly

As we bring Copilot to customers, we are guided by our AI principles, Responsible AI Standard, and decades of research on AI. And our Copilot Copyright Commitment means customers can be confident using our Copilot services and the output they generate without worrying about copyright claims.

Learn more

To learn more about Microsoft Copilot, read about all of today’s Copilot announcements on our Official Microsoft Blog, and for all the blogs, videos, and assets related to today’s announcement, please visit our microsite. You can learn more about Microsoft 365 Copilot on our support page. Go to WorkLab to learn more about the art and science of prompting.

1 Data represents top 20 percent of users by volume of searches across M365 services, emails received, and sent and read chats in Teams, respectively

2 Microsoft annual Work Trend Index 2023: Work Trend Index | Will AI Fix Work? (microsoft.com)

3 Data reflects the top 20 percent Windows devices by app volume per day"
Microsoft_News,https://www.microsoft.com/en-us/security/blog/2023/09/21/new-microsoft-security-tools-to-protect-families-and-businesses/,,New Microsoft security tools to protect families and businesses,"Today marks an exciting milestone in Microsoft’s AI journey. This morning, at an event in New York City, we made several major announcements to empower people across work and life—you can read more about Microsoft Bing and Edge with Copilot, what’s new from Microsoft 365 Copilot and Bing Chat Enterprise for work, Microsoft Designer and Copilot in Microsoft 365, Windows 11, and new Surface devices in Yusuf Medhi’s blog.

These innovations will redefine how we live and work with AI, and it’s so exciting to see the progress we are making to put AI and other capabilities into the hands of our customers across every aspect of their whole lives.

As we rapidly iterate and improve technology, it’s imperative that we do so with a security-first mindset. This means both building products that are secure by default and ensuring that we are adopting and deploying new technologies, like AI, in a secure and responsible way.

Designing Windows security for the new era

Today, we shared the upcoming Windows 11 update that will be available on September 26, 2023. That update includes several important security features and updates that help make this the most personal and intelligent Windows experience yet. I want to take a moment to highlight some of the key security features you’ll hear more about next week:

Building the passwordless future

We’ve talked for years about the passwordless future that we envision here at Microsoft. We know that passwords are one of the most common entry points for attacks—in fact, there are more than 4,000 password attacks every second—a nearly three-fold increase since last year.1 That’s why it’s more important than ever for organizations and individuals to use passwordless options whenever possible. In the Windows 11 update, we’re excited to introduce:

Even more passwordless : IT teams will now be able to remove the option to enter a password on day one for all Windows 11 devices with Windows Hello for Business, prompting employees to use more secure login options.

: IT teams will now be able to remove the option to enter a password on day one for all Windows 11 devices with Windows Hello for Business, prompting employees to use more secure login options. More with passkeys: For the past several years we have been committed to working with our industry partners and the FIDO Alliance to further the passwordless future with passkeys. Passkeys are the cross-platform, cross-ecosystem future of accessing websites and applications. Today we are pleased to share that Windows 11 users can better take advantage of passkeys. After creating a passkey with Windows Hello, you can access a website or application using your face, fingerprint, or device PIN. You can manage passkeys stored on your Windows PC and sign in using passkeys saved on your mobile phone for added convenience. You can use passkeys on a variety of services such as GitHub.com, DocuSign.com, and more.

Empowering IT with new security tools

The latest Windows 11 will also include powerful new tools that empower IT teams to keep their organizations and employees more secure, including:

Custom App Control for Business policies with Microsoft Intune: Applications are the lifeblood of our digital experiences, but they can also become entry points for threats. With application control, apps must earn trust to run, ensuring only approved, secure, and trusted apps are allowed onto devices. By preventing unwanted or malicious code from running, application control is a critical part of a comprehensive security strategy. Application control is often cited as one of the most effective means of defending against malware. Customers can now use App Control for Business (formerly called Windows Defender Application Control) and its next-generation capabilities to protect their digital estate from malicious code. With App Control for Business, IT teams can configure what runs in a business environment through Microsoft Intune or other MDMs in the admin console, including setting up Intune as a managed installer.

Applications are the lifeblood of our digital experiences, but they can also become entry points for threats. With application control, apps must earn trust to run, ensuring only approved, secure, and trusted apps are allowed onto devices. By preventing unwanted or malicious code from running, application control is a critical part of a comprehensive security strategy. Application control is often cited as one of the most effective means of defending against malware. Customers can now use App Control for Business (formerly called Windows Defender Application Control) and its next-generation capabilities to protect their digital estate from malicious code. With App Control for Business, IT teams can configure what runs in a business environment through Microsoft Intune or other MDMs in the admin console, including setting up Intune as a managed installer. Config Refresh: We often uncover threat actors launching attacks designed to evade security measures by changing settings and system configurations. Config Refresh enables settings in the Policy Configuration Service Provider (CSP) on a Windows 11 device to be reset every 90 minutes by default, or every 30 minutes if desired. This protects against configuration settings being unexpectedly changed through either malicious software or registry edits and ensures that your settings are retained in the way IT configured them.

We will share more details about these and other new Windows 11 features next week.

New advanced security for Microsoft 365 Personal, Family, and Basic subscribers

As a company, we are also thinking about how we equip individuals with tools and information to better protect themselves at home. Today, we are excited to announce new advanced security benefits for Microsoft 365 Personal, Family, and Basic subscribers.

Microsoft Defender for individuals introduces credit monitoring and privacy protection in the United States

Today, we shared two new additions to Microsoft Defender for individuals that will help individuals and families protect their personal data online:

Credit monitoring: The Defender identity theft monitoring capabilities will now be expanded with new credit monitoring functionality. Users will get an alert any time there is activity related to their credit that might be malicious, enabling them to act quickly and help stop activity while it’s occurring.

The Defender identity theft monitoring capabilities will now be expanded with new credit monitoring functionality. Users will get an alert any time there is activity related to their credit that might be malicious, enabling them to act quickly and help stop activity while it’s occurring. Privacy protection: Privacy protection shields sensitive data from threats when users are connected to open and public Wi-Fi networks. It reduces online tracking and protects against bad actors on unsecured network and enables users to hide their IP address and location from websites, apps, and advertisers that may attempt to track online activity to collect personal data. Privacy protection also encrypts traffic and data through a VPN.

Learn more about Microsoft Defender for individuals.

OneDrive advanced security in Microsoft 365 Basic

Earlier this year, we launched our most affordable subscription plan, Microsoft 365 Basic. As promised, we’re now adding the OneDrive advanced security features in our Microsoft 365 Personal and Family plans to the Microsoft 365 Basic plan at no extra cost. Starting October 12, 2023, Microsoft 365 Basic subscribers will have access to OneDrive advanced security features like unlimited files in your Personal Vault, expiring sharing links, password-protected sharing links, files restore, and ransomware detection and recovery. Microsoft 365 Basic continues to offer 100 GB of cloud storage and incredible peace of mind benefits at an incredible price.

Using AI securely and responsibly

As we celebrate our advancements across AI, it’s important to reiterate our commitment to deploying these technologies securely and responsibly. I have been lucky enough to have had a front-row seat as we built, tested, and iterated on these amazing AI technologies. But as we’ve watched this evolve, we recognize that, as Spider-Man would say, “With great power, comes great responsibility.” That is why we are committed to building and deploying AI responsibly and ethically. You can read more about our commitments at the Empowering Responsible AI practices hub.

We’ve heard from customers and seen firsthand that employees are eager to use AI in the workplace. But many leaders have concerns about the use of AI in their organizations. They worry that it can introduce unnecessary risk. That’s why we are taking a safe and secure approach for customers, empowering them to feel confident in using AI at work. For example, Bing Chat Enterprise helps employees tap into the power of AI while ensuring prompts and responses aren’t logged or used to train the underlying model. Our commitments to enterprise-grade security, privacy, identity, compliance, and responsible AI in Microsoft 365 Copilot remain unchanged. And lastly we will continue to use AI to drive a paradigm shift in security with Microsoft Security Copilot. We empathize with security and IT leaders trying to navigate a challenging landscape and will continue to build security into our products to help them harness the power of AI confidently.

As part of our time in New York today, I am pleased to be a part of a panel discussion on this topic. Thank you for being part of our journey and making security forefront in your lives.

Stay tuned for more exciting details from Windows next week as we celebrate the availability of the new Windows 11 on September 26, 2023.

Learn more

To learn more about Microsoft Security solutions, visit our website. Bookmark the Security blog to keep up with our expert coverage on security matters. Also, follow us on LinkedIn (Microsoft Security) and Twitter (@MSFTSecurity) for the latest news and updates on cybersecurity.

1Microsoft internal data."
Microsoft_News,https://blogs.microsoft.com/blog/2023/09/21/announcing-microsoft-copilot-your-everyday-ai-companion/,,"Announcing Microsoft Copilot, your everyday AI companion","Updated November 15, 2023: To simplify the user experience and make Copilot more accessible to everyone, Bing Chat and Bing Chat Enterprise will now simply become Microsoft Copilot. For more information: https://aka.ms/BingIgnite

We are entering a new era of AI, one that is fundamentally changing how we relate to and benefit from technology. With the convergence of chat interfaces and large language models you can now ask for what you want in natural language and the technology is smart enough to answer, create it or take action. At Microsoft, we think about this as having a copilot to help navigate any task. We have been building AI-powered copilots into our most used and loved products – making coding more efficient with GitHub, transforming productivity at work with Microsoft 365, redefining search with Bing and Edge and delivering contextual value that works across your apps and PC with Windows.

Today we take the next step to unify these capabilities into a single experience we call Microsoft Copilot, your everyday AI companion. Copilot will uniquely incorporate the context and intelligence of the web, your work data and what you are doing in the moment on your PC to provide better assistance – with your privacy and security at the forefront. It will be a simple and seamless experience, available in Windows 11, Microsoft 365, and in our web browser with Edge and Bing. It will work as an app or reveal itself when you need it with a right click. We will continue to add capabilities and connections to Copilot across to our most-used applications over time in service of our vision to have one experience that works across your whole life.

Copilot will begin to roll out in its early form as part of our free update to Windows 11, starting Sept. 26 — and across Bing, Edge, and Microsoft 365 Copilot this fall. We’re also announcing some exciting new experiences and devices to help you be more productive, spark your creativity, and to meet the everyday needs of people and businesses.

With over 150 new features, the next Windows 11 update is one of our most ambitious yet, bringing the power of Copilot and new AI powered experiences to apps like Paint, Photos, Clipchamp and more right to your Windows PC.

Bing will add support for the latest DALL.E 3 model from OpenAI and deliver more personalized answers based on your search history, a new AI-powered shopping experience, and updates to Bing Chat Enterprise, making it more mobile and visual.

Microsoft 365 Copilot will be generally available for enterprise customers on Nov. 1, 2023, along with Microsoft 365 Chat, a new AI assistant that will completely transform the way you work.

Additionally, we introduced powerful new Surface devices that bring all these AI experiences to life for you, and they are available for pre-order beginning today.

New Windows 11 Update delivers over 150 new features, including bringing the power of Copilot to the PC

Today, we’re thrilled to share our next step toward making Windows the destination for the best AI experiences – with a new update that delivers our most personal experience yet coming on Sept. 26.

Here’s a look at some of what’s new in the latest update for Windows 11:

YouTube Video Click here to load media

Copilot in Windows (in preview) empowers you to create faster, complete tasks with ease and lessens your cognitive load – making once complicated tasks, simple. We’ve made accessing the power of Copilot seamless as it’s always right there for you on the taskbar or with the Win+C keyboard shortcut providing assistance alongside all your apps, on all screen sizes at work, school or at home.

(in preview) empowers you to create faster, complete tasks with ease and lessens your cognitive load – making once complicated tasks, simple. We’ve made accessing the power of Copilot seamless as it’s always right there for you on the taskbar or with the Win+C keyboard shortcut providing assistance alongside all your apps, on all screen sizes at work, school or at home. Paint has been enhanced with AI for drawing and digital creation with the addition of background removal and layers as well as a preview of Cocreator that brings the power of generative AI to the Paint app.

has been enhanced with AI for drawing and digital creation with the addition of background removal and layers as well as a preview of Cocreator that brings the power of generative AI to the Paint app. Photos has also been enhanced with AI including new features to make editing your photos a breeze. With Background Blur you can make the subject of your photo stand out quickly and easily. The Photos app automatically finds the background in the photo, and with a single click, instantly highlights your subject and blurs out the background. We’ve improved search, with photos stored in OneDrive (home or personal) accounts, you can now quickly find the photo you’re looking for based on the content of the photo. You can also now find photos based on the location where they were taken.

has also been enhanced with AI including new features to make editing your photos a breeze. With Background Blur you can make the subject of your photo stand out quickly and easily. The Photos app automatically finds the background in the photo, and with a single click, instantly highlights your subject and blurs out the background. We’ve improved search, with photos stored in OneDrive (home or personal) accounts, you can now quickly find the photo you’re looking for based on the content of the photo. You can also now find photos based on the location where they were taken. Snipping Tool now offers more ways to capture content on your screen – with this update you can now extract specific text content from an image to paste in another application or, you can easily protect your sensitive information with text redaction by using text actions on the post capture screen. And, with the addition of sound capturing using audio and mic support, it’s easier to create compelling videos and content from your screen.

now offers more ways to capture content on your screen – with this update you can now extract specific text content from an image to paste in another application or, you can easily protect your sensitive information with text redaction by using text actions on the post capture screen. And, with the addition of sound capturing using audio and mic support, it’s easier to create compelling videos and content from your screen. Clipchamp , now with auto compose, helps you with scenes suggestions, edits and narratives based on your images and footage automatically so you can create and edit videos to share with family, friends, and social media like a pro.

, now with auto compose, helps you with scenes suggestions, edits and narratives based on your images and footage automatically so you can create and edit videos to share with family, friends, and social media like a pro. Notepad will start automatically saving your session state allowing you to close Notepad without any interrupting dialogs and then pick up where you left off when you return. Notepad will automatically restore previously open tabs as well as unsaved content and edits across those open tabs.

will start automatically saving your session state allowing you to close Notepad without any interrupting dialogs and then pick up where you left off when you return. Notepad will automatically restore previously open tabs as well as unsaved content and edits across those open tabs. With the new Outlook for Windows , you can connect and coordinate your various accounts (including Gmail, Yahoo, iCloud, and more) in one app. Intelligent tools help you write clear, concise emails and seamlessly attach important documents and photos from OneDrive. To learn more, visit this link.

, you can connect and coordinate your various accounts (including Gmail, Yahoo, iCloud, and more) in one app. Intelligent tools help you write clear, concise emails and seamlessly attach important documents and photos from OneDrive. To learn more, visit this link. Modernized File Explorer, we are introducing a modernized File Explorer home, address bar and search box all designed to help you more easily access important and relevant content, stay up to date with file activity and collaborate without even opening a file. Also coming to File Explorer is a new Gallery feature designed to make it easy to access your photo collection.

we are introducing a modernized File Explorer home, address bar and search box all designed to help you more easily access important and relevant content, stay up to date with file activity and collaborate without even opening a file. Also coming to File Explorer is a new Gallery feature designed to make it easy to access your photo collection. New text authoring experiences to voice access and new natural voices in Narrator , continuing our ongoing commitment to making Windows 11 the most accessible version of Windows yet.

and , continuing our ongoing commitment to making Windows 11 the most accessible version of Windows yet. Windows Backup makes moving to a new Windows 11 PC easier than ever. With Windows Backup, transitioning most files, apps and settings from one PC to another, is seamless so everything is right where you left it, exactly how you like it.

These experiences, including Copilot in Windows and more will start to become available on Sept. 26 as part of our latest update to Windows 11, version 22H2.

Bing and Edge are redefining how we interact with the web

Today, we’re announcing new features in Bing and Edge to supercharge your day powered by the latest models delivering the most advanced capabilities for AI available. You can use Bing Chat today with Microsoft Edge or at bing.com/chat. Features will begin to roll out soon.

Personalized answers. Now, your chat history can inform your results. For example, if you’ve used Bing to track your favorite soccer team, next time you’re planning a trip it can proactively tell you if the team is playing in your destination city. If you prefer responses that don’t use your chat history, you can turn this feature off in Bing settings.

Now, your chat history can inform your results. For example, if you’ve used Bing to track your favorite soccer team, next time you’re planning a trip it can proactively tell you if the team is playing in your destination city. If you prefer responses that don’t use your chat history, you can turn this feature off in Bing settings. Copilot in Microsoft Shopping. From Bing or Edge, you can now more quickly find what you’re shopping for online. When you ask for information on an item, Bing will ask additional questions to learn more, then use that information to provide more tailored recommendations. And you can trust you’re getting the best price – in fact, in the last 12 months, shoppers have been offered more than $4 billion in savings on Microsoft Edge. Soon, you’ll also be able to use a photo or saved image as the starting point for shopping.

DALL.E 3 model from OpenAI in Bing Image Creator . DALL.E 3 delivers a huge leap forward with more beautiful creations and better renderings for details like fingers and eyes. It also has a better understanding of what you’re asking for, which results in delivering more accurate images. We’re also integrating Microsoft Designer directly into Bing to make editing your creations even easier.

. DALL.E 3 delivers a huge leap forward with more beautiful creations and better renderings for details like fingers and eyes. It also has a better understanding of what you’re asking for, which results in delivering more accurate images. We’re also integrating Microsoft Designer directly into Bing to make editing your creations even easier. Content Credentials . As we continue to take a responsible approach to generative AI, we’re adding new Content Credentials which uses cryptographic methods to add an invisible digital watermark to all AI-generated images in Bing – including time and date it was originally created. We will also bring support for Content Credentials to Paint and Microsoft Designer.

. As we continue to take a responsible approach to generative AI, we’re adding new Content Credentials which uses cryptographic methods to add an invisible digital watermark to all AI-generated images in Bing – including time and date it was originally created. We will also bring support for Content Credentials to Paint and Microsoft Designer. Bing Chat Enterprise Updates. Since its introduction just two months ago, more than 160 million Microsoft 365 users now have access to Bing Chat Enterprise at no additional cost and the response has been incredible. Today we’re announcing that Bing Chat Enterprise is now available in the Microsoft Edge mobile app. We’re also bringing support for multimodal visual search and Image Creator to Bing Chat Enterprise. Boost your creativity at work with the ability to find information using images and creating them.

YouTube Video Click here to load media

Transforming work with Microsoft 365 Copilot, Bing Chat Enterprise and Windows

In March, we showed you what Microsoft 365 Copilot can do in the apps millions of people use every day across work and life – Word, Excel, PowerPoint, Outlook and Teams – using just your own words. After months of learning alongside customers like Visa, General Motors, KPMG and Lumen Technologies, we’re excited to share that Microsoft 365 Copilot will be generally available for enterprise customers on Nov. 1.

YouTube Video Click here to load media

Today, we’re also introducing a new, hero experience in Microsoft 365 Copilot: Microsoft 365 Chat. You saw a glimpse of Microsoft 365 Chat in March, then called Business Chat — but rapid advancements over the last few months have taken it to a whole new level. Microsoft 365 Chat combs across your entire universe of data at work, including emails, meetings, chats, documents and more, plus the web. Like an assistant, it has a deep understanding of you, your job, your priorities and your organization. It goes far beyond simple questions and answers to give you a head start on some of your most complex or tedious tasks — whether that’s writing a strategy document, booking a business trip, or catching up on emails.

Over the past few years, the pace and volume of work have only increased. On a given workday, our heaviest users search for what they need 18 times, receive over 250 Outlook emails and send or read nearly 150 Teams chats.[1] Teams users globally are in three times more meetings each week than they were in 2020.[2] And on Windows, some people use 11 apps in a single day to get work done. [3] Microsoft 365 Chat tames the complexity, eliminates the drudgery and helps you reclaim time at work. Preview customers can access it today on Microsoft365.com, Teams, or in Bing when signed in with their work account. In the future you’ll be able to access it wherever you see the Copilot icon when signed in with your work account.

To empower you at work, we’re also introducing new capabilities for Copilot in Outlook, Word, Excel, Loop, OneNote and OneDrive. Bing Chat Enterprise —the first entry point into generative AI for many companies — is getting a few upgrades. And as part of our big Windows 11 update, Windows 365 Switch and Windows 365 Boot will be generally available making it even easier to access your Windows Cloud PC. This will help employees achieve more, while making it easier for IT to deploy, manage and secure. Check out the Microsoft 365 blog to learn more about how Microsoft 365, Bing Chat Enterprise and Windows are transforming the way we work.

Unleashing personal productivity and creativity with Designer and Copilot in Microsoft 365

Designer , the newest addition to our family of Microsoft 365 consumer apps, helps you quickly create stunning visuals, social media posts, invitations, and more using cutting-edge AI. Today, we’re showing some powerful new features, many of which will be powered by OpenAI’s Dall.E 3. Generative expand uses AI to extend your image beyond its borders, generative fill adds a new object or background, and generative erase can remove unwanted objects.[4] Dall.E 3 will also soon power the image generation experience in Designer, making it easy to add original, higher quality images to your design in seconds.

YouTube Video Click here to load media

We’re also integrating Designer into Microsoft 365 Copilot for consumers — starting with Word. Designer uses the context of your document to propose visuals to choose from; you can make it more personal by uploading your own photos too. And within moments, you can transform a text-heavy document with custom graphics. We’re starting to test Microsoft 365 Copilot with a small group of Microsoft 365 consumer subscribers and look forward to expanding the preview to more people over time. Seventy percent of creators tell us one of the most difficult parts of the creation process is just getting started.[5] With creative tools like Designer, plus Bing Image Creator, Clipchamp and Paint, you can now have an immediate visual draft of almost anything — with a few simple prompts.

Introducing new Surface devices available for pre-order beginning today for people and businesses

There is no better stage to bring to life all of the incredible AI experiences from across Microsoft than our new Surface devices. Surface is at the forefront of device performance and processor technology. We have been investing in silicon advancements to augment this next wave of AI innovation, unlocking experiences like Windows Studio Effects in Surface Pro 9 with 5G and continuing to increase performance to run the latest AI models with powerful devices like the new Surface Laptop Studio 2.

YouTube Video Click here to load media

The new Surface Laptop Studio 2 is the most powerful Surface we’ve ever built. Turbocharged with the latest Intel® Core processors and cutting-edge NVIDIA® Studio tools for creators-with up to 2x more graphics performance than MacBook Pro M2 Max, [6] Surface Laptop Studio brings together the versatility to create and the power to perform — a stunning 14.4″ PixelSense Flow touchscreen display and flexible design with three unique postures. And with new customizations brought to the haptic touchpad to improve accessibility – we’re proud to call it the most inclusive touchpad on any laptop today.

YouTube Video Click here to load media

The new Surface Laptop Go 3 will turn heads with its balance of style and performance. It’s our lightest and most portable Surface Laptop, with a touchscreen display, and packed with premium features like an incredible typing experience and a Fingerprint Power Button, and it comes in four stylish colors. With Intel® Core i5 performance, all-day battery life, and robust RAM and storage options, it’s the perfect everyday laptop and stage for the latest AI tools from Microsoft.

Surface Go 4 for Business is our most portable Surface 2-in-1. This fall, the new Surface Go will be available exclusively for organizations to meet the growing needs of frontline workers and educators. We can’t wait to see how it will help businesses modernize and make their users more productive.

is our most portable Surface 2-in-1. This fall, the new Surface Go will be available exclusively for organizations to meet the growing needs of frontline workers and educators. We can’t wait to see how it will help businesses modernize and make their users more productive. Surface Hub 3 is the premier collaboration device built for hybrid work, designed end-to-end by Microsoft. The Microsoft Teams Rooms on Windows experience is familiar and intuitive on a brilliant 50” or 85” screen. The 50” Surface Hub 3 brings entirely new ways to co-create with Portrait, Smart Rotation and Smart AV. AI-enhanced collaboration tools – like Cloud IntelliFrame and Copilot in Whiteboard – shine on Surface Hub 3.

3D printable Adaptive Pen Grips for Surface Pen have been added to our lineup of adaptive accessories enabling more people to engage in digital inking and creation than before. They are available for purchase through Shapeways or as downloadable plans for 3D printing. To hear more about how we’re taking steps to close the disability divide, check out our video.

To pre-order one of our incredible new Surface devices, visit Microsoft.com, Bestbuy.com, and our Surface for Business page and blog to learn more about all of today’s new products.

The new era of AI with Copilot from Microsoft is here – and it’s ready for you

We believe that Microsoft is the place where powerful, useful AI experiences come together – simply, securely and responsibly – into the products you use most. Today, we showed you how we are not only increasing the usefulness of these experiences, but we are expanding them​. From Windows 11 as the destination for the best AI experiences to empower people using it at work, school and home​. To Microsoft 365, the most trusted productivity suite on the planet​. To Bing and Edge, the most innovative search engine and browser available​. All of it coming together on Windows 11 PCs like Surface​. And with Copilot helping you get things done, helping you create and connect to people you care about or the world around you​. We can’t wait to see what you can do with these experiences.

Learn more on the Microsoft 365 blog and the Security blog. And for all the blogs, videos and assets related to today’s announcements, please visit our microsite.

[1] Data represents top 20% of users by volume of searches across M365 services, emails received, and sent and read chats in Teams, respectively.

[2] Microsoft annual Work Trend Index 2023- Work Trend Index | Will AI Fix Work? (microsoft.com)

[3] Data reflects the top 20% Windows devices by app volume per day.

[4] Generative erase in Microsoft Designer is generally available to try today, with generative expand and fill coming soon.

[5] Survey of 941 creators commissioned by Microsoft in June 2022.

[6] Tested by Microsoft in September 2023 using CineBench 2024 GPU benchmark comparing Surface Laptop Studio 2 with RTX 2000 Ada Generation to MacBook Pro14” with M2 Max 19 12 core / 30 core configuration.

Tags: AI, Bing, Designer, Microsoft 365, Microsoft Copilot, Microsoft Edge, Surface, Windows 11"
Microsoft_News,https://news.microsoft.com/september-2023-event/,,"Announcing Microsoft Copilot, your everyday AI companion","Today we take the next step to unify your favorite AI capabilities into a single experience we call Microsoft Copilot, your everyday AI companion. Copilot will uniquely incorporate the context and intelligence of the web, your work data and what you are doing in the moment on your PC to provide better assistance – with your privacy and security at the forefront.

Read more"
Microsoft_News,https://www.microsoft.com/en-us/worklab/podcast/futurist-amy-webb-on-the-most-plausible-outcomes-for-ai-and-work,,Futurist Amy Webb on the Plausible Outcomes for AI and Work,"MOLLY WOOD: That was Amy Webb. She’s a quantitative futurist and CEO of the Future Today Institute. And she looks at what business leaders can do today to prepare for a future, or present, with AI. There is of course no way to predict the future, yet, but Amy and her team are doing their best. Together, they use data to find emerging trends about the ways that AI will impact humanity. In today’s episode, Amy shares her most plausible outcomes for what the future looks like with AI, and what business leaders can do today to make sure their organizations are set up for success. And here’s my conversation with Amy.

[Music]

MOLLY WOOD: Set the stage for people who may not be familiar with your work. You are a futurist, what does that mean, in the context of business specifically?

AMY WEBB: So, futurists don’t actually predict the future. That’s not our job. We are really people who work in strategy. So we take signals in the present that help us identify trends—that describes what we can know. Uncertainties are areas over which no one entity has total control. So those are the things that we cannot know. So we combine the stuff that we know, along with the stuff that we can’t know, that’s going to be variable. That helps us create what-if scenarios. The scenarios aren’t the end of the work—they tend to be narrative, and sometimes they veer into something that feels or sounds like sci-fi, but they really are strategic. The whole point of a scenario is, if it’s done well, you’re extrapolating out but you still have enough data that you can help anybody see alternative futures. And what that allows a business to do is to work back to the present and make better decisions. So this is really strategy work. And I would argue, the fundamentals of foresight should be required of every leader, just as the fundamentals of strategy at this point are required of every leader.

MOLLY WOOD: We are taking it almost as a given now that AI is the future. And so I guess I want to start by saying, do you agree with that? And how much is it informing your work right now?

AMY WEBB: So the answer is, I do not agree. And that’s because AI is the present. This is part of the problem that I see organizations and leaders really struggling with. AI still feels like a frontier technology. AI has been with us for, you know, dozens of years. If you use a mobile phone, you are using AI. Molly, you and I having this conversation in two separate cities, using a streaming service, like, we are using AI. I don’t want to sound glib, but I do think it’s worth noting that some of the technologies that we’re hearing about in AI sound very magical, but they’re not magic. They’ve been in some form of development now for a very long time. Yes, they will be a part of us going forward, which is all the more reason why it’s very important right now to get very clear on what this technology is, what it isn’t, and realistically why it matters.

MOLLY WOOD: So what do you think, given that at least socially, conversationally, and probably technologically, we are at a bit of a tipping point… what do you think the next one to five years entail in terms of answering those questions—what it is and what it isn’t, especially?

AMY WEBB: Yeah, so the sort of moment that AI is having right now falls within the generative category, and specifically as it relates to language. What most people are familiar with right now is ChatGPT. The GPT stands for generative pre-trained transformer. And these systems need lots of data. And you have to train models on those data, basically telling them like, you know, if a system sees a picture of an elbow, like yes, this is an elbow versus no, that is not a knee, right, things that might look otherwise similar. This is the place that we’re at right now. The much more interesting aspect of this is, how that technology becomes an enabler of other technologies. So for example, imagine a robot arm, and imagine an array of packages and boxes and toys, just like a giant cluttered mess. Imagine being able to tell that robot arm, pick out the prehistoric animal—without having to specify “little toy plastic dinosaur,” but describing it more naturally using natural language. And that robot arm successfully picking the right thing. Previously, a researcher to train a robot arm would have had to painstakingly just over and over and over again, specifically measure, you know, that the exact size of that dinosaur, the placement and sort of tweak over and over and over again. The difference now is we’re teaching the robot arm to learn through repetition. And that’s why today’s chat-based systems are interesting. But what they enable going forward is the thing that I would keep my eye on.

MOLLY WOOD: I know you said you don’t predict the future. And yet, I do want to dig into the optimistic scenarios that you think are possible, and how we can get there. Because there is some magic. That’s the magic.

AMY WEBB: Yeah, totally. So maybe let me go backwards. I was meeting with some of our clients in the healthcare space. And I think those in healthcare are looking at this new technology with both excitement and concern. Excitement because it does promise to automate some routine tasks that are just enormous cost centers. But concern because some of the folks who have maybe spent, you know, a decade in school learning how to do something specific, like oncology, are concerned about what that means for the future of their jobs. So I took a publicly available P&L for a hospital that I found online, I hit, you know, copy, and I pasted the text into ChatGPT. The P&L for this hospital was a disaster, the hospital was bleeding money. They were clearly in crisis mode. And I was imagining the executive leaders of that hospital having crisis meetings trying to figure out, how do they shore up their operating budget. So I dumped the data into ChatGPT and asked, using a prompt, how can I reduce operating budget by—I think I just picked a random number—8 percent year over year without reducing headcount, which would be the typical place that a company or a hospital would usually look. And within 27 seconds, it spit out a very detailed analysis of many other ways to trim costs, without having to cut back on essential services, or reducing headcount. Now, here’s the thing. There’s nothing in there that was surprising. But what it did do was, the 80 percent of the work that would have been a cost center for that team, they would have had to spend a ton of time and energy and effort and resources to just say, yes, these are the obvious things. So what’s kind of amazing about this, I think going forward, is, that system or one like it, can get that stuff out of the way and allow that executive team to focus 80 percent of their time instead on creative alternatives, which is what, frankly, they should be doing anyways. So to me, that’s emblematic of what we might see going forward. But what’s interesting here is that if you ask anybody in that field, what do you think the future of AI is? They immediately think about reducing headcount. I don’t think that’s actually the case.

MOLLY WOOD: It’s such an interesting way to sort of shift that narrative to say, what if you actually use this technology to specifically choose to save jobs?

AMY WEBB: Some of the big reports that have come out, with detailed numbers about how AI will generate all of this economic growth while at the same time eliminating, you know, hundreds of thousands or millions of jobs. I think those numbers are wrong. The forecasts that we put together show something very different. And listen, this is not, I’m not being a sort of cheerleader for AI. It’s not that at all. I’m a pragmatist. There are technical reasons why a lot of the jobs that are being forecast to go away, it’s improbable that that’s the future, which means that leaders are probably looking at their future the wrong way. Most of the executive leadership that I talked to, regardless of industry, are looking at AI as a way of managing bottom line growth, which is really a story about efficiencies, getting more productivity out. The better way to look at this is, how does AI increase top line? Meaning, where are your new work streams that didn’t exist before? How can you do things that you were not able to do before because you didn’t have time? Again, I think that’s one of the huge benefits of this that nobody’s talking about. Some of these tools, what they do is they generate time. And that’s the number one thing that I hear from every executive that they just do not have. And that becomes an excuse for why they don’t innovate.

MOLLY WOOD: Yes, you just go back to the same old well over and over and over, and unfortunately that well is often headcount. But on that point, your book, The Big Nine, is about the world’s most important companies when it comes to the future of AI. Microsoft is one of them. And as you said, you’re a pragmatist. There are lots of scenarios, not all of which are good. So what is your advice to these companies?

AMY WEBB: AI is a technology. It’s an umbrella full of technologies. It’s kind of a strange metaphor, since the technologies would fall down from the umbrella, but I think you understand what I mean—the bucket full of technologies [Laughs]. And I think if leaders of organizations have the right understanding and background, and they’re not making decisions based on fear, then I think that growth is highly plausible. So, I see a lot of upside there. What we’re also hearing about, which is true, is how this technology creates geopolitical challenges and potentially further divides society because of misinformation or any other number of things. What I will say is that some of the companies in the AI space—Microsoft, I think, is a leader here—have really been working hard to think through plausible futures, and ways in which those serious challenges are abated. Maybe we head them off in advance. But I don’t see every company doing that.

MOLLY WOOD: So it sounds like you’re saying, let’s hone in on the business leader, kind of, tactical advice. Specifically, it’s, do not stick your head in the sand about this, right? There is a lot of hype. And it is your job to not ignore it and not buy the hype, right, to try to chart that middle path.

AMY WEBB: Yeah, and you and I are like, hey, just, like, be reasonable, everybody. [Laughs] I mean, that is really, really, really hard to do right now. This is the most complex operating environment I’ve seen since I started doing this work 20 years ago. You need to have lots of partners to make all of this work. We had a client who was very, very interested in generative AI, and they wanted to get to strategy, they wanted to go three to five years in the future. They wanted a plan, they wanted the strategic direction and everything else. And we asked them a very basic question: when was the last time you did a data audit? And the answer was, we don’t know. And we said, okay, no problem, who is the person in charge of doing the data audit in your organization? They don’t know. And we said, okay, whatever, you’re a huge giant global corporation, you’re C-suite people… we’ll figure it out for you. Who do we call? And the bottom line was, they want a future where they’re going to reap the benefits of AI. They don’t have their internal infrastructure shored up yet. And you can’t leap to an AI future without having some of that internal stuff taken care of first, which again, you know, fear and FOMO are very powerful forces. And it’s—this is going to be a tough road ahead—to put those aside, set your eye on where you think AI helps your business grow, you know, and then do a gap analysis. And then you’re just, it’s strategy and execution, which every leader knows how to do.

MOLLY WOOD: I want to ask you about human collaboration. You know, we’re coming out of this very weird time. And now we have this idea that we’re going to interact with AI for information. How are you thinking about the future of human collaboration?

AMY WEBB: So if I think about the times, personally, that I’ve been the most excited, invigorated, working on projects, it’s when the stuff that just takes up time where you feel like you’re trudging through mud, like, that’s out of the way. And then you have the foundation that you need to really do the true collaborative, exciting work. I think there isn’t as much collaboration, because people just don’t have time anymore. Our lives become really complicated. So for me, personally, a future in which I can use a trusted AI resource—and trust here is very big, that’s a big deal—but if I could use a trusted resource to get the, you know, even half of the stuff that I have to get through on a daily basis as a CEO of my company, if I could just get that stuff out of the way… and again, this is like decision making. Can I just get a summary of the thing I have to make a decision about? Can I trust that summary, you know, without having to go through and read pages or multiple spreadsheets or whatever it might be, that opens the door for me then to work with my senior leaders and collaborate on the next things in our pipeline or other things that we want to do. So I think this unlocks that opportunity for collaboration. It also means, like, maybe we wade into areas that we just haven’t been before. I think when people talk about AI and creativity, they immediately think of visual effects or music or art. I think there’s a huge amount of untapped business creativity potential that we’re going to see unlocked sometime in the next few years.

MOLLY WOOD: Okay, so as leaders start to think about this, what are the kinds of futurist thinking frameworks that they should put this planning into? Because I love the idea of saying to people, think about what could be unlocked here instead of what can be lost. It’s the abundance mindset.

AMY WEBB: So we have a framework that we always recommend to everybody—it’s open source, it’s available online, at just about anywhere. It’s called a time cone. So, in a lot of organizations, when thinking about the future as happening, companies tend to use a line, right, and basically a line tends to mark whatever, two, three years in the future. And the issue with a line is—a timeline—it doesn’t account for uncertainty. And although it may feel like the future has been set in stone, given where we are with AI, the truth is, there’s an enormous amount of uncertainty, just huge amounts of uncertainty at how a lot of this will pan out. For that reason, a cone is a better shape. So in the very present—this would be on the, sort of, you’re thinking about this, on the left hand side where the vector is, that’s today—the further out in time you go, the more that that cone opens up. And in the present, we have the data that we can observe and the perspectives that we have. So we can make decisions that are more tactical in nature. The further out in time you go, you have less certainty, you have more variables, therefore the cone gets very wide. It doesn’t mean that we don’t make decisions, you just have to make different types of decisions. So that cone, imagine, has four segments—the farthest out, which is the farthest out in time, that represents transformation. So imagine 10 years in the future, and AI has transformed your business, your work stream, your industry, the world, right, whatever it might be, what does that transformation look like? And given what you know to be true today, what decisions would you need to make in order to win, to sort of play and win in that future? The second segment in from transformation is long-term strategy. So again, if this is the longer term future, then what are the longer term strategic decisions that would have to be made? And that tends to have to do with organizational changes, investments, M&A, things like that. The next one in is old-school strategy. That’s your next two years. Therefore, what do we need to do? And then the present day one is tactics. What is nice about this time cone is that it forces your team to make decisions in sort of four time horizons, related to anything, but in this case, AI. It also asks you to think very near-term and long-term at the same time. That’s the number one tool that I would recommend.

MOLLY WOOD: Okay, listener, pause here if you need to and write this down, because even if it’s not planning for AI, useful, right? And now, back to Amy and what else can create AI abundance in your organization.

AMY WEBB: The other one is simple. It’s called ADM. We use this all the time. And if you’re a fan of Adam Driver the actor, I guess this is a good way to remember it. Adam is not spelled like a-d-a-m though. It’s spelled ADM. So act, decide, monitor. Every time you hear something new about AI, make sure that the source is correct and things aren’t being overblown. Then put it into a category: is this something we need to act on today? And, truly, without some type of action today, we get disrupted, we lose market value, we have a communications problem, whatever it might be. The center one is decide. This is somewhat near-term, it rises to the level of, we’re going to have to make a decision, we have to position ourselves. The last category is monitor, which is, this caught my attention, so it’s important enough, but we don’t need to do anything with it right now. But we still want to keep paying attention. The act of categorizing, when it comes to something that’s very emotional at the moment, like AI, gives you a sense that there’s forward momentum. And it organizes yourself and your team to take action when the time is right.

MOLLY WOOD: Right. I love it. So to be intentional, be thoughtful, apply frameworks to keep you from doing anything too quickly. Smart. All right. Final question for you, Amy. As you mentioned earlier, AI has the ability to save us a lot of time. What have you been doing with your extra time?

AMY WEBB: So, this is a true story. I’ve automated some of my work. And I’m a competitive cyclist. I have managed to eke out, you know, between 15 minutes and maybe an hour a day. And so now I no longer have an excuse to not do my core workout that I wish—I conveniently said I didn’t have enough time for before. And now there’s no excuse. So, thanks to AI, I have to do more core workout.

MOLLY WOOD: So what you’re saying is you’re a futurist and you run your own company and you are also a competitive cyclist.

AMY WEBB: But I’m bad on the hills. So there’s that. I’m a sprinter.

MOLLY WOOD: Amy Webb is a quantitative futurist and the CEO of the Future Today Institute. Thanks so much for being our guide today.

AMY WEBB: Thank you.

MOLLY WOOD: And that’s it for this episode of WorkLab, the podcast from Microsoft. Please subscribe and check back for the next episode, where I’ll be talking to Sam Schillace, corporate vice president and deputy chief technology officer at Microsoft, about AI consumer product culture and the next phase of productivity. If you’ve got a question or a comment, drop us an email at worklab@microsoft.com. And check out Microsoft’s Work Trend Indexes and the WorkLab digital publication, where you’ll find all of our episodes along with thoughtful stories that explore how business leaders are thriving in today’s digital world. You can find all of it at microsoft.com/worklab. As for this podcast, please rate us, review, and follow us wherever you listen. It helps us out a ton. The WorkLab podcast is a place for experts to share their insights and opinions. As students of the future of work, Microsoft values inputs from a diverse set of voices. That said, the opinions and findings of our guests are their own, and they may not necessarily reflect Microsoft’s own research or positions. WorkLab is produced by Microsoft with Godfrey Dadich Partners and Reasonable Volume. I’m your host, Molly Wood. Sharon Kallander and Matthew Duncan produce this podcast. Jessica Voelker is the WorkLab editor."
Microsoft_News,https://www.microsoft.com/en-us/industry/blog/financial-services/2023/09/19/the-era-of-generative-ai-driving-transformation-in-financial-services/,,The era of generative AI: Driving transformation in financial services,"We joined financial professionals at the Sibos 2023 conference on September 18 to 21, 2023 to discuss how we can tackle global challenges using the power of partnerships and technology. Today, I had a fireside chat with Dmitri Sedov, Global Group Head of Data Intelligence at the London Stock Exchange Group (LSEG). We shared how we are reshaping the future of global finance through our 10-year strategic partnership.

Financial markets are changing rapidly, creating new challenges and opportunities for all participants. For our customers, there is demand for the right data at the right time with reduced complexity and increased flexibility. LSEG’s comprehensive data and analytics and Microsoft’s trusted and secure global cloud platform and AI capabilities enable us to co-innovate solutions for the financial markets eco-system. These innovations will evolve how customers gain value from their data to unlock opportunities by combining LSEG’s data and content sources in Microsoft Fabric, integrated into the enterprise-wide data catalog and governance framework of Microsoft Purview.

Innovating to meet customer needs

Analytics and modeling are now critical to success as the increasing demand for diverse data fuels business decisions and drives the need for a simplified approach that meets business needs. In addition, as regulations become more quantitative, it has created substantial challenges in terms of lost time and capital for customers who don’t have the necessary data and analytics infrastructure in place.

Historically, Microsoft provided our horizontal cloud platforms to our customers such as solutions for developers—Microsoft Azure, Microsoft 365, and Microsoft Teams, notably among them—while LSEG separately delivered financial market infrastructure, data, and analytics. The burden largely fell on our mutual customers to map those building blocks to their business problems and to bring these assets together in a coherent way. That forced our customers to bear the cost and complexity of this integration.

With our partnership, we seek to help our customers climb the value chain by bringing these complementary assets together. We will transform financial services workflows to help finance and investment professionals improve decisions, communications, and productivity while maintaining regulatory compliance. Together we will offer customers a simpler and more connected solution with:

Cloud-based data architecture that consolidates LSEG datasets on one, flexible infrastructure that is simple, responsive, and efficient, and built to meet the data needs of the enterprise.

Cloud analytics and modeling services built on Microsoft Azure Machine Learning.

A comprehensive security approach enabling preventative and detective controls to meet the security, privacy, and compliance needs of this regulated industry.

Customers will be able to use the combination of Microsoft Fabric powered by LSEG data, analytics, and data management capabilities to enhance their workflow and bring greater efficiency and productivity to their organizations. To bring that to life, you can see in this workflow illustration how LSEG and Microsoft’s collaboration will drive significant productivity by simplifying the whole process of finding, managing, and distributing massive content sets.

Speaking about enhancing productivity, we also discussed how the LSEG-Microsoft partnership will evolve the customer experience at-scale across global financial markets to deliver the most advanced, easily accessible financial data and insights through:

A single point of access to financial markets data that reduces time and cost for financial institutions to discover, integrate, manage, share, and derive insights from petabytes of financial and alternative data.

Intelligent analytics solutions that reduce the time and cost for creating, distributing, and running complex analytic models across APIs and through the Microsoft productivity suite.

An integrated financial services workspace that empowers customers to make informed decisions with confidence and greater speed through seamless workflows and increased productivity.

The uniqueness of this partnership is in LSEG’s data and analytics, coupled with the Microsoft cloud platform, data platform, and Microsoft 365 collaboration suite. In this way, we meet customers where they are, while creating vertical industry value. Unifying data with Microsoft Cloud for Financial Services can make data and analytics much easier to discover and use—whether that is finding pricing analytics in Excel, connecting with counterparties through Microsoft Teams, or using Microsoft 365 Copilot in Microsoft productivity apps to access LSEG financial markets data. Together, we will benefit customers by increasing productivity while offering greater efficiency, resilience, and scalability across all workflows.

Moving ahead with generative AI

The benefits of AI and machine learning have accelerated the rate of change in financial innovation enabling frictionless customer experiences, empowering employees to apply their creativity and talent rather than focusing on tedious work while enabling deeper insights to drive better decisions.

AI enables technology to understand and speak the language of industry. Generative AI will enable organizations to better take advantage of technology, collapsing data barriers and decoding the complex landscape of macroeconomics, markets, and regulations.

“Microsoft AI improves the way we work, and we are making AI tools a better fit for financial services. We are combining Microsoft’s dependable and scalable infrastructure with the breadth and depth of LSEG’s trusted high-quality data and IP safeguards. Together we are shaping a future where technology supercharges our customers’ workflows and insights reliably, effectively, and responsibly.“ —Dmitri Sedov, Global Group Head, LSEG Data Intelligence.

Microsoft responsible ai Read the latest

Microsoft AI tools are making work easier, and LSEG is making AI more valuable to financial services. AI is only as good as the quality of the data it consumes. LSEG brings a unique capability to demonstrate data trust with a breadth and depth of aggregated, cleaned, and codified financial markets data as well as extensive data management knowledge and understanding of what regulators and the world’s largest financial institutions need. These capabilities sit alongside Microsoft’s Responsible AI commitments, including our recently announced Copilot Copyright Commitment to protect our customers from copyright claims arising from their use of our copilots.

The benefit of AI for customers and clients will be in how quickly and easily they can access the right data to generate insights with AI that are both reliable and relevant to the task at hand.

Microsoft Fabric and the embedded generative AI capabilities in Fabric present another great transformation for financial services. Microsoft Fabric will be the cornerstone of LSEG’s Data Platform, and their financial markets intelligence will help enable the financial markets ecosystem to leverage generative AI and other capabilities. We will also use AI to address the data discoverability challenge itself by using AI models to better understand user preferences, predictively surfacing relevant data, and categorizing vast datasets into intuitive segments. All of LSEG’s data available through Microsoft Fabric will also be published in Microsoft Purview, enabling this data to be discovered in the enterprise data catalog and governed centrally alongside other proprietary and commercially acquired data sets.

LSEG’s quantitative and engineering talent and proven ability to provide the right data for the financial services community bring the credible expertise needed to ensure generative AI provides the optimal yet secure experience for our customers. There is a profound opportunity for our customers to unlock new value and we are excited to deliver this value together with LSEG.

Discover more"
Microsoft_News,https://news.microsoft.com/source/features/ai/ai-alberta-canada-wildfire-firefighting/,,Fighting Canada’s record wildfires with a combination of AI and intuition,"As a longtime wildfire manager in Alberta, Canada, Ed Trenchard is used to making tough decisions during volatile emergencies. But he has had to make many this year during the country’s worst wildfire season on record, with blazes forcing thousands of people to flee their homes and burning an unprecedented 17 million hectares (42 million acres), according to the Canadian Interagency Forest Fire Centre.

One of Trenchard’s main duties in Alberta is deciding where to position fire crews, helicopters and other resources the day before a wildfire is predicted to start. The task is like moving chess pieces in a high-stakes battle against an opponent who may be more aggressive than expected or not show up at all. He and his fellow duty officers make their decisions daily based on fire danger ratings, coverage requirements and intuition.

“From an emergency response perspective, we rely on duty officers to make a decision. Right or wrong, make a decision,” said Trenchard, a wildfire management specialist and a regional and provincial duty officer for Alberta Wildfire, the province’s forest firefighting agency. “It can be a lot of pressure on a person.”

But in 2022, Alberta Wildfire started using an AI-powered tool to help duty officers make decisions and use resources more strategically. Built by AltaML, a developer of AI solutions in Edmonton, Alberta, the tool leverages machine learning to analyze tens of thousands of data points to predict the next day’s likelihood of new fires by region.

For daily fire planning, Trenchard said duty officers have traditionally used a decades-old Canadian system that rates fire danger and occurrence, or the predicted risk and severity of wildfires based on weather, forest conditions and other environmental factors. They also incorporate intuition based on years of experience and their local knowledge, like how close a predicted fire is to homes or if it’s a holiday weekend busy with campfires."
Microsoft_News,https://news.microsoft.com/europe/features/assisted-by-ai-a-workforce-of-bees-tracks-pollution-and-boosts-biodiversity/,,"Assisted by AI, a workforce of bees tracks pollution and boosts biodiversity","When Karl Wenner looks at his farm on Upper Klamath Lake in the mountains of southern Oregon, he sees a landscape in transition.

He and his partners converted part of their fields of barley into wetlands along the shore of the lake to filter runoff and protect the quality of the water that eventually flows back into the Klamath River, which empties into the Pacific on California’s coast. The project is part of a larger effort to clean up the river, remove dams and bring back salmon.

At Lakeside Farms, that transformation is being guided by a surprising source of information: the pollen collected by tens of thousands of honeybees. A Belgian start-up called BeeOdiversity enlisted Wenner, who is also a beekeeper, to help in a survey in the Klamath River Basin. Each colony, with 50,000 bees, harvests pollen over an area of more than two square miles, collecting as many as 4 billion tiny samples in a year. The resulting data creates a clear, accurate picture of the plant life and pollution present in the environment.

“I didn’t know anything about what they were going to do,” Wenner says. “I thought well, that sounds cool, what the heck, I’ll try it. And then they started sending me the data, and it was like ‘Holy cow! This is powerful stuff.’”

The bees’ data revealed rare native plants that Wenner didn’t know were there, as well as invasive species that needed to be removed to create balance.

Karl Wenner by one of the new wetland areas at Lakeside Farms on Upper Klamath Lake in Oregon. Photo by Karl Wenner.

Farmers are among a growing number of beneficiaries of BeeOdiversity’s unique system of data collection. The company now has clients in 20 countries. In Europe, public water utilities and water bottling companies like Nestlé are using the system to monitor and protect sources of mineral water. Industrial clients use the bees to check compliance with regulations and monitor the environment to preserve soils and biodiversity.

With expertise and tools shared by Microsoft and Accenture, the company has developed what it calls BeeOimpact, a system that is using machine learning to extrapolate data over much larger areas. This assesses the impact of an activity on local biodiversity. BeeOdiversity now has its first clients for this platform. In the Azure cloud, it uses machine learning in Azure Data Factory to identify areas where pesticides may be in high concentrations. This brings the benefits of bee-gathered data to much broader areas at a much lower cost.

Innovative technology and the genius of nature are working together to create a data set found nowhere else.

Saving the bees

BeeOdiversity cofounder Bach Kim Nguyen wrote his Ph.D. dissertation on the reasons behind bee colony collapses, a global problem. The causes include the use of pesticides, habitat loss and increased vulnerability to pests and diseases. When he finished his studies, Nguyen made saving bees his mission in life.

He says he’s always been passionate about these social insects and describes a bee colony as a super organism. Each of the 50,000 bees in a colony has a role, and all work together to support the hive. “They’re a good model for us,” he says.

Bees on a hive frame at the BeeOdiversity lab and offices near Nivelles, Belgium. The queen is in the center with a bright dot on her torso. Photo by Chris Welsch for Microsoft.

Bees are also essential to us. Of the 100 crop species that provide 90% of food worldwide, 71 are pollinated by bees, according to the Food and Agriculture Organization of the United Nations.

Nguyen invented a system that knocks a tiny bit of pollen off the worker bees as they return to the hive – enough for research, but not so much as to rob the bees of nutrition. Using laboratory analysis and AI models to establish some correlations between results, BeeOdiversity can identify more than 500 pesticides and heavy metals, as well as the plants in the area.

Once the data is analyzed, BeeOdiversity scientists make recommendations to clients and stakeholders to reduce pesticide use and improve the overall environment. “In that way we are working on factors like biodiversity and pollution,” Nguyen says. “And in the end, we save the bees.”

Since its founding in 2012, BeeOdiversity has won numerous awards, including an Ashoka fellowship, research funding from the European Union and being included in Microsoft’s Share AI and Entrepreneurship for Positive Impact Accelerator programs. BeeOdiversity was also selected for the AB InBev 100+ Accelerator program.

As part of that program, the beverage giant AB InBev and BeeOdiversity are collaborating on a pilot project in and near the AB InBev hops-production area near George, on South Africa’s southern coast.

Alyssa Jooste, Africa sustainability manager for AB InBev, says it’s the only place on the continent where hops for beer can be grown. Invasive plants, like pine trees, black wattle and eucalyptus, use as much as 60% more water than native species in an area where it is scarce, she says. For more than 10 years, AB InBev has been working with the World Wildlife Fund South Africa to clear areas of those species to protect precious water sources and restore native species.

As part of its pilot project with AB InBev, BeeOdiversity is using data gathered by six bee colonies to gauge the impact of the removal of invasive species as well as the presence of pesticides in the environment. The bees collect pollen at farms and nature reserves nearby. BeeOdiversity is also using DNA analysis to evaluate the soil in the area.

“The information from the soil sampling as well as the pollen and biodiversity analysis will infer how successful our clearing initiatives have been in restoring biodiversity and soil health,” Jooste says. “It will form a baseline on which we can make decisions going forward.”"
Microsoft_News,https://news.microsoft.com/source/features/digital-transformation/ai-denver-choice-market-convenience-store-data/,,"How data, AI and a breakfast burrito helped Denver’s Choice Market chart a future course","For Choice Market, valuable data that will help inform its next generation of convenience stores was wrapped up in a seemingly unlikely place — a breakfast burrito.

The Denver-based company’s burritos, made from a proprietary recipe that includes house green chili and comes in a vegan version, have long been one of its best-selling items. But when Choice Market implemented Microsoft Smart Store Analytics, combined with AiFi’s camera-only technology that enables autonomous shopping, it made a startling discovery that changed its approach to the popular product.

The app’s heat map showed that customers were heading for the burrito area in the afternoon — and walking away empty-handed. The company responded by ramping up burrito production across its stores and moving the burritos up closer to eye level, increasing sales of the breakfast-turned-lunch item by half almost overnight.

Choice Market is using data to better understand customer behavior and is developing a chatbot to help customers as they shop.

“We figured people would not want a breakfast burrito in the afternoon or evening, but we looked at the data and we realized that we were wrong,” says Amanda Dentici, chief operating officer for Choice Market. “And we’re happy to be wrong in that situation.”

The example underscores the importance of data for understanding customer behavior as Choice Market moves further into the autonomous retail market. Its first store, an urban market that opened in 2017, has a full kitchen turning out made-to-order bowls, salads and other items. That was followed by a combined convenience store and fuel center with charging for electric vehicles, a second urban market and three minimarts, all in Denver, and additional stores are opening soon.

Ranging from 50 to 500 square feet, the minimarts are fully autonomous, meaning no cashiers, lines or checkouts. Using Choice Market’s app, customers scan a QR code when they enter the store, and AiFi’s system — which uses sensors and computer vision, a type of AI — identifies what they pluck from store shelves, then the app delivers a receipt within minutes of a purchase. Customers can also order groceries and fresh meals for pick-up through the app or have items delivered by electric vehicle.

Choice Market Chief Operating Officer Amanda Dentici, left, confers with CEO and founder Mike Fogarty.

A frictionless shopping experience

When Choice Market CEO and founder Mike Fogarty launched the company, the autonomous retail industry was still in its infancy. Over the next few years, Fogarty says, he learned that providing a simple, seamless shopping experience that eliminates potential obstacles to making a purchase — the industry term is “frictionless” — was important for customer adoption. Additional challenges over the past few years, including labor shortages, inflation and soaring rates of retail theft, also influenced Choice Market’s move toward autonomous stores.

“There are all these headwinds facing our industry, so part of this is just the practical need to innovate and to automate where possible so that you can continue to grow and be a sustainable and profitable company,” Fogarty says.

“The other part is very much customer-centric. What’s more convenient than scanning your QR code once, grabbing your items and leaving, and then getting your receipt within five minutes or so? We’re essentially selling customers their time back.”

Click here to load media

Microsoft launched Smart Store Analytics in January 2023 in partnership with California-based AiFi. The app uses data from AiFi’s AI-powered platform to provide insights that enable retailers to make better decisions about merchandising, inventory and store layout. It does not use biometrics or facial recognition, only creating a fully anonymous stick-figure virtual avatar of customers as they enter a store.

Choice Market installed Smart Store Analytics a few months after its release and was soon getting valuable insights. Beyond the burrito scenario, the company discovered that customers were buying items together that traditionally aren’t near each other in stores, such as energy drinks and refrigerated protein bars, and that they most frequently chose a certain flavor of chips — Doritos Nacho Cheese — to accompany a sandwich.

After moving those items close to each other, Choice Market saw an immediate uptick in sales. Average shopping times dropped from four to two minutes, and the company hopes to get that down to about 90 seconds.

Merchandising changes at Choice Market based on insights from Microsoft Smart Store Analytics have reduced average shopping times across stores.

The insights provided by Smart Store Analytics, Fogarty says, are “exactly what we need and want as a retailer. And in fact, for pretty much every retailer, it’s a true unlock. It’s digitizing what was only available on online channels and e-commerce and bringing that into the real world, giving you the ability to understand who’s coming into your store and why they’re not shopping certain fixtures and what they’re putting back on the shelf versus buying.

“That was never available, but now it is, and that data is indescribable.”

Convenience stores that appeal to women

Fogarty founded Choice Market after seeing a need for a store offering higher-quality, healthier foods than the typical convenience store and that didn’t require customers to navigate through large parking lots and sprawling supermarkets to access those items.

Choice Market CEO and founder Mike Fogarty felt the convenience store industry was overlooking an important demographic — millennial and Gen Z women.

He had spent time in Barcelona and appreciated being able to go to a neighborhood market and get what he needed every few days. The U.S. convenience store market, Fogarty felt, hadn’t evolved much over the past half-century; legacy convenience stores stocked largely the same products they always had, in the same layout, and weren’t changing with the times as consumers shifted to smoking less, driving fewer miles and choosing healthier foods.

In particular, Fogarty felt the industry was overlooking an important demographic — health-conscious, urban-dwelling millennial and Gen Z women who are more likely to reach for a smoothie than a Slurpee or a veggie burger instead of a hot dog.

“There’s a lot of data out there that suggests that traditional convenience stores really struggle with in-store purchases from female demographics,” he says. “That was the core thesis of the business — that that customer still wants convenience and quick, fresh, healthy food, but there’s not a retailer out there providing those options to them or that choice.”

Choice Market offers a mix of healthy foods, products from local vendors and made-to-order meals.

Having those options appeals to Denver resident Norma Quinones, who regularly pops into Choice Market to grab a snack of turkey sticks and her favorite beverage, a sparkling tea with hops, or sometimes a bowl with salmon and veggies. Shopping at Choice Market saves her the “stress tax” involved with bigger stores, she says, adding that even the self-checkout at another store near her home can take a frustrating amount of time.

“I just want to be in and out, especially if I just want to grab a snack,” says Quinones, who’s in her 30s and owns a juice company. “I don’t want to be in line for eight minutes to do it.”

Quinones also likes being able to get a quick, made-to-order meal that she says is typically better than other stores’ offerings.

“It has more of that restaurant experience of it being fresher and tastier than something you get at a hot bar that might be crusty around the edges,” she says. “I’ve had some great days at the hot bar, and I’ve had like a crummy $17 crusty-edge dinner that made me even sadder than when I was hungry.”

The company will soon open additional stores in Denver as it moves further into the autonomous retail market.

Choice Market has been as intentional about its stores’ interiors as what’s on their shelves. The modern, crisp black-and-white spaces are accentuated with art and pops of color, and thoughtful details such as plants and music help create a welcoming environment.

Dentici went into a Choice Market a few years ago while visiting family in Denver and was so impressed that she sent Fogarty a message on LinkedIn. At the time, she was the CEO of a small gourmet food and wine retail chain on the East Coast. Fogarty soon hired her as Choice Market’s COO.

“It really resonated with me when I walked in for the first time,” Dentici says. “Not only the merchandising and product selection, the fresh food offering and the quality, but also the music was warm and inviting and the bathrooms were really clean. The people working in the store were able to articulate the technology and were really friendly. I was so excited about the experience that I felt the need to reach out.”

Providing a simple, seamless shopping experience is key to Choice Market’s strategy.

Choice Market seeks to further improve that experience through a chatbot it is developing to help customers as they shop. The company is exploring other uses of AI for customer service and operations, and plans to use insights from Smart Store Analytics to inform stock replenishment, determine optimum pricing and make additional merchandising decisions.

“We’re at the very early stages of unlocking the power of the data,” Fogarty says. “Having that data, in combination with a target customer that I think everybody’s looking to target — higher-income, younger, millennial and Gen Z customers — that data becomes very powerful in terms of insights and actionability.”

Top photo: Choice Market’s breakfast burritos became even more popular after the company implemented data-driven changes. All photos by Microsoft."
Microsoft_News,https://news.microsoft.com/source/features/digital-transformation/how-nyc-public-schools-invited-ai-into-its-classrooms/,,‘Technology is not something we can hide from students’: How NYC Public Schools invited AI into its classrooms,"Generative AI burst onto the scene in late 2022 with the launch of ChatGPT. Almost overnight, the technology – capable of creating new content in real-time – was everywhere.

But New York City Public Schools soon declared one place generative AI would not be: its classrooms.

“When ChatGPT launched, it literally shook up the entire IT universe,” said Zeeshan Anwar, the district’s chief product officer. “And our first reaction was to block it in schools because we didn’t know how teachers and students would react and use the technology.”

Caution morphed into curiosity, however. Principals started to request access to ChatGPT for their schools. By May 2023, the head of New York City Public Schools wrote an Op-ed announcing the district was reversing course.

Zeeshan Anwar

“Eventually we just realized that technology is not something we can hide from students,” Anwar said. “You need to embrace it, introduce it in a controlled fashion. So we said, ‘OK, we have a data foundation. ChatGPT and OpenAI are here. Let’s work with Microsoft to bring this into the classroom.’”

The result of that collaboration: a custom AI-powered teaching assistant that can offer real-time feedback and answer questions for students. It was built on Azure OpenAI Service, which provides organizations access to OpenAI’s models (including ChatGPT) combined with Azure’s enterprise capabilities and the AI-optimized infrastructure of Azure.

The school district recently piloted the assistant in three high school computer science courses. In a two-week span, nearly 100 students asked the teaching assistant more than 2,000 questions – exponentially more than the three teachers could have fielded, said Tara Carrozza, director of the district’s Digital Learning and Innovation (DLI) team.

Microsoft Source spoke with Anwar and Carrozza about the teaching assistant, what they’ve learned from the pilot and the promise of AI in the classroom.

SOURCE: What was the district’s goal in creating an AI-powered chatbot?

CARROZZA: We’re focused on creating 21st century, student-centered classrooms. That’s really where the concept of the teaching assistant comes from: We want to give as much individualized support as possible to every student. It allows for continuous and personalized feedback to a student.

Tara Carrozza

SOURCE: How did you go about bringing that concept to life?

CARROZZA: When the Op-ed came out, interest in generative AI and AI-empowered tools went through the roof. We have a team of Digital Learning and Innovation teacher ambassadors who created resources and lessons on how to critically consider AI in the classroom across different content areas, different grades, and specifically for students with disabilities and multilingual learners. We also created, in partnership with our Computer Science for All team, a citywide foundational course called “From AI to Generative AI in Education.”

Our quick agility to build and pilot the teaching assistant, and do a very rapid continuous feedback loop with both high school students and staff, was in part from using the open-resource Microsoft TEALS intro to computer science curriculum.

SOURCE: So you had the curriculum. But where did the data come from?

ANWAR: During Covid, we worked with Microsoft to create a data hub we call DAP – data as a platform. Currently, DAP has close to 2 billion records. That data was our foundation when we began collaborating with Microsoft on the teaching assistant.

It is critical for everyone to understand that the model and the data only live in the (Department of Education) environment. Building this on Azure OpenAI Service is key for us in terms of security of our data.

CARROZZA: The best thing about the partnership with Microsoft is that security is baked into everything. People ask, ‘How do we know it’s compliant? What’s happening with our data?’ But we’re working with the premier technology company in the world, so we know we’re doing it the right way.

SOURCE: What feedback did you get from teachers and students?

ANWAR: One of the first things we heard was that the chatbot gave answers too quickly. If I’m a student asking a question, the teacher might not give me a direct answer because they want me to think on my own, right? So teachers wanted the chatbot to take a step back and offer hints, to push the students and keep them thinking. The content filtration capabilities in Azure OpenAI Service make that very easy.

CARROZZA: We worked closely with the IT team on a pedagogical taxonomy of categorizing prompt types and outputs to support students discovering answers themselves. The scaffolded feedback helped keep students engaged and motivated by success to move along. Students are building their metacognition about how they personally are learning.

SOURCE: Is the dream true personalized learning, where the chatbot would tailor every response to the individual?

ANWAR: We’re not there yet but that is the longer goal we’re working on.



When a user logs into the AI hub, we have access to pertinent information regarding the student, including the school they are enrolled in, their current courses, attendance records and grades. We can also track the number of assignments submitted on time and identify areas where they may require assistance. All this data is securely stored within our data platform, which boasts robust layers of security and controlled access overseen by a select group of data administrators.



Based on that entire picture, the AI should be able to deliver a very specific, personalized set of answers. The dream is to interact with each student based on all that data so I can feed them information in a way they understand.

SOURCE: How does AI fit into the district’s educational goals?

CARROZZA: At the heart of our AI work, and why we’re embracing it in New York City, is equity. We must embrace emergent technologies that are pervasive across the world, to increase the equity of access and opportunity for our students, particularly for our Black and Brown students and our students with disabilities and multilingual learners.

Our mission is for students to graduate on a pathway to a rewarding career and long-term economic security, equipped to be a positive force for change. Our kids need to be exposed to these tools, to be fluent in them. If we are not using AI in education, we’re putting our students at risk of being behind.

SOURCE: What comes next?

ANWAR: We’ll collaborate with as many educators as we can. I want to hear from them how they want this technology to work in their classroom. Every classroom is unique, so I want to understand the specific needs of their classrooms.

And we’ll talk to students as well about how they would like to use the technology. We’ll take that feedback and grow the AI hub and the teaching assistant. My goal is that this technology should be enabled in each and every school and in each and every classroom.

Top photo by SDI Productions/Getty Images. Portraits courtesy of NYC Public Schools."
Microsoft_News,https://www.microsoft.com/en-us/worklab/how-ai-gives-you-data-synthesis-superpowers,,How AI Gives You Data Synthesis Superpowers,"This article first appeared in the WorkLab newsletter. Be the first to get our updates by subscribing here.

We’re all living in a data haystack. You’ve got files on your OneDrive—some organized, some dumped in a heap in your documents. Files on your corporate server—some properly named and categorized, some not. Somewhere among your calendar, emails, chats, documents, meetings, and contacts is a needle—the sliver of insight you need now.

Think of Microsoft 365 Copilot as a magnet. One of the most powerful aspects of Copilot is its ability to search across the web and all of the information you have access to—your organization’s data as well as your own—and pull out just the data and info you need in a secure, compliant, and privacy-preserving way. According to findings from the earliest Copilot users, people overwhelmingly use AI to help them find what they need amid all that data.



Copilot will also marshal those needles for you. Ask it to look at three different documents and identify common themes, and it will surface those themes, summarize them (if you like), and deliver them as a table, combing through data from your emails, documents, and the web to deliver organized, useful, and actionable material.

Or ask it to explain hard-to-parse company concepts. Say your company has recently introduced a new type of technology. To pick a non-random example: In May, Microsoft announced Semantic Index for Copilot, a powerful new capability, but one that can be difficult for non-technical people to wrap their heads around quickly. Let’s say you didn’t work on the project and needed to get up to speed fast. Ask Copilot: “I need to explain Semantic Index to a CEO. I need to include an explanation of what it is, how it works, and a value proposition associated with it. Create a script I could use. Also include an analogy that can help a non-technical person understand it.”

Copilot’s response:

Semantic Index for Copilot uses a technique that allows computers to understand the actual meaning of sentences, documents, and meetings, and identifies related concepts to your query or sample content. It works by analyzing the relationships between words and concepts, and then representing that information in a way that can be easily searched and retrieved. The value proposition of Semantic Index for Copilot is that it interprets your search queries to produce sophisticated, meaningful, and multilingual responses that help you to be more productive.

An analogy that can help a non-technical person understand Semantic Index is to think of it as a librarian organizing books in a library. Instead of simply arranging books by their titles or authors, the librarian uses their knowledge of the books’ contents to group them by subject matter and themes. This makes it easier for library patrons to find the books they need, even if they don't know the exact title or author. Similarly, Semantic Index helps computers understand the meaning of data, so they can provide more accurate and relevant search results.

It takes time to find, ingest, analyze, and synthesize multiple documents, time that could be better spent on higher-level work—the work that’s rewarding, strategic, and creative. And when enough people in an organization can quickly and easily find those needles in the digital haystack, just imagine the rich fabric they’ll be able to sew together."
Microsoft_News,https://news.microsoft.com/source/features/ai/west-des-moines-iowa-ai-supercomputer/,,How a small city in Iowa became an epicenter for advancing AI,"For the past few years, Microsoft has been powering the future of AI from a cluster of datacenters located amidst sprawling farmlands and rural roads in Iowa.

Iowa is home to an Azure supercomputer Microsoft built for artificial intelligence research company OpenAI to train breakthrough AI models capable of assisting with an increasing range of tasks, from analyzing documents to writing and debugging computer code and helping plan vacations. That work has made a small city in America’s heartland an unlikely epicenter for the AI revolution that has captivated the world since ChatGPT, OpenAI’s conversational AI system, was released in November 2022.

“These supercomputing systems are really the lifeblood of our research,” said OpenAI’s Katie Mayer, who manages the company’s partnership with Microsoft. “To do the work that we’re doing at this scale and to develop really novel AI capabilities, you need these systems. They’ve really accelerated the rate of progress that we are all benefiting from now.”

Those systems, hosted in Azure, have been instrumental in developing OpenAI’s GPT-4 model that is now embedded across a range of Microsoft technologies, including the new Bing search engine and a growing number of assistive AI-powered copilot applications that help people accomplish complex cognitive tasks, such as Microsoft 365 Copilot for productivity apps and Microsoft Security Copilot for cybersecurity.

The Iowa supercomputer is among the largest and most powerful in the world, according to Microsoft. The company plans to continue investing in datacenters in the U.S. to benefit its customers and further America’s leadership in AI innovation, said Noelle Walsh, Microsoft’s corporate vice president for Cloud Operations and Innovation.

“I think this is a wonderful strategic advantage for the U.S.,” Walsh said. “This technology is going to change our lives and solve problems that we’ve never been able to solve.

“I’m delighted we can deliver this and match our power consumption with renewable energy while being water efficient. We strive to be good neighbors in the communities in which we operate and are proud to be part of West Des Moines, Iowa.”

Microsoft opened its first datacenter in West Des Moines in 2012, attracted by the area’s availability of land, skilled workforce, large fiber optic network and the state’s reliable and renewable energy resources — Microsoft is matching 100% of the energy used by its Iowa datacenters with renewable energy. Two additional Microsoft datacenter campuses in West Des Moines followed, and Microsoft plans to open a fourth and fifth there by end of 2023.

When Microsoft and OpenAI formed a partnership in 2019 to collaborate on AI technologies and make AI more broadly available, the physical datacenter infrastructure to host a supercomputer in Iowa was already in place. OpenAI needed supercomputing power on an unprecedented scale, and the two companies began working together to develop a custom computing system in Iowa to train large AI models."
Microsoft_News,https://blogs.microsoft.com/on-the-issues/2023/09/07/copilot-copyright-commitment-ai-legal-concerns/,,Microsoft announces new Copilot Copyright Commitment for customers,"announced the expansion of the Copilot Copyright Commitment, now called the Customer Copyright Commitment, include commercial customers using the Azure OpenAI Service. By extending the cover the outputs from the Azure OpenAI Service, Microsoft is broadening our commitment to defend these customers and pay for any adverse judgments if they are sued for copyright infringement for the use of the Azure OpenAI Service outputs. This expansion of our copyright commitment is intended to further address customer concerns relating to potential IP infringement liability that could result from the use of the output of Microsoft’s Copilots and Azure OpenAI Service. required . For our Azure OpenAI Service, we offer documentation and tooling that support the responsible use of AI and reduce risks of infringing copyrighted content.

Microsoft’s AI-powered Copilots are changing the way we work, making customers more efficient while unlocking new levels of creativity. While these transformative tools open doors to new possibilities, they are also raising new questions. Some customers are concerned about the risk of IP infringement claims if they use the output produced by generative AI. This is understandable, given recent public inquiries by authors and artists regarding how their own work is being used in conjunction with AI models and services.

To address this customer concern, Microsoft is announcing our new Copilot Copyright Commitment. As customers ask whether they can use Microsoft’s Copilot services and the output they generate without worrying about copyright claims, we are providing a straightforward answer: yes, you can, and if you are challenged on copyright grounds, we will assume responsibility for the potential legal risks involved.

This new commitment extends our existing intellectual property indemnity support to commercial Copilot services and builds on our previous AI Customer Commitments. Specifically, if a third party sues a commercial customer for copyright infringement for using Microsoft’s Copilots or the output they generate, we will defend the customer and pay the amount of any adverse judgments or settlements that result from the lawsuit, as long as the customer used the guardrails and content filters we have built into our products.

You’ll find more details below. Let me start with why we are offering this program:

We believe in standing behind our customers when they use our products. We are charging our commercial customers for our Copilots, and if their use creates legal issues, we should make this our problem rather than our customers’ problem. This philosophy is not new: For roughly two decades we’ve defended our customers against patent claims relating to our products, and we’ve steadily expanded this coverage over time. Expanding our defense obligations to cover copyright claims directed at our Copilots is another step along these lines. We are sensitive to the concerns of authors, and we believe that Microsoft rather than our customers should assume the responsibility to address them. Even where existing copyright law is clear, generative AI is raising new public policy issues and shining a light on multiple public goals. We believe the world needs AI to advance the spread of knowledge and help solve major societal challenges. Yet it is critical for authors to retain control of their rights under copyright law and earn a healthy return on their creations. And we should ensure that the content needed to train and ground AI models is not locked up in the hands of one or a few companies in ways that would stifle competition and innovation. We are committed to the hard and sustained efforts that will be needed to take creative and constructive steps to advance all these goals. We have built important guardrails into our Copilots to help respect authors’ copyrights. We have incorporated filters and other technologies that are designed to reduce the likelihood that Copilots return infringing content. These build on and complement our work to protect digital safety, security, and privacy, based on a broad range of guardrails such as classifiers, metaprompts, content filtering, and operational monitoring and abuse detection, including that which potentially infringes third-party content. Our new Copilot Copyright Commitment requires that customers use these technologies, creating incentives for everyone to better respect copyright concerns.

More details on our Copilot Copyright Commitment

The Copilot Copyright Commitment extends Microsoft’s existing IP indemnification coverage to copyright claims relating to the use of our AI-powered Copilots, including the output they generate, specifically for paid versions of Microsoft commercial Copilot services and Bing Chat Enterprise. This includes Microsoft 365 Copilot that brings generative AI to Word, Excel, PowerPoint, and more – enabling a user to reason across their data or turn a document into a presentation. It also includes GitHub Copilot, which enables developers to spend less time on rote coding, and more time on creating wholly new and transformative outputs. There are important conditions to this program, recognizing that there are potential ways that our technology could intentionally be misused to generate harmful content. To protect against this, customers must use the content filters and other safety systems built into the product and must not attempt to generate infringing materials, including not providing input to a Copilot service that the customer does not have appropriate rights to use.

This new benefit doesn’t change Microsoft’s position that it does not claim any intellectual property rights in the outputs of its Copilot services.

We have published more details of the Copilot Copyright Commitment for customers and welcome the opportunity to have further conversations as Copilots become more widely available.

Our shared AI journey

Today’s announcement is a first step. Like all new technologies, AI raises legal questions that our industry will need to work through with a wide array of stakeholders. This step represents a pledge to our customers that the copyright liability of our products is ours to shoulder, not theirs.

Microsoft is bullish on the benefits of AI, but, as with any powerful technology, we’re clear-eyed about the challenges and risks associated with it, including protecting creative works. It is our responsibility to help manage these risks by listening to and working with others in the tech sector, authors and artists and their representatives, government officials, the academic community, and civil society. We look forward to building on such announcements with new initiatives that help ensure that AI advances the spread of knowledge while protecting the rights and needs of creators.

Tags: AI, artificial intelligence, copilot copyright commitment"
Microsoft_News,https://news.microsoft.com/source/features/ai/copilot-dynamics-365-customer-service/,,"New Copilot capabilities help Microsoft’s own customer service engineers deliver faster, smarter results","When a Microsoft customer service agent like Azure support escalation engineer Michael Simons takes a case out of his queue, he never knows what kind of inquiry will appear in his chat window. Will it be a simple case for which he can provide a solution easily? Or will it be a time-consuming issue that requires complex troubleshooting? And – as always – there are several more customers who would like to take advantage of his expertise.

That makes time, and accuracy, of the essence. Fortunately, Simons and tens of thousands of other Microsoft customer service support engineers now have a new AI-powered experience at their disposal. Copilot in Dynamics 365 Customer Service, which will become generally available next month, helps employees deliver faster and more focused customer care by drafting contextual and personalized answers to questions in both chat and email, and by providing an interactive chat experience over knowledge bases and case history.

A copilot is an application that uses modern AI and large language models such as GPT-4 to help people with everyday tasks, allowing them to spend more time on the highest value parts of their job and less time on mundane chores. Microsoft Dynamics 365 Copilot offers a suite of assistive AI solutions for sales, service, marketing, operations and supply chain roles.

“It’s like having a sous chef in the kitchen,” Simons said. “I’m going to be cooking the meal, but I need someone to keep an eye on the sauces.”

Microsoft’s Customer Service and Support team, which assists more than one billion customers worldwide, addresses inquiries spanning software implementations to Xbox and Surface devices. Given that many cases do require extensive troubleshooting to solve the problem, a major advantage of Copilot in Dynamics 365 Customer Service is that it gives agents more time to do the work that utilizes their skill sets and makes the job more rewarding.

Support engineers like Michael Simons can use Copilot in Microsoft Dynamics 365 Customer Service to provide a summarization of a customer’s case and quickly get abreast of the situation so they can begin strategizing on how to solve it. Photo by Dan DeLong for Microsoft.

Instead of poring over case histories to try and determine the customer’s issue, for example, engineers can use Copilot to provide a summarization of the case that allows them to quickly get abreast of the situation and begin strategizing on how to solve it.

“It’s really getting them sharply focused on the work they enjoy doing the most and where they have the most value,” said Bryan Belmont, corporate vice president for Microsoft’s Customer Service and Support. “It takes some of the drudgery out of their lives that no one enjoys but is still really critical for doing a good job.”

The insights gained from having thousands of Microsoft’s own customer support engineers test Copilot capabilities in their own workflows has helped fine tune the product and make it more useful for everyone, said Geoff Maxwell, general manager for Microsoft’s Customer and Digital Experience.

“When we apply our tools across tens of thousands of people, that’s an incredible opportunity for us to make sure we actually learn how to apply them and make the product better,” he said.“We’re at the start of this journey, as many of our customers are. There’s so much opportunity here to make it even more effective.”

For Simons, who handles customer inquiries about Azure virtual machines and storage, one of his pain points occurred when writing post-call summaries after completing a case. The documentation and minutiae he had to address in between cases could make it difficult to move on quickly.

When he gets a new case, for instance, there’s often back and forth with a customer while troubleshooting the issue, which is documented in the chat.

“Then I have to summarize that whole transcript in a note so that if someone else read it, they could pick up where I left off or figure out that I solved it this way. After that, I write an email with a shorter summary of the interaction to the customer so they have it for their records. If you do the math on that, I’m writing the same conversation three different times,” Simons said.

A conversation summary generated by Copilot in Microsoft Dynamics 365 Customer Service captures key information like the customer’s name, the issue or request, the steps taken so far, the case status and any relevant facts or data. It will also highlight any sentiment expressed by the customer or the agent, plus action items or next steps. Image by Microsoft.

“Where Copilot comes in is what usually used to take me 30-45 minutes, I can now finish in like 5-10 minutes. It automatically summarizes the whole chat for me and gives me everything I talked to the customer about in a nice bullet-point format that I can just copy and paste,” he said.

It’s natural for experienced professionals who are good at their jobs to be skeptical about whether and how next-generation AI tools will benefit them. But those questions tend to fade once people start using Copilot and seeing what it can and can’t do, Maxwell said.

“Our support engineers are wicked smart,” Maxwell said. “They take on difficult customer problems and fix them. So, if you can get a couple of those lightbulb moments to get their curiosity going, what we start to see is that they start wanting to experiment with Copilot. If they go use it a few times, they quickly learn how to make it more effective for them.”

A key challenge in customer service operations is maintaining a high-quality knowledge base – the documents, procedures, manuals, frequently asked questions and other resources – agents need to pull from to help address customer inquiries.

As the conversation between a customer and service engineer progresses during a chat, Copilot can surface relevant articles and documents that have helped resolve similar problems – and add to the data that helps teams assess which pieces of content are most useful or what knowledge gaps still exist.

“If I have any quick questions and need to refer to a document to reference something for a customer, instead of me having to search for it and find it in a bunch of links, Copilot gets me to where I want directly,” says Akshaya Gunasekar, a Microsoft support engineer for Azure Networking. “It also links me to the right document from Microsoft’s public documentation, so I can share it directly. It definitely saves time.”

Microsoft’s Office of the Chief Economist, in partnership with the Dynamics 365 product group, recently completed a study evaluating Copilot’s early impact on productivity among Microsoft’s commercial business support engineers. In the most productive scenario, the study found that in one support business, 10% of cases that normally require collaboration with peers were resolved independently. This means fewer customers had to experience being put on hold.

Copilot has been particularly effective in helping newer agents who don’t have years of experience or institutional experience get up to speed and find relevant information more quickly, the study found. Specifically, for low severity chat cases in one area of Microsoft’s commercial support business, the study observed a 12% reduction in average handle time – the time actively spent on resolving customer cases.

“Where we are seeing some of the biggest impact is with early-in-career agents and engineers,” Belmont said. “Being able to enable a person whose only been in the role a month or two to access the knowledge of folks who have been there 10 years is amazing.”

Those working on the front lines of customer service stress that AI tools can’t replace the trust that comes from personalized service or deliver empathy that someone looking for help instinctively wants.

Sakshi Tyagi, a technical support engineer for Azure App Service, is excited about advances in AI technology, like Copilot in Microsoft Dynamics 365 Customer Service, and how they can help her provide better services for customers. Photo by Dan DeLong for Microsoft.

“A customer is always going to need some assistance,” said Sakshi Tyagi, a technical support engineer for Azure App Service. “And they are going to need an engineer to do that. Copilot helps us help the customer.”

And engineers still need to play a major role in vetting the information that Copilot offers.

“Realistically, a human is never coming out of the loop,” Maxwell said. “We need them to read and review what is being proposed. There will be times where they need to change something.”

While Copilot has already started delivering benefits to Microsoft’s support engineers and their customers, it’s just the tip of the iceberg for the potential of the product, which Belmont describes as being in a state of “continuous evolution.” Using feedback from support engineers, statistics from user data and the needs of customers will allow Copilot’s designers to expand its suite of tools to provide help where needed. As to what’s next? Only time will tell.

“We’ve all seen sci-fi TV shows where they have a supercomputer,” Simons said. “But you still have a whole crew. You still have engineers. They ask the computer to do something, and that’s how I see Copilot working. It’s not answering the questions for us, it’s not solving the problems – it’s us asking Copilot, can you check these settings for me?”

“It’s legitimately impressive. It really does take you to the next level,” Simons said.

Related links:"
Microsoft_News,https://news.microsoft.com/source/latam/features/ai/amazon-ai-rainforest-deforestation/?lang=en,,AI may hold a key to the preservation of the Amazon rainforest,"“The capacity to analyze massive amounts of data is critical here because we know that it’s a rainforest that spans countries and millions of square kilometers,” Arbeláez said. “So, to have a global view of the Amazon basin, you truly need the power of AI and these new models.”

The next step is critical to the biodiversity of the rainforest. Camera boxes have been placed throughout the Colombian Amazon. Anytime the cameras see movement, they take a picture. A single camera can take up to 300,000 photos. But having a researcher flip through every single image would take years.

So, AI programs help speed up the process. The Department of Biological Sciences at Universidad de Los Andes contributed 110,000 images collected over the past four years. With the help of AI, researchers trained a model that detects which images contain animals and those that do not. Now, only 10 percent of images need to be manually validated, freeing up valuable hours for other research. Additionally, being able to quickly determine what images have been captured is key, because if something seems out of place, it could be a sign of ecological shifts that need to be addressed.

“It’s like a picture in time,” Ochoa said. “Monitoring allows us to see how plants and animals live and thrive. But if we see the wrong species in the camera, that is called a bioindicator. For instance, if we see a bird that is normally found in the savannah and is now in the Amazon, this is a red flag. We can say to the authorities, ‘We are getting information of a species that was previously not in this area. There is a change in the ecosystem.’”

“This technology, and the data it generates, allows us to inform decision-makers in the policy area to help us, especially when we are dealing with invasive species,” Ochoa added.

The final element of Project Guacamaya is sound. Using bioacoustics, researchers can capture sound from the Amazon and use an audio AI model to differentiate bird and non-bird sounds to classify bird and other animal species. Guacamaya consolidates more than 100,000 sounds into 1,000 recordings to have a baseline, and then trains a model to detect the different sounds and classify them. This helps scientists gain bird identification with reliability above 80%, which is a major milestone considering there are more than 2,000 bird species in Colombia.

Using bioacoustics, researchers can capture sound from the Amazon and use an audio AI model to differentiate bird and non-bird sounds to classify bird and other animal species. Video by Microsoft, images by Alexander von Humboldt Institute, sounds by Universidad de los Andes.

“The use of this (technology) allows us to diminish the cost of the research in the field,” Ochoa said. “For someone to listen to biodiversity for three months, is something that no one can afford. This technology allows us to do that in a very cost-efficient way.”

Protecting the Amazon rainforest is a large-scale issue that no one organization or entity can tackle on its own. Collaboration is a critical part of Project Guacamaya, with numerous groups coming together to bring their own expertise to the table, and then hopefully create models that can be used throughout the country and the region for the greater good.

“Our goal here is to bring everyone in the same room and work jointly towards a common goal, because each of the partners and institutions can have a complementary role on the project,” Arbeláez said. “To protect the world’s largest rainforest from the effects of climate change, this needs to be a joint effort from all the countries that have a stake in the Amazon. We truly hope the region’s leaders and all our Latin America siblings will take this project as their own.”

In Brazil, where the effects of deforestation and mining in the Amazon have been most prominent, a collaboration between Microsoft, environmental organization Imazon and nonprofit Fundo Vale Foundation called PrevisIA is also addressing the problem using technology.

The PrevisIA platform uses Microsoft’s AI to analyze data and satellite images to forecast and monitor deforestation in Brazil’s Amazon. Imazon uses satellite images and then stores them in the Azure cloud, where AI algorithms detect unofficial roads and other risk factors of deforestation. The resulting output is visualized in an interactive map, highlighting the high-risk areas. This information is then used to support decision-making for safeguarding the rainforest."
Microsoft_News,https://news.microsoft.com/2023/08/30/lumen-technologies-dives-into-microsoft-365-copilot-to-help-enhance-employee-efficiency-and-customer-relationships/,,Lumen Technologies dives into Microsoft 365 Copilot to help enhance employee efficiency and customer relationships,"Lumen Technologies dives into Microsoft 365 Copilot to help enhance employee efficiency and customer relationships

Generative AI tool shows early signs of helping Lumen innovate for growth

DENVER, Colo., and REDMOND, Wash. — Aug. 30, 2023 — Lumen Technologies Inc. (NYSE: LUMN), a multinational technology company, is working with Microsoft Corp. (Nasdaq: MSFT) to deploy Microsoft 365 Copilot to empower its approximately 30,000 employees. Lumen is beta-testing Microsoft 365 Copilot as a part of the Early Access Program (EAP). The company has already seen the benefits of equipping some of its teams with Microsoft’s large language model (LLM) AI solutions, with plans to deploy the tech more broadly in the future.

“We are thrilled to be leading the early deployment of Microsoft 365 Copilot at Lumen Technologies,” said Kate Johnson, president and CEO, Lumen Technologies Inc. “Giving our workforce the digital tools they need to deliver dramatically improved customer experiences with greater ease is an essential part of our company transformation. Our people are seeing immediate productivity improvements with Copilot, allowing them to focus on more value-added activities each day.”

Microsoft 365 Copilot can disrupt the telecommunications industry by providing employees with a tool to help enhance creativity, productivity and skills with real-time intelligent assistance. It has the potential to significantly improve employee productivity by automating tedious tasks and providing powerful tools for data analysis and decision-making. With features such as meeting summaries in Microsoft Teams and Copilot enhancements across Outlook, PowerPoint and other Microsoft 365 apps, employees can get back important time to deliver on strategic priorities.

Customer service teams at Lumen are using Copilot to surface relevant policies, summarize tickets or easily access step-by-step repair instructions from manuals. Sales and customer experience teams are using Copilot to add depth and context to customer communications and summarize actions and next steps. Across the board, teams are using Copilot to quickly create presentations, and for new business proposal and statement-of-work creation to deliver a consistent Lumen message and experience.

Lumen is among the first companies to start working with Microsoft 365 Copilot as one of the EAP adopters. Microsoft 365 Copilot combines the power of LLMs with data in the Microsoft Graph — calendar, emails, chats, documents, meetings and more — and the Microsoft 365 apps to turn words into a powerful productivity tool.

“Microsoft 365 Copilot has the power to revolutionize the way we work, enabling people to focus on what truly matters and drive their organizations forward,” said Deb Cupp, president, Americas Microsoft. “We are thrilled to be delivering this technology to innovative companies like Lumen to help them achieve their goals.”

As a pioneer in the telecommunications industry, Lumen is pushing the envelope when it comes to enhancing the customer experience. By harnessing the power of advanced AI technologies such as generative AI and AI language models through tools like Microsoft 365 Copilot, Lumen can provide their teams with the cutting-edge tools they need to succeed and drive their business forward.

About Lumen Technologies

Lumen connects the world. We are dedicated to furthering human progress through technology by connecting people, data, and applications – quickly, securely, and effortlessly. Everything we do at Lumen takes advantage of our network strength. From metro connectivity to long-haul data transport to our edge cloud, security, and managed service capabilities, we meet our customers’ needs today and as they build for tomorrow. For news and insights visit news.lumen.com, LinkedIn: /lumentechnologies, Twitter: @lumentechco, Facebook: /lumentechnologies, Instagram: @lumentechnologies, and YouTube: /lumentechnologies.

About Microsoft

Microsoft (Nasdaq “MSFT” @Microsoft) enables digital transformation for the era of an intelligent cloud and an intelligent edge. Its mission is to empower every person and every organization on the planet to achieve more.

For more information, press only:

Microsoft Media Relations, WE Communications for Microsoft, (425) 638-7777, [email protected]

Danielle Spears, Corporate Communications for Lumen, (407) 961-3838, [email protected]"
Microsoft_News,https://techcommunity.microsoft.com/t5/microsoft-teams-blog/supercharge-brand-content-with-the-typeface-ai-app-for-microsoft/ba-p/3907848,,Supercharge brand content with the Typeface AI app for Microsoft Teams,"We are just starting to scratch the surface of what generative AI can do, and yet it’s already beginning to transform the marketing industry. An April 2023 survey of global CMOs revealed that about 70 percent of their organizations use generative AI, with nearly half using it to create higher-quality content faster than before.¹ The next jump for enterprises is how to use the technology to produce content at scale while mastering your brand and your voice.

The new Typeface app for Microsoft Teams, available today, will help enterprises make that leap forward. It uses the powerful combination of Azure Machine Learning, Azure OpenAI Service, and Typeface's brand-personalized AI to create content significantly faster than humans can, allowing companies to scale marketing efforts and produce a range of assets such as creative briefs, email campaigns, multimedia online ads, and more. And it all happens in Teams, where chats provide the business context and collaborative capabilities users need without switching apps.

The Typeface app in Teams, with a message introducing the bot.

In this post, I’ll explore how Typeface harnesses generative AI to supercharge branding and marketing initiatives, how Typeface was able to quickly develop an app for Teams to bring AI-based content creation into the flow of work, and how the future of generative AI could remake marketing and other enterprise functions.

How Typeface personalizes branded content in a flash

Understanding a company’s brand and voice is vital for generative AI to produce effective creative assets. To help Typeface learn, a customer supplies content examples, style guidelines, product details, and imagery to train Typeface’s proprietary Affinity AI to build a unique model for each brand. Users can then quickly generate personalized multimedia content with pre-built Typeface workflows and templates, including ad images, product listings, SEO meta tags, and more.

Imagine you’re a marketing manager starting a social media campaign to promote a new line of apple drinks from a consumer goods brand. In Typeface, you can quickly generate a caption and an image at once, customized for a specific target audience. In less than a minute, Typeface produces personalized results that can be brought into a variety of social media platforms.²

A sample Instagram post created by Typeface AI displays a can of apple juice with water splashing in the background.

With a few clicks, the can of juice can be swapped with other images to show updated packaging or an entirely new drink line, and more copy options can be produced in seconds.

How Typeface integrates generative AI into Microsoft Teams

The boost to creative output that Typeface can provide is clear, so it only makes sense to have that force multiplier available in Microsoft Teams. In fact, Typeface has a layer called Typeface Flow, which is all about offering the app on the platform where users work.

“Employees work collaboratively, and we want content creation tools to come to us wherever we already are,” says Vishal Sood, Head of Product at Typeface. “Microsoft Teams is an immensely popular platform where users are already brainstorming and sharing content with their teams, so it's a perfect fit to bring the power of Typeface to Teams and provide creative value right in the flow of work.”

A screenshot of the Typeface app in Teams, with a pop up asking the user if they want to create from a template, create an image, create text, or share from existing projects.

Sood and his Typeface colleagues took advantage of Microsoft documentation to streamline app development and also used Teams Toolkit and Visual Studio Code

“The development process was easy, and we were able to stand up the first version of the Typeface for Teams app in just a few days,” Sood says. “Then we worked closely with Microsoft to refine the user experience. It is an extremely valuable partnership for us.”

With its new Teams app , Typeface aims to increase adoption and engagement with existing customers, which helps independent software vendors (ISVs) improve customer retention

How enterprises can get the most from Typeface for Teams

Not only will customers be able to use the capabilities of the Typeface platform in Teams, they will also have functionality exclusive to the Teams app.

Employees can brainstorm individually using the personal app experience within Teams. Once they’ve ideated, they can generate assets using Typeface AI and share their work on Teams for broader reviews without switching contexts. Typeface utilizes message extensions so that users can leverage the massive amount of content they’ve collaborated on in Teams. For example, they can simply right-click on a video of an executive’s speech and tell Typeface to draft a blog post from that file.

As illustrated by the points above, the two main enterprise use cases of Typeface for Teams are ideation and collaboration. In the ideation phase, employees can use generative AI to go from a blank page to a complete draft almost instantly, with more polish than would be possible manually. Then the draft can be shared easily on Teams for feedback loops and collaborative refinement in the same space where users, content, and business context all come together.

For those crucial feedback loops, Typeface offers a rich, AI-based editing experience. Using the Generative Refine feature, users can highlight sections of text and choose from a range of editing options, such as improve writing, summarize, and change tone or language. Similar options are available for images as well, including altering specific portions of a picture or extending it with AI, adding or deleting assets from an image, adding filters, and overlaying text.

A screenshot of the Typeface app in Teams, showing an Instagram post that has been shared in chat.

All content produced on the platform comes with three layers of brand control. Typeface is built with Azure OpenAI Service, which helps Typeface ensure that each company’s information is used only for their own model and not to train others. Azure OpenAI Service also provides content filtering services in alignment with Microsoft’s Responsible AI Standards, so that prompts and outputs are appropriate. And the proprietary Typeface Safe layer allows enterprises to indicate other keywords or content that’s off limits. How Typeface and generative AI will evolve In the near future, Typeface aims to extend its app across Microsoft 365 to Word, PowerPoint, and Excel. There are also plans to leverage the wealth of data in Microsoft Graph, the access point for Microsoft 365, so that the app can utilize contextual enterprise information for generating output, though the privacy of that data will be maintained so that it’s not used to train, retrain, or improve foundation models. Using that rich enterprise data, creative content and internal assets for HR, finance, and other groups will be built with the intelligence of the whole business and shared in the flow of work in Teams. Typeface also adds the missing piece for any part of the business to create content at speed: personalization. The app can help establish a center of excellence for content creation fueled by generative AI that’s trained on your brand and can gather enterprise-wide context. ""Our vision is to create this unified, intelligent content hub that learns from your existing assets and then personalizes content across marketing, HR, sales, and other use cases at scale,” says Typeface Founder and CEO Abhay Parasnis. “Typeface can provide more value by delivering this personalized content fabric on Teams, a platform with hundreds of millions of users across business groups in some of the world’s largest companies. Typeface for Teams will maximize the reach and impact that generative AI can have on branded content creation for all your users.” Learn more about harnessing AI with collaborative apps in Microsoft Teams Give customers an experience they’ll love by building collaborative apps with Microsoft Teams.



Check out these resources for more information on Teams apps and Microsoft support: Take advantage of best practices for growing your app.

Find out how to expand your business with ISV Success.

Learn more about reaching users through the Microsoft commercial marketplace. Discover Typeface for Teams and learn more about how to personalize content creation with generative AI. This integration is available at no additional charge to all Typeface customers who also have a Microsoft Teams account. Not a Typeface customer but interested in trying it? Sign up for a 30-day free trial by adding the app and clicking “sign up.” We love sharing partner success stories. If you have a story, please contact us."
Microsoft_News,https://azure.microsoft.com/en-us/blog/microsoft-and-accenture-partner-to-tackle-methane-emissions-with-ai-technology/,,Microsoft and Accenture partner to tackle methane emissions with AI technology,"This post was co-authored by Dan Russ, Associate Director, and Sacha Abinader, Managing Director from Accenture.

The year 2022 was a notable one in the history of our climate—it stood as the fifth warmest year ever recorded1. An increase in extreme weather conditions, from devastating droughts and wildfires to relentless floods and heat waves, made their presence felt more than ever before—and 2023 seems poised to shatter still more records. These unnerving circumstances demonstrate the ever-growing impact of climate change that we’ve come to experience as the planet continues to warm.

Microsoft’s sustainability journey

At Microsoft, our approach to mitigating the climate crisis is rooted in both addressing the sustainability of our own operations and in empowering our customers and partners in their journey to net-zero emissions. In 2020, Microsoft set out with a robust commitment: to be a carbon-negative, water positive, and zero-waste company, while protecting ecosystems, all by the year 2030. Three years later, Microsoft remains steadfast in its resolve. As part of these efforts, Microsoft has launched Microsoft Cloud for Sustainability, a comprehensive suite of enterprise-grade sustainability management tools aimed at supporting businesses in their transition to net-zero.

Moreover, our contribution to several global sustainability initiatives has the goal of benefiting every individual and organization on this planet. Microsoft has accelerated the availability of innovative climate technologies through our Climate Innovation Fund and is working hard to strengthen our climate policy agenda. Microsoft’s focus on sustainability-related efforts forms the backdrop for the topic tackled in this blog post: our partnership with Accenture on the application of AI technologies toward solving the challenging problem of methane emissions detection, quantification, and remediation in the energy industry.

“We are excited to partner with Accenture to deliver methane emissions management capabilities. This combines Accenture’s deep domain knowledge together with Microsoft’s cloud platform and expertise in building AI solutions for industry problems. The result is a solution that solves real business problems and that also makes a positive climate impact.”—Matt Kerner, CVP Microsoft Cloud for Industry, Microsoft.

Why is methane important?

Methane is approximately 85 times more potent than carbon dioxide (CO 2 ) at trapping heat in the atmosphere over a 20-year period. It is the second most abundant anthropogenic greenhouse gas after CO 2 , accounting for about 20 percent of global emissions.

The global oil and gas industry is one of the primary sources of methane emissions. These emissions occur across the entire oil and gas value chain, from production and processing to transmission, storage, and distribution. The International Energy Agency (IEA) estimates that it is technically possible to avoid around 75 percent of today’s methane emissions from global oil and gas operations. These statistics drive home the importance of addressing this critical issue.

Microsoft’s investment in Project Astra

Microsoft has signed on to the Project Astra initiative—together with leading energy companies, public sector organizations, and academic institutions—in a coordinated effort to demonstrate a novel approach to detecting and measuring methane emissions from oil and gas production sites.

Project Astra entails an innovative sensor network that harnesses advances in methane-sensing technologies, data sharing, and data analytics to provide near-continuous emissions monitoring of methane across oil and gas facilities. Once operational, this kind of smart digital network would allow producers and regulators to pinpoint methane releases for timely remediation.

Accenture and Microsoft—The future of methane management

Attaining the goal of net-zero methane emissions is becoming increasingly possible. The technologies needed to mitigate emissions are maturing rapidly, and digital platforms are being developed to integrate complex components. As referenced in Accenture’s recent methane thought leadership piece, “More than hot air with methane emissions”. What is needed now is a shift—from a reactive paradigm to a preventative one—where the critical issue of leak detection and remediation is transformed into leak prevention by leveraging advanced technologies.

Accenture’s specific capabilities and toolkit

To date, the energy industry’s approach to methane management has been fragmented and comprised of a host of costly monitoring tools and equipment that have been siloed across various operational entities. These siloed solutions have made it difficult for energy companies to accurately analyze emissions data, at scale, and remediate those problems quickly.

What has been lacking is a single, affordable platform that can integrate these components into an effective methane emissions mitigation tool. These components include enhanced detection and measurement capabilities, machine learning for better decision-making, and modified operating procedures and equipment that make “net-zero methane” happen faster. These platforms are being developed now and can accommodate a wide variety of technology solutions that will form the digital core necessary to achieve a competitive advantage.

Accenture has created a Methane Emissions Monitoring Platform (MEMP) that facilitates the integration of multiple data streams and embeds key methane insights into business operations to drive action (see Figure 1 below).

Figure 1: Accenture’s Methane Emissions Monitoring Platform (MEMP).

The cloud-based platform, which runs on Microsoft Azure, enables energy companies to both measure baseline methane emissions in near real-time and detect leaks using satellites, fixed wing aircraft, and ground level sensing technologies. It is designed to integrate multiple data sources to optimize venting, flaring, and fugitive emissions. Figure 2 below illustrates the aspirational end-to-end process incorporating Microsoft technologies. MEMP also facilitates connectivity with back-end systems responsible for work order creation and management, including the scheduling and dispatching of field crews to remediate specific emission events.

Figure 2: The Methane Emissions Monitoring Platform Workflow (aspirational).

Microsoft’s AI tools powering Accenture’s Methane Emissions Monitoring Platform

Microsoft has provided a number of Azure-based AI tools for tackling methane emissions, including tools that support sensor placement optimization, digital twin for methane Internet of Things (IoT) sensors, anomaly (leak) detection, and emission source attribution and quantification. These tools, when integrated with Accenture’s MEMP, allow users to monitor alerts in near real-time through a user-friendly interface, as shown in Figure 3.

Figure 3: MEMP Landing Page visualizing wells, IoT sensors, and Work Orders.

“Microsoft has developed differentiated AI capabilities for methane leak detection and remediation, and is excited to partner with Accenture in integrating these features onto their Methane Emissions Monitoring Platform, to deliver value to energy companies by empowering them in their path to net-zero emissions”—Merav Davidson, VP, Industry AI, Microsoft.

Methane IoT sensor placement optimization

Placing sensors in strategic locations to ensure maximum potential coverage of the field and timely detection of methane leaks is the first step towards building a reliable end-to-end IoT-based detection and quantification solution. Microsoft’s solution for sensor placement utilizes geospatial, meteorological, and historical leak rate data and an atmospheric dispersion model to model methane plumes from sources within the area of interest and obtain a consolidated view of emissions. It then selects the best locations for sensors using either a mathematical programming optimization method, a greedy approximation method, or an empirical downwind method that considers the dominant wind direction, subject to cost constraints.

In addition, Microsoft provides a validation module to evaluate the performance of any candidate sensor placement strategy. Operators can evaluate the marginal gains offered by utilizing additional sensors in the network, through sensitivity analysis as shown in Figure 4 below.

Figure 4: Left: Increase in leak coverage with a number of sensors. By increasing the number of sensors that are available for deployment, the leak detection ratio (i.e., the fraction of detected leaks by deployed sensors) increases. Right: Source coverage for 15 sensors. The arrows map each sensor (red circles) to the sources (black triangles) that it detects.

End-to-end data pipeline for methane IoT sensors

To achieve continuous monitoring of methane emissions from oil and gas assets, Microsoft has implemented an end-to-end solution pipeline where streaming data from IoT Hub is ingested into a Bronze Delta Lake table leveraging Structured Streaming on Spark. Sensor data cleaning, aggregation, and transformation to algorithm data model are done and the resultant data is stored in a Silver Delta Lake table in a format that is optimized for downstream AI tasks.

Methane leak detection is performed using uni- and multi-variate anomaly detection models for improved reliability. Once a leak has been detected, its severity is also computed, and the emission source attribution and quantification algorithm then identifies the likely source of the leak and quantifies the leak rate.

This event information is sent to the Accenture Work Order Prioritization module to trigger appropriate alerts based on the severity of the leak to enable timely remediation of fugitive or venting emissions. The quantified leaks can also be recorded and reported using tools such as the Microsoft Sustainability Manager app. The individual components of this end-to-end pipeline are described in the sections below and illustrated in Figure 5.

Figure 5: End-to-end IoT data pipeline that runs on Microsoft Azure demonstrating methane leak detection, quantification, and remediation capabilities.

Digital twin for methane IoT sensors

Data streaming from IoT sensors deployed in the field needs to be orchestrated and reliably passed to the processing and AI execution pipeline. Microsoft’s solution creates a digital twin for every sensor. The digital twin comprises a sensor simulation module that is leveraged in different stages of the methane solution pipeline. The simulator is used to test the end-to-end pipeline before field deployment, reconstruct and analyze anomalous events through what-if scenarios and enable the source attribution and leak quantification module through a simulation-based, inverse modeling approach.

Anomaly (leak) detection

A methane leak at a source could manifest as an unusual rise in the methane concentration detected at nearby sensor locations that require timely mitigation. The first step towards identifying such an event is to trigger an alert through the anomaly detection system. A severity score is computed for each anomaly to help prioritize alerts. Microsoft provides the following two methods for time series anomaly detection, leveraging Microsoft’s open-source SynapseML library, which is built on the Apache Spark distributed computing framework and simplifies the creation of massively scalable machine learning pipelines:

Univariate anomaly detection : Based on a single variable, for example, methane concentration. Multivariate anomaly detection : Used in scenarios where multiple variables, including methane concentration, wind speed, wind direction, temperature, relative humidity, and atmospheric pressure, are used to detect an anomaly.

Post-processing steps are implemented to reliably flag true anomalous events so that remedial actions can be taken in a timely manner while reducing false positives to avoid unnecessary and expensive field trips for personnel. Figure 6 below illustrates this feature in Accenture’s MEMP: the ‘hover box” over Sensor 6 documents a total of seven alerts resulting in just two work orders being created.

Figure 6: MEMP dashboard visualizing alerts and resulting work orders for Sensor 6.

Emission source attribution and quantification

Once deployed in the field, methane IoT sensors can only measure compound signals in the proximity of their location. For an area of interest that is densely populated with potential emission sources, the challenge is to identify the source(s) of the emission event. Microsoft provides two approaches for identifying the source of a leak:

Area of influence attribution model: Given the sensor measurements and location, an “area of influence” is computed for a sensor location at which a leak is detected, based on the real-time wind direction and asset geo-location. Then, the asset(s) that lie within the computed “area of influence” are identified as potential emissions sources for that flagged leak. Bayesian attribution model: With this approach, source attribution is achieved through inversion of the methane dispersion model. The Bayesian approach comprises two main components—a source leak quantification model and a probabilistic ranking model—and can account for uncertainties in the data stemming from measurement noise, statistical and systematic errors, and provides the most likely sources for a detected leak, the associated confidence level and leak rate magnitude.

Considering the high number of sources, low number of sensors, and the variability of the weather, this poses a complex but highly valuable inverse modeling problem to solve. Figure 7 provides insight regarding leaks and work orders for a particular well (Well 24). Specifically, diagrams provide well-centric and sensor-centric assessments that attribute a leak to this well.

Figure 7: Leak Source Attribution for Well 24.

Further, Accenture’s Work Order Prioritization module using Microsoft Dynamics 365 Field Service application (Figure 8) enables Energy operators to initiate remediation measures under the Leak Detection and Remediation (LDAR) paradigm.

Figure 8: Dynamics 365 Work Order with emission source attribution and CH 4 concentration trend data embedded.

Looking ahead

In partnership with Microsoft, Accenture is looking to continue refining MEMP, which is built on the advanced AI and statistical models presented in this blog. Future capabilities of MEMP look to move from “detection and remediation” to “prediction and prevention” of emission events, including enhanced event quantification and source attribution.

Microsoft and Accenture will continue to invest in advanced capabilities with an eye toward both:

Integrating industry standards platforms such as Azure Data Manager for Energy (ADME) and Open Footprint Forum to enable both publishing and consumption of emissions data. Leveraging Generative AI to simplify the user experience.

Learn more

Case study

Duke Energy is working with Accenture and Microsoft on the development of a new technology platform designed to measure actual baseline methane emissions from natural gas distribution systems.

Accenture Methane Emissions Monitoring Platform

More information regarding Accenture’s MEMP can be found in “More than hot air with methane emissions”. Additional information regarding Accenture can be found on the Accenture homepage and on their energy page.



Microsoft Azure Data Manager for Energy

Azure Data Manager for Energy is an enterprise-grade, fully managed, OSDU Data Platform for the energy industry that is efficient, standardized, easy to deploy, and scalable for data management—ingesting, aggregating, storing, searching, and retrieving data. The platform will provide the scale, security, privacy, and compliance expected by our enterprise customers. The platform offers out-of-the-box compatibility with major service company applications, which allows geoscientists to use domain-specific applications on data contained in Azure Data Manager for Energy with ease.

Related publications and conference presentations

Source Attribution and Emissions Quantification for Methane Leak Detection: A Non-Linear Bayesian Regression Approach. Mirco Milletari, Sara Malvar, Yagna Oruganti, Leonardo Nunes, Yazeed Alaudah, Anirudh Badam. The 8th International Online & Onsite Conference on Machine Learning, Optimization, and Data Science.

Surrogate Modeling for Methane Dispersion Simulations Using Fourier Neural Operator. Qie Zhang, Mirco Milletari, Yagna Oruganti, Philipp Witte. Presented at the NeurIPS 2022 Workshop on Tackling Climate Change with Machine Learning.

1NASA Says 2022 Fifth Warmest Year on Record, Warming Trend Continues"
Microsoft_News,https://blogs.microsoft.com/on-the-issues/2023/08/23/indias-ai-opportunity/,,India’s AI Opportunity,"This post is the foreword written by Brad Smith for Microsoft’s report Governing AI: A Blueprint for India. The first part of the report details five ways India could consider policies, laws, and regulations around AI. The second part focuses on Microsoft’s internal commitment to ethical AI, showing how the company is both operationalizing and building a culture of responsible AI. The final part shares case studies from India demonstrating how AI is already helping address major societal issues in the country. Read the full report here.

“Don’t ask what computers can do, ask what they should do.”

That is the title of the chapter on AI and ethics in a book I coauthored with Carol Ann Browne in 2019. At the time, we wrote that “this may be one of the defining questions of our generation.” Four years later, the question has seized center stage not just in the world’s capitals, but around many dinner tables.

As people use or hear about the power of OpenAI’s GPT-4 foundation model, they are often surprised or even astounded. Many are enthused or even excited. Some are concerned or even frightened. What has become clear to almost everyone is something we noted four years ago—we are the first generation in the history of humanity to create machines that can make decisions that previously could only be made by people.

Countries around the world are asking common questions. How can we use this new technology to solve our problems? How do we avoid or manage new problems it might create? How do we control technology that is so powerful? These questions call not only for broad and thoughtful conversation, but decisive and effective action.

Earlier this year, the global population exceeded eight billion people. Today, one out of every six people on Earth live in India. India is experiencing a significant technological transformation that presents a tremendous opportunity to leverage innovation for economic growth. This paper offers some of our ideas and suggestions as a company, placed in the Indian context.

To develop AI solutions that serve people globally and warrant their trust, we’ve defined, published, and implemented ethical principles to guide our work. And we are continually improving engineering and governance systems to put these principles into practice. Today, we have nearly 350 people working on responsible AI at Microsoft, helping us implement best practices for building safe, secure, and transparent AI systems designed to benefit society.

New opportunities to improve the human condition

The resulting advances in our approach to responsible AI have given us the capability and confidence to see ever-expanding ways for AI to improve people’s lives. By acting as a copilot in people’s lives, the power of foundation models like GPT-4 is turning search into a more powerful tool for research and improving productivity for people at work. And for any parent who has struggled to remember how to help their 13-year-old child through an algebra homework assignment, AI-based assistance is a helpful tutor.

While this technology will benefit us in everyday tasks by helping us do things faster, easier, and better, AI’s real potential is in its promise to unlock some of the world’s most elusive problems. We’ve seen AI help save individuals’ eyesight, make progress on new cures for cancer, generate new insights about proteins, and provide predictions to protect people from hazardous weather. Other innovations are fending off cyberattacks and helping to protect fundamental human rights, even in nations afflicted by foreign invasion or civil war. We are optimistic about the innovative solutions from India that are included in Part 3 of this report. These solutions demonstrate how India’s creativity and innovation can address some of the most pressing challenges in various domains such as education, health, and environment.

In so many ways, AI offers perhaps even more potential for the good of humanity than any invention that has preceded it. Since the invention of the printing press with movable type in the 1400s, human prosperity has been growing at an accelerating rate. Inventions like the steam engine, electricity, the automobile, the airplane, computing, and the internet have provided many of the building blocks for modern civilization. And like the printing press itself, AI offers a new tool to genuinely help advance human learning and thought.

Guardrails for the future

Another conclusion is equally important: it’s not enough to focus only on the many opportunities to use AI to improve people’s lives. This is perhaps one of the most important lessons from the role of social media. Little more than a decade ago, technologists and political commentators alike gushed about the role of social media in spreading democracy during the Arab Spring. Yet five years after that, we learned that social media, like so many other technologies before it, would become both a weapon and a tool—in this case aimed at democracy itself.

Today, we are 10 years older and wiser, and we need to put that wisdom to work. We need to think early on and in a clear-eyed way about the problems that could lie ahead.

We also believe that it is just as important to ensure proper control over AI as it is to pursue its benefits. We are committed and determined as a company to develop and deploy AI in a safe and responsible way. The guardrails needed for AI require a broadly shared sense of responsibility and should not be left to technology companies alone. Our AI products and governance processes must be informed by diverse multistakeholder perspectives that help us responsibly develop and deploy our AI technologies in cultural and socioeconomic contexts that may be different than our own.

When we at Microsoft adopted our six ethical principles for AI in 2018, we noted that one principle was the bedrock for everything else—accountability. This is the fundamental need: to ensure that machines remain subject to effective oversight by people and the people who design and operate machines remain accountable to everyone else. In short, we must always ensure that AI remains under human control. This must be a first-order priority for technology companies and governments alike.

This connects directly with another essential concept. In a democratic society, one of our foundational principles is that no person is above the law. No government is above the law. No company is above the law, and no product or technology should be above the law. This leads to a critical conclusion: people who design and operate AI systems cannot be accountable unless their decisions and actions are subject to the rule of law.

In many ways, this is at the heart of the unfolding AI policy and regulatory debate. How do governments best ensure that AI is subject to the rule of law? In short, what form should new law, regulation, and policy take?

A five-point blueprint for the public governance of AI

Building on what we have learned from our responsible AI program at Microsoft, we released a blueprint in May that detailed our five-point approach to help advance AI governance. In this version, we present those policy ideas and suggestions in the context of India. We do so with the humble recognition that every part of this blueprint will benefit from broader discussion and require deeper development. But we hope this can contribute constructively to the work ahead. We offer specific steps to:

• Implement and build upon new government-led AI safety frameworks.

• Require effective safety brakes for AI systems that control critical infrastructure.

• Develop a broader legal and regulatory framework based on the technology architecture for AI.

• Promote transparency and ensure academic and public access to AI.

• Pursue new public-private partnerships to use AI as an effective tool to address the inevitable societal challenges that come with new technology.

More broadly, to make the many different aspects of AI governance work on an international level, we will need a multilateral framework that connects various national rules and ensures that an AI system certified as safe in one jurisdiction can also qualify as safe in another. There are many effective precedents for this, such as common safety standards set by the International Civil Aviation Organization, which means an airplane does not need to be refitted midflight from Delhi to New York.

As the current holder of the G20 Presidency and Chair of the Global Partnership on AI, India is well positioned to help advance a global discussion on AI issues. Many countries will look to India’s leadership and example on AI regulation. India’s strategic position in the Quad and efforts to advance the Indo-Pacific Economic Framework present further opportunities to build awareness amongst major economies and drive support for responsible AI development and deployment within the Global South.

Working towards an internationally interoperable approach to responsible AI is critical to maximizing the benefits of AI globally. Recognizing that AI governance is a journey, not a destination, we look forward to supporting these efforts in the months and years to come.

Governing AI within Microsoft

Ultimately, every organization that creates or uses advanced AI systems will need to develop and implement its own governance systems. Part 2 of this paper describes the AI governance system within Microsoft—where we began, where we are today, and how we are moving into the future.

As this section recognizes, the development of a new governance system for new technology is a journey in and of itself. A decade ago, this field barely existed. Today Microsoft has almost 350 employees specializing in it, and we are investing in our next fiscal year to grow this further.

As described in this section, over the past six years we have built out a more comprehensive AI governance structure and system across Microsoft. We didn’t start from scratch, borrowing instead from best practices for the protection of cybersecurity, privacy, and digital safety. This is all part of the company’s comprehensive Enterprise Risk Management (ERM) system, which has become a critical part of the management of corporations and many other organizations in the world today.

When it comes to AI, we first developed ethical principles and then had to translate these into more specific corporate policies. We’re now on version 2 of the corporate standard that embodies these principles and defines more precise practices for our engineering teams to follow. We’ve implemented the standard through training, tooling, and testing systems that continue to mature rapidly. This is supported by additional governance processes that include monitoring, auditing, and compliance measures.

As with everything in life, one learns from experience. When it comes to AI governance, some of our most important learning has come from the detailed work required to review specific, sensitive AI use cases. In 2019, we founded a sensitive use review program to subject our most sensitive and novel AI use cases to rigorous, specialized review that results in tailored guidance. Since that time, we have completed roughly 600 sensitive use case reviews. The pace of this activity has quickened to match the pace of AI advances, with almost 150 such reviews taking place in the last 11 months.

All of this builds on the work we have done and will continue to do to advance responsible AI through company culture. That means hiring new and diverse talent to grow our responsible AI ecosystem and investing in the talent we already have at Microsoft to develop skills and empower them to think broadly about the potential impact of AI systems on individuals and society. It also means that much more than in the past, the frontier of technology requires a multidisciplinary approach that combines great engineers with talented professionals from across the liberal arts.

At Microsoft, we look to engage stakeholders from around the world as we develop our responsible AI work to ensure it is informed by the best thinking from people working on these issues globally and to advance a representative discussion on AI governance. As one example, earlier in 2023, Microsoft’s Office of Responsible AI partnered with the Stimson Center’s Strategic foresight hub to launch our Global Perspectives Responsible AI Fellowship. The purpose of the fellowship is to convene diverse stakeholders from civil society, academia, and the private sector in Global South countries for substantive discussions on AI, its impact on society, and ways that we can all better incorporate the nuanced social, economic, and environmental contexts in which these systems are deployed.

A comprehensive global search led us to select fellows from Africa (Nigeria, Egypt, and Kenya), Latin America (Mexico, Chile, Dominican Republic, and Peru), Asia (Indonesia, Sri Lanka, India, Kyrgyzstan, and Tajikistan), and Eastern Europe (Turkey). Later this year, we will share outputs of our conversations and video contributions to shine light on the issues at hand, present proposals to harness the benefits of AI applications, and share key insights about the responsible development and use of AI in the Global South.

All this is offered in this paper in the spirit that we’re on a collective journey to forge a responsible future for artificial intelligence. We can all learn from each other. And no matter how good we may think something is today, we will all need to keep getting better.

As technology change accelerates, the work to govern AI responsibly must keep pace with it. With the right commitments and investments that keep people at the center of AI systems globally, we believe it can."
Microsoft_News,https://blogs.microsoft.com/blog/2023/08/22/microsoft-and-epic-expand-ai-collaboration-to-accelerate-generative-ais-impact-in-healthcare-addressing-the-industrys-most-pressing-needs/,,"Microsoft and Epic expand AI collaboration to accelerate generative AI’s impact in healthcare, addressing the industry’s most pressing needs","Today, the promise of technology to help us solve some of the biggest challenges we face has never been more tangible, and nowhere is generative AI more needed, and possibly more impactful, than in healthcare. Epic and Microsoft have been paving the way to bring generative AI to the forefront of the healthcare industry. Together, we are working to help clinicians better serve their patients and are addressing some of the most urgent needs, from workforce burnout to staffing shortages.

We combined Microsoft’s large-scale cloud and AI technologies with Epic’s deep understanding of the healthcare industry and clinical workflows to address many current issues affecting clinicians. Today, we are announcing the expansion of our strategic initiative to bring AI to healthcare at scale, integrating conversational, ambient and generative AI technologies across the Epic electronic health record (EHR) ecosystem. Intended to speed development of solutions for healthcare’s most critical needs, the initiative will expand secure access to AI-powered clinical insights and administrative tools within a wide range of Epic modules to enhance patient care, increase operational efficiency, improve healthcare experiences, and support the financial integrity of health systems globally.

We are working together to rapidly deploy dozens of copilot solutions that securely unlock the potential value that the Microsoft Cloud and our AI technologies enable as health systems strive to overcome the urgent staffing, financial and clinical access challenges they face today. Epic will showcase many of these new capabilities that build on our Azure OpenAI Service and Nuance DAX Express solutions at its annual Users Group Meeting today, including:

Enhancing clinician productivity with note summarization : Building on the previously announced AI-assisted Epic In Basket, the new solutions are targeted at increasing clinical efficiency for physicians and nurses, helping them become more productive in their daily clinical workflow. The solutions will help support faster documentation through suggested text and rapid review with in-context summaries.

: Building on the previously announced AI-assisted Epic In Basket, the new solutions are targeted at increasing clinical efficiency for physicians and nurses, helping them become more productive in their daily clinical workflow. The solutions will help support faster documentation through suggested text and rapid review with in-context summaries. Enhancing clinician productivity with embedded ambient clinical documentation : Leveraging Nuance’s Dragon Ambient eXperience (DAX) technology, which is already deployed with hundreds of Epic customers and currently supporting thousands of physicians, Epic will showcase this DAX Express AI technology embedded into the native Epic Hyperdrive platform and Haiku mobile application, further enhancing a seamless workflow experience for users. In addition, Nuance has been named by Epic as one of the first Partners in Epic’s Partner and Pals third-party vendor program.

: Leveraging Nuance’s Dragon Ambient eXperience (DAX) technology, which is already deployed with hundreds of Epic customers and currently supporting thousands of physicians, Epic will showcase this DAX Express AI technology embedded into the native Epic Hyperdrive platform and Haiku mobile application, further enhancing a seamless workflow experience for users. In addition, Nuance has been named by Epic as one of the first Partners in Epic’s Partner and Pals third-party vendor program. Driving administrative efficiencies through reduction in manual, labor intensive processes : Revenue cycle management is one of many areas where generative AI can meaningfully improve efficiency. For example, Epic will demonstrate an AI-powered solution that provides medical coding staff with suggestions based on clinical documentation in the EHR to improve accuracy and streamline the entire coding and billing processes.

: Revenue cycle management is one of many areas where generative AI can meaningfully improve efficiency. For example, Epic will demonstrate an AI-powered solution that provides medical coding staff with suggestions based on clinical documentation in the EHR to improve accuracy and streamline the entire coding and billing processes. Advancing medicine for better patient outcomes: By using Azure OpenAI Service, Epic is now delivering generative AI exploration for an initial set of users via SlicerDicer to fill gaps in clinical evidence using real-world data and to study rare diseases and more.

Our work to integrate Azure OpenAI Service and Nuance ambient technologies within the Epic ecosystem shows that broader strategic collaborations can rapidly accelerate the availability of actionable AI-driven solutions for healthcare organizations and the patients they serve.

By 2025, the U.S. Department of Health and Human Services predicts that there will be a nationwide shortage of 90,000 physicians. Additionally, 40% to 60% of clinicians report they are experiencing burnout. On top of these challenges, healthcare providers are facing financial pressures while also trying to efficiently and effectively deliver quality care. According to McKinsey & Company, nearly a quarter of U.S. national health expenditure goes toward administrative costs, which could be reduced through technology.

Additionally, the urgent need to improve operational and clinical efficiency was highlighted again in a recent UPMC Center for Connected Medicine/KLAS Research survey of 58 executives at provider and payor organizations. The survey found that health systems are prioritizing investments over the next two years in AI solutions focusing on operational optimization, health/disease management and prediction, diagnostic imaging, population health management, value-based care, patient engagement and clinical research.

Epic and Microsoft’s expanded collaboration will build upon our recently announced integrations, including Azure OpenAI Service into Epic’s EHR to automatically draft message responses, as well as a solution that will bring natural language queries and interactive data analysis to SlicerDicer, Epic’s self-service reporting tool. Microsoft and Nuance also recently collaborated to integrate Nuance® Dragon® Ambient eXperience™ Express (DAX Express™) solution into the Epic platform with a comprehensive approach to incorporating a broader array of AI-powered capabilities for clinical and administrative users.

Epic’s approach to leveraging Microsoft’s technology and infrastructure is unprecedented in time and scope. Together, we are bringing generative AI to healthcare at scale as quickly as possible, responsibly and in partnership with providers, in order to address the ongoing issues affecting healthcare.

Tags: AI, Azure OpenAI Service, healthcare"
Microsoft_News,https://aka.ms/AAluvnv,,Microsoft solutions boost Fortune 500 frontline productivity with next-generation AI,"Frontline workers represent the face of organizations and make up the lion’s share of the workforce. Gartner estimates that there are 2.7 billion frontline workers — more than twice the number of desk-based workers.i The current macroeconomic climate highlighted by labor and supply chain shortages has put a lot of pressure on these workers to carry more work as organizations drive efficiency across business operations.

The recent Work Trend Index shows that there is an opportunity for digital tools to help ease the burden on these essential workers. Over 60% of frontline workers struggle with having to do repetitive or menial tasks that take time away from more meaningful work and not having enough of the necessary resources to get their work done efficiently.ii In addition, 1 in 2 frontline workers cite being burned out in their jobs, and 45% note they are likely to consider changing employers in the next year.ii Investment in technology that enables frontline workers to thrive is a huge opportunity for business leaders – one that will drive positive outcomes for employees, customers, and the bottom line if solved correctly.

Today, over 60% of the Fortune 500 use Microsoft 365 to empower frontline workers. Microsoft is committed to investing in innovative solutions to help frontline workers thrive. With AI transforming productivity across most segments of the workforce, our survey found that 65% of frontline workers are optimistic that AI will help them in their jobs.ii.

We are excited to introduce new tools and integrations including bringing the power of next-generation AI to the frontline across three key areas:

Intelligent operations

Effortless communication

Trusted experiences

These innovations will improve efficiency, enhance customer experiences, and enable faster decision making.

YouTube Video Click here to load media

Intelligent operations

Whether it’s for an inspection, installation or a maintenance request, frontline service managers want to spend their time helping their team deliver exceptional service operations and not on inefficient tasks like copying and pasting information from one system to another. We seek to infuse the productivity applications frontline managers use everyday with the robust data and intelligence of underlying business applications. This helps streamline the frontline experience and drive efficiency with operations.

Copilot in Dynamics 365 Field Service with Outlook and Microsoft Teams integrations brings the power of next-generation AI to service professionals on the frontline. Frontline service managers who receive customer escalations in Outlook or Microsoft Teams can use Copilot in Dynamics 365 to streamline work order creation with relevant details pre-populated from emails or chats, optimize technician scheduling with data-driven recommendations based on factors such as travel time, availability and skillset, as well as generate draft responses to customer messages summarizing next steps without switching apps.

brings the power of next-generation AI to service professionals on the frontline. Frontline service managers who receive customer escalations in Outlook or Microsoft Teams can use Copilot in Dynamics 365 to streamline work order creation with relevant details pre-populated from emails or chats, optimize technician scheduling with data-driven recommendations based on factors such as travel time, availability and skillset, as well as generate draft responses to customer messages summarizing next steps without switching apps. Dynamics 365 Field Service app in Microsoft Teams will enable frontline technicians to access key work order functionality in their flow of work. Technicians will now be able to see upcoming work orders at a glance in their home experience in Teams, share full work order details and easily access Dynamics 365 Remote Assist in one click to troubleshoot with remote experts in real time if they need additional support to complete jobs.

Maintaining end-to-end visibility on operations can be time-consuming for frontline managers with fluctuating team schedules and often a large, dispersed team. Soon Microsoft 365 Copilot can ground prompts and retrieve insights for frontline managers, leveraging data from the Shifts app with a new Shifts plugin for Microsoft 365 Copilot, in addition to user and company data it has access to such as Teams chat history, SharePoint, emails and more. This will enable frontline managers to quickly get a list of important items specific to their team and location to speed up time-consuming tasks like covering shifts and onboarding new employees.

Effortless communication

Workplace culture is built upon a connection to the company mission, and it all starts with strong lines of communication. When companies establish an easy way to access consistent communications, frontline workers feel informed and connected. With a single communications platform to reach their entire workforce, corporate communicators don’t have to switch out of their digital workspace to connect to the frontline.

Announcements in Viva Connections enables corporate communicators to draft, schedule and target important announcements like urgent communications, role-specific updates and safety policy changes to frontline workers. Communicators can quickly send messages directly from Viva Connections without having to leave Teams. Messages are delivered to the frontline through push notifications on their mobile devices and announcement cards in their Teams home experience.

enables corporate communicators to draft, schedule and target important announcements like urgent communications, role-specific updates and safety policy changes to frontline workers. Communicators can quickly send messages directly from Viva Connections without having to leave Teams. Messages are delivered to the frontline through push notifications on their mobile devices and announcement cards in their Teams home experience. To build a sense of belonging and purpose across your entire workforce, Targeted Campaigns in Viva Engage enables communicators to create campaigns that promote company-wide initiatives targeted to frontline audiences.

Trusted experiences

Many on the frontline work across multiple devices and often hand them over after a shift ends. To enable shift and part-time workers to be productive from the moment they log in, Windows 365 Frontline makes it easy and affordable to extend the power of Cloud PCs to employees on the frontline so they can securely access their personalized Windows experience on any device, no matter where they work.

Securing data across shared devices, while still ensuring a seamless end-user experience can be challenging. A digital identity allows frontline workers to access and move between the technology needed to do their work, whether they are on a shared device or a dedicated one.

For organizations using Intune, they can use Microsoft Entra ID (formerly Azure Active Directory) to enable a single sign-in and sign-out experience for Teams, Outlook, Power Apps and more with shared device mode for Android and iOS devices . This allows frontline workers to wipe their device quickly and compliantly for the next shift.

. This allows frontline workers to wipe their device quickly and compliantly for the next shift. And organizations using SOTI or VMware Workspace ONE as their endpoint management solution can now also enroll Android devices in Microsoft Entra ID with shared device mode.

At Microsoft, we believe that technology can be a powerful force to reimagine how work gets done. By investing in innovative solutions for the frontline workforce, we are helping to drive positive change for frontline employees, customers and the bottom line. Frontline innovations across Dynamics 365 , Microsoft 365, Windows 365 Frontline, Intune and partner endpoint management solutions push the boundaries of what is possible and work toward a brighter future for all.

i Gartner, Hype Cycle™ for Digital Workplace Applications, 2022, August 2022

ii The Work Trend Index survey was conducted by an independent research firm, Edelman Data x Intelligence, among 31,000 full-time employed or self-employed workers across 31 markets, 6,019 of which are frontline workers, between February 1, 2023, and March 14, 2023. This survey was 20 minutes in length and conducted online, in either the English language or translated into a local language across markets. One thousand full-time workers were surveyed in each market, and global results have been aggregated across all responses to provide an average. Each market is evenly weighted within the global average. Each market was sampled to be representative of the full-time workforce across age, gender, and region; each sample included a mix of work environments (in-person, remote vs. non-remote, office settings vs. non-office settings, etc.), industries, company sizes, tenures, and job levels. Markets surveyed include: Argentina, Australia, Brazil, Canada, China, Colombia, Czech Republic, Finland, France, Germany, Hong Kong, India, Indonesia, Italy, Japan, Malaysia, Mexico, Netherlands, New Zealand, Philippines, Poland, Singapore, South Korea, Spain, Sweden, Switzerland, Taiwan, Thailand, United Kingdom, United States, and Vietnam.

Tags: AI, Microsoft 365 Copilot, Microsoft Dynamics 365 Copilot, Work Trend Index"
Microsoft_News,https://azure.microsoft.com/en-us/blog/scale-generative-ai-with-new-azure-ai-infrastructure-advancements-and-availability/,,Scale generative AI with new Azure AI infrastructure advancements and availability,"Generative AI is a powerful and transformational technology that has the potential to advance a wide range of industries from manufacturing to retail, and financial services to healthcare. Our early investments in hardware and AI infrastructure are helping customers to realize the efficiency and innovation generative AI can deliver. Our Azure AI infrastructure is the backbone of how we scale our offerings, with Azure OpenAI Service at the forefront of this transformation, providing developers with the systems, tools, and resources they need to build next-generation, AI-powered applications on the Azure platform. With generative AI, users can create richer user experiences, fuel innovation, and boost productivity for their businesses.

As part of our commitment to bringing the transformative power of AI to our customers, we’re announcing updates to how we’re empowering businesses with Azure AI infrastructure and applications. With the global expansion of Azure OpenAI Service, we are making OpenAI’s most advanced models, GPT-4 and GPT-35-Turbo, available in multiple new regions, providing businesses worldwide with unparalleled generative AI capabilities. Our Azure AI infrastructure is what powers this scalability, which we continue to invest in and expand. We’re also delivering the general availability of the ND H100 v5 Virtual Machine series, equipped with NVIDIA H100 Tensor Core graphics processing units (GPUs) and low-latency networking, propelling businesses into a new era of AI applications.

Here’s how these advancements extend Microsoft’s unified approach to AI across the stack.

General availability of ND H100 v5 Virtual Machine series: Unprecedented AI processing and scale

Today marks the general availability of our Azure ND H100 v5 Virtual Machine (VM) series, featuring the latest NVIDIA H100 Tensor Core GPUs and NVIDIA Quantum-2 InfiniBand networking. This VM series is meticulously engineered with Microsoft’s extensive experience in delivering supercomputing performance and scale to tackle the exponentially increasing complexity of cutting-edge AI workloads. As part of our deep and ongoing investment in generative AI, we are leveraging an AI optimized 4K GPU cluster and will be ramping to hundreds of thousands of the latest GPUs in the next year.

The ND H100 v5 is now available in the East United States and South Central United States Azure regions. Enterprises can register their interest in access to the new VMs or review technical details on the ND H100 v5 VM series at Microsoft Learn.

The ND H100 v5 VMs include the following features today:

AI supercomputing GPUs: Equipped with eight NVIDIA H100 Tensor Core GPUs, these VMs promise significantly faster AI model performance than previous generations, empowering businesses with unmatched computational power.

Next-generation computer processing unit (CPU): Understanding the criticality of CPU performance for AI training and inference, we have chosen the 4th Gen Intel Xeon Scalable processors as the foundation of these VMs, ensuring optimal processing speed.

Low-latency networking: The inclusion of NVIDIA Quantum-2 ConnectX-7 InfiniBand with 400Gb/s per GPU with 3.2 Tb/s per VM of cross-node bandwidth ensures seamless performance across the GPUs, matching the capabilities of top-performing supercomputers globally.

Optimized host to GPU performance: With PCIe Gen5 providing 64GB/s bandwidth per GPU, Azure achieves significant performance advantages between CPU and GPU.

Large scale memory and memory bandwidth: DDR5 memory is at the core of these VMs, delivering greater data transfer speeds and efficiency, making them ideal for workloads with larger datasets.

These VMs have proven their performance prowess, with up to six times more speedup in matrix multiplication operations when using the new 8-bit FP8 floating point data type compared to FP16 in previous generations. The ND H100 v5 VMs achieve up to two times more speedup in large language models like BLOOM 175B end-to-end model inference, demonstrating their potential to optimize AI applications further.

Azure OpenAI Service goes global: Expanding cutting-edge models worldwide

We are thrilled to announce the global expansion of Azure OpenAI Service, bringing OpenAI’s cutting-edge models, including GPT-4 and GPT-35-Turbo, to a wider audience worldwide. Our new live regions in Australia East, Canada East, East United States 2, Japan East, and United Kingdom South extend our reach and support for organizations seeking powerful generative AI capabilities. With the addition of these regions, Azure OpenAI Service is now available in even more locations, complementing our existing availability in East United States, France Central, South Central United States, and West Europe. The response to Azure OpenAI Service has been phenomenal, with our customer base nearly tripling since our last disclosure. We now proudly serve over 11,000 customers, attracting an average of 100 new customers daily this quarter. This remarkable growth is a testament to the value our service brings to businesses eager to harness the potential of AI for their unique needs.

As part of this expansion, we are increasing the availability of GPT-4, Azure OpenAI’s most advanced generative AI model, across the new regions. This enhancement allows more customers to leverage GPT-4’s capabilities for content generation, document intelligence, customer service, and beyond. With Azure OpenAI Service, organizations can propel their operations to new heights, driving innovation and transformation across various industries.

A responsible approach to developing generative AI

Microsoft’s commitment to responsible AI is at the core of Azure AI and Machine Learning. The AI platform incorporates robust safety systems and leverages human feedback mechanisms to handle harmful inputs responsibly, ensuring the utmost protection for users and end consumers. Businesses can apply for access to Azure OpenAI Service and unlock the full potential of generative AI to propel their operations to new heights.

We invite businesses and developers worldwide to join us in this transformative journey as we lead the way in AI innovation. Azure OpenAI Service stands as a testament to Microsoft’s dedication to making AI accessible, scalable, and impactful for businesses of all sizes. Together, let’s embrace the power of generative AI and Microsoft’s commitment to responsible AI practices to drive positive impact and growth worldwide.

Customer inspiration

Generative AI is revolutionizing various industries, including content creation and design, accelerated automation, personalized marketing, customer service, chatbots, product and service innovation, language translation, autonomous driving, fraud detection, and predictive analytics. We are inspired by the way our customers are innovating with generative AI and look forward to seeing how customers around the world build upon these technologies.

Mercedes-Benz is innovating its in-car experience for drivers, powered by Azure OpenAI Service. The upgraded “Hey Mercedes” feature is more intuitive and conversational than ever before. KPMG, a global professional services firm, leverages our service to improve its service delivery model, achieve intelligent automation, and enhance the coding lifecycle. Wayve trains large scale foundational neural-network for autonomous driving using Azure Machine Learning and Azure’s AI infrastructure. Microsoft partner SymphonyAI launched Sensa Copilot to empower financial crime investigators to combat the burden of illegal activity on the economy and organizations. By automating data collection, collation, and summarization of financial and third-party information, Sensa Copilot identifies money laundering behaviors and facilitates quick and efficient analysis for investigators. Discover all Azure AI and ML customer stories.

Learn more

Resources and getting started with Azure AI

Azure AI Portfolio

Azure AI Infrastructure

Azure OpenAI Service"
Microsoft_News,https://www.microsoft.com/en-us/security/blog/2023/08/07/microsoft-ai-red-team-building-future-of-safer-ai/,,Microsoft AI Red Team building future of safer AI,"An essential part of shipping software securely is red teaming. It broadly refers to the practice of emulating real-world adversaries and their tools, tactics, and procedures to identify risks, uncover blind spots, validate assumptions, and improve the overall security posture of systems. Microsoft has a rich history of red teaming emerging technology with a goal of proactively identifying failures in the technology. As AI systems became more prevalent, in 2018, Microsoft established the AI Red Team: a group of interdisciplinary experts dedicated to thinking like attackers and probing AI systems for failures.

We’re sharing best practices from our team so others can benefit from Microsoft’s learnings. These best practices can help security teams proactively hunt for failures in AI systems, define a defense-in-depth approach, and create a plan to evolve and grow your security posture as generative AI systems evolve.

The practice of AI red teaming has evolved to take on a more expanded meaning: it not only covers probing for security vulnerabilities, but also includes probing for other system failures, such as the generation of potentially harmful content. AI systems come with new risks, and red teaming is core to understanding those novel risks, such as prompt injection and producing ungrounded content. AI red teaming is not just a nice to have at Microsoft; it is a cornerstone to responsible AI by design: as Microsoft President and Vice Chair, Brad Smith, announced, Microsoft recently committed that all high-risk AI systems will go through independent red teaming before deployment.

The goal of this blog is to contextualize for security professionals how AI red teaming intersects with traditional red teaming, and where it differs. This, we hope, will empower more organizations to red team their own AI systems as well as provide insights into leveraging their existing traditional red teams and AI teams better.

Red teaming helps make AI implementation safer

Over the last several years, Microsoft’s AI Red Team has continuously created and shared content to empower security professionals to think comprehensively and proactively about how to implement AI securely. In October 2020, Microsoft collaborated with MITRE as well as industry and academic partners to develop and release the Adversarial Machine Learning Threat Matrix, a framework for empowering security analysts to detect, respond, and remediate threats. Also in 2020, we created and open sourced Microsoft Counterfit, an automation tool for security testing AI systems to help the whole industry improve the security of AI solutions. Following that, we released the AI security risk assessment framework in 2021 to help organizations mature their security practices around the security of AI systems, in addition to updating Counterfit. Earlier this year, we announced additional collaborations with key partners to help organizations understand the risks associated with AI systems so that organizations can use them safely, including the integration of Counterfit into MITRE tooling, and collaborations with Hugging Face on an AI-specific security scanner that is available on GitHub.

Security-related AI red teaming is part of a larger responsible AI (RAI) red teaming effort that focuses on Microsoft’s AI principles of fairness, reliability and safety, privacy and security, inclusiveness, transparency, and accountability. The collective work has had a direct impact on the way we ship AI products to our customers. For instance, before the new Bing chat experience was released, a team of dozens of security and responsible AI experts across the company spent hundreds of hours probing for novel security and responsible AI risks. This was in addition to the regular, intensive software security practices followed by the team, as well as red teaming the base GPT-4 model by RAI experts in advance of developing Bing Chat. Our red teaming findings informed the systematic measurement of these risks and built scoped mitigations before the product shipped.

Guidance and resources for red teaming

AI red teaming generally takes place at two levels: at the base model level (e.g., GPT-4) or at the application level (e.g., Security Copilot, which uses GPT-4 in the back end). Both levels bring their own advantages: for instance, red teaming the model helps to identify early in the process how models can be misused, to scope capabilities of the model, and to understand the model’s limitations. These insights can be fed into the model development process to improve future model versions but also get a jump-start on which applications it is most suited for. Application-level AI red teaming takes a system view, of which the base model is one part. For instance, when AI red teaming Bing Chat, the entire search experience powered by GPT-4 was in scope and was probed for failures. This helps to identify failures beyond just the model-level safety mechanisms, by including the overall application specific safety triggers.

Together, probing for both security and responsible AI risks provides a single snapshot of how threats and even benign usage of the system can compromise the integrity, confidentiality, availability, and accountability of AI systems. This combined view of security and responsible AI provides valuable insights not just in proactively identifying issues, but also to understand their prevalence in the system through measurement and inform strategies for mitigation. Below are key learnings that have helped shape Microsoft’s AI Red Team program.

AI red teaming is more expansive. AI red teaming is now an umbrella term for probing both security and RAI outcomes. AI red teaming intersects with traditional red teaming goals in that the security component focuses on model as a vector. So, some of the goals may include, for instance, to steal the underlying model. But AI systems also inherit new security vulnerabilities, such as prompt injection and poisoning, which need special attention. In addition to the security goals, AI red teaming also includes probing for outcomes such as fairness issues (e.g., stereotyping) and harmful content (e.g., glorification of violence). AI red teaming helps identify these issues early so we can prioritize our defense investments appropriately. AI red teaming focuses on failures from both malicious and benign personas. Take the case of red teaming new Bing. In the new Bing, AI red teaming not only focused on how a malicious adversary can subvert the AI system via security-focused techniques and exploits, but also on how the system can generate problematic and harmful content when regular users interact with the system. So, unlike traditional security red teaming, which mostly focuses on only malicious adversaries, AI red teaming considers broader set of personas and failures. AI systems are constantly evolving. AI applications routinely change. For instance, in the case of a large language model application, developers may change the metaprompt (underlying instructions to the ML model) based on feedback. While traditional software systems also change, in our experience, AI systems change at a faster rate. Thus, it is important to pursue multiple rounds of red teaming of AI systems and to establish systematic, automated measurement and monitor systems over time. Red teaming generative AI systems requires multiple attempts. In a traditional red teaming engagement, using a tool or technique at two different time points on the same input, would always produce the same output. In other words, generally, traditional red teaming is deterministic. Generative AI systems, on the other hand, are probabilistic. This means that running the same input twice may provide different outputs. This is by design because the probabilistic nature of generative AI allows for a wider range in creative output. This also makes it tricky to red teaming since a prompt may not lead to failure in the first attempt, but be successful (in surfacing security threats or RAI harms) in the succeeding attempt. One way we have accounted for this is, as Brad Smith mentioned in his blog, to pursue multiple rounds of red teaming in the same operation. Microsoft has also invested in automation that helps to scale our operations and a systemic measurement strategy that quantifies the extent of the risk. Mitigating AI failures requires defense in depth. Just like in traditional security where a problem like phishing requires a variety of technical mitigations such as hardening the host to smartly identifying malicious URIs, fixing failures found via AI red teaming requires a defense-in-depth approach, too. This involves the use of classifiers to flag potentially harmful content to using metaprompt to guide behavior to limiting conversational drift in conversational scenarios.

Building technology responsibly and securely is in Microsoft’s DNA. Last year, Microsoft celebrated the 20-year anniversary of the Trustworthy Computing memo that asked Microsoft to deliver products “as available, reliable and secure as standard services such as electricity, water services, and telephony.” AI is shaping up to be the most transformational technology of the 21st century. And like any new technology, AI is subject to novel threats. Earning customer trust by safeguarding our products remains a guiding principle as we enter this new era – and the AI Red Team is front and center of this effort. We hope this blog post inspires others to responsibly and safely integrate AI via red teaming.

Resources

AI red teaming is part of the broader Microsoft strategy to deliver AI systems securely and responsibly. Here are some other resources to provide insights into this process:

Contributions from Steph Ballard, Forough Poursabzi, Amanda Minnich, Gary Lopez Munoz, and Chang Kawaguchi."
Microsoft_News,https://blogs.bing.com/search/august-2023/Celebrating-6-months-of-the-new-AI-powered-Bing,,Celebrating 6 months of the new AI-powered Bing,"It’s been six months since we reinvented search with the new AI-powered Bing and Edge. In that short time, you’ve engaged in so many unique and creative ways; to date we’ve seen over 1 billion chats and over 750 million images fill the world of Bing! We’ve also seen nine consecutive quarters of growth on Edge, meaning we’re more able than ever to bring our best-in-class AI experiences to users across the web.



While we’re excited to see where we’ll go in the next six months, we wanted to take a moment to celebrate how much the game has changed so far.



Smarter ways to get things done



Bing Image Creator: Powered by the latest DALL∙E models from our partners at OpenAI, Bing Image Creator allows you to bring your ideas to life, simply by using your own words to describe the picture you want to see. For example, you can go from chatting with Bing about recommended décor choices for your living room, to asking Bing to draw up a few of the options to help visualize what it would look like in real life. We’ve already heard of many great scenarios combining visual and verbal AI-generated content in one place, and we’re excited for you to see what’s next.



Chat History: Your feedback told us you loved the answers from previous chats and wished they could be saved for future reference. Since then, we’ve made updates to the Bing Chat experience—Bing now remembers the history of previous chats t and displays them on the right-hand side of the chat window under “Recent Activity”. From there, you can return to any previously saved conversation and pick up where you left off. Chat History also has controls that allow you to easily delete, rename, export, or share a specific conversation with others, so the insight you get from a great chat doesn’t just last for just the initial conversation itself.

AI-powered search wherever you are



Bing Mobile App – The flagship Bing app lets you access our best-in-class AI-powered features on the go, across your mobile devices. With our new AI-powered Bing features, you get full access to Bing: complete, cited answers without having to scroll through endless links; access to Bing Image Creator features on your phone or tablet; and more. We also worked hard to deliver mobile-specific scenarios, such as a homescreen widget; if you’ve got your hands full running errands, for example, you can simply click into the Bing app from your homescreen, ask a question using voice input, and get Bing’s response—all with only few clicks!



Windows Copilot: Our AI revolution is not limited just to the web; just like we brought new AI experiences to mobile devices, we’ve brought them your PC as well! With Windows Copilot, Windows is the first PC platform to provide centralized AI experiences to its customers. With Windows Copilot and Bing Chat, you can focus on bringing your ideas to life, completing complex projects, and collaborating instead of spending energy finding, launching, and working across multiple applications. Windows Copilot makes every user a power user, helping you take action, customize your settings, and seamlessly connect across your favorite apps Available today for Windows Insiders.



Bing in SwiftKey: Millions of people around the world love SwiftKey for its AI-powered predictive text technology, which makes texting without typos easier, even when you’re in a rush or multi-tasking. Bing integrates into SwiftKey in three major ways—Search, Chat, and Tone—which you can access by clicking the Bing icon on the keyboard. These features let you leverage the power of AI to do things like compose texts, get AI translations from one language to another, edit the tone of an email, and more.

Newest features



Third-Party Browser Support: With so many new, useful features now a part of Bing, we’re excited to announce you can start experiencing the new AI-powered Bing in third-party browsers on web and mobile soon. This next step in the journey allows Bing to showcase the incredible value of summarized answers, image creation and more, to a broader array of people. You’ll get most of the great benefits of Bing and we’ll continue to optimize along the way to meet your needs across different browsers. While these experiences work well in your preferred browser, for the best-in-class Bing Chat experience, we continue to encourage you to use Bing in the Microsoft Edge browser. With Edge, you'll unlock longer conversations, chat history, and more Bing features built right into the browser. To experience the best browser for Bing, and get the full breadth of features, simply open the Microsoft Edge browser and click the Bing Chat icon in the sidebar.



Multimodal Visual Search in Chat: This feature leverages OpenAI models to let you to input into Chat with images—either a picture you’ve taken or one you’ve found elsewhere—and prompt Bing Chat with related questions. Bing Chat can understand the context of an image, interpret it, and answer questions about it. For example, you can use Visual Search to ask Bing Chat about the architecture of a building you’ve taken a picture of or take a picture of the contents of your fridge and ask for lunch ideas.



Dark Mode: This feature, which saves battery and is easier on your eyes, now works in both Bing Chat and Bing Chat Enterprise in your desktop browser, and it’s also available in the Bing mobile app. This was another top requested feature, and we’re glad to have brought it to you.



Bing Chat Enterprise: Bing Chat Enterprise brings the power of the new AI-powered Bing to work. Our next search experience gives your organization AI-powered chat – complete with verifiable answers and citations as well as commercial data protection. With Bing Chat Enterprise, user and business data are protected and will not leak outside the organization. What goes in—and comes out—remains protected.



As excited as we are by the progress from these first six months, we’re even more excited by what’s to come in the next six months! We’re already hard at work on new experiences like Bing Chat plug-ins and refining existing experiences, but we also want to keep hearing from you! Feedback is one of our sources of inspiration and a great way to ensure as we build the future of AI-powered search that we’re delivering features that are as helpful and delightful as possible for you. So please, keep the feedback coming!



Thanks,



The Bing Team"
Microsoft_News,https://podcasts.apple.com/us/podcast/kevin-scott-putting-ai-into-the-hands-of-people-everywhere/id1632459165?i=1000623337683,,‎Tools and Weapons with Brad Smith: Kevin Scott: Putting AI into the hands of people everywhere on Apple Podcasts,"Microsoft’s Chief Technology Officer, Kevin Scott, believes that for AI to benefit everyone, humans must be at the center of its development. His philosophy was shaped by his rural Virginia roots, where he belonged to a hardworking community that used creativity, perseverance, and curiosity to support each other and tackle practical challenges.



In this episode, we talk about how a culture grounded in human values can lead to safer products, how AI can increase access to critical services like education and medicine, and what Chopin’s G Minor Ballade can teach us about AI and human connection."
Microsoft_News,https://www.linkedin.com/pulse/fighting-wildfire-ai-juan-m-lavista-ferres,,Fighting wildfire with AI,"As we think about the growing wildfire season around the world and its impact on people and the planet, it’s easy to feel powerless. But AI can help.

Wildfires are already breaking records in North America. So far this year, we’ve seen more than 28 million acres burned in Canada, blanketing smoke across the east coast and creating unsafe air for millions. Recent fires surrounding the Mediterranean resulted in the evacuation of thousands and in the death of two helicopter pilots in Greece. In July, we saw the hottest day on Earth ever recorded, four days in a row, creating dangerous heat conditions and perpetuating drought-like conditions. And according to a recent Challenge Seattle report, in Microsoft’s home state of Washington, we should expect to spend several days indoors again this year. Memories are still fresh from 2022 when multiple parts of the state had the worst air quality in the world for several days.

How can we mitigate this crisis?

One of the biggest challenges is that forest fires are the result of random variables – a stochastic process – so it’s impossible to predict exactly when and where they will occur. In addition, forests are vast and managing resources to know how and when to deploy firefighting tools is difficult. In Washington state alone, there are over 22.5 million forested acres, covering about half of the state’s land area. At the Microsoft AI for Good Lab, we knew AI could potentially be a powerful tool. With AI, we can build probability models that can help us to better prepare and have help ready where it will be needed most. Accurate and reliable prediction of wildfires can help the stakeholders and decision-makers take timely, strategic, and effective actions to prevent, detect and, suppress the wildfires before they become out of control.

To see if we can accurately and reliably predict wildfires based on prediction modeling, we developed a framework based on historical burned area maps, climate, and geospatial data to see how AI could be used to model and predict risk for wildfires with the goal of better resource management and deployment to help fight wildfires.

In collaboration with Dr. Narendran Kodandapani from the Center for Advanced Spatial and Environmental Research in Bengaluru and the Indian Space Research Organization, we focused on the Western Ghats Mountain range in India. This UNESCO World Heritage site includes one of the “world’s eight ‘hottest hotspots’ of biological diversity” and is home to one of the best representatives of non-equatorial tropical evergreen forests anywhere, along with at least 325 globally threatened flora, fauna, bird, amphibian, reptile, and fish species. It is also home to devastating annual forest fires during the dry summer season.

While predicting wildfires is extremely challenging, we demonstrated that the historical data and machine learning models provide important insights to decision-makers on how to direct their resources more efficiently. Reasoning over this data, and making sense of it, would be impossible without AI. This modeling framework and evaluation scheme can be used for any landscapes where historically burned areas or wildfire incidents are available. Such proactive actions can help minimize potential damage caused by the ignition and the spread of future fires.

Researchers and Microsoft are also working to improve seasonal forecasting to help with water allocation and wildfire management. Improvements in adaptive bias correction – a method that combines these forecasts with models that use machine learning and AI – are markedly improving the ability to predict both temperature and precipitation two to six weeks in advance. This information will be used by local and federal agencies in the US and beyond.

Other AI Solutions

Microsoft isn’t the only company using AI to help solve this problem. Bringing machine learning technology to wildfire detection, start-up Pano AI offers an early detection tool that combines the power of AI and cloud-based software, and leverages cameras, satellites, and other data feeds to identify smoke and fire immediately, pinpoint latitude and longitude, and automatically alert fire-monitoring professionals to deploy resources quickly.

And RADR-Fire – or Rapid Analytics for Disaster Response for Wildfires, developed by the Pacific Northwest National Laboratory – uses remote sensing data to map and analyze wildfire behavior, inform fire management decisions, and predict future damage. RADRFIRE can predict the direction and speed of wildfires and pinpoint hardest-hit areas and can highlight hot spots to inform where fire retardant should be dropped, project what interventions might be best suited to suppress the fire in the moment based on past fires experiences, and suggest emergency exit routes.

As we get deeper into another wildfire season, it’s heartening to see advances in this technology to help."
Microsoft_News,https://www.microsoft.com/en-us/worklab/why-using-a-polite-tone-with-ai-matters,,Why Using a Polite Tone with AI Matters,"This article first appeared in the WorkLab newsletter. Be the first to get our updates by subscribing here.

We’ve all heard the advice to “treat others the way you want to be treated.” But does that apply to AI?

It should, says Microsoft’s Kurtis Beavers, a director on the design team for Microsoft Copilot. It’s not that your AI chatbot feels appreciative when you say please and thank you. But using basic etiquette when interacting with AI, Beavers tells WorkLab , helps generate respectful, collaborative outputs.

“Using polite language sets a tone for the response,” he explains. LLMs—large language models, a.k.a. generative AI—are trained on human conversations. In the same way that your email autocomplete suggests a likely next word or phrase, LLMs pick a sentence or paragraph it thinks you might want based on your input. Put another way, it’s a giant prediction machine making highly probabilistic guesses at what would plausibly come next. So when it clocks politeness, it’s more likely to be polite back. The same is true of your colleagues, strangers on the street, and the barista making your iced Americano: when you’re kind to them, they tend to be kind to you too.

Generative AI also mirrors the levels of professionalism, clarity, and detail in the prompts you provide. “It’s a conversation,” Beavers says—and it’s on the user to set the vibe. (On the flip side, if you use provocative or rude language, you’ll likely get some sass back. Just like humans, AI can’t always be the bigger person.)

Rather than order your chatbot around, start your prompts with “please”: please rewrite this more concisely ; please suggest 10 ways to rebrand this product . Say thank you when it responds, and be sure to tell it you appreciate the help. Doing so not only ensures you get the same graciousness in return, but it also improves the AI’s responsiveness and performance.

An added bonus? It’s good practice for interacting with humans."
Microsoft_News,https://www.linkedin.com/posts/bradsmi_six-additional-commitments-to-expand-responsible-activity-7090346212637204480-_8iD/,,Brad Smith on LinkedIn: Six Additional Commitments to Expand Responsible AI,"Last week, Microsoft shared our strong support for The White House’s Voluntary AI Commitments. Harnessing AI in ways that will benefit society requires advanced AI to be safe, secure, and trustworthy. The commitments set forth by the White House are an important step in these efforts and we look forward to working with our industry peers, government, civil society, and academia to realize the goals. We also want to highlight six additional commitments Microsoft made to further expand our responsible AI practices. We believe that these will help us deliver more trustworthy AI systems that benefit not only our customers, but the whole of society. These steps advance transparency and accountability. They range from supporting a pilot of the National AI Research Resource to advocating for the establishment of a national registry of high-risk AI systems. We have also committed to broad-scale implementation of the NIST AI Risk Management Framework, and adoption of cybersecurity practices that are attuned to unique AI risks. We continue to strengthen our responsible AI program and integrate it across the company. We believe this is critical to unlock the potential of AI to have positive impacts on communities around the globe while staying clear-eyed about the risks. Here is a bit more detail on our commitments."
Microsoft_News,https://news.microsoft.com/source/shortform/nc-fusion/,,NC Fusion,"Another NC Fusion player, Madison Casteen , 15, knows s occer’s demands may chase away some girls . But the game has show n Casteen that she thrives under pressure : “ Everything’s not going to be handed to you. You have to push through.”

"
Microsoft_News,https://blogs.microsoft.com/on-the-issues/2023/07/26/anthropic-google-microsoft-openai-launch-frontier-model-forum/,,"Microsoft, Anthropic, Google, and OpenAI launch Frontier Model Forum","Microsoft, Anthropic, Google , and OpenAI are launching the Frontier Model Forum, an industry body focused on ensuring safe and responsible development of frontier AI models.

The Forum aims to help (i) advance AI safety research to promote responsible development of frontier models and minimize potential risks, (ii) identify safety best practices for frontier models, (iii) share knowledge with policymakers, academics, civil society , and others to advance responsible AI development; and (iv) support efforts to leverage AI to address society’s biggest challenges.

The Frontier Model Forum will establish an Advisory Board to help guide its strategy and priorities.

The Forum welcomes participation from other organizations developing frontier AI models willing to collaborate toward the safe advancement of these models.

July 26, 2023 – Today, Anthropic, Google, Microsoft, and OpenAI are announcing the formation of the Frontier Model Forum, a new industry body focused on ensuring safe and responsible development of frontier AI models. The Frontier Model Forum will draw on the technical and operational expertise of its member companies to benefit the entire AI ecosystem, such as through advancing technical evaluations and benchmarks, and developing a public library of solutions to support industry best practices and standards.

The core objectives for the Forum are:

Advancing AI safety research to promote responsible development of frontier models, minimize risks, and enable independent, standardized evaluations of capabilities and safety. Identifying best practices for the responsible development and deployment of frontier models, helping the public understand the nature, capabilities, limitations, and impact of the technology. Collaborating with policymakers, academics, civil society , and companies to share knowledge about trust and safety risks. Supporting efforts to develop applications that can help meet society’s greatest challenges , such as climate change mitigation and adaptation, early cancer detection and prevention, and combating cyber threats.

Membership criteria

The Forum defines frontier models as large-scale machine-learning models that exceed the capabilities currently present in the most advanced existing models, and can perform a wide variety of tasks.

Frontier Model Forum membership is open to organizations that:

Develop and deploy frontier models (as defined by the Forum).

Demonstrate strong commitment to frontier model safety, including through technical and institutional approaches.

Are willing to contribute to advancing the Frontier Model Forum’s efforts including by participating in joint initiatives and supporting the development and functioning of the initiative.

The Forum welcomes organizations that meet these criteria to join this effort and collaborate on ensuring the safe and responsible development of frontier AI models.

What the Frontier Model Forum will do

Governments and industry agree that, while AI offers tremendous promise to benefit the world, appropriate guardrails are required to mitigate risks. Important contributions to these efforts have already been made by the U.S. and UK governments, the European Union, the OECD, the G7 (via the Hiroshima AI process), and others.

To build on these efforts, further work is needed on safety standards and evaluations to ensure frontier AI models are developed and deployed responsibly. The Forum will be one vehicle for cross-organizational discussions and actions on AI safety and responsibility.

The Frontier Model Forum will focus on three key areas over the coming year to support the safe and responsible development of frontier AI models:

Identifying best practices: Promote knowledge sharing and best practices among industry, governments, civil society, and academia, with a focus on safety standards and safety practices to mitigate a wide range of potential risks.

Advancing AI safety research: Support the AI safety ecosystem by identifying the most important open research questions on AI safety. The Forum will coordinate research to progress these efforts in areas such as adversarial robustness, mechanistic interpretability, scalable oversight, independent research access, emergent behaviors, and anomaly detection. There will be a strong focus initially on developing and sharing a public library of technical evaluations and benchmarks for frontier AI models.

Facilitating information sharing among companies and governments: Establish trusted, secure mechanisms for sharing information among companies, governments, and relevant stakeholders regarding AI safety and risks. The Frontier Model Forum will follow best practices in responsible disclosure from areas such as cybersecurity.

Kent Walker, President, Global Affairs, Google & Alphabet said: “We’re excited to work together with other leading companies, sharing technical expertise to promote responsible AI innovation. Engagement by companies, governments, and civil society will be essential to fulfill the promise of AI to benefit everyone.”

Brad Smith, Vice Chair & President, Microsoft said: “Companies creating AI technology have a responsibility to ensure that it is safe, secure, and remains under human control. This initiative is a vital step to bring the tech sector together in advancing AI responsibly and tackling the challenges so that it benefits all of humanity.”

Anna Makanju, Vice President of Global Affairs, OpenAI said: “Advanced AI technologies have the potential to profoundly benefit society, and the ability to achieve this potential requires oversight and governance. It is vital that AI companies – especially those working on the most powerful models – align on common ground and advance thoughtful and adaptable safety practices to ensure powerful AI tools have the broadest benefit possible. This is urgent work and this forum is well– positioned to act quickly to advance the state of AI safety.”

Dario Amodei, CEO, Anthropic said: “Anthropic believes that AI has the potential to fundamentally change how the world works. We are excited to collaborate with industry, civil society, government, and academia to promote safe and responsible development of the technology. The Frontier Model Forum will play a vital role in coordinating best practices and sharing research on frontier AI safety.”

How the Frontier Model Forum will work

Over the coming months, the Frontier Model Forum will establish an Advisory Board to help guide its strategy and priorities, representing a diversity of backgrounds and perspectives.

The founding Frontier Model Forum companies will also establish key institutional arrangements including a charter, governance, and funding with a working group and executive board to lead these efforts. We plan to consult with civil society and governments in the coming weeks on the design of the Forum and on meaningful ways to collaborate.

The Frontier Model Forum welcomes the opportunity to help support and feed into existing government and multilateral initiatives such as the G7 Hiroshima process, the OECD’s work on AI risks, standards, and social impact, and the U.S.-EU Trade and Technology Council.

The Forum will also seek to build on the valuable work of existing industry, civil society, and research efforts across each of its workstreams. Initiatives such as the Partnership on AI and MLCommons continue to make important contributions across the AI community, and the Frontier Model Forum will explore ways to collaborate with and support these and other valuable multistakeholder efforts.

Tags: AI, artificial intelligence, European Union, Frontier Model Forum, machine learning, Responsible AI"
Microsoft_News,https://blogs.microsoft.com/on-the-issues/2023/07/21/commitment-safe-secure-ai/,,"Our commitments to advance safe, secure, and trustworthy AI","Today, Microsoft is announcing its support for new voluntary commitments crafted by the Biden-Harris administration to help ensure that advanced AI systems are safe, secure, and trustworthy. By endorsing all of the voluntary commitments presented by President Biden and independently committing to several others that support these critical goals, Microsoft is expanding its safe and responsible AI practices, working alongside other industry leaders.

By moving quickly, the White House’s commitments create a foundation to help ensure the promise of AI stays ahead of its risks. We welcome the President’s leadership in bringing the tech industry together to hammer out concrete steps that will help make AI safer, more secure, and more beneficial for the public.

Guided by the enduring principles of safety, security, and trust, the voluntary commitments address the risks presented by advanced AI models and promote the adoption of specific practices – such as red-team testing and the publication of transparency reports – that will propel the whole ecosystem forward. The commitments build upon strong pre-existing work by the U.S. Government (such as the NIST AI Risk Management Framework and the Blueprint for an AI Bill of Rights) and are a natural complement to the measures that have been developed for high-risk applications in Europe and elsewhere. We look forward to their broad adoption by industry and inclusion in the ongoing global discussions about what an effective international code of conduct might look like.

Microsoft’s additional commitments focus on how we will further strengthen the ecosystem and operationalize the principles of safety, security, and trust. From supporting a pilot of the National AI Research Resource to advocating for the establishment of a national registry of high-risk AI systems, we believe that these measures will help advance transparency and accountability. We have also committed to broad-scale implementation of the NIST AI Risk Management Framework, and adoption of cybersecurity practices that are attuned to unique AI risks. We know that this will lead to more trustworthy AI systems that benefit not only our customers, but the whole of society.

You can view the detailed commitments Microsoft has made here.

It takes a village to craft commitments such as these and put them into practice at Microsoft. I would like to take this opportunity to thank Kevin Scott, Microsoft’s Chief Technology Officer, with whom I co-sponsor our responsible AI program, as well as Natasha Crampton, Sarah Bird, Eric Horvitz, Hanna Wallach, and Ece Kamar, who have played key leadership roles in our responsible AI ecosystem.

As the White House’s voluntary commitments reflect, people must remain at the center of our AI efforts and I’m grateful to have strong leadership in place at Microsoft to help us deliver on our commitments and continue to develop the program we have been building for the last seven years. Establishing codes of conduct early in the development of this emerging technology will not only help ensure safety, security, and trustworthiness, it will also allow us to better unlock AI’s positive impact for communities across the U.S. and around the world."
Microsoft_News,https://blogs.microsoft.com/blog/2023/07/18/microsoft-and-meta-expand-their-ai-partnership-with-llama-2-on-azure-and-windows/,,Microsoft and Meta expand their AI partnership with Llama 2 on Azure and Windows,"In recent months, the remarkable strides made in AI innovation have ignited a wave of transformative possibilities, captivating our collective imagination with the promise of reshaping industries and the way we work.

Today, at Microsoft Inspire, Meta and Microsoft announced support for the Llama 2 family of large language models (LLMs) on Azure and Windows. Llama 2 is designed to enable developers and organizations to build generative AI-powered tools and experiences. Meta and Microsoft share a commitment to democratizing AI and its benefits and we are excited that Meta is taking an open approach with Llama 2. We offer developers choice in the types of models they build on, supporting open and frontier models and are thrilled to be Meta’s preferred partner as they release their new version of Llama 2 to commercial customers for the first time.

Now Azure customers can fine-tune and deploy the 7B, 13B, and 70B-parameter Llama 2 models easily and more safely on Azure, the platform for the most widely adopted frontier and open models. In addition, Llama will be optimized to run locally on Windows. Windows developers will be able to use Llama by targeting the DirectML execution provider through the ONNX Runtime, allowing a seamless workflow as they bring generative AI experiences to their applications.

Our growing partnership with Meta

Meta and Microsoft have been longtime partners on AI, starting with a collaboration to integrate ONNX Runtime with PyTorch to create a great developer experience for PyTorch on Azure, and Meta’s choice of Azure as a strategic cloud provider. Today’s announcement builds on our partnership to accelerate innovation in the era of AI and further extends Microsoft’s open model ecosystem and position as the world’s supercomputing platform for AI.

Azure’s purpose-built AI supercomputing platform is uniquely designed from the facility, hardware and software to support the world’s leading AI organizations to build, train and deploy some of the most demanding AI workloads. The availability of the Llama 2 models with Azure AI enables developers to take advantage of Azure AI’s powerful tooling for model training, fine-tuning, inference, and particularly the capabilities that support AI safety.

The inclusion of the Llama 2 models in Windows helps propel Windows as the best place for developers to build AI experiences tailored for their customers’ needs and unlock their ability to build using world-class tools like Windows Subsystem for Linux (WSL), Windows terminal, Microsoft Visual Studio and VS Code.

Expanding Azure AI model catalog and Windows availability

Llama 2 is the latest addition to our growing Azure AI model catalog. The model catalog, currently in public preview, serves as a hub of foundation models and empowers developers and machine learning (ML) professionals to easily discover, evaluate, customize and deploy pre-built large AI models at scale.

The catalog eliminates the need for users to manage all infrastructure dependencies when operationalizing Llama 2. It provides turnkey support for model fine-tuning and evaluation, including powerful optimization techniques such as DeepSpeed and ONNX Runtime, that can significantly enhance the speed of model fine-tuning.

Windows developers will be able to easily build new experiences using Llama 2 that can be accessed via GitHub Repo. With Windows Subsystem for Linux and highly capable GPUs, developers can fine tune LLMs to meet their specific needs right on their Windows PCs.

Building responsibly with Azure

Responsible AI is at the heart of Microsoft’s approach to AI and how we partner. For years we’ve invested heavily in making Azure the place for responsible, cutting-edge AI innovation, whether customers are building their own models or using pre-built and customizable models from Microsoft, Meta, OpenAI and the open-source ecosystem.

At Microsoft, we mitigate potential risks presented by the use of large language models through an iterative, layered approach that includes experimentation and measurement. Azure AI customers can test Llama 2 with their own sample data to see how it performs for their particular use case. Then, customers can use prompt engineering and retrieval augmented generation (RAG) techniques to develop, evaluate and optimize meta-prompts for their app and deliver safer and more reliable experiences for end users.

Services like Azure AI Content Safety add another layer of protection, helping ensure a safer online experience with AI apps. Part of our collaboration with Meta led to combining Meta’s safety techniques with Azure AI Content Safety so that by default, the deployments of the Llama 2 models in Azure AI come with a layered safety approach.

Today’s expansion of our model catalog with Llama 2 and our partnership with Meta is a big step forward in achieving a responsible, open approach to AI.

Visit the Azure AI model catalog and start using Llama 2 today.

Tags: Azure, Azure AI, large language models, Llama 2, Meta, Microsoft Inspire"
Microsoft_News,https://blogs.microsoft.com/blog/2023/07/18/furthering-our-ai-ambitions-announcing-bing-chat-enterprise-and-microsoft-365-copilot-pricing/,,Furthering our AI ambitions – Announcing Bing Chat Enterprise and Microsoft 365 Copilot pricing,"Updated November 15, 2023: To simplify the user experience and make Copilot more accessible to everyone, Bing Chat and Bing Chat Enterprise will now simply become Microsoft Copilot. For more information: https://aka.ms/BingIgnite

At Microsoft, we are working to provide a copilot for every person in their lives and at work. Earlier this year, we introduced the new AI-powered Bing, your copilot for the web, fundamentally reinventing search as a category with complete answers, a full chat experience, and features to unlock creativity. We also introduced Microsoft 365 Copilot, which combines the power of large language models (LLMs) with your data in the Microsoft Graph and Microsoft 365 apps to usher in a whole new way of working, using just your own words. Since then, we’ve seen millions of people incorporate Bing into their lives for the first time in new ways to unlock their creativity and gain a better understanding of the world.

And feedback from customers in our Microsoft 365 Copilot Early Access Program, is that Copilot promises to be a game changer for productivity.

Today at Microsoft Inspire, we’re excited to unveil the next steps in our journey: First, we’re significantly expanding Bing to reach new audiences with Bing Chat Enterprise, delivering AI-powered chat for work, and rolling out today in Preview – which means that more than 160 million people already have access. Second, to help commercial customers plan, we’re sharing that Microsoft 365 Copilot will be priced at $30 per user, per month for Microsoft 365 E3, E5, Business Standard and Business Premium customers, when broadly available; we’ll share more on timing in the coming months. Third, in addition to expanding to more audiences, we continue to build new value in Bing Chat and are announcing Visual Search in Chat, a powerful new way to search, now rolling out broadly in Bing Chat.

Bing Chat Enterprise — AI-powered chat for work

Employees are looking to use AI tools to help them unlock creativity and productivity at work — 70% say they would delegate as much work as possible to AI according to our Work Trend Index. But using AI tools that aren’t built for the enterprise inadvertently puts sensitive business data at risk. As organizations adopt AI, they want to be confident their data is protected.

Bing Chat Enterprise gives your organization AI-powered chat for work with commercial data protection. With Bing Chat Enterprise, user and business data are protected and will not leak outside the organization. What goes in — and comes out — remains protected. Chat data is not saved, and Microsoft has no eyes-on access – which means no one can view your data. And, your data is not used to train the models. Whether researching industry insights, analyzing data, or looking for inspiration, Bing Chat Enterprise gives people access to better answers, greater efficiency and new ways to be creative.

YouTube Video Click here to load media

Just like Bing Chat, Bing Chat Enterprise is grounded in web data and provides complete, verifiable answers with citations, along with visual answers that include graphs, charts and images, and is designed in line with our AI principles.

Bing Chat Enterprise is rolling out in preview today and is included at no additional cost in Microsoft 365 E3, E5, Business Standard and Business Premium. And in the future, it will be available as a stand-alone offering for $5 per user, per month. You can access Bing Chat Enterprise using your work account wherever Bing Chat is supported — Bing.com/chat and the Microsoft Edge sidebar. And, in the future, Bing Chat Enterprise will also be accessible from Windows Copilot.

Announcing Microsoft 365 Copilot pricing for commercial customers

Bing Chat Enterprise unlocks generative AI for work. And Microsoft 365 Copilot brings a whole new way of working – reasoning over all your business data in the context of your enterprise, including the ability to ask questions and get answers from the web. Microsoft 365 Copilot will be available for commercial customers for $30 per user per month for Microsoft 365 E3, E5, Business Standard and Business Premium customers when broadly available.

Microsoft 365 Copilot is built on Microsoft’s trusted and comprehensive approach to enterprise-grade security, privacy, identity, compliance and responsible AI — so you know it’s enterprise ready. This means:

Copilot inherits your existing Microsoft 365 security, privacy, identity and compliance policies.

Your data is logically isolated and protected within your Microsoft 365 tenant, and always within your control.

At the tenant level, Copilot respects individual and group permission policies.

While some generative AI apps focus on a single capability, like real-time transcription or copywriting, Microsoft 365 Copilot is in a class all its own. It has all the capabilities of Bing Chat Enterprise, plus so much more. Copilot puts thousands of skills at your command and can reason over all your content and context to take on any task. It’s grounded in your business data in the Microsoft Graph — that’s all your emails, calendar, chats, documents and more. So, Copilot can generate an update from the morning’s meetings, emails and chats to send to the team; get you up to speed on project developments from the last week; or create a SWOT analysis from internal files and data from the web.

Microsoft 365 Copilot is incredible on its own, and it’s also integrated into the apps millions of people use every day. Copilot jump-starts your creativity in Word, analyzes data in Excel, designs presentations in PowerPoint, triages your Outlook inbox, summarizes meetings in Teams – whether you attended or not – and so much more.

In May, we announced the expansion of our Microsoft 365 Copilot paid Early Access Program to 600 enterprise customers worldwide, including companies like KPMG, Lumen, and Emirates NBD. We’re learning that the more customers use Copilot, the more their enthusiasm for Copilot grows. Soon, no one will want to work without it.

Microsoft 365 Copilot: Thousands of skills. All your data. Infinite possibilities. Learn more here.

YouTube Video Click here to load media

Search with images — not just words — using Visual Search in Chat

In addition to unlocking the power of generative AI to people at work, we continue to deliver new features and experiences in Bing Chat to help people make the most of this technology. Part of this work is a focus on building visual features in Bing Chat. And today we’re pleased to announce we’re rolling out multimodal capabilities via Visual Search in Chat.

Leveraging OpenAI’s GPT-4 model, Visual Search in Chat lets anyone upload images and search the web for related content. Take a picture, or use one you find elsewhere, and prompt Bing to tell you about it — Bing can understand the context of an image, interpret it, and answer questions about it. Whether you’re traveling to a new city on vacation and asking about the architecture of a particular building or at home trying to come up with lunch ideas based on the contents of your fridge, upload the image into Bing Chat and use it to harness the web’s knowledge to get you answers. Visual Search in Chat is beginning to roll out now via desktop and the Bing mobile app and we are working to bring this to Bing Chat Enterprise over time.

YouTube Video Click here to load media

There is incredible opportunity for our customers and partners to realize the promise of AI in life and at work – and do so in a way that meets the highest standards for enterprise, security, privacy, compliance and responsible AI. We’re excited about what the future holds – and we’re just getting started.

Editor’s note: As of Aug. 21, we have extended Bing Chat Enterprise eligibility to Microsoft 365 A3 and A5 licenses for faculty. Read the official announcement at https://aka.ms/BCEforEDUFaculty

Tags: AI, Bing Chat Enterprise, Microsoft 365 Copilot, Microsoft Inspire, Visual Search"
Microsoft_News,https://blogs.microsoft.com/blog/2023/07/18/microsoft-inspire-accelerating-ai-transformation-through-partnership/,,Microsoft Inspire: Accelerating AI transformation through partnership,"Collaboration is a key component of Microsoft’s success. Our partner ecosystem consists of more than 400,000 partners worldwide, and they play a key role in making new technology available to customers, especially in today’s AI-focused world. Microsoft Inspire is a chance to acknowledge the role our partners play in customer success and to share new opportunities and ways to engage with Microsoft products.

To recognize the impressive achievements of our collaborators, we kicked off Microsoft Inspire by celebrating the finalists and winners in the 2023 Microsoft Partner of the Year Awards, which were announced in late June. The awards highlight partner success and innovation in an array of categories, across solution areas, industries, business transformation and social impact.

This year’s Microsoft Inspire continues our push to make AI a transformative tool for our customers and partners. We’re excited to share even more AI-powered solutions and show how Microsoft partners can apply these AI innovations across their organizations in a variety of ways, from expansion of AI skilling to new products and services that drive customer success. Read on for some of the top announcements at this year’s event.

Introducing Bing Chat Enterprise

Since launching the new Bing in February, we’ve heard from many corporate customers who are excited to empower their organizations with powerful new AI tools but are concerned that their companies’ data will not be protected. That’s why today we’re announcing Bing Chat Enterprise, which gives organizations AI-powered chat for work with commercial data protection. What goes in – and comes out – remains protected, giving commercial customers managed access to better answers, greater efficiency and new ways to be creative.

Bing Chat Enterprise will start rolling out today in preview to organizations licensed for Microsoft 365 E5, E3, Business Premium and Business Standard at no additional cost. We will also make Bing Chat Enterprise available as a stand-alone subscription in the future for $5 per user, per month. Learn more and find out how to get started with Bing Chat Enterprise.

Announcing Microsoft 365 Copilot Pricing

Today, we’re also pleased to announce pricing for Microsoft 365 Copilot. It will be available for $30 per user per month for Microsoft 365 E3, E5, Business Standard and Business Premium customers when generally available.

While some generative AI apps focus on a single capability, like real-time transcription or copywriting, Microsoft 365 Copilot puts thousands of skills at your command. By grounding answers in business data like your documents, emails, calendar, chats, meetings and contacts, and combining them with your working context – the meeting you’re in now, the emails you’ve exchanged on a topic, the chats you had last week – Copilot delivers richer, more relevant and more actionable responses to your questions.

And, Microsoft 365 Copilot is integrated into the apps millions of people use every day. Copilot jump-starts your creativity in Word, analyzes data in Excel, designs presentations in PowerPoint, triages your Outlook inbox, summarizes meetings in Teams – whether you attended or not – and so much more.

Empowering sellers and customer service agents with AI

Sellers need to have as many options in their toolboxes as possible. So, we’re adding more functionality to Microsoft Sales Copilot directly within Dynamics 365 Sales, such as AI-generated opportunity summary, contextualized email drafts and meeting preparations. This empowers sellers to improve productivity and close more deals with Customer Relationship Management (CRM) task automation (including Salesforce), actionable real-time insights and AI-assisted content and recommendations to personalize customer interactions at scale. These add to AI capabilities already available in Microsoft Sales Copilot such as Teams calls summaries and email thread summaries. Viva Sales, announced in June 2022, kickstarted our work of transforming seller experiences, and these capabilities are now part of Sales Copilot. Read more about Microsoft Sales Copilot.

At Microsoft Inspire, we’re also highlighting how customers like Virgin Money are empowering their customer service departments with tailored chatbots built with Power Virtual Agents. With Copilot in Power Virtual Agents, within minutes, businesses can train a chatbot using natural language to reference internal and external knowledge sources, customer service applications and web data via Bing Search. Virgin Money developed their chatbot in two weeks, and it addresses more than 195,000 customer interactions a month, helping their service agents focus on more complex customer inquiries.

Process Mining in Power Automate

Organizations often have a difficult time identifying blockages in their workflows and how to clear them. To help, Microsoft is announcing the general availability of next-generation AI features within Power Automate Process Mining, providing customers with AI-powered insights to optimize existing processes and drive efficiencies through low-code automation. With Process Mining, users can understand what is happening across their business, use AI that generates insights, app and automation suggestions, and use Power Platform to quickly build the solutions they need. Learn more about Process Mining in Power Automate.

Azure OpenAI expanded availability

We’ve been thrilled to see the enthusiasm and business adoption of Azure OpenAI Service, with more than 4,500 customers using the product. Witnessing customers do amazing things, like building chatbots using organizational data, summarizing text and generating content, is exciting to watch develop.

Now, we’re bringing the service to more organizations around the world. Last week, we expanded access to Azure OpenAI Service, increasing its availability in North America and Western Europe, while making it available for Asia for the first time.

New Azure capabilities and investments

We are also going to announce a substantial investment to increase the scale and availability of Azure Migrate & Modernize, and to launch Azure Innovate, an all-new dedicated investment we are making in response to the heightened demands for analytics and AI. These new offerings have expanded scenario coverage and offer richer incentives and support for everything from fast, frictionless migrations to building new AI-powered apps.

Meta and Microsoft partnership

Meta and Microsoft have announced support for the Llama family of large language models on Azure and Windows. As part of this announcement, Microsoft will be Meta’s preferred partner as they release their new version of Llama 2 to commercial customers for the first time. This announcement means that Azure customers will be able to easily fine-tune and deploy the 7B-parameter, 13B-parameter, and 70B-parameter Llama 2 models easily and safely on Azure, In addition, Llama 2 will be optimized to run locally on Windows – enabling Windows developers to take advantage of Llama 2 by targeting the Direct ML execution provider through the ONNX runtime. More on this announcement can be found here.

Expanded strategic collaboration with Epic

We are excited to highlight an expansion of our strategic collaboration with Epic, a leading healthcare software company, where we are using the power of AI to help clinicians spend less time on administrative functions and more time on providing quality care. Epic has integrated Azure OpenAI Service into its electronic health record (EHR) software to provide multiple solutions, from helping clinicians explore clinical data in a conversational and intuitive way to helping them more efficiently reply to patient messages. And with Nuance DAX Express, we are embedding our AI-powered clinical documentation capabilities directly into Epic workflows to help providers further lessen the administrative workloads that lead to burnout, expand access to care for patients and enhance healthcare outcomes.

Additionally, Epic customers are now utilizing Azure Large Instances to achieve the scale needed to run large Epic EHR databases – up to 50 million database accesses per second. This allows Epic customers to scale beyond the previous limits of shared public cloud infrastructure solutions.

The new Microsoft AI Cloud Partner Program

In another milestone, Microsoft Inspire marks the launch of the Microsoft AI Cloud Partner Program, the next generation of our partner program, which empowers every partner to deliver customer value while leveraging Microsoft AI and the Microsoft Cloud. Through the Microsoft AI Cloud Partner Program, we’re providing partners with a comprehensive portfolio of investments for all partner business models, at every stage of maturity.

The Microsoft AI Cloud Partner Program utilizes the entire partner lifecycle, including onboarding, skilling, go-to-market, incentives and co-selling. Partners get the value and benefits of the previous program plus access to new offerings and benefits specific to AI. And there is no action for a partner to take to move to the new program – we’ve moved all existing partners into the new program effective immediately and partners maintain their existing benefits and designations. Read more about the Microsoft AI Cloud Partner Program.

Additional partner updates

We have several updates with new opportunities for partners to go-to-market and scale their businesses, including:

ISV Success updates: Announced in preview at last Microsoft Inspire, ISV Success is the pathway for ISV partners within the AI Cloud Partner Program and is now generally available. ISV Success offers product and cloud benefits, demo and sandbox environments, technical consults to build and publish applications, and once published, sales and marketing benefits to help accelerate deals through Microsoft commercial marketplace. In addition, partners participating in ISV Success will also get access to GitHub Copilot as part of ISV Success benefits at the end of 2023.

Announced in preview at last Microsoft Inspire, ISV Success is the pathway for ISV partners within the AI Cloud Partner Program and is now generally available. ISV Success offers product and cloud benefits, demo and sandbox environments, technical consults to build and publish applications, and once published, sales and marketing benefits to help accelerate deals through Microsoft commercial marketplace. In addition, partners participating in ISV Success will also get access to GitHub Copilot as part of ISV Success benefits at the end of 2023. Multiparty private offers: As part of our continued investments in the Microsoft commercial marketplace, we also announced multiparty private offers, which empower partners to work together to sell customized deals through the Microsoft commercial marketplace.

As part of our continued investments in the Microsoft commercial marketplace, we also announced multiparty private offers, which empower partners to work together to sell customized deals through the Microsoft commercial marketplace. New Solutions Partner designations for more partners: We are introducing new designations as part of the AI Cloud Partner Program to provide opportunities for additional partners to differentiate their technical capabilities and demonstrate customer success. This includes a new training services designation for learning partners, ISV designations for partners building solutions aligned with the Microsoft Cloud and our industry clouds, and a support services designation.

We are excited about today’s announcements and our commitment to accelerating AI transformation, driving customer success, and fueling partner business growth and profitability. This is just a snapshot of the updates being announced at Microsoft Inspire – for a more comprehensive review, please see the additional resources at the end of this post.

And for more information on today’s announcements, be sure to register for Microsoft Inspire and tune into the Day 1 keynotes from Satya Nadella, Judson Althoff and Nicole Dezen, or watch them on demand.

Related links:

Join us at Microsoft Inspire

Microsoft 2023 Partner of the Year Awards winners and finalists

Furthering our AI Ambitions – Announcing Bing Chat Enterprise and Updates to Microsoft 365 Copilot

Find out how to get started with Bing Chat Enterprise

How Microsoft Sales Copilot will empower sellers and customer service agents

Learn more about Power Mining in Power Automate

New Azure capabilities and investments

Find more out about the Microsoft AI Cloud Partner Program

Tags: AI, Azure, Bing Chat Enterprise, Cloud, healthcare, Microsoft 365 Copilot, Microsoft Inspire, Power Automate"
Microsoft_News,https://news.microsoft.com/2023/07/11/kpmg-and-microsoft-enter-landmark-agreement-to-put-ai-at-the-forefront-of-professional-services/,,KPMG and Microsoft enter landmark agreement to put AI at the forefront of professional services,"KPMG and Microsoft enter landmark agreement to put AI at the forefront of professional services

Multi-year cloud and AI alliance to supercharge the employee experience and accelerate innovation for clients across Audit, Tax and Advisory



LONDON and REDMOND, Wash. — July 11, 2023 — KPMG and Microsoft have announced a significant expansion of their global relationship that will reshape professional services across a number of business-critical areas including workforce modernization, safe and secure development, and use of Artificial Intelligence (AI) solutions for clients, industries and society more broadly.

The industry-leading collaboration between the two global organizations includes a KPMG multibillion dollar commitment in Microsoft cloud and AI services over the next 5 years that will help to unlock potential incremental growth opportunity for KPMG of over US$12 billion. The expanded alliance will enhance KPMG client engagements and supercharge the employee experience in a way that is responsible, trustworthy and safe.

The Microsoft cloud and Azure OpenAI Service capabilities will empower the KPMG global workforce of 265,000 to unleash their creativity, provide faster analysis and spend more time on strategic advice. This will enable them to help clients, including more than 2,500 KPMG & Microsoft joint clients, keep pace with the rapidly evolving AI landscape and solve their greatest business challenges while positioning them for success in the future world of work.

As an early access partner for Microsoft 365 Copilot and Azure OpenAI Service, KPMG professionals will pilot the technologies with select business groups across the global organization, bringing together the increased capabilities of these tools with their experience, insights and sector expertise to enhance client engagements and accelerate digital solution development.

Bill Thomas, Global Chairman and CEO, KPMG International, said: “Our renewed and strengthened relationship with Microsoft is an exciting moment for our people and our clients. It will help harness the power of our multidisciplinary model by ensuring that our people always have the right expertise, skills, and tools to overcome challenges and provide the very best advice to clients. It will also help make KPMG a more agile and resilient business that continues to be an interesting and exciting place to work.

This expansion of our global alliance builds on the combined power of two world-class organizations that share a common set of core values, working together to responsibly use cutting-edge cloud and AI technologies. KPMG is embracing the future, and we believe that AI is key to unlocking sustainable growth in a way that will build a better future for our people, our clients and society.”

Satya Nadella, Chairman and CEO, Microsoft, said: “We have a real opportunity to apply this next generation of AI to help transform every industry, including professional services. Our expanded partnership with KPMG will bring together AI innovation across the Microsoft Cloud with KPMG’s tax, audit and advisory expertise to empower its employees and unlock insights for its customers.”

The collaboration which spans more than a decade underpinned by this major expansion will benefit KPMG firms’ core business areas in the following ways:

Audit

By infusing data analytics, AI and Azure Cognitive Services into the audit process, through the KPMG smart audit platform KPMG Clara, 85,000 audit professionals who collectively work on hundreds of thousands of audits a year will be empowered to focus more closely on higher-risk areas of the audit, sector-specific risks and challenges – to the benefit of both stakeholders and capital markets. This integration also opens up new market opportunities for KPMG professionals and their clients. For example, with the integration of Microsoft Fabric, KPMG teams will have the ability to directly point to client data instead of having to ingest it, which is a key component to helping enable KPMG professionals to perform audits on a more real time basis.

Tax

Integrating Azure OpenAI Service and Microsoft Fabric into KPMG Digital Gateway, a KPMG single platform solution, will give clients access to the full suite of KPMG Tax & Legal technologies, and allow them to gain more integrated and transparent access to their data and take a more holistic management approach to their tax functions. This was demonstrated most recently through a co-developed AI solution using the Azure OpenAI Service that helps to analyze environmental, social and governance (ESG) data, establish data patterns and draft ESG tax transparency reports, all at increased speed and scale. Additionally, KPMG firms will operate a generative-AI powered “virtual assistant” to create new client service models to help tax professionals become more efficient. It will also help with revenue-generating opportunities such as product experience enhancements and Knowledge management for complex tax laws.

Advisory

Developing an AI-enabled application development and knowledge platform on Microsoft Azure will expedite the creation of specialized solutions for clients, helping to enhance their competitive advantage and profitability while putting ethics and security at the very core of the offerings. The benefits and ongoing success of this continued collaboration already include a joint engagement with Coca-Cola EuroPacific Partners (CCEP) of which Peter Brickley, Chief Information Officer at CCEP said, “KPMG and Microsoft are working together with Coca-Cola EuroPacific Partners on innovative use cases which pioneer improvements to back-office efficiency using generative AI on the Azure platform. By using this new technology, we will prepare our organization for the future, improve our employee experience and support our growth ambitions globally.”

Making an Impact

KPMG professionals will work together with Microsoft to help support businesses with their ESG agendas. Building on the success of the KPMG Circularity Tracker and an ESG and climate data management and analytics solution, both of which have Microsoft Cloud for Sustainability and Microsoft Azure at their core, joint teams will continue to help clients to unify their data sources, leverage the required inputs to help make real-time value-add decisions, and help them to deliver on their sustainability commitments.

In addition, to enhance the commercial prospects of the agreement, KPMG and Microsoft will continue to explore and participate in joint opportunities where they can work together to drive social and community impact worldwide. These currently include the UNESCO global education coalition and KPMG’s 10×30 strategy to help economically empower 10 million underprivileged youths by 2030 — through education, employment and entrepreneurship opportunities. The companies will also continue to work together to enhance the reliability of carbon accounting through the Carbon Call to which both KPMG and Microsoft were founding signatories.

For media inquiries, please contact:

Kathryn Wright, Head of Global External Communications, KPMG International

T: +44 (0)7880784296

E: [email protected]

Microsoft Media Relations, WE Communications for Microsoft

T: +1 (425) 638-7777

E: [email protected]

Some or all of the services described herein may not be permissible for KPMG audit clients and their affiliates or related entities.

The information contained herein is of a general nature and is not intended to address the circumstances of any particular individual or entity. Although we endeavor to provide accurate and timely information, there can be no guarantee that such information is accurate as of the date it is received or that it will continue to be accurate in the future. No one should act on such information without appropriate professional advice after a thorough examination of the particular situation.

© 2023 Copyright owned by one or more of the KPMG International entities. KPMG International entities provide no services to clients. All rights reserved.

KPMG refers to the global organization or to one or more of the member firms of KPMG International Limited (“KPMG International”), each of which is a separate legal entity. KPMG International Limited is a private English company limited by guarantee and does not provide services to clients. For more detail about our structure please visit kpmg.com/governance.

The KPMG name and logo are trademarks used under license by the independent member firms of the KPMG global organization.

ABOUT MICROSOFT

Microsoft (Nasdaq “MSFT” @Microsoft) enables digital transformation for the era of an intelligent cloud and an intelligent edge. Its mission is to empower every person and every organization on the planet to achieve more.

Editor’s note – July 12, 2023 – The note to editors about additional clients already seeing the benefits of KPMG teams was removed."
Microsoft_News,https://azure.microsoft.com/en-us/blog/ai-for-business-leaders-discover-ai-advantages-in-this-microsoft-ai-learn-series/,,Microsoft AI Learn series: Advantages of AI for business leaders,"AI is becoming a game-changer for businesses across industries and is ushering in a transformative era of innovation, efficiency, and unprecedented possibilities. With AI continuing to automate and optimize vast swaths of the economy, it’s become table stakes for executives and other business decision-makers (BDMs) to understand the latest developments. As a leader in all things AI, Microsoft has spearheaded a curriculum created especially for you and your colleagues to help you build the knowledge, insights, and skills needed to make the most of AI technologies.1

No matter your level of technical know-how, this comprehensive AI educational series spans vertical and horizontal topics focused on outcomes to help your organization extract the many benefits AI offers:

Explore the competitive advantage of AI and how it offers improved decision-making, efficiency, and productivity.

Learn about the potential of AI and what you need to make informed decisions about its adoption and implementation.

Discover real-world examples from the Microsoft AI journey.

Get guidance and best practices from Microsoft experts and other industry leaders.

Introducing the Transform Your Business with Microsoft AI educational series

Transform Your Business with Microsoft AI is designed to bridge the gap between AI technology and business strategy. It helps BDMs understand the potential of AI and equips them with the necessary insights to make informed decisions about AI adoption and implementation. It caters to individuals responsible for shaping AI strategy, managing AI projects, and driving digital transformation within their organizations.

Our curriculum is divided into several modules, each addressing a specific area of AI implementation. Topics include AI strategy, culture, responsible AI, ethics, organizational change management, data-driven decision-making, and AI transformation in specific industries. Modules are presented in a variety of learning formats to accommodate different learning preferences and schedules. These include self-paced online courses, immersive workshops, case studies, snackable videos and articles, and more.

Participants will get insight into real-world examples from the Microsoft AI journey, showcasing how AI technologies have been applied successfully across various business domains. In addition, we bring together experts from Microsoft, as well as industry leaders and AI practitioners, to provide guidance and share best practices. You’ll hear from experienced professionals who have implemented AI in real-world scenarios, offering valuable perspectives and lessons learned.

How companies are using AI to increase efficiency and customer service

Many companies across industries have already begun realizing the value of engaging not only with AI but with the AI experts and solutions at Microsoft.

H&R Block uses AI and Microsoft tools to improve customer experience and the accuracy and efficiency of its tax preparation services. They use Azure Form Recognizer to extract data from tax documents automatically, which saves time and reduces errors.

Azure Cognitive Search makes it easier for tax professionals to find the information they need, and Azure Machine Learning models help better predict and minimize the likelihood of audits for their clients. An AI chatbot created by Azure Bot Service can answer customer questions every day so customers can get help with their taxes at any time.

Construction company Strabag SE also employs Microsoft AI solutions to improve efficiency and reduce risk. They use Microsoft Azure Active Directory to provide single sign-on access to their employees, and Azure Synapse Analytics, Azure Databricks, Azure Machine Learning, and Azure SQL to build data-driven insights. This has helped them to improve their project planning, risk management, and cost control.

In addition, Strabag SE utilizes AI to predict the likelihood of project delays, identify potential safety hazards on construction sites, and optimize their supply chain, so that they can get the materials they need when they need them while controlling costs.

H&R Block and Strabag SE are just two examples of how AI and Microsoft tools are being used to improve financial outcomes for companies across different industries. As AI technology continues to develop, we can expect to see even more innovative ways to use AI to increase efficiency, planning, customer service, safety, and more.

Stay on the cutting edge of AI advancements

Just as the launch of ChatGPT has created excitement and awareness of AI within the consumer sphere, ongoing advancements in large language models and generative AI has created an urgency to get AI deployed across organizations at a faster pace. As the technology continues to evolve, we’ll help you stay on the cutting edge by providing updates on the latest developments, emerging trends, and evolving best practices through additional resources and community engagement.

With an emphasis on responsible AI, including ethics, fairness, transparency, and accountability, this learning path aims to empower organizations of all sizes—from startups to large enterprises—to harness the potential of AI.

Transform Your Business with Microsoft AI is accessible globally, allowing business leaders from around the world to benefit from its educational resources. It aims to empower organizations of all sizes, ranging from startups to large enterprises, to harness the potential of AI and drive innovation.

AI has the potential to reshape the business world in profound ways, ushering in a transformative era of innovation, efficiency, and unprecedented possibilities. With its ability to process vast amounts of data, learn from patterns, and make autonomous decisions, AI has the power to change how businesses operate, compete, and create value. By taking part in Transform Your Business with Microsoft AI, business leaders can arm themselves with the knowledge, insights, and skills needed to leverage AI technologies strategically.

Professionals around the world know that the cloud is transforming the business landscape for the better while offering unparalleled opportunities for innovation and growth. As you look to the cloud to do more with less and to help support your organization’s goals and success, we’re confident that Azure can help you save money by migrating your apps and data to the cloud, optimizing cloud costs, and reinvesting those savings to drive progress.

To quickly learn the advantages of Azure and how it can support your organization’s success, this new learning path focuses on real-world examples across multiple industries. The new Get to know Microsoft Azure cloud platform: An overview for business professionals learning path on Microsoft Learn demonstrates how cloud adoption can benefit your operations, drive cost savings, fuel growth, and more. For more details, read Business leaders: Take a 90-minute cloud journey, with Azure training created just for you.

Discover more

For more information and to begin your journey, visit the Microsoft Learn homepage.

1 Microsoft is a Leader in the 2023 Gartner® Magic Quadrant™ for Cloud AI Developer Services, June 8, 2023."
Microsoft_News,https://blogs.bing.com/search/june-2023/New-AI-powered-Microsoft-Shopping-tools-arrive-on-the-new-Bing-and-Edge,,New AI-powered Microsoft Shopping tools arrive on the new Bing and Edge,"Online shopping revolutionized the way we research, find, and buy the things we want and need. But as options and information grow, online shopping has become overwhelming. Online shoppers describe the process as stressful and confusing. There is simply too much to choose from, places to look, and information to sort through. Not to mention, frustration with finding relevant deals that actually work at checkout or knowing which customer ratings and reviews to trust.



Online shopping just feels like more work.



Our goal is to bring more joy to shopping—from the initial spark of inspiration to the exciting unboxing experience—by making the process easier and giving you confidence, you’re getting the right item at the right price. Microsoft Shopping already helps you save time and money with tools across Bing, Edge, Microsoft Start, and Outlook. In fact, Microsoft Edge has offered $3.7 billion in savings to shoppers worldwide in the last year thanks to built-in shopping features like Coupons, Cashback, Price History, and Price Comparison. Plus, US shoppers can save an average of $400 per year with Microsoft Edge.



Today, we’re excited to announce new Microsoft Shopping tools in Bing and Edge that help you shop and save with confidence, harnessing the power of AI to make it easier to discover, research, and complete your purchase, all in one place with information you need from expert sources.

Discover what you need with Buying Guides—even when you’re not sure what that is

Most years, back-to-school shopping comes with a school supplies list—but not when it comes to college. Highlighters, folders, and notebooks don’t even cover the basics, so what do new college students really need? Bing can help with answers to all your questions about college supplies. Start by going to Bing.com and typing “college supplies” into the search box. Your shopping assistant for the web will do the research for you, using AI to generate a tailored Buying Guide that tells you what to look for in each category, offers product suggestions, and shows the specifications of multiple, similar items next to each other in a smart compare table, so you can quickly compare options without having to click around to various websites. You can also access Buying Guides in the Edge sidebar or in Bing Chat. Buying Guides in Bing are available now in the US and will be rolling out to other markets over time. Buying Guides in Edge are starting to roll out worldwide.

Actual user interface may differ

Shop confidently with summarized reviews and insights

Now that you know that noise-cancelling headphones are essential for getting some distraction-free study time, how do you choose which ones to buy? Prices range from $30 to $300, and each brand has different specs and an overwhelming number of reviews. While shopping for headphones, you can open Bing Chat in the Edge sidebar and Bing will suggest what aspects to consider when shopping for headphones like sound quality, fit and device compatibility. And when you find a specific pair you like, you can ask Bing Chat in Edge to briefly summarize what people are saying about it online and provide a quick look at top insights and popular opinions about the product. Review Summaries are starting to roll out today worldwide just in time for back-to-school.



Actual user interface may differ

Find the best price and save money even after you’ve made a purchase

Now that you’ve picked out the headphones you want, Microsoft Shopping tools on Bing and Edge can help you find the best price and time to buy, so you can complete your purchase with the peace of mind that you got a great deal. Our Price Match feature continues to work for you, even after your purchase, by monitoring the item's price and assisting you in requesting a match if it drops. We’ve partnered with top US retailers with existing price match policies and will be adding more over time. Price Comparison and Price History are built-in browser features that help ensure you’re buying at the right place and time, and Edge helps you automatically apply coupons and cashback when shopping online, right from Bing Chat. Package Tracking also keeps tabs on your purchase from the Edge sidebar, so you don’t have to dig through your inbox for shipping confirmations and tracking numbers. Price Match will be rolling out soon in the US. Price History, Price Comparison, Coupons, Cashback, and Package Tracking are already available in select markets and built-in to Edge.



Actual user interface may differ

Shop and save with Microsoft Shopping on Bing and Edge today

Get ready to rediscover the joy of shopping with Microsoft Shopping’s new AI-powered tools in Bing and Edge. Visit bing.com/shopping on PC or mobile, or download the Bing app to get started!"
Microsoft_News,https://news.microsoft.com/2023/06/29/moodys-and-microsoft-develop-enhanced-risk-data-analytics-research-and-collaboration-solutions-powered-by-generative-ai/,,"Moody’s and Microsoft develop enhanced risk, data, analytics, research and collaboration solutions powered by Generative AI","Moody’s and Microsoft develop enhanced risk, data, analytics, research and collaboration solutions powered by Generative AI

Strategic partnership for next-gen solutions built on Microsoft Azure OpenAI Service, Microsoft Fabric, and Microsoft Teams and Moody’s proprietary data to empower financial services, capital markets, and more

NEW YORK and REDMOND, Wash. — June 29, 2023 — Moody’s Corporation (NYSE:MCO) and Microsoft (NASDAQ: MSFT) today announced a new strategic partnership to deliver next-generation data, analytics, research, collaboration and risk solutions for financial services and global knowledge workers. Built on a combination of Moody’s robust data and analytical capabilities and the power and scale of Microsoft Azure OpenAI Service, the partnership creates innovative offerings that enhance insights into corporate intelligence and risk assessment, powered by Microsoft AI and anchored by Moody’s proprietary data, analytics, and research.

Strategic Partnership Highlights

Microsoft and Moody’s are co-creating new products and services for research and risk assessment, built on Azure OpenAI Service for enhanced data and risk management.

“Moody’s CoPilot,” an internal copilot tool, is now deployed to Moody’s 14,000 global employees, and will combine Moody’s proprietary data, analytics and research with the latest large language models (LLMs) and Microsoft’s world-class generative AI technology to drive firm-wide innovation and enhance employee productivity in a safe and secure digital sandbox.

Moody’s is adopting Microsoft Teams to provide a new platform for its knowledge workers and customers that will enhance collaboration, productivity, and communication, while maintaining the highest compliance standards.

For internal use and co-innovations, Microsoft is leveraging Moody’s broad range of solutions, including Moody’s Orbis database – one of the world’s most powerful databases on companies – with applications that include third-party reference data, counterparty risk assessment, and supply chain management.

Microsoft and Moody’s will collaborate on the opportunity to deliver data to their shared customers through Microsoft Fabric , a new analytics platform for end-to-end data management.

a new analytics platform for end-to-end data management. Moody’s commits to using Microsoft’s Azure cloud platform to power its growing suite of generative AI capabilities and cloud-based applications.

Rob Fauber, president and chief executive officer of Moody’s Corporation, said, “Generative AI represents a once-in-a-generation opportunity to enhance how companies navigate the ever-evolving world of exponential risk. By combining Microsoft’s cutting-edge AI capabilities with our proprietary data, research and analytics, Moody’s is positioned to lead the next generation of risk analysis, helping our customers make better decisions by unlocking deeper, more integrated, and unmatched perspectives on risk. We have activated our 14,000 global employees to drive unprecedented experimentation and ignite new innovations across our suite of products and solutions. We are excited to partner with Microsoft to set the standard for how generative AI will pioneer new advancements across our industry.”

Unlocking Advancements in Integrated Risk Analysis

A new copilot tool for customers, “Moody’s Research Assistant” will unlock the full potential of Moody’s resources and solutions to provide customers with a multifaceted view of risk. Built on Microsoft Azure OpenAI Service and available through multiple channels, including Microsoft Teams, Moody’s Research Assistant will quickly compile and summarize complex information from multiple data sources, all in a safe and secure environment that protects private and proprietary information. Among its many anticipated uses will be the ability to generate custom, detailed analyses of a company or sector by seamlessly combining data from across multiple dimensions – such as firmographic data, credit indicators, economic forecasts, and risk and reputational profiles – to provide fast, contextual and informative answers based on the integration of expansive LLMs and Moody’s industry-leading data, analytics and research.

Bill Borden, corporate vice president of worldwide financial services at Microsoft said, “Our partnership will bring together world-class insights from Moody’s with the capabilities, trust and breadth of Microsoft Cloud — including Azure OpenAI Service, Fabric and Teams — to enable next-gen solutions that will unlock powerful business intelligence and transform productivity and collaboration. We look forward to the new opportunities and value this will bring to employees and firms across banking, capital markets and insurance as well as those in other industries such as manufacturing, telecommunications, transportation and utilities.”

Enhancing Moody’s Collaboration and Productivity through Microsoft Teams

Additionally, through the partnership, Moody’s will leverage Microsoft Teams to create a new collaboration, productivity and communication platform for its knowledge workers and customers. With the integration of Moody’s copilot tools, Teams will automate and streamline manual workflows, provide more efficient access to data and content, and synthesize and summarize information from across multiple data sets, resulting in better insights, improved productivity and compliance, and enhanced employee and customer experiences.

Collaborating to Enhance the New Microsoft Fabric

Microsoft and Moody’s will collaborate on the opportunity to deliver data to their shared customers through Microsoft Fabric, a new end-to-end data analytics platform. Microsoft Fabric includes technologies like Azure Synapse Analytics, Azure Data Factory, and Power BI in a single unified product, allowing data engineers opportunity to easily connect and curate data from multiple sources, eliminating sprawl, while better governing data across the entire organization.

ABOUT MOODY’S CORPORATION

Moody’s (NYSE: MCO) is a global integrated risk assessment firm that empowers organizations to make better decisions. Its data, analytical solutions and insights help decision-makers identify opportunities and manage the risks of doing business with others. We believe that greater transparency, more informed decisions, and fair access to information open the door to shared progress. With approximately 14,000 employees in more than 40 countries, Moody’s combines international presence with local expertise and over a century of experience in financial markets.

ABOUT MICROSOFT

Microsoft (Nasdaq “MSFT” @Microsoft) enables digital transformation for the era of an intelligent cloud and an intelligent edge. Its mission is to empower every person and every organization on the planet to achieve more.

“SAFE HARBOR” STATEMENT UNDER THE PRIVATE SECURITIES LITIGATION REFORM ACT OF 1995

Certain statements contained in this release are forward-looking statements and are based on future expectations, plans and prospects for Moody’s business and operations that involve a number of risks and uncertainties. Such statements involve estimates, projections, goals, forecasts, assumptions and uncertainties that could cause actual results or outcomes to differ materially from those contemplated, expressed, projected, anticipated or implied in the forward-looking statements. Stockholders and investors are cautioned not to place undue reliance on these forward-looking statements. The forward-looking statements and other information in this release are made as of the date hereof, and Moody’s undertakes no obligation (nor does it intend) to publicly supplement, update or revise such statements on a going-forward basis, whether as a result of subsequent developments, changed expectations or otherwise, except as required by applicable law or regulation. In connection with the “safe harbor” provisions of the Private Securities Litigation Reform Act of 1995, Moody’s is identifying certain factors that could cause actual results to differ, perhaps materially, from those indicated by these forward-looking statements. Those factors, risks and uncertainties include, but are not limited to: the impact of current economic conditions, including capital market disruptions, inflation and related monetary policy actions by governments in response to inflation, on worldwide credit markets and on economic activity, including on the volume of mergers and acquisitions, and their effects on the volume of debt and other securities issued in domestic and/or global capital markets; the uncertain effectiveness and possible collateral consequences of U.S. and foreign government initiatives and monetary policy to respond to the current economic climate, including instability of financial institutions, credit quality concerns, and other potential impacts of volatility in financial and credit markets; the global impact of the Russia – Ukraine military conflict on volatility in world financial markets, on general economic conditions and GDP in the U.S. and worldwide, on global relations and on the Company’s own operations and personnel; other matters that could affect the volume of debt and other securities issued in domestic and/or global capital markets, including regulation, increased utilization of technologies that have the potential to intensify competition and accelerate disruption and disintermediation in the financial services industry, as well as the number of issuances of securities without ratings or securities which are rated or evaluated by non-traditional parties; the level of merger and acquisition activity in the U.S. and abroad; the uncertain effectiveness and possible collateral consequences of U.S. and foreign government actions affecting credit markets, international trade and economic policy, including those related to tariffs, tax agreements and trade barriers; the impact of MIS’s withdrawal of its credit ratings on countries or entities within countries and of Moody’s no longer conducting commercial operations in countries where political instability warrants such action; concerns in the marketplace affecting our credibility or otherwise affecting market perceptions of the integrity or utility of independent credit agency ratings; the introduction of competing products or technologies by other companies; pricing pressure from competitors and/or customers; the level of success of new product development and global expansion; the impact of regulation as an NRSRO, the potential for new U.S., state and local legislation and regulations; the potential for increased competition and regulation in the EU and other foreign jurisdictions; exposure to litigation related to our rating opinions, as well as any other litigation, government and regulatory proceedings, investigations and inquiries to which Moody’s may be subject from time to time; provisions in U.S. legislation modifying the pleading standards and EU regulations modifying the liability standards applicable to credit rating agencies in a manner adverse to credit rating agencies; provisions of EU regulations imposing additional procedural and substantive requirements on the pricing of services and the expansion of supervisory remit to include non-EU ratings used for regulatory purposes; uncertainty regarding the future relationship between the U.S. and China; the possible loss of key employees and the impact of the global labor environment; failures or malfunctions of our operations and infrastructure; any vulnerabilities to cyber threats or other cybersecurity concerns; the timing and effectiveness of our restructuring programs, such as the 2022 – 2023 Geolocation Restructuring Program; currency and foreign exchange volatility; the outcome of any review by controlling tax authorities of Moody’s global tax planning initiatives; exposure to potential criminal sanctions or civil remedies if Moody’s fails to comply with foreign and U.S. laws and regulations that are applicable in the jurisdictions in which Moody’s operates, including data protection and privacy laws, sanctions laws, anti-corruption laws, and local laws prohibiting corrupt payments to government officials; the impact of mergers, acquisitions, such as our acquisition of RMS, or other business combinations and the ability of Moody’s to successfully integrate acquired businesses; the level of future cash flows; the levels of capital investments; and a decline in the demand for credit risk management tools by financial institutions. These factors, risks and uncertainties as well as other risks and uncertainties that could cause Moody’s actual results to differ materially from those contemplated, expressed, projected, anticipated or implied in the forward-looking statements are described in greater detail under “Risk Factors” in Part I, Item 1A of Moody’s annual report on Form 10-K for the year ended December 31, 2022, and in other filings made by the Company from time to time with the SEC or in materials incorporated herein or therein. Stockholders and investors are cautioned that the occurrence of any of these factors, risks and uncertainties may cause the Company’s actual results to differ materially from those contemplated, expressed, projected, anticipated or implied in the forward-looking statements, which could have a material and adverse effect on the Company’s business, results of operations and financial condition. New factors may emerge from time to time, and it is not possible for the Company to predict new factors, nor can the Company assess the potential effect of any new factors on it. Forward-looking and other statements in this document may also address our corporate responsibility progress, plans, and goals (including sustainability and environmental matters), and the inclusion of such statements is not an indication that these contents are necessarily material to investors or required to be disclosed in the Company’s filings with the Securities and Exchange Commission. In addition, historical, current, and forward-looking sustainability-related statements may be based on standards for measuring progress that are still developing, internal controls and processes that continue to evolve, and assumptions that are subject to change in the future.

For more information:

Microsoft Media Relations, WE Communications for Microsoft, (425) 638-7777, [email protected]

Moody’s Investor Relations, Shivani Kak, (212) 553, 0298, [email protected]

Moody’s Communications, Michael Adler, (212) 553-4667, [email protected]"
Microsoft_News,https://www.microsoft.com/en-us/worklab/podcast/wharton-professor-ethan-mollick-on-the-urgency-of-getting-in-front-of-ai,,Ethan Mollick on the Urgency of Getting in Front of AI,"MARY MELTON: Today I’m talking to Ethan Mollick, an entrepreneurship and innovation professor at the Wharton School of Business, who embraces the power of AI to further the education of his students—and of his own education. In January, Ethan mandated the use of AI in his curriculum. In today’s episode, he shares what he’s learned from that experience and how he sees AI positively transforming not just the future of education, but of entrepreneurship and the workplace. He talks about how business leaders can use the technology to help them in decision making, and he walks us through some specific cases of AI in action in the workplace. When he isn’t researching or teaching, he’s advising start-ups and organizations. And now, my conversation with Ethan.

MARY MELTON: Hello, Ethan Mollick, and welcome to WorkLab . Thank you for joining us.

ETHAN MOLLICK: Thanks for having me. I’m really pleased to be here.

MARY MELTON: What are the topics of expertise that you dabble in, and how does AI fit into all of those?

ETHAN MOLLICK: So I’m sort of an accidental expert in AI. I’ve been AI-adjacent my whole career. So I worked with the MIT Media Lab and Marvin Minsky’s AI lab back in the day, but I’ve never been a computer scientist. What I have been fascinated by is both entrepreneurship—so, I teach a lot on research entrepreneurship, especially team success and innovation. I’m also super interested in, how do we teach in new ways. So I run something at Wharton called Wharton Interactive, which is their internal game studio, where we build teaching games to teach business skills at scale. And that’s sort of where I’ve been encountering AI the most is, how do we use this as a teaching tool? So I’ve been playing with this a lot since before ChatGPT came out. When Chat was released, it happened to overlap very much with what I was already studying and interested in. So I sort of took a deep dive into that area.

MARY MELTON: When did you start Wharton Interactive?

ETHAN MOLLICK: It’s been around in one form or another since about 2014, officially kind of kicked off in 2018. So I’ve been building games for teaching for a while. I wrote a book on the topic back over a decade ago, so it’s been a topic of a lot of interest. How do we teach the most people real work skills that are useful at scale? Because it turns out, even minor amounts of business knowledge can transform people’s lives. So it’s a really important thing to be able to do.

MARY MELTON: So you’ve got a wealth of knowledge on the topic of AI. Can you reflect for a moment on what you make of this moment? And were you surprised at how fast we got here?

ETHAN MOLLICK: Oh, absolutely. I mean, AI has always been almost here, right? So before Chat came out in November of last year, I was experimenting with GPT-3, the previous version. It was kind of miraculous, it wrote as well as a fifth grader. Like, that was so cool. But we’ve been expecting AI to be the thing forever, and it hasn’t ever taken off, right? There’s been these AI winters. I think I was less surprised than a lot of people, because once I saw Chat, I was like, oh my god, this is the moment. It’s all going to happen here. Maybe took other people a month or two to catch up, but that’s a pretty fast adoption curve for any technology.

MARY MELTON: Where were you when you first realized that this had taken off, like, that this was going to become actually the topic du jour and move from something that was in the background to something that everyone is talking about?

ETHAN MOLLICK: Actually, I introduced it to my entrepreneurship class three days, four days after ChatGPT came out, and by the end of that first class, one of the students had already created a working software prototype using GPT-3.5, using Chat, to demonstrate the product they were developing for the class. And I posted it on Twitter that night. By the next day, we see scouts had already contacted them about potential funding opportunities. By the Thursday, a couple of days after that, 60–70 percent of my students already used Chat to do things anywhere from working on better messages for their clubs to explaining why they got problems wrong on tests to helping them brainstorm ideas for outlines, all sorts of uses.

MARY MELTON: So on one hand, you sound very positive, but on the other hand, I’ve also seen that you’ve written in your newsletter, which is called One Useful Thing , that we’re living in something that you’ve described as an “AI-haunted era.” How does that measure up with the positivity part of it?

ETHAN MOLLICK: AI is a general purpose technology. It is going to affect everything we do. General purpose technologies are these rare events like steam power, the computer, or electrification, or maybe the internet, where a new technology comes along that touches everything. And so AI is doing that, right, and that means its results are going to be very different to different places. Some industries will be unaffected—not that many, but some. Some industries will be hugely affected. Some jobs it will have a huge impact, some will not. It’s hard to know in advance. So when I say “AI-haunted era,” I mean AI is kind of a background to everything we’re doing, sort of like the internet is today. And that is going to be both good and bad. I think that trying to lump this together as it’s one set of risks or dangers, you know, versus one set of big wins is hard. It’s going to be that way on a very micro basis. The level of jobs, organizations, companies, industries, countries, societies is a big picture.

MARY MELTON: So looking at it, you see it as that much of a game changer in the way that steam engines and the internet changed the way we live our lives.

ETHAN MOLLICK: I want to make it clear, like when people talk about technologies in the future, they often talk about them—like, I’m sure you had blockchain conversations on this. Blockchain was like five years out, and the proponents were like, It’s going to change everything in five years from now. Like, that’s not the case with this. And I think it’s hard for people to wrap their head around the fact that, like, this is here now. If every letter banning AI goes through and we don’t produce any more AI after today’s, it’s still going to have a profound effect on how we work, on how we learn, because it’s an incredibly capable system already. I don’t feel like I’m going out on a limb here to say that it’s going to be transformational, because you don’t need to wait four years or five years to see if it’s transformational. You can see it right now in the fact that 14 percent of Americans have already tried this technology, which is a really new technology. And of those, you know, over a third of them consider it incredibly useful and a third find it useful. And very few people find it not useful at all. And that’s without any training or knowledge. So I think this is the beginning of something big.

MARY MELTON: Fourteen percent is a huge number.

ETHAN MOLLICK: This is the fastest technology we know of to 100 million users.

MARY MELTON: Wow.

ETHAN MOLLICK: It’s a big deal, right, ChatGPT. So 14 percent penetration of the US in a short period of time for a new tech is quite big.

MARY MELTON: One thing you’ve said is that we should think of AI as a person, not a software. Tell me more about what you think about that.

ETHAN MOLLICK: Let’s start two steps back. Let’s just talk about what AI is, because it means a lot of different things, right? People think about the Terminator robot or about HAL or about Jarvis in Iron Man , or they think about self-driving cars, the kind of AI that business analytics at Microsoft offers. That was sort of what we talked about with AI before November, which is the idea of machine learning, of predictive analytics, the idea that you could take a whole bunch of data, throw it at the AI, and it would tell you a pattern in that data. And, pretty good at predicting patterns, it was pretty bad at human-sounding interactions. So in 2017, a famous paper called “Attention Is All You Need,” and it proposes the idea of a large language model and a few tools that created it. Large language models are also predictive. They’re predicting the future, but they’re predicting what word or part of a word, called a token, would come next in a conversation—so, fancy autocompletes, essentially. So they sucked out every piece of the information on the internet and created very complex associations between various words and phrases to complete sentences. Now, the weird thing that happened is when those models got large enough, when they reached the size of billions of parameters the way ChatGPT did, then they started to exhibit a large amount of the illusion of reasoning and creativity. I mean, they actually act creative, right? We don’t quite know the reasons why the size of the model made such a difference. It’s not that these systems are sentient, but as a result, they act in a way very different than other kinds of software, they act more like people than like software. And by that I don’t mean they’re alive, they’re not sentient, but that they are good at humanlike tasks, like writing and coding. They’re bad at machine-like tasks like math, and they make mistakes and sort of fool themselves like humans do. So when I say “work with them like humans,” I don’t mean they’re people, but I do mean that it’s a useful way to think about what they’re good at rather than thinking about them like software.

MARY MELTON: Well, let’s talk a little bit about what AI can and cannot do. You wrote a practical guide about this and the six capabilities that you stated. It can write stuff. It can make images. It can come up with ideas. It can make videos. It can code and it can learn stuff. Which one of those do you think are going to be most useful to business leaders?

ETHAN MOLLICK: So we missed a few things there, right? Like, it could do analysis. It is capable of doing original work as well. I mean, look, the biggest use and the thing all business leaders are going to need to grapple with is AI being integrated into office applications, writing performance reviews, writing a marketing research document, writing marketing material, where the AI can do that stuff faster. So I think this is a huge opportunity to think about, what do we do with a giant productivity gain? How do we get people to do more meaningful work and that they’re aimed in the right directions? There’s a lot of open questions to think about there.

MARY MELTON: So what are the best ways to write a prompt or engage with a tool like Bing Chat? And also, what are some common mistakes that people are making?

ETHAN MOLLICK: So on the common mistakes side, the first three things everyone does with AI are always kind of the same. It doesn’t work like traditional search, right, it’ll get some things wrong, it integrates information. That’s the first thing people do. The second thing people do is try and interact with it, like having a fun conversation, usually ask it about the future of AI. The AI is not magical. It doesn’t know the future, and it doesn’t have a personality really. So people get frustrated. Third thing they do is maybe they ask it stuff about themselves and they run again into hallucinations. The idea that when you ask the AI to know something it doesn’t know, it makes up the information. That’s a very common consequence, and then people get pretty annoyed and walk away. The problem is that that’s not really showcasing what makes AI powerful. It is actually quite good at search in the right kind of way. Think about it like an intern you’re delegating tasks to: Write me a draft of something. Actually, paragraph two is pretty good. Make paragraph three better. Add a different example in paragraph four. Can you make it sound more formal? That kind of interaction is much more powerful, so it’s less of us starting with the perfect prompt, but it’s much more about interacting with the system the way you would with a person.

MARY MELTON: Yeah. What have you learned from how you’ve approached bringing AI into the classroom that may be helpful for managers and leaders, in terms of creating that psychological safe space to create an environment where you’re talking about this and you’re sharing best practices and what you’re learning. I think, based on my understanding, that you’ve made it actually mandatory for students to use AI.

ETHAN MOLLICK: Yes, we are seeing 30 to 70 percent performance improvements across different studies. Nobody knows the real answer yet, but that’s huge. Put that in context: steam power was 18 to 22 percent when it was put into a factory in the early 1800s. These are numbers we’ve never seen before, right? Companies will do a massive installation of software to get a 3 or 4 percent performance improvement. These are huge numbers. This is the biggest thing that’s happened to white collar work—you know, at least since the computer, maybe even, you know, before. It’s hard to know. And it’s happening all at once. So I think every organization should have every alarm bell ringing about what’s going on now. Both about how their employees are using it, how they might want to use it, how they could gain an advantage, how competitors might gain an advantage, how everybody all over the world who didn’t used to speak English fluently can now speak English fluently. And that’s a big change to happen overnight. So I think there’s two things. One, making it mandatory, making people use it. I don’t think you’d be remiss as a leader of a large scale Fortune 1000 company to take, you know, the top 20 percent most creative people in your company, require they all use AI for a week, and give a million-dollar prize to whoever comes up with the best way to automate parts of their job while promising you’re not going to fire anyone as a result of this. Like, I don’t think it’s an overreaction. I think a lot of people are viewing this as, is it an IT problem or a legal problem or a grand strategy problem. It’s not. This is a very down and dirty situation that has to be dealt with. So what I’ve learned from class is, people have to use it a lot. You need like 10 hours of time on ChatGPT or Bing or whatever before you start to actually get use out of it and really get it. And then you also need some training. It helps to understand, the training is not like you have to pay a consultant tons of money. It’s just a very basic sense of like, okay, you interact with this like you do a person, but a little bit of training does help.

MARY MELTON: You’ve said that in the future, AI in classrooms will be undetectable, ubiquitous, and transformative, and that the quality of the work for your students has improved since doing this. Is that right?

ETHAN MOLLICK: I mean, I have really smart students, but the quality of ideas has definitely gone up because now people can bounce ideas off more people. Certainly I’ve demanded a lot more material for my class. So they used to have to put an outline together. Now the outline actually has to be critiqued by three famous entrepreneurs, have 10 possible things that go wrong, require one almost impossible task they do, and it has to have some visions of the future, all generated by AI to go along with the outline that they write.

MARY MELTON: Now, have you required them to do more work because you know they’re going to have more time to do more work because of the assistance of the AI?

ETHAN MOLLICK: Yeah, a lot of the things that we used to have to spend time on, we don’t have to and we can generate a lot more material. It changes the way you relate to work, right? You’re working in hybrid with the AI; you’re not just working on your own anymore.

MARY MELTON: Tell me, what is the transfer problem?

ETHAN MOLLICK: So there’s a general problem in education. We could teach you stuff in a classroom pretty well, but people have trouble applying that to other situations other than exactly what they learn in class. So that’s transfer. If I teach you how to solve a math problem, will you see that math problem in the real world and know how to solve it? AI has a lot of really positive things it could do for education. One of the sets of stuff is about, you know, helping teachers. One way to transfer ideas is to actually teach someone else who could teach the AI, correct it when it’s wrong about topics. We’ve also been using AIs to create simulations so students can have a simulated partner to negotiate with, or discuss things with—another really powerful approach to solving transfer with AI.

MARY MELTON: Those are all very exciting possibilities. Is there any one in particular that excites you the most regarding the future of AI, and the impacts it could have on either education and/or entrepreneurship?

ETHAN MOLLICK: Both of them have the same kind of answer, which is that one of the problems we have in the world is the hidden Einstein problem, right? Which is that talent is much more evenly distributed than opportunity. Just to give you some examples. The start-up world is full of broken opportunities. So people in Philadelphia raised more money for venture capital last year than everyone in Japan put together. Actually, Penn grads raised more money than everyone of France and Germany put together. Women make up 38 percent of business owners in the United States—they only get 2 percent of venture capital. These are not even numbers. And that’s just in the US where you have access to things. There’s lots of parts of the world where there’s very smart people who don’t have access to the kinds of tools or abilities that we do here, and that includes an opportunity to learn. We’ve known for a long time, or at least strongly suspected, that the most transformative kind of teaching you can get is essentially one-on-one adaptive tutoring. And it’s really hard to do that at scale. It’s very hard to do in much of the world where there’s not a lot of money in teaching and people have lots of opportunity costs when they’re do teach. You can actually do some really impressive tutoring at scale. So the idea of having a tool that is universally applicable, that works for everybody around the world—Bing’s in like 169 countries, I think. I mean, that’s an incredible tool. So to me it’s the democratization of opportunity. Think about all the innovations and things, the ideas that were lost that can now be taken advantage of.

MARY MELTON: You’ve talked about how getting AI ready requires rethinking systems rather than job roles. Can you say more about that?

ETHAN MOLLICK: So there’s actually, jobs is the wrong unit of analysis for thinking about change. When we talk about jobs in academic literature, we actually think about jobs as bundles of tasks. And some of those tasks, AI is going to be very good at helping you with. Some, it’s going to be able to take things off your plate, some it’s not going to be good at at all. So change is going to happen at the task level, not the job level. Change is also going to happen at the system level. The way we run companies today is the same way we ran companies roughly in 1920 or even 1853, right? Large multinational corporations, lots of layers of middle management. Those are dependent on the technologies and capabilities we have today. So that’s about to change. We have different capabilities now. Are you still going to do sprints as the way of organizing work? When AI can let some people work much harder than they did before. You don’t need to wait for people to catch up. Do you still want to have all the stand-up meetings you did? Like, we have to change the systems of work, and that’s going to be a very big change.

MARY MELTON: That’s a huge change. You teach entrepreneurship and you work with start-ups. You have said that AI is an amazing co-founder.

ETHAN MOLLICK: So, a third of Americans had an idea for a start-up and haven’t done anything about it. And part of it is there’s lots of barriers. It’s hard to do research. It’s hard to write a business plan. Guess what? You can ask the AI, Give me 20 ideas for how to launch a business. You know, tell me details, step by step, how to do it. Write me the letter that I need to send. Help me fill out this form. Help me create code for this. How should I test this idea? You have a co-founder you got for free that can help you with lots of tasks. That’s incredible power.

MARY MELTON: And you’ve experimented with this yourself and with your students. And have you found the answers that you get when you propose something like, Give me 20 ideas for how to write a business plan are pretty on target?

ETHAN MOLLICK: Yes. I mean, they’re not right. I mean, but most ideas are wrong. When I ask it for business advice, it’s good , right? I would say, you know, a lot of the common tasks out there, AI hits around the 80th percentile of ability. Like, I’d like to think I teach a better class than the AI would, but it’s not terrible, right? It makes mistakes too. But so do humans. I find it to be very useful to use this as an adjunct to the kind of work you’re doing otherwise. It’s good enough to kind of get you over the starting line. Not as good as the best human, but pretty good.

MARY MELTON: And it sounds like it gives you great jumping-off points to think about ways to phrase questions to yourself or for something that’s like a larger business plan.

ETHAN MOLLICK: Even more than that, there is a bunch of research that is coming out showing that AI is reasonable as a proxy to talk to also for market research. So you can interview the AI and you’ll get reasonable answers. They’re not going to be accurate as much as talking to people, but it can help you practice talking to people to get some interesting ideas. When you survey AI about willingness to pay, it gives reasonably accurate survey results. So it’s not just about, you know, having a companion to punch ideas off of. It’s not just a tool to create content. It’s also about this other piece.

MARY MELTON: That's incredible. What is some advice you could give to a business leader who hasn’t yet dived deeply into this and may be feeling nervous about what they should be doing?

ETHAN MOLLICK: I really strongly believe the only way out is through here, and you have to just start using it. So the question is, who’s using it in your organization? Do they feel safe talking to you about how they’re using it? Are you using it? The idea that somebody is, like, too busy to play with AI, I can tell you this is a COVID moment. This is as big a deal as anything your organization has ever encountered. And you need to be spending your time right now dealing with this. So just putting things on the back burner doesn’t make sense either. I see people handing things off to IT departments. This is not a really good IT solution. It’s something very different. So you can’t just have IT handling it. This has to be a whole-of-organization approach to solving and addressing a very, very, very big burning issue.

MARY MELTON: It’s not too late to jump in, obviously. You’re right at the start of it, but at the same time it can be too late pretty fast if you don’t start.

ETHAN MOLLICK: If you really—if scenarios 2 or 3 are right and there’s either exponential growth or continued fast linear growth, right, in some way, then you need to get used to this now, because only then will you start to get a sense of what’s happening next. I just can’t emphasize it enough: It’s not too late. But, you know, this is the second-best time to start using AI. The first best time was a couple of months ago.

MARY MELTON: Well, thank you so much, Ethan Mollick, for joining us and getting us inspired to get in there and not be scared and start working on it.

ETHAN MOLLICK: Oh, well, thank you for having me.

MARY MELTON: Thank you so much.

MARY MELTON: Thanks again to Ethan Mollick for that insightful and really fascinating conversation about the future of work and AI. If you’ve got a question you’d like us to pose to leaders, drop us an email at worklab@microsoft.com. And check out the WorkLab digital publication, where you’ll find transcripts of all of our episodes, along with thoughtful stories that explore the ways we work today. You can find all of it at Microsoft.com/WorkLab. As for this podcast, rate us, review us, and follow us wherever you listen, please. It helps us out a lot. The WorkLab podcast is a place for experts to share their insights and opinions. As students of the future of work, Microsoft values inputs from a diverse set of voices. That said, the opinions and findings of our guests are their own, and they may not necessarily reflect Microsoft’s own research or positions. WorkLab is produced by Microsoft with Godfrey Dadich Partners and Reasonable Volume. I’m your host, Mary Melton, and my co-host is Elise Hu. Sharon Kallander and Matthew Duncan produce this podcast. Jessica Voelker is the WorkLab editor. Thanks for listening."
Microsoft_News,https://www.linkedin.com/pulse/microsofts-launches-new-ai-skills-training-resources-part-behncken,,Microsoft Launches New AI Skills Training and Resources as part of Skill for Jobs Initiative,"AI offers tremendous potential to empower workers around the world – but only if everyone, everywhere has the skills to use it. It's little surprise that, according to the World Economic Forum, AI skills represent the third-highest priority for companies’ training strategies, right alongside analytical and creative thinking.

To begin addressing this need, today we are launching a new AI Skills Initiative to help people and communities around the world learn how to harness the power of AI. The Microsoft AI Skills Initiative includes new, free coursework developed with LinkedIn, including the first Professional Certificate on Generative AI in the online learning market; a new open global grant challenge in coordination with data.org to uncover new ways of training workers on generative AI; and greater access to free digital learning events and resources for everyone to improve their AI fluency.

As noted in Microsoft’s recent Work Trend Index, AI is uniquely poised to create a whole new way of working just as the pace of information work is outpacing our ability to keep up. A whopping 62% of survey respondents said they struggle with too much time spent searching for information in their workday. And while 49% of people say they’re worried AI will replace their jobs, even more—70%—would delegate as much work as possible to AI to lessen their workloads. To that end, our new AI Skills Initiative aims to help workers around the world stay ahead of emerging skills gaps and take advantage of these new technologies.

Here’s how:

Revolutionizing skills training – the Generative AI Skills Grant Challenge

While much focus has been on the potential for AI to drive efficiency and unleash human creativity, AI also represents a sea change for how people can learn. We know the demand for skills training -- whether in the cybersecurity field or baseline digital skills – is massive and continues to grow. We’ll need to revolutionize how we train people, and we believe that AI skills can help. We’re just starting to explore the possibilities. And that’s incredibly exciting – and daunting.

That’s why, alongside data.org, Microsoft’s AI for Good Lab, and GitHub, we’re launching the Generative AI Skills Grant Challenge, an open grant program to explore, develop, and implement how nonprofit, social enterprise, and research or academic institutions can train and empower the workforce to use generative AI. This global grant will support organizations driving skilling and economic growth, especially those focusing on fair and community-led implementations of generative AI with historically marginalized populations around the world. In addition to financial support, the awardees will receive access to a cohort experience, Microsoft events, Azure-based cloud computing resources as well as data training and technical guidance from Microsoft and GitHub experts.

We strongly encourage nonprofit organizations, social enterprises, and academic or research institutions dedicated to upskilling opportunities in generative AI to apply. The grant is now accepting applications, with a deadline for initial proposals on August 15, 2023, and we’ll announce the winners this Fall. To learn more about the new grant visit data.org/challenge.

New, free skilling content

As part of our Skills for Jobs program, we're partnering with LinkedIn Learning to launch the first Professional Certificate on Generative AI in the online learning market. Through this new coursework, workers will learn introductory concepts of AI, including a look at responsible AI frameworks, and receive a Career Essentials certificate when they pass the assessment. This Professional Certificate on Generative AI is currently available in English and will launch in Spanish, Portuguese, French, German, Simplified Chinese, and Japanese over the coming months on LinkedIn Learning. As with the six other Career Essentials Professional Certificates offered with our Skills for Jobs program, this coursework will be unlocked and available for free through 2025

We’ll also launch a trainer toolkit for teachers, trainers, and facilitators who, as we know from the past five years of our skilling work, are critical in providing skilling resources and training to local communities. The toolkit will include downloadable, bite-sized content for trainers, including a new AI course built for educators by Microsoft Education and content on the practical uses of AI. Additionally, we are releasing the Microsoft Learn AI Skills Challenge, a free technical training challenge to learn essential AI skills with Microsoft products and services, beginning on July 17th – sign up HERE.

What’s next

Through our Skills for Jobs program, Microsoft has been working to bring digital skills to people around the world and ensure they’re not left behind in the digital economy. We’ve reached millions, helped people find new careers, and focused on the cybersecurity field and new, in-demand jobs in the digital economy. I’m extremely proud of what we’ve accomplished. This new effort is the next step in that campaign, marking a new beginning that will build on a new wave of technology innovation to come. We’re already seeing energy and excitement about AI’s potential and, more than anything, a tremendous appetite to learn more. Over the coming months we’ll be announcing new dimensions to this effort, with new partners, new goals, and new ideas. And, as always, we’ll share our lessons learned as the program evolves.

As Microsoft’s President and Vice Chair Brad Smith recently said, “AI offers perhaps even more potential for the good of humanity than any invention that has preceded it.” But to live up to this potential, people need the skills to use AI effectively and ethically."
Microsoft_News,https://azure.microsoft.com/en-us/blog/the-economic-benefits-of-innovating-with-azure-ai/,,The economic benefits of innovating with Azure AI,"At Microsoft Build this year our CEO Satya Nadella grounded the excitement surrounding AI back to one simple goal: to better serve unmet user needs. He asked “Why do we build software?” and, in doing so, he reminded us it’s not the technological capabilities of AI tools that make them so valuable, but instead where we apply them and for whom. Great products have always, and will always, be about people, and that’s what’s energizing us most on the Microsoft Azure team right now.

Azure customers are already infusing AI in incredible ways, building next-gen app experiences with cutting-edge innovation from Azure AI services with the backing of Azure’s trusted cloud platform. CarMax, H&R Block, the NBA, and most recently announced, Mercedes-Benz are putting Azure AI to work to differentiate their respective businesses, and they’re proving how investments in innovation quickly pay themselves forward—even during a challenging economy. When AI-powered apps like the CarMax research tool help us scour online reviews of 4,500 car types in seconds, or NBA CourtOptix serves up insights behind our favorite players’ moves, we see first-hand how our own needs inspire truly remarkable software development.

Even so, some customers that are ready to invest in AI tell us that they need help making the financial case for the tools they need to build great products. That’s why today we’re sharing a new Total Economic Impact™ (TEI) study conducted by Forrester Consulting, which captures the costs and benefits of innovating with Azure AI services over a three-year journey. The report analyzes not just one Azure AI service but the exponential effect of multiple. CarMax, for example, leverages a combination of Azure OpenAI’s Chat GPT, Azure Cognitive Search, and Azure Machine Learning Responsible AI dashboard to design their own data-driven AI solution. When you partner with Azure, you gain access to pre-trained large language models that are enterprise-ready and it’s exciting to see customers combine our products to create their own digital IP with the same building blocks Microsoft trusts for its products.

Bring high-quality AI to market with fast ROI

Grounded in a composite organization, trusted financial model, and interviews with decision-makers across five organizations, our new Forrester study shows how Azure AI services collectively resulted in a 284 percent return on investment. Forrester breaks this big number down into tangible value by category, calculating $12.6 million gains from business growth and $16.1 million gains in spending optimization. Impact of such magnitude doesn’t happen overnight, but it also happens a lot sooner than some organizations might think. With a well-architected cloud foundation, AI can be infused smoothly into all kinds of applications and start automating cumbersome processes fairly fast.

In Forrester’s findings, Azure AI services showed potential payback in less than six months because Azure’s pre-trained models are so accurate and the services integrate well across other Azure and Microsoft Cloud products. Azure AI also offers turnkey services that unblock specific tasks even faster out of the box. Azure Form Recognizer, for example, continues to be incredibly popular because it was purposefully designed to make documents intelligent and searchable. In a single service, it brings together business logic, the orchestration of multiple AI skills, and a UI to support more nimble app deployment.

Above is an executive summary from the Total Economic Impact of Microsoft Azure AI, a study conducted by Forrester Consulting and commissioned by Microsoft in April of 2023.

Start small to move quickly and grow fast

Creating space and resources for technological innovation has never been easy, but it’s what keeps companies competitive through economic headwinds. Lately, what’s been most interesting for me as a B2B marketer is watching my own friends and family members realize the possibilities of AI as we experiment with prompt engineering in the new Bing around a dinner table. It has struck me that AI isn’t in the background anymore; it’s very much at the forefront of how we think about tackling solutions through software and what we as humans expect from digital experiences. The transformative shift of generative AI has all industries reimagining their products and services. In Forrester’s study, Azure AI helped generate revenue from new products, and the value of these compounded in worth year-over-year, generating $3.1 million of revenue growth in year one, then $5.6 million in year two, and $6.9 million in year three. Well-calculated risks are the ones organizations can’t afford not to take, especially when they serve those unmet user needs.

The qualitative interviews Forrester conducted for the study revealed a trend across the five different organizations who participated: using a planful pilot approach produces strong financial results. In aggregate, value was mapped from initial planning, model development, and training with just eight people to an expanded team of 40 data engineers and data scientists. The study itself essentially demonstrates what a startup mentality inside a large organization can do. One retail customer interviewed said something that just stuck with me as we look at the cash flow chart below, they said, “Before, we didn’t have maturity around ML (machine learning). Now that we do, we can move away from a subscription-based tool which is not cheap, and go to a consumption-based tool like Azure, where 100 percent of what we build is an asset [to our organization] …” That’s exactly what innovating with Azure is about: helping you build your own proprietary value in the cloud—unique solutions your competitors can’t buy.

Above is a cash flow chart from the Total Economic Impact of Microsoft Azure AI, a study conducted by Forrester Consulting and commissioned by Microsoft in April of 2023.

The AI adventure

We often talk about technology as a journey, and in this journey, AI is what gives digital transformation a sense of adventure and purpose again. The cost savings and optimization of cloud computing will continue to fund the magic of AI. It’s all interconnected and when you partner with Azure to build and run AI, that’s how we’ll support your vision and your teams.

Be sure to download the full Forrester study here and contact your Microsoft account team to learn more about how to get started with AI today. All you need is a great business idea. Learn more about Azure AI today."
Microsoft_News,https://news.microsoft.com/source/shortform/new-ai-powered-tools-are-helping-democratize-agriculture-in-argentina/,,New AI-powered tools are helping democratize agriculture in Argentina,"New AI-powered tools are helping democratize agriculture in Argentina and beyond by connecting small farmers with agronomists, data scientists and algorithms that help them sow, water, fertilize and harvest more efficiently — and become more sustainable and competitive.

"
Microsoft_News,https://news.microsoft.com/source/features/ai/argentina-wine-agriculture/,,AI empowers Argentine small farmers and winemakers to compete better,"When Elizabeth Panella’s father passed away in 2015, she and her brothers inherited the family vineyards in Argentina. Panella, who had an established career as an accountant, found herself immersed in grapes and wine.

The siblings were just getting their feet under them as newly minted vintners in Mendoza, the largest wine-producing region in South America, known for its Malbec, when the pandemic hit — in the middle of the harvest season. People around the world were embracing remote work and video calls to avoid spreading the virus, and Panella likewise turned to technology to help reduce physical contact in tallying buckets of grapes picked.

Before long, she’d adopted a slew of new AI-powered tools that now are helping revolutionize and democratize agriculture in Argentina and beyond by giving small farmers access to agronomists, data scientists and algorithms that help them sow, water, fertilize and harvest more efficiently to save money and become more sustainable and competitive. Other countries around the globe are taking note of the “agtech” revolution as governments try to boost food production to feed growing populations, even amid a shrinking supply of water and farmland and increasing challenges from geopolitical and economic unrest.

“There’s a sense of rootedness, and we don’t want tomorrow to be lost,” Panella says. “We have continued with the tradition of my great-grandparents, grandparents and my father, and now we are handling the wine production as best as we can to deliver the farm to our children in the future” — including by embracing new agricultural demands, such as traceability, which she says is “much easier to carry out with technology.”

About a quarter of the earth’s arable land and forests are in Latin America, according to The Nature Conservancy. And Argentina in particular is an agricultural powerhouse, ranking among the top providers of food worldwide, according to the World Bank, and specializing in wine, beef and soybeans, among other crops. So, the country’s vintners and farmers have vast influence over global food production.

Click here to load media

“Agriculture is the essence of life and the mother of all industries,” says Agrobit CEO and founder Horacio Balussi. “To put a seed in the ground and grow food gives people a different vision of the world and their life, so farmers are different people, very special.”

Balussi, who grew up as the son of a carpenter in a community of corn farmers in Argentina, created Agrobit, a tech company that began with agricultural software 40 years ago and in 2019 used AI and machine learning for the country’s first intelligent agriculture system.

Agrobit worked with Microsoft to build a customizable, Azure-based platform and then to accelerate its certification and entry into the marketplace to get it to farmers and vintners faster. Microsoft already had experience in the industry through its Project FarmBeats and Project FarmVibes programs, which use data from sensors, drones, satellites, connected tractors and other equipment on the farm to feed AI-powered tools and algorithms that turn data into intelligence. Microsoft recently announced Microsoft Azure Data Manager of Agriculture, a commercial solution that is built on the foundation of Project FarmBeats.

Agrobit’s first AI-enabled platform focused on soybeans, corn and wheat, and has expanded from there to help manage 50 different crops, including lemons, tomatoes and avocados, all grown on about 7 million acres of its clients’ farms. The system constantly improves, helping growers produce greater output while reducing the input — such as seed, water and fertilizer — by putting precise amounts in precise places to create a more sustainable model for food production, Balussi says. Agrobit clients are seeing overall cost savings of as much as 30% when they implement the systems’ recommendations, says José Avalis, an Agrobit technologist."
Microsoft_News,https://blogs.bing.com/search/june-2023/Bing-Preview-Release-Notes-Bing-Chat-iOS-Widget-and-more,,Bing Preview Release Notes: Bing Chat iOS Widget and more,"We continue to ship previously announced features and respond to your product feedback. Some of these features may temporarily appear in your Bing Chat experience as we experiment with them. These Release Notes will update you on which features have shipped and are fully available to everyone as of today.

Here’s what we updated this week:

Bing Chat iOS widget: We’ve launched a new Bing Chat widget you can add to iOS. Once installed, you can initiate chat from your Home screen. If you have an iOS device, instructions for how to add widgets to your Home screen can be found here (as previously announced this is already available on Android).

Expanded voice language support: Last week, we shipped improvements to voice and text-to-speech language support. This week, we released text-to-speech support for even more languages: Arabic, Bulgarian, Catalan, Croatian, Czech, Danish, Dutch, Estonian, Filipino, Finnish, Greek, Gujrati, Hebrew, Hindi, Hungarian, Icelandic, Indonesian, Irish, Italian, Korean, Latvian, Lithuanian, Maltese, Marathi, Norsk Bokmål, Polish, Portuguese, Romanian, Russian, Slovak, Spanish, Swedish, Tamil, Telugu, Thai, Turkish, Ukrainian, and Urdu.

Svo mörg tungumál!

Mobile voice performance improvements: We’ve improved the performance of the voice input button on the Bing mobile app for iOS and Android. It should now indicate it’s listening instantly once you tap it.

Keep your feedback coming!

- The Bing Team"
Microsoft_News,https://cloudblogs.microsoft.com/dynamics365/bdm/2023/06/15/introducing-next-generation-ai-and-microsoft-dynamics-365-copilot-capabilities-for-erp/,,Introducing next-generation AI and Copilot capabilities for ERP,"Welcome to a new era in enterprise resource planning (ERP) systems, powered by AI. In recent years, businesses have embraced AI to automate and enhance processes from planning to forecasting. Now, generative AI is taking center stage as a game-changing technology that promises to modernize the way work gets done, driving innovation across ERP; from streamlining operations to speeding time to actionable insight.

Dynamics 365 Copilot, announced in March, takes advantage of recent advancements in generative AI to automate tedious tasks and unlock the full creativity of the workforce. In April, we shared how generative AI can be applied to key supply chain processes, and today we are introducing more AI-powered assistance across our ERP portfolio, included in Microsoft Dynamics 365 Finance, Dynamics 365 Project Operations, and Dynamics 365 Supply Chain Management. To activate these new Copilot features within your Dynamics 365 products, work with your IT admin.

ERP systems have long been the central nervous system of modern businesses, centralizing data for better business insight from core functions like finance, HR, procurement, resourcing, and supply chains. However, traditional ERP solutions have struggled to keep pace with the dynamic nature of today’s global markets. Complex and rigid processes within ERP create more work for people, and repetitive manual data entry overwhelms departments. Dynamics 365 Copilot promises to help finance managers, collections agents, project managers, and procurement professionals complete time-consuming tasks and get insights faster.

Speed time to insight—get the most from your ERP data

Harnessing big data is even more crucial as we enter a new era defined by next-generation AI. At Microsoft Build 2023, we announced how Microsoft Dynamics 365 and Microsoft Fabric work with Dataverse and our business intelligence tools to deliver actionable insights and reporting. Our upcoming extended planning and analytics solution will build on this powerful foundation to help finance managers and business analysts spend less time slicing and dicing data. With the ability to use familiar tools like Microsoft Power BI and Excel infused with Copilot capabilities, these professionals can:

Use natural language to bring data to life by simply describing the visuals and insights that one is looking for. Copilot will help create a Microsoft Power BI dashboard or report—complete with visualizations and summaries—and help refine it. One can dig into the data further by asking questions. Copilot will find the right answer.

Collaboratively align plans, budgets, and forecasts with business strategy.

Streamline sales and operations planning.

Automate financial consolidation for seamless book closing.

Strategically close talent gaps for an empowered workforce, gain a comprehensive view of cash flow dynamics, and access highly accurate predictions through advanced predictive analytics powered by machine learning and AI.

By using these tools and technologies, finance managers can optimize their performance, allocate resources effectively, and drive better financial outcomes for their organizations.

Deliver more strategic value with intelligent automation for project managers

Project managers frequently struggle to complete projects on time and within budget. Today, we are announcing Copilot capabilities for Dynamics 365 Project Operations to dramatically reduce the time spent on project status reports, task planning, and risk assessments.

With Copilot, project managers can rapidly create new project plans for new engagements in minutes, instead of hours, simply by describing details of the project using natural language. Copilot will generate a project plan that can be further refined by the project manager.

Once the project is underway, the project manager can use Copilot to create a project status report, which Copilot will help generate in moments—reducing the hours often spent manually researching and writing. To ensure project success, Copilot then can be used to identify risks and suggest mitigation plans on a continuous basis. For example, the project manager can prompt Copilot to search across all open projects to identify common project risks that can derail a project, such as significant delays or budget overruns.

With Copilot, project managers can improve efficiency, reduce risks, and focus on more strategic and value-added activities.

Supercharge productivity of collections agents and procurement professionals

Today, we are announcing Copilot capabilities that will help collections agents and procurement professionals enhance productivity and better collaborate with customers.

Timely payments and healthy cash flows are increasingly important in times of economic uncertainty. With Copilot in Dynamics 365 Finance, collections managers have quick access to credit and payment history so they can prioritize and personalize customer communication, helping to increase successful collection rates and proactively keep customers in good standing.

Disruptions to supply chains are an everyday occurrence, and supply and demand can shift quickly. Workers like procurement professionals and buyers are tasked to sort through large volumes of purchase order change responses daily and need more intelligent and agile tools to help address and streamline this process. Order responses oftentimes require changes to ordered quantities, delivery dates, or products delivered. Today, procurement professionals must review the changes for individual orders one by one to identify the risk to plan and potential downstream impacts. With Copilot in Dynamics 365 Supply Chain Management, users are able to efficiently handle changes to purchase orders at scale and assess the impact and risk to help optimize procurement decisions.

They can quickly identify high-impact or low-impact changes and take rapid action to address any risk. Copilot enables quick collaboration with internal and external stakeholders that brings relevant information into Outlook and Teams using natural language. Users can also dig deeper with pointed questions to refine and approve changes so they can rapidly adapt their sourcing plans to meet customer and partner needs.

At Microsoft, we are fully committed to revolutionizing the future of ERP by harnessing the power of intelligent, composable technologies. With its ability to speed time to insight, intelligently automate processes, and foster productivity, Copilot can help you stay ahead in an increasingly complex business landscape. With Copilot, you’re in control as it is grounded in your business data and automatically inherits your valuable security, compliance and privacy policies, regulations, and processes. Stay tuned and join us on this exciting journey into the future of ERP.

Learn more about the latest AI breakthroughs with Microsoft Dynamics 365 Copilot on the Dynamics 365 AI webpage or through a free trial.

Next-generation AI across Microsoft business applications With next-generation AI, interactions with AI across business roles and processes will become second nature. Discover more about AI"
Microsoft_News,https://azure.microsoft.com/en-us/blog/mercedes-benz-enhances-drivers-experience-with-azure-openai-service/,,Mercedes-Benz enhances drivers’ experience with Azure OpenAI Service,"With ChatGPT, MBUX Voice Assistant “Hey Mercedes” will become even more intuitive – the U.S. beta program is expected to last three months.

When I started driving in the 1990s, I thought I was living in the future. My first car had everything I thought I could ever need: a built-in radio, lighting when you opened the door, windows you could roll down with a crank, a clock and even air-conditioning for those really hot days growing up on the East Coast.

That car is long gone, but my passion for driving things forward lives on, which is why I’m excited to share how Mercedes-Benz is using Microsoft AI capabilities to enhance experiences for some drivers today.

As the last six months have shown us, the power of generative AI goes beyond cutting-edge language models—it’s what you build with it that matters most. Our Azure OpenAI Service lets companies tap into the power of the most advanced AI models (Open AI’s GPT-4, GPT-3.5, and more) combined with Azure’s enterprise capabilities and AI-optimized infrastructure to do extraordinary things.

Mercedes-Benz takes in-car voice control to a new level with Azure OpenAI Service

Today, Mercedes-Benz announced they are integrating ChatGPT via Azure OpenAI Service to transform the in-car experience for drivers. Starting June 16, drivers in the United States can opt into a beta program that makes the MBUX Voice Assistant’s “Hey Mercedes” feature even more intuitive and conversational. Enhanced capabilities include:

Elevated voice command and interaction : ChatGPT enables more dynamic conversations, allowing customers to experience a voice assistant that not only understands voice commands but also engages in interactive conversations.

: ChatGPT enables more dynamic conversations, allowing customers to experience a voice assistant that not only understands voice commands but also engages in interactive conversations. Expanded task capability : Whether users need information about their destination, a recipe, or answers to complex questions, the enhanced voice assistant will provide comprehensive responses, allowing drivers to keep their hands on the wheel and eyes on the road.

: Whether users need information about their destination, a recipe, or answers to complex questions, the enhanced voice assistant will provide comprehensive responses, allowing drivers to keep their hands on the wheel and eyes on the road. Contextual follow-up questions : Unlike standard voice assistants that often require specific commands, ChatGPT excels at handling follow-up questions and maintaining contextual understanding. Drivers can ask complex queries or engage in multi-turn conversations, receiving detailed and relevant responses from the voice assistant.

: Unlike standard voice assistants that often require specific commands, ChatGPT excels at handling follow-up questions and maintaining contextual understanding. Drivers can ask complex queries or engage in multi-turn conversations, receiving detailed and relevant responses from the voice assistant. Integration with third-party services: Mercedes-Benz is exploring the ChatGPT plugin ecosystem, which would open up possibilities for integration with various third-party services. This could enable drivers to accomplish tasks like restaurant reservations, movie ticket bookings, and more, using natural speech commands, further enhancing convenience and productivity on the road.

With the three-month beta program, Mercedes-Benz customers can become early adopters of this groundbreaking technology. Based on the findings of the beta program and customer feedback, Mercedes-Benz will consider further integration of this technology into future iterations of their MBUX Voice Assistant while maintaining the highest standards of customer privacy on and off the road.

With Microsoft, Mercedes-Benz is paving the way for a more connected, intelligent, and personalized driving experience, and accelerating the automotive industry through AI.

In case you missed it, at Microsft Build we recently announced updates to Azure OpenAI Service to help you more easily and responsibly deploy generative AI capabilities powered by Azure. You can now:

Use your own data (coming to public preview later this month), allowing you to create more customized, tailored experiences based on organizational data.

(coming to public preview later this month), allowing you to create more customized, tailored experiences based on organizational data. Add plugins to simplify integrating external data sources with APIs.

to simplify integrating external data sources with APIs. Reserve provision throughput (generally available with limited access later this month) to gain control over the configuration and performance of OpenAI’s large language models at scale.

(generally available with limited access later this month) to gain control over the configuration and performance of OpenAI’s large language models at scale. Create safer online environments and communities with Azure AI Content Safety, a new Azure AI service integrated into Azure OpenAI Service and Azure Machine Learning prompt flow that helps detect and remove content from prompts and generation that don’t meet content management standards.

A responsible approach

Microsoft has a layered approach for generative models, guided by Microsoft’s responsible AI principles. In Azure OpenAI Service, an integrated safety system provides protection from undesirable inputs and outputs and monitors for misuse. In addition, Microsoft provides guidance and best practices for customers to responsibly build applications using these models and expects customers to comply with the Azure OpenAI Code of Conduct. With Open AI’s GPT-4, new research advances from OpenAI have enabled an additional layer of protection. Guided by human feedback, safety is built directly into the GPT-4 model, which enables the model to be more effective at handling harmful inputs, thereby reducing the likelihood that the model will generate a harmful response.

Get started with Azure OpenAI Service"
Microsoft_News,https://news.microsoft.com/apac/features/microsofts-tom-burt-on-geopolitics-and-cybersecurity-in-the-age-of-ai/,,Microsoft’s Tom Burt on geopolitics and cybersecurity in the age of AI,"As digital threats proliferate across the world, it’s getting harder to keep them at bay. Wars are now fought both on the ground and in cyberspace. New AI technologies can help ward off cyberattacks or could – in the absence of future regulation – help the bad actors.

These are some of the issues that keep Tom Burt, Microsoft’s corporate vice president of Customer Security and Trust, up at night. We caught up with him during his trip through Asia. He talked about emerging cybersecurity threats in the region and his experience at the IIS Shangri-La Dialogue in Singapore, where defense chiefs met in early June to talk about security challenges in Asia.

Here is an edited transcript.

Q: You were just at the IISS security conference in Singapore. What jumped out at you? Any surprises?

A: Last year, the hybrid war in Ukraine was new and the use of destructive malware by Russia as part of its invasion of Ukraine was new. This year, everyone remains very interested in what the threat environment is and what they can do to address that.

The one part that was surprising, which has gotten quite a bit of press, was the appearance by both the Secretary of Defense of the United States – and his speech – and then his analog, General Li from the People’s Republic of China and his somewhat fiery speech that I think took a number of us by surprise.

It made clear that the tensions between the two nations remain high.

It really reinforced the need for Microsoft to be great partners with the region’s governments and especially to help them have strong, resilient cybersecurity.

Q: You have touched on cybersecurity threats by nation states. How is that evolving and what’s been done since?

A: In terms of the nation state threat landscape, what we’re seeing with Russia is an ongoing effort for its cyber activity to support its invasion and war with Ukraine. What we’ve seen just in the last couple of months is a significant resurgence in cyber activity and most of it has been to gain information, intelligence and understanding of a wide range of targets within Ukraine as well as in the US, the UK and the EU, especially those that are supporting Ukraine’s defense, including private enterprise.

Iran has been stepping up its aggression. Other than Russia in Ukraine, it’s the only other nation state we see at this time utilizing any kind of destructive malware. We’ve seen Iran utilizing ransomware to actually steal money and engaging in a wider range of intelligence-gathering attacks.

Historically, they’ve largely worked in the Middle East and targeted the energy sector, but now we’ve seen them extending that much more broadly around the globe, especially targeting the US and a wider range of sectors.

North Korea has continued to engage in intelligence gathering especially in the region, particularly targeting Japan, but also in the US and other regional targets – especially in academia and think tanks as well as some military technology targets.

But the big development with North Korea is its great success in stealing cryptocurrency equivalent to hundreds of millions of dollars – enough so that their cyber operation has become an important funder of government operations.

And then there’s China.

We’ve seen China continuing and even expanding its cyber operations to gather intelligence and information globally but with a particular focus on the Asia Pacific region, Southeast Asian countries in particular.

The Microsoft Threat Intelligence team recently published a blog on this great work that they did tracking a Chinese actor called Volt Typhoon who engaged in some very creative attacks utilizing IoT devices as a means of gaining entry into networks at critical infrastructure targets in Guam and in the United States.

Q: You mentioned hybrid warfare in Ukraine continuing to be of interest. Are there implications or lessons here for Asia?

A: Maybe the most important lesson was the importance of the hyperscale cloud.

At the outset of the war, one of the first missiles launched by Russia targeted the Ukraine government datacenter. And Ukraine had just recently passed laws to allow them to move to the cloud.

We know it’s the case that security in the hyperscale cloud is much greater than you can ever provide on premise. We proved that in Ukraine, when Microsoft’s Defender for Endpoint used an AI algorithm to identify Russian wiper malware and stop it from being installed in the customer’s network.

With the 65 trillion signals that we get into Microsoft from our global ecosystem every day, we will be able to train ever more capable AI to identify code and systems that are up to no good and protect our customers.

The other lesson we learned was how the work that the Microsoft Threat Intelligence team does to track these nation state actors provides a great resource to help defend against these attacks.

There have been times when we’ve been able to provide that threat intelligence quickly enough to prevent an attack, and there are other times when that threat intelligence has helped them recover more quickly.

Continuing to build partnerships across governments and working together on how we can better defend against cyberthreats is the right solution. The hybrid war in Ukraine makes clear how the private and public sectors need to work together to achieve digital peace. So those are really the key lessons learned."
Microsoft_News,https://www.microsoft.com/en-us/industry/blog/financial-services/2023/06/05/combat-financial-crime-with-ai-and-advanced-technology-from-microsoft/,,Combat financial crime with AI and advanced technology from Microsoft,"Financial services organizations have long recognized technology as a transformative force in their business models. Now they’re at the cusp of taking advantage of new advances in AI and data science to seriously combat some of the most pernicious criminal activities around the world.

With Microsoft Cloud for Financial Services, our customers are managing financial services data at scale and building solutions that improve customer experiences and operational efficiencies. With the advent of generative AI capabilities in Azure OpenAI Service, businesses can now unlock new value from their data not only to drive better customer outcomes but also to improve their protection against various kinds of financial crime—including fraud, electronic crime, and money laundering.

The financial costs and scale of these crimes are staggering. Worldwide, the estimated total of laundered money in a year is at least two percent of global gross domestic product, or USD800 billion.1 For financial services organizations, the cost of financial crime compliance reached USD213.9 billion in 20212—USD56.7 billion in Canada and the United States alone in 2022,3 a 13.6 percent increase from 2021.

Until recently, financial services organizations have felt hamstrung in their ability to combat the worst forms of criminal activity. They play a cat-and-mouse game with bad actors who use a wide variety of financial instruments in sophisticated ways, exploiting the distributed nature of the financial system to perpetrate their crimes. Criminals might, for example, engage in small transactions across many different institutions, or across different accounts in the same financial institution, to mask their activities.

Protecting privacy while advancing security

The global focus on digital privacy in an increasingly interconnected world is a cornerstone of trust, human rights, and individual empowerment. Privacy is mandated by legislation around the world, such as the Digital Charter Implementation Act 2022 in Canada and in the European Union’s General Data Protection Regulation. And of course, banks and other financial services firms also know that customers will vote with their feet if their data is leaked or mishandled.

At its core, privacy is about protecting personal information. And this poses some challenges in fighting financial crime, because it impairs organizations from knitting together a complete picture of what an individual bad actor or a group of bad actors may be doing. The keys are all there in transaction records, account information, customer relationship databases, and so on. But they remain off limits when they are associated with personally identifiable information.

Fortunately, businesses can now attack the problem using novel technologies such as confidential computing and AI that allow multiple parties to safely gain insights from financial data without violating privacy requirements.

Confidential computing and de-identification: New layers of protection

A host of modern, cloud-based capabilities and methods enables this shift. For one, data can be better protected in the cloud with solutions like Azure confidential computing. This unique service encrypts data while it’s being processed, meaning that data is no longer only protected at rest and in transit, but also in use. While in memory, it simply cannot be accessed by cloud operators, malicious administrators, or even privileged software such as a hypervisor.

The root of trust in Azure confidential computing resides in independent hardware. Not even Microsoft operators can access the encryption keys. This is what enables government customers to independently, cryptographically verify the identity and “known good state” of the cloud operating environment they are relying on.

Concurrently, regulators are beginning to recognize the impact of new techniques for de-identification, which obfuscates or removes personally identifiable information from data sets. Data masking, data perturbation, and differential privacy are some of the powerful tools and methods of de-identification that are proving their effectiveness by making data available to AI to deliver important insights without putting privacy at risk.

While securing the benefits of strong privacy protections, financial services organizations are now able to work across enterprise data sets—to reason over data from not just one location, but across different locations and potentially even different institutions. This dramatically changes how a firm handles data. Swift is just one recent example of a financial services firm that has benefited from these innovations in building an anomaly detection model for transactional data without copying or moving data from secure locations. And, significantly, it means that AI and related tools and technologies will now be able to explore, analyze, and spot trends and insights that not only help their businesses, but can have positive societal impact as well.

How AI helps financial services organizations

With AI, financial services firms have new capabilities for risk assessment and scoring, which can help prioritize investigations and resources. They can also benefit from pattern recognition, which can detect anomalies and suspicious activities across large sets of financial transactions, customer data, and other sources. This has significant implications for fraud management, which financial services organizations rely on to mitigate their risks. If a firm can show new levels of due diligence, underwriting costs can potentially be reduced.

Additionally, generative AI can be used to analyze a wide array of unstructured data from a variety of internal repositories to spot indicators of potentially suspicious activities. Natural language processing will assist in the delivery of regulatory documents, legal texts, and compliance reports. And financial institutions may realize broad organizational benefits through integration into productivity applications. At Microsoft, we’re all about democratizing AI and making these tools approachable and available not simply to the data analysts and mathematicians, but to people across the business. This is reflected in the broad innovations announced recently at Microsoft Build 2023, in which we have integrated AI into Azure, Microsoft 365, our development tools, and much more. These AI-powered products help surface more useful information for better decision-making and greater efficiencies across the organization.

The art of the possible

In our work with customers, we see a wave of interest in exploring the potential of these powerful new tools to fight fraud, money laundering, and other forms of financial crime. In Canada, privacy enhancing capabilities have long been bolstered by affirmation from the Information and Privacy Commissioner of Ontario that de-identification is a legitimate and valuable way to protect information, and enterprises have been provided with guidance on how to proceed. It’s powerful confirmation that organizations can leverage new approaches to address privacy considerations as they explore new opportunities. Once we light up the art of the possible, the dialogue quickly shifts and we can work collaboratively to solve these tough challenges.

Fight financial crime with the Microsoft Cloud

Collaboration is the key to industry-wide progress in the fight against all kinds of financial crime and fraud. Working well together is a core Microsoft value, and that means much more than ensuring that our products and tool sets are integrated. It means that we recognize that these challenges are bigger than us or any one company, organization, or entity. So, we promote and support the roles that every player in the ecosystem performs, from industry partners to government officials, regulators, law enforcement agencies, and of course customers.

For financial services organizations who want to explore these new possibilities, an exploratory engagement or proof-of-concept is a good way to examine how the technology and process puzzle pieces fit together. We’re constantly amazed at the inventive and impactful ways that customers are employing these tools to do better for their organizations and the world at large.

Read further in a recent post about how the Microsoft Cloud helps banks manage risk and discover real-world customer examples and other resources that show how Microsoft and our global partners can help banks deepen risk insights, facilitate regulatory compliance, and combat financial crime.

124 Alarming Money Laundering Statistics [New Data 2022 & Infographic], BusinessDIT.

2Global spend on financial crime compliance at financial institutions reaches $213.9 billion, Finextra.

3True Cost of Finacial Crime Compliance Study for the United States an Canada, LexisNexis Risk Solutions."
Microsoft_News,https://blogs.microsoft.com/blog/2023/06/08/announcing-microsofts-ai-customer-commitments/,,Announcing Microsoft’s AI Customer Commitments,"AI is creating unparalleled opportunities for businesses of every size and across every industry. We are seeing our customers embrace AI services to drive innovation, increase productivity and solve critical problems for humanity, such as the development of breakthrough medical cures and new ways to meet the challenges of climate change.

At the same time, there are legitimate concerns about the power of the technology and the potential for it to be used to cause harm rather than benefits. It’s not surprising, in this context, that governments around the world are looking at how existing laws and regulations can be applied to AI and are considering what new legal frameworks may be needed. Ensuring the right guardrails for the responsible use of AI will not be limited to technology companies and governments: every organization that creates or uses AI systems will need to develop and implement its own governance systems. That’s why today we are announcing three AI Customer Commitments to assist our customers on their responsible AI journey.

First, we will share what we are learning about developing and deploying AI responsibly and assist you in learning how to do the same. Microsoft has been on a responsible AI journey since 2017, harnessing the skills of nearly 350 engineers, lawyers and policy experts dedicated to implementing a robust governance process that guides the design, development and deployment of AI in safe, secure and transparent ways. More specifically we are:

Sharing expertise: We are committed to sharing this knowledge and expertise with you by publishing the key documents we developed during this process so that you can learn from our experiences. These include our Responsible AI Standard, AI Impact Assessment Template, AI Impact Assessment Guide, Transparency Notes, and detailed primers on the implementation of our responsible AI by design approach.

Providing training curriculum: We will also share the work we are doing to build a practice and culture of responsible AI at Microsoft, including key parts of the curriculum that we use to train Microsoft employees.

Creating dedicated resources: We will invest in dedicated resources and expertise in regions around the world to respond to your questions about deploying and using AI responsibly.

Second, we are creating an AI Assurance Program to help you ensure that the AI applications you deploy on our platforms meet the legal and regulatory requirements for responsible AI. This program will include the following elements:

Regulator engagement support: We have extensive experience helping customers in the public sector and highly regulated industries manage the spectrum of regulatory issues that arise when dealing with the use of information technology. For example, in the global financial services industry, we worked closely for a number of years with both customers and regulators to ensure that this industry could pursue digital transformation on the cloud while complying with its regulatory obligations. One learning from this experience has been the industry’s requirement that financial institutions verify customer identities, establish risk profiles and monitor transactions to help detect suspicious activity, the “know your customer” requirements. We believe that this approach can apply to AI in what we are calling “KY3C,” an approach that creates certain obligations to know one’s cloud, one’s customers and one’s content. We want to work with you to apply KY3C as part of our AI Assurance Program.

Risk framework implementation: We will attest to how we are implementing the AI Risk Management Framework recently published by the U.S. National Institute of Standards and Technology (NIST) and will share our experience engaging with NIST’s important ongoing work in this area.

Customer councils: We will bring customers together in customer councils to hear their views on how we can deliver the most relevant and compliant AI technology and tools.

Regulatory advocacy: Finally, we’ll play an active role in engaging with governments to promote effective and interoperable AI regulation. The recently launched Microsoft blueprint for AI governance presents our proposals to governments and other stakeholders for appropriate regulatory frameworks for AI. We have made available a presentation of this blueprint by Microsoft Vice Chair and President Brad Smith and a white paper discussing it in detail.

Third, we will support you as you implement your own AI systems responsibly, and we will develop responsible AI programs for our partner ecosystem.

Dedicated resources: We will create a dedicated team of AI legal and regulatory experts in regions around the world as a resource for you to support your implementation of responsible AI governance systems in your businesses.

Partner support: Many of our partners have already created comprehensive practices to help customers evaluate, test, adopt and commercialize AI solutions, including creating their own responsible AI systems. We are launching a program with selected partners to leverage this expertise to assist our mutual customers in deploying their own responsible AI systems. Today we can announce that PwC and EY are our launch partners for this exciting program.

Ultimately, we know that these commitments are only the start, and we will have to build on them as both the technology and regulatory conditions evolve. But we are also excited by this opportunity to partner more closely with our customers as we continue on the responsible AI journey together.

Tags: AI, Responsible AI"
Microsoft_News,https://azure.microsoft.com/en-us/blog/unlock-new-insights-with-azure-openai-service-for-government/,,Azure OpenAI Service: Transforming Workloads for Azure Government,"Microsoft continues to develop and advance cloud services to meet the full spectrum of government needs while complying with United States regulatory standards for classification and security. The latest of these tools, generative AI capabilities through Microsoft Azure OpenAI Service, can help government agencies improve efficiency, enhance productivity, and unlock new insights from their data.

Many agencies require a higher level of security given the sensitivity of government data. Microsoft Azure Government provides the stringent security and compliance standards they need to meet government requirements for sensitive data.

Currently, large language models that power generative AI tools live in the commercial cloud. For government customers, Microsoft has developed a new architecture that enables government agencies to securely access the large language models in the commercial environment from Azure Government allowing those users to maintain the stringent security requirements necessary for government cloud operations.

If you’re an Azure Government customer (United States federal, state, and local government or their partners), you now have the opportunity to use the Microsoft Azure OpenAI Service through purpose-built, AI-optimized infrastructure providing access to OpenAI’s advanced generative models.

Azure OpenAI Service

Azure OpenAI Service REST APIs provide access to OpenAI’s powerful language models, including GPT-4, GPT-3, and Embeddings. You can adapt these models to your specific task, including but not limited to content generation, summarization, semantic search, and natural language-to-code translation.

You can also access the service using REST APIs, Python SDK, or our web-based interface in the Azure AI Studio. As an Azure Government customer or partner, you can access and operationalize advanced AI models and algorithms at scale. Developers can use Azure OpenAI Service to access pre-trained GPT models to build and deploy AI-enabled applications more quickly and with minimal effort.

Capability enhancements with Azure OpenAI Service

Azure OpenAI Services can help government customers accelerate their operations and unlock new insights to meet their mission needs. This service will enable key new functions to help customers:

Accelerate content generation: Automatically generate responses based on mission or project inquiries to help reduce the time and effort required for research and analysis, enabling teams to focus on higher-level decision-making and strategic tasks.

Streamline content summarization: Generate summaries of logs and rapid analysis of articles, analysts, and field reports.

Optimize semantic search: Enable enhanced information discovery and knowledge mining.

Simplify code generation: Build custom applications using natural language to query proprietary data models and rapidly generate code documentation.

One of the most effective ways to generate reliable answers is to prompt the model to draw its responses from grounding data. If your use case relies on up-to-date, reliable information and is not purely a creative scenario, we strongly recommend providing grounding data based on trusted internal data sources. In general, the closer you can get your source material to the final form of the answer you want, the less work the model needs to do, which means there is less opportunity for error.

Azure Government to Azure commercial networking

Azure Government peers directly to the commercial Microsoft Azure network, including routing and transport capabilities to the internet and the Microsoft Corporate network. Azure Government limits its exposed surface area by applying extra protections and communications capabilities of the commercial Azure network. Additional information highlighting Azure Government environment isolation can be found on our Azure Government security website.

Microsoft encrypts all Azure traffic within a region or between regions using MACsec, which relies on AES-128 block cipher for encryption. This traffic stays entirely within the Microsoft global network backbone and never enters the public internet. The backbone is one of the largest in the world with more than 250,000 km of lit fiber optic and undersea cable systems.

Access and reference architecture

Access to the Azure OpenAI Service is available through the Azure Government environment. Azure Government peers directly with the commercial Azure network and doesn’t peer directly with the public internet or the Microsoft corporate network. As shown in the reference architecture in Figure 1, connection to Azure OpenAI is over the Microsoft backbone network to access and operationalize advanced AI models and algorithms securely and at scale.

Figure 1: Azure Government OpenAI access reference architecture.

Protecting your data, privacy, and security​

Microsoft Azure Government provides stringent security and compliance standards necessary to meet government requirements for sensitive data. Through this architecture, government applications and data environments remain on Azure Government. Only the queries submitted to the Azure OpenAI Service transit into the Azure OpenAI model in the commercial environment through an encrypted network and do not remain in the commercial environment. Government data is not used for learning about your data or to train the OpenAI model.

Microsoft allows customers who meet additional Limited access eligibility criteria and attest to specific use cases to apply to modify the Azure OpenAI content management features. If Microsoft approves a customer’s request to modify data logging, then Microsoft does not store any prompts and completions associated with the approved Azure subscription for which data logging is configured off in Azure commercial.

As part of our reference architecture, it is recommended to complete the approval process to modify content filters and data logging via this online form to ensure no logging data exists in Azure commercial. An example of how to modify your data logging settings is available on our Data, privacy, and security for Azure OpenAI Service website.

Microsoft responsible AI principles

When you create technologies that can change the world, we believe you must also ensure that the technology is used responsibly. That’s why we are committed to creating responsible AI by design. Our work is guided by decades of research on AI, grounding, and privacy-preserving machine learning as well as our Responsible AI Standard and a core set of AI principles: fairness, reliability and safety, privacy and security, inclusiveness, transparency, and accountability. We put these principles into practice across the company to develop and deploy AI that will have a positive impact on society. We take a cross-company approach through cutting-edge research, best-of-breed engineering systems, and excellence in policy and governance. Additional information on our Microsoft Responsible AI Principles is available at Our approach to responsible AI at Microsoft website.

Azure OpenAI Service Frequently Asked Questions

How does Microsoft recommend implementing this reference architecture?

Have an account and subscription in Azure Government and Azure Commercial.

Recommended steps per environment:

Azure Commercial Azure Government Request access to Azure OpenAI. Deploy your application utilizing your access to Azure OpenAI API. Request to modify content filters and data logging. Complete the required authorizations (IATT and ATO) for customer-specific workloads. Only utilize prompts for inferencing—do not leverage fine-tuning with Controlled Unclassified Information (CUI) data.

When will access to Azure OpenAI be available for Azure Government customers?

Access to the Azure OpenAI Service is available to approved enterprise customers and partners through the Microsoft Azure Government environment. Customers can access the Azure OpenAI Service REST APIs on Azure Commercial from Azure Government as highlighted in the reference architecture above.

How do the capabilities of the Azure OpenAI Service compare to OpenAI?

Azure OpenAI Service gives customers advanced language AI with OpenAI GPT-4, GPT-3, and Embeddings. The Azure OpenAI API is compatible with the OpenAI API, providing efficiencies for developers and users. With Azure OpenAI Service, customers get the benefit of the security capabilities of Microsoft Azure Government powered by OpenAI’s models.

How do you enable secure access to Azure OpenAI Service?

Access to Azure OpenAI Service is enabled through transport-layer security (TLS). Azure Government peers directly with the commercial Microsoft Azure network and doesn’t peer directly with the public internet or the Microsoft corporate network. Your data is never used to train the OpenAI model (your data is your data).

Getting started with Azure OpenAI Service

Government enterprise workloads can be complex and mission-critical with requirements such as high throughput, low latency, compliance, availability, and data sovereignty. Azure OpenAI Service requires registration and is only available to approved enterprise customers and partners.

Sign up here to learn how AI can accelerate your mission and stay up to date on Microsoft’s AI for government advancements.

We published an Azure Government OpenAI Access QuickStart that uses Azure CLI to deploy an isolated Docker container to Azure Container Instances in Azure Government using code from the Azure OpenAI QuickStart."
Microsoft_News,https://news.microsoft.com/source/features/digital-transformation/the-last-frontier-of-disruption-with-its-new-ai-chatbot-ey-teams-seek-to-take-the-pain-out-of-payroll-questions,,"‘The last frontier of disruption’: With its new AI chatbot, EY teams seek to take the pain out of payroll questions","An employee in Hungary asked if having twins would impact his parental leave. A worker in Spain wondered whether the bonus of $20,000 euros she received would be taxed. Another employee asked what requirements he would have to abide by if he went to work in a United Arab Emirates country as a foreign national.

Those queries, received by clients of multinational professional services organization EY, underscore the complexity organizations worldwide face in trying to answer employees’ payroll questions. To address that challenge, the EY organization (previously named Ernst & Young) worked with Microsoft to create a generative AI chatbot that will be developed to answer payroll questions from employees across the 159 countries and 49 languages that EY clients encompass.

The chatbot, which leverages the Microsoft Cloud and ChatGPT in Azure OpenAI Service, uses a large language model (LLM) that analyzes information from pay slips, tax regulations and employer policies to provide answers to complex payroll questions — with the goal of increasing employee satisfaction and reducing costs for employers.

Sheri Sullivan.

“Payroll touches employees more than any other function,” says Sheri Sullivan, EY global payroll operate leader. “Employees around the globe currently have a very poor experience when it comes to getting answers to their payroll questions. And employers struggle with that.”

Research has shown that employee attraction and retention are directly proportional to workers’ experiences on the job, Sullivan says. And pay is central to that, she says — not only the amount, but also employees’ perception that they are being paid fairly and understand payroll policies.

Payroll issues are complicated by myriad factors ranging from tax regulations that vary between countries and even local municipalities to employer policies and individual circumstances. The coronavirus pandemic exacerbated those complexities, Sullivan says, with the growth of remote work and its resulting impacts on payroll.

Organizations have traditionally handled payroll queries in several ways — through a designated individual, basic chatbots that can usually handle only rudimentary questions, traditional call centers, or in some cases, not at all, Sullivan says. The result is often an inefficient and costly system that leads to frustration for employees, who may simply give up before getting answers to their questions.

“Payroll is really, I like to say, the last frontier of disruption,” Sullivan says. “There’s been lots of investment in human capital management systems and finance systems and other back systems. But with payroll, there’s been limited investment for the past 20 years, because the technology hasn’t had the capabilities to deal with all the deviations and complexities within payroll.”

EY’s chatbot will answer payroll questions from employees across 159 countries and in 49 languages. (Photo by HBS/Adobe Stock.)

That’s changing with the emergence of generative AI capabilities. EY teams have been working closely with Microsoft for several years to help EY’s clients implement cloud-based solutions across various sectors. Addressing payroll questions has long been a challenge for EY member firms, Sullivan says, and as Microsoft moved to make ChatGPT available in Azure OpenAI Service in March 2023, EY teams saw an opportunity to address the issue.

EY teams began developing a proof of concept for the organization’s chatbot, uploading data from a range of sources into the bot and asking its payroll consultants in various countries to share questions employees had recently asked, then using that information to train its model.

“That is really at the heart of our IP,” says Ken Priyadarshi, EY global tax prompt engineering leader. “It’s going inside the heads of our practitioners and asking, ‘What are some of the really interesting ways clients might ask payroll questions that require a little bit more reasoning and thinking?’”

Ken Priyadarshi.

Azure OpenAI Service allows customers to run the same models as OpenAI, but with Azure’s security protocols. That will enable EY teams to deploy the chatbot across countries and regulatory environments, Priyadarshi says.

“For us, the differentiator was not only security but also tooling to work in a user-friendly, fast way,” he says. “Our developers were able to use Microsoft’s Azure OpenAI Service capabilities to build what I would call a private ChatGPT for payroll in collaboration with Microsoft very quickly.”

In internal testing, Sullivan says, the chatbot quickly answered questions in over 27 languages. EY teams are currently piloting the chatbot with clients to gauge employee satisfaction, cost to employers and the bot’s ability to accurately address questions in a single interaction. EY teams anticipate that the technology will be able to answer more than 80% of payroll questions and save employers over half the current costs of addressing those queries.

“There is interest from clients in the largest countries to be part of this pilot,” Sullivan says. “The interest is through the roof, because this is such a pain point for them.”

EY professionals and the organization’s clients are also excited when they see what the bot can do, Sullivan says. While some professionals are cautious about the technology or concerned about its possible impact on their jobs, she says the bot won’t replace them but instead free them up to review data, trends and outcomes, and make recommendations, “instead of doing the manual work to compile and process the data.”

Priyadarshi sees the promise of generative AI chatbots in what he terms “intelligent co-sourcing” — merging deep subject matter experience with large language models to provide information in a human, conversational way.

“We can train an LLM using a practice’s knowledge, and then help surface deep insights, and also support knowledge discovery using bots and copilots,” he says. “And that’s, I think, the future of this capability, not just for payroll, but for all kinds of knowledge worker practices.”

Top photo by Robert Daly/Caia Image. All photos courtesy of EY."
Microsoft_News,https://news.microsoft.com/source/features/digital-transformation/the-last-frontier-of-disruption-with-its-new-ai-chatbot-ey-teams-seek-to-take-the-pain-out-of-payroll-questions/,,"‘The last frontier of disruption’: With its new AI chatbot, EY teams seek to take the pain out of payroll questions","An employee in Hungary asked if having twins would impact his parental leave. A worker in Spain wondered whether the bonus of $20,000 euros she received would be taxed. Another employee asked what requirements he would have to abide by if he went to work in a United Arab Emirates country as a foreign national.

Those queries, received by clients of multinational professional services organization EY, underscore the complexity organizations worldwide face in trying to answer employees’ payroll questions. To address that challenge, the EY organization (previously named Ernst & Young) worked with Microsoft to create a generative AI chatbot that will be developed to answer payroll questions from employees across the 159 countries and 49 languages that EY clients encompass.

The chatbot, which leverages the Microsoft Cloud and ChatGPT in Azure OpenAI Service, uses a large language model (LLM) that analyzes information from pay slips, tax regulations and employer policies to provide answers to complex payroll questions — with the goal of increasing employee satisfaction and reducing costs for employers.

Sheri Sullivan.

“Payroll touches employees more than any other function,” says Sheri Sullivan, EY global payroll operate leader. “Employees around the globe currently have a very poor experience when it comes to getting answers to their payroll questions. And employers struggle with that.”

Research has shown that employee attraction and retention are directly proportional to workers’ experiences on the job, Sullivan says. And pay is central to that, she says — not only the amount, but also employees’ perception that they are being paid fairly and understand payroll policies.

Payroll issues are complicated by myriad factors ranging from tax regulations that vary between countries and even local municipalities to employer policies and individual circumstances. The coronavirus pandemic exacerbated those complexities, Sullivan says, with the growth of remote work and its resulting impacts on payroll.

Organizations have traditionally handled payroll queries in several ways — through a designated individual, basic chatbots that can usually handle only rudimentary questions, traditional call centers, or in some cases, not at all, Sullivan says. The result is often an inefficient and costly system that leads to frustration for employees, who may simply give up before getting answers to their questions.

“Payroll is really, I like to say, the last frontier of disruption,” Sullivan says. “There’s been lots of investment in human capital management systems and finance systems and other back systems. But with payroll, there’s been limited investment for the past 20 years, because the technology hasn’t had the capabilities to deal with all the deviations and complexities within payroll.”

EY’s chatbot will answer payroll questions from employees across 159 countries and in 49 languages. (Photo by HBS/Adobe Stock.)

That’s changing with the emergence of generative AI capabilities. EY teams have been working closely with Microsoft for several years to help EY’s clients implement cloud-based solutions across various sectors. Addressing payroll questions has long been a challenge for EY member firms, Sullivan says, and as Microsoft moved to make ChatGPT available in Azure OpenAI Service in March 2023, EY teams saw an opportunity to address the issue.

EY teams began developing a proof of concept for the organization’s chatbot, uploading data from a range of sources into the bot and asking its payroll consultants in various countries to share questions employees had recently asked, then using that information to train its model.

“That is really at the heart of our IP,” says Ken Priyadarshi, EY global tax prompt engineering leader. “It’s going inside the heads of our practitioners and asking, ‘What are some of the really interesting ways clients might ask payroll questions that require a little bit more reasoning and thinking?’”

Ken Priyadarshi.

Azure OpenAI Service allows customers to run the same models as OpenAI, but with Azure’s security protocols. That will enable EY teams to deploy the chatbot across countries and regulatory environments, Priyadarshi says.

“For us, the differentiator was not only security but also tooling to work in a user-friendly, fast way,” he says. “Our developers were able to use Microsoft’s Azure OpenAI Service capabilities to build what I would call a private ChatGPT for payroll in collaboration with Microsoft very quickly.”

In internal testing, Sullivan says, the chatbot quickly answered questions in over 27 languages. EY teams are currently piloting the chatbot with clients to gauge employee satisfaction, cost to employers and the bot’s ability to accurately address questions in a single interaction. EY teams anticipate that the technology will be able to answer more than 80% of payroll questions and save employers over half the current costs of addressing those queries.

“There is interest from clients in the largest countries to be part of this pilot,” Sullivan says. “The interest is through the roof, because this is such a pain point for them.”

EY professionals and the organization’s clients are also excited when they see what the bot can do, Sullivan says. While some professionals are cautious about the technology or concerned about its possible impact on their jobs, she says the bot won’t replace them but instead free them up to review data, trends and outcomes, and make recommendations, “instead of doing the manual work to compile and process the data.”

Priyadarshi sees the promise of generative AI chatbots in what he terms “intelligent co-sourcing” — merging deep subject matter experience with large language models to provide information in a human, conversational way.

“We can train an LLM using a practice’s knowledge, and then help surface deep insights, and also support knowledge discovery using bots and copilots,” he says. “And that’s, I think, the future of this capability, not just for payroll, but for all kinds of knowledge worker practices.”

Top photo by Robert Daly/Caia Image. All photos courtesy of EY."
Microsoft_News,https://news.microsoft.com/source/shortform/people-of-ai-feeling-an-enormous-responsibility-to-get-it-right,,People of AI: Feeling ‘an enormous responsibility to get it right’,"Sriram has also seen the benefits of AI spread in his work, where it’s helping him better structure his schedule and make sure tasks don’t slip through the cracks, as well as in the kitchen, where it’s helping the avid cook and baker experiment with new food and flavor pairings.

"
Microsoft_News,https://blogs.microsoft.com/blog/2023/05/30/reflections-on-ai-and-the-future-of-human-flourishing/,,Reflections on AI and the future of human flourishing,"Recent advances in artificial intelligence have sparked both wonder and anxiety as we contemplate its transformative potential. AI holds enormous promise to enrich our lives, but this anticipation comes intertwined with apprehensions about the challenges and risks that may emerge. To nurture a future where AI is leveraged to the benefit of people and society, it is crucial to bring together a wide array of voices and perspectives.

With this goal in mind, I am honored to present the “AI Anthology,” a compilation of 20 inspiring essays authored by distinguished scholars and professionals from various disciplines. The anthology explores the diverse ways in which AI can be channeled to benefit humanity while shedding light on potential challenges. By bringing together these different viewpoints, our aim is to stimulate thought-provoking conversations and encourage collaborative efforts that will guide AI toward a future that harnesses its potential for human flourishing.

I first encountered GPT-4, a remarkable large-scale language model, in the fall of 2022 while serving as the chair of Microsoft’s Aether Committee. The Aether leadership and engineering teams were granted early access to OpenAI’s latest innovation, with a mission to investigate potential challenges and wider societal consequences of its use. Our inquiries were anchored in Microsoft’s AI Principles, which were established by the committee in collaboration with Microsoft’s leadership in 2017. We conducted a comprehensive analysis of GPT-4’s capabilities, focusing on the possible challenges that applications employing this technology could pose in terms of safety, accuracy, privacy and fairness.

GPT-4 left me awestruck. I observed unexpected glimmers of intelligence beyond those seen in prior AI systems. When compared to its predecessor, GPT-3.5 — a model utilized by tens of millions as ChatGPT — I noticed a significant leap in capabilities. Its ability to interpret my intentions and provide sophisticated answers to numerous prompts felt like a “phase transition,” evoking imagery of emergent phenomena that I had encountered in physics. I found that GPT-4 is a polymath, with a remarkable capacity to integrate traditionally disparate concepts and methodologies. It seamlessly weaves together ideas that transcend disciplinary boundaries.

The remarkable capabilities of GPT-4 raised questions about potential disruptions and adverse consequences, as well as opportunities to benefit people and society. While our broader team vigorously explored safety and fairness concerns, I delved into complex challenges within medicine, education and the sciences. It became increasingly evident that the model and its successors — which would likely exhibit further jumps in capabilities — hold tremendous potential to be transformative. This led me to contemplate the wider societal ramifications.

Questions came to mind surrounding artistic creation and attribution, malicious actors, jobs and the economy, and unknown futures that we cannot yet envision. How might people react to no longer being the unparalleled fount of intellectual and artistic thought and creation, as generative AI tools become commonplace? How would these advancements affect our self-identity and individual aspirations? What short- and long-term consequences might be felt in the job market? How might people be credited for their creative contributions that AI systems would be learning from? How might malicious actors exploit these emerging powers to inflict harm? What are important potential unintended consequences of the uses, including those we might not yet foresee?

At the same time, I imagined futures in which people and society could thrive in extraordinary ways by harnessing this technology, just as they have with other revolutionary advances. These transformative influences range from the first tools of cognition — our shared languages, enabling unprecedented cooperation and coordination — to the instruments of science and engineering, the printing press, the steam engine, electricity, and the internet, culminating in today’s recent advances in AI.

Eager to investigate these opportunities in collaboration with others across a wide array of disciplines, we initiated the “AI Anthology” project, with OpenAI’s support. We invited 20 experts to explore GPT-4’s capabilities and contemplate the potential influences of future versions on humanity. Each participant was granted early confidential access to GPT-4, provided case studies in education, scientific exploration and medicine, drawn from my explorations, and asked to focus on two core questions:

How might this technology and its successors contribute to human flourishing?

How might we as society best guide the technology to achieve maximal benefits for humanity?

Building upon the ideas presented in my Tanner Lecture at the University of Michigan in November 2022 (Arc of Intelligence: Humanity and its Tools of Reason and Imagination), these questions highlight the importance of long-term thinking and maintaining an optimistic perspective on AI’s potential to enrich human lives. We could unlock immense potential benefits. But to realize this potential, we must create technical innovations and policies to protect against malicious uses and unintended consequences.

This anthology is a testament to the promise of envisioning and collaboration and to the importance of diverse perspectives in shaping the future of AI. The 20 essays offer a wealth of insights, hopes and concerns, illustrating the complexities and possibilities that arise with the rapid evolution of AI.

As you read these essays, I encourage you to remain open to new ideas, engage in thoughtful conversations, and lend your insights to the ongoing discourse on harnessing AI technology to benefit and empower humanity. The future of AI is not a predetermined path, but a journey we must navigate together with wisdom, foresight and a deep sense of responsibility. I hope that the ideas captured in these essays contribute to our collective understanding of the challenges and opportunities we face. They can help guide our efforts to create a future where AI systems complement human intellect and creativity to promote human flourishing.

Welcome to the “AI Anthology.” May it inspire you, challenge you, and ignite meaningful conversations that lead us toward a future where humanity flourishes by harnessing AI in creative and valuable ways.

We will publish four new essays at the beginning of each week starting today. The complete “AI Anthology” will be available on June 26, 2023.

As Microsoft’s Chief Scientific Officer, Eric Horvitz spearheads company-wide initiatives, navigating opportunities and challenges at the confluence of scientific frontiers, technology and society. He is known for his contributions to AI theory and practice, including research on principles and applications of AI amidst the complexities of the open world.

The views, opinions and proposals expressed in these essays are those of the authors and do not necessarily reflect the official policy or position of any other entity or organization, including Microsoft and OpenAI. The authors are solely responsible for the accuracy and originality of the information and arguments presented in their essays. Participation in the “AI Anthology” was voluntary and no incentives or compensation were provided to the authors.

Tags: AI"
Microsoft_News,https://blogs.microsoft.com/on-the-issues/2023/05/25/how-do-we-best-govern-ai/,,How do we best govern AI?,"This post is the foreword written by Brad Smith for Microsoft’s report Governing AI: A Blueprint for the Future. The first part of the report details five ways governments should consider policies, laws, and regulations around AI. The second part focuses on Microsoft’s internal commitment to ethical AI, showing how the company is both operationalizing and building a culture of responsible AI.

“Don’t ask what computers can do, ask what they should do.”

That is the title of the chapter on AI and ethics in a book I co-authored in 2019. At the time, we wrote that, “This may be one of the defining questions of our generation.” Four years later, the question has seized center stage not just in the world’s capitals, but around many dinner tables.

As people have used or heard about the power of OpenAI’s GPT-4 foundation model, they have often been surprised or even astounded. Many have been enthused or even excited. Some have been concerned or even frightened. What has become clear to almost everyone is something we noted four years ago – we are the first generation in the history of humanity to create machines that can make decisions that previously could only be made by people.

Countries around the world are asking common questions. How can we use this new technology to solve our problems? How do we avoid or manage new problems it might create? How do we control technology that is so powerful?

These questions call not only for broad and thoughtful conversation, but decisive and effective action. This paper offers some of our ideas and suggestions as a company.

These suggestions build on the lessons we’ve been learning based on the work we’ve been doing for several years. Microsoft CEO Satya Nadella set us on a clear course when he wrote in 2016 that, “Perhaps the most productive debate we can have isn’t one of good versus evil: The debate should be about the values instilled in the people and institutions creating this technology.”

Since that time, we’ve defined, published, and implemented ethical principles to guide our work. And we’ve built out constantly improving engineering and governance systems to put these principles into practice. Today, we have nearly 350 people working on responsible AI at Microsoft, helping us implement best practices for building safe, secure, and transparent AI systems designed to benefit society.

New opportunities to improve the human condition

The resulting advances in our approach have given us the capability and confidence to see ever-expanding ways for AI to improve people’s lives. We’ve seen AI help save individuals’ eyesight, make progress on new cures for cancer, generate new insights about proteins, and provide predictions to protect people from hazardous weather. Other innovations are fending off cyberattacks and helping to protect fundamental human rights, even in nations afflicted by foreign invasion or civil war.

Everyday activities will benefit as well. By acting as a copilot in people’s lives, the power of foundation models like GPT-4 is turning search into a more powerful tool for research and improving productivity for people at work. And, for any parent who has struggled to remember how to help their 13-year-old child through an algebra homework assignment, AI-based assistance is a helpful tutor.

In so many ways, AI offers perhaps even more potential for the good of humanity than any invention that has preceded it. Since the invention of the printing press with movable type in the 1400s, human prosperity has been growing at an accelerating rate. Inventions like the steam engine, electricity, the automobile, the airplane, computing, and the internet have provided many of the building blocks for modern civilization. And, like the printing press itself, AI offers a new tool to genuinely help advance human learning and thought.

Guardrails for the future

Another conclusion is equally important: It’s not enough to focus only on the many opportunities to use AI to improve people’s lives. This is perhaps one of the most important lessons from the role of social media. Little more than a decade ago, technologists and political commentators alike gushed about the role of social media in spreading democracy during the Arab Spring. Yet, five years after that, we learned that social media, like so many other technologies before it, would become both a weapon and a tool – in this case aimed at democracy itself.

Today we are 10 years older and wiser, and we need to put that wisdom to work. We need to think early on and in a clear-eyed way about the problems that could lie ahead. As technology moves forward, it’s just as important to ensure proper control over AI as it is to pursue its benefits. We are committed and determined as a company to develop and deploy AI in a safe and responsible way. We also recognize, however, that the guardrails needed for AI require a broadly shared sense of responsibility and should not be left to technology companies alone.

When we at Microsoft adopted our six ethical principles for AI in 2018, we noted that one principle was the bedrock for everything else – accountability. This is the fundamental need: to ensure that machines remain subject to effective oversight by people , and the people who design and operate machines remain accountable to everyone else. In short, we must always ensure that AI remains under human control. This must be a first-order priority for technology companies and governments alike.

This connects directly with another essential concept. In a democratic society, one of our foundational principles is that no person is above the law. No government is above the law. No company is above the law, and no product or technology should be above the law. This leads to a critical conclusion: People who design and operate AI systems cannot be accountable unless their decisions and actions are subject to the rule of law.

In many ways, this is at the heart of the unfolding AI policy and regulatory debate. How do governments best ensure that AI is subject to the rule of law? In short, what form should new law, regulation, and policy take?

A five-point blueprint for the public governance of AI

Section One of this paper offers a five-point blueprint to address several current and emerging AI issues through public policy, law, and regulation. We offer this recognizing that every part of this blueprint will benefit from broader discussion and require deeper development. But we hope this can contribute constructively to the work ahead.

First, implement and build upon new government-led AI safety frameworks. The best way to succeed is often to build on the successes and good ideas of others. Especially when one wants to move quickly. In this instance, there is an important opportunity to build on work completed just four months ago by the U.S. National Institute of Standards and Technology, or NIST. Part of the Department of Commerce, NIST has completed and launched a new AI Risk Management Framework.

We offer four concrete suggestions to implement and build upon this framework, including commitments Microsoft is making in response to a recent White House meeting with leading AI companies. We also believe the administration and other governments can accelerate momentum through procurement rules based on this framework.

Second, require effective safety brakes for AI systems that control critical infrastructure. In some quarters, thoughtful individuals increasingly are asking whether we can satisfactorily control AI as it becomes more powerful. Concerns are sometimes posed regarding AI control of critical infrastructure like the electrical grid, water system, and city traffic flows.

This is the right time to discuss this question. This blueprint proposes new safety requirements that, in effect, would create safety brakes for AI systems that control the operation of designated critical infrastructure. These fail-safe systems would be part of a comprehensive approach to system safety that would keep effective human oversight, resilience, and robustness top of mind. In spirit, they would be similar to the braking systems engineers have long built into other technologies such as elevators, school buses, and high-speed trains, to safely manage not just everyday scenarios, but emergencies as well.

In this approach, the government would define the class of high-risk AI systems that control critical infrastructure and warrant such safety measures as part of a comprehensive approach to system management. New laws would require operators of these systems to build safety brakes into high-risk AI systems by design. The government would then ensure that operators test high-risk systems regularly to ensure that the system safety measures are effective. And AI systems that control the operation of designated critical infrastructure would be deployed only in licensed AI datacenters that would ensure a second layer of protection through the ability to apply these safety brakes, thereby ensuring effective human control.

Third, develop a broad legal and regulatory framework based on the technology architecture for AI. We believe there will need to be a legal and regulatory architecture for AI that reflects the technology architecture for AI itself. In short, the law will need to place various regulatory responsibilities upon different actors based upon their role in managing different aspects of AI technology.

For this reason, this blueprint includes information about some of the critical pieces that go into building and using new generative AI models. Using this as context, it proposes that different laws place specific regulatory responsibilities on the organizations exercising certain responsibilities at three layers of the technology stack: the applications layer, the model layer, and the infrastructure layer.

This should first apply existing legal protections at the applications layer to the use of AI. This is the layer where the safety and rights of people will most be impacted, especially because the impact of AI can vary markedly in different technology scenarios. In many areas, we don’t need new laws and regulations. We instead need to apply and enforce existing laws and regulations, helping agencies and courts develop the expertise needed to adapt to new AI scenarios.

There will then be a need to develop new law and regulation s for highly capable AI foundation models, best implemented by a new government agency. This will impact two layers of the technology stack. The first will require new regulations and licensing for these models themselves. And the second will involve obligations for the AI infrastructure operators on which these models are developed and deployed. The blueprint that follows offers suggested goals and approaches for each of these layers.

In doing so, this blueprint builds in part on a principle developed in recent decades in banking to protect against money laundering and criminal or terrorist use of financial services. The “Know Your Customer” – or KYC – principle requires that financial institutions verify customer identities, establish risk profiles, and monitor transactions to help detect suspicious activity. It would make sense to take this principle and apply a KY3C approach that creates in the AI context certain obligations to know one’s cloud, one’s customers, and one’s content.

In the first instance, the developers of designated, powerful AI models first “know the cloud” on which their models are developed and deployed. In addition, such as for scenarios that involve sensitive uses, the company that has a direct relationship with a customer – whether it be the model developer, application provider, or cloud operator on which the model is operating – should “know the customers” that are accessing it.

Also, the public should be empowered to “know the content” that AI is creating through the use of a label or other mark informing people when something like a video or audio file has been produced by an AI model rather than a human being. This labeling obligation should also protect the public from the alteration of original content and the creation of “deep fakes.” This will require the development of new laws, and there will be many important questions and details to address. But the health of democracy and future of civic discourse will benefit from thoughtful measures to deter the use of new technology to deceive or defraud the public.

Fourth, promote transparency and ensure academic and nonprofit access to AI. We believe a critical public goal is to advance transparency and broaden access to AI resources. While there are some important tensions between transparency and the need for security, there exist many opportunities to make AI systems more transparent in a responsible way. That’s why Microsoft is committing to an annual AI transparency report and other steps to expand transparency for our AI services.

We also believe it is critical to expand access to AI resources for academic research and the nonprofit community. Basic research, especially at universities, has been of fundamental importance to the economic and strategic success of the United States since the 1940s. But unless academic researchers can obtain access to substantially more computing resources, there is a real risk that scientific and technological inquiry will suffer, including relating to AI itself. Our blueprint calls for new steps, including steps we will take across Microsoft, to address these priorities.

Fifth, pursue new public-private partnerships to use AI as an effective tool to address the inevitable societal challenges that come with new technology. One lesson from recent years is what democratic societies can accomplish when they harness the power of technology and bring the public and private sectors together. It’s a lesson we need to build upon to address the impact of AI on society.

We will all benefit from a strong dose of clear-eyed optimism. AI is an extraordinary tool. But, like other technologies, it too can become a powerful weapon, and there will be some around the world who will seek to use it that way. But we should take some heart from the cyber front and the last year-and-a-half in the war in Ukraine. What we found is that when the public and private sectors work together, when like-minded allies come together, and when we develop technology and use it as a shield, it’s more powerful than any sword on the planet.

Important work is needed now to use AI to protect democracy and fundamental rights, provide broad access to the AI skills that will promote inclusive growth, and use the power of AI to advance the planet’s sustainability needs. Perhaps more than anything, a wave of new AI technology provides an occasion for thinking big and acting boldly. In each area, the key to success will be to develop concrete initiatives and bring governments, respected companies, and energetic NGOs together to advance them. We offer some initial ideas in this report, and we look forward to doing much more in the months and years ahead.

Governing AI within Microsoft

Ultimately, every organization that creates or uses advanced AI systems will need to develop and implement its own governance systems. Section Two of this paper describes the AI governance system within Microsoft – where we began, where we are today, and how we are moving into the future.

As this section recognizes, the development of a new governance system for new technology is a journey in and of itself. A decade ago, this field barely existed. Today, Microsoft has almost 350 employees specializing in it, and we are investing in our next fiscal year to grow this further.

As described in this section, over the past six years we have built out a more comprehensive AI governance structure and system across Microsoft. We didn’t start from scratch, borrowing instead from best practices for the protection of cybersecurity, privacy, and digital safety. This is all part of the company’s comprehensive enterprise risk management (ERM) system, which has become a critical part of the management of corporations and many other organizations in the world today.

When it comes to AI, we first developed ethical principles and then had to translate these into more specific corporate policies. We’re now on version 2 of the corporate standard that embodies these principles and defines more precise practices for our engineering teams to follow. We’ve implemented the standard through training, tooling, and testing systems that continue to mature rapidly. This is supported by additional governance processes that include monitoring, auditing, and compliance measures.

As with everything in life, one learns from experience. When it comes to AI governance, some of our most important learning has come from the detailed work required to review specific sensitive AI use cases. In 2019, we founded a sensitive use review program to subject our most sensitive and novel AI use cases to rigorous, specialized review that results in tailored guidance. Since that time, we have completed roughly 600 sensitive use case reviews. The pace of this activity has quickened to match the pace of AI advances, with almost 150 such reviews taking place in the 11 months.

All of this builds on the work we have done and will continue to do to advance responsible AI through company culture. That means hiring new and diverse talent to grow our responsible AI ecosystem and investing in the talent we already have at Microsoft to develop skills and empower them to think broadly about the potential impact of AI systems on individuals and society. It also means that much more than in the past, the frontier of technology requires a multidisciplinary approach that combines great engineers with talented professionals from across the liberal arts.

All this is offered in this paper in the spirit that we’re on a collective journey to forge a responsible future for artificial intelligence. We can all learn from each other. And no matter how good we may think something is today, we will all need to keep getting better.

As technological change accelerates, the work to govern AI responsibly must keep pace with it. With the right commitments and investments, we believe it can."
Microsoft_News,https://www.linkedin.com/pulse/5-new-developer-opportunities-ai-era-satya-nadella,,5 new developer opportunities in this AI era,"The following is adapted from my remarks at Microsoft Build this morning.

Developer conferences are special places, especially when platform shifts are in the air. So, it’s exciting to be able to come back to Microsoft Build 2023 with a sense of anticipation that something big is unfolding around us.

I’ve always loved Steve Jobs’ description of computers as “bicycles for the mind.” It’s a beautiful metaphor, and I think it captures the essence of what computing is. And then, last November, we got an upgrade. With the launch of ChatGPT, computing went from a “bicycle for the mind” to a “steam engine for the mind.”

And now, as developers, we look forward to what we can do in this new era. Every layer of the technology stack will be changed forever.

At Build this year, we have more than 50 announcements, and I want to highlight five of them.

Bringing Bing to ChatGPT

ChatGPT is the fastest-growing consumer app we’ve ever seen. And we are now bringing Bing to ChatGPT as the default search experience, so we can provide answers that are timelier, more up-to-date, and grounded by search and web data. We’re excited to launch this integration in ChatGPT Plus starting today and to make it available to the free tier soon. And this is just the start of what we plan to do with our partners at OpenAI to bring the best of Bing to the ChatGPT experience.

Windows Copilot

Second, we are bringing Copilot to the biggest canvas of all: Windows. This is going to make every Windows user a power user, helping them take action, customize their settings, and seamlessly connect across their favorite apps:

Copilot stack and copilot extensibility

Next, we’ve built our copilots with a common architectural stack, and we are now making it available so that everyone can build their own AI apps and copilots—from the AI infrastructure, to foundation models, to the AI orchestration, all the way up to your copilot and its extensibility.

Whether it’s ChatGPT, Bing Chat, Microsoft Copilots, or your copilots, they will all share the same extensibility model. This is one of the most powerful things for any developer: to be able to write a plugin once and have it reach billions of users across all of these surface areas.

And we’re already seeing fantastic momentum:

Yusuf Mehdi, CVP and Consumer Chief Marketing Officer, showed all of this in action:

Azure AI Studio

Our new Azure AI Studio is the full-lifecycle developer toolchain for the new era of AI. You can train your own models, ground AI models—such as OpenAI’s ChatGPT and GPT-4—on your own data, create prompt workflows, and more. It also includes built-in support for AI safety.

We’ve been at work on AI safety for years. We have AI principles, which we have translated into a core set of processes that we implement across our engineering stack, as well as compliance and oversight. But the real priority is to build it throughout the entire toolchain, and that’s what we’re doing with Azure AI Studio:

Microsoft Fabric

Every AI app starts with data. That’s why we’re thrilled to announce Microsoft Fabric. It’s the biggest launch of a data product from Microsoft since the launch of SQL Server.

It unifies compute and storage, the product experience, governance, and the business model, across all the different types of analytics workloads. And this unification, at the end of the day, is what I think will fuel the next generation of AI applications:

***

As developers, one of the things that we should ask ourselves is: Why do we build technology?

The positive relationship between technology and economic growth has been evident for a long time. But it’s not just economic growth. We want lifespans to go up. We want education, prosperity, and standard of living to go up—everywhere. That’s why we build. That’s why we innovate. That’s why technology exists. It’s not technology for technology’s sake. It is for that broad impact."
Microsoft_News,https://blogs.windows.com/windowsdeveloper/2023/05/23/welcoming-ai-to-the-microsoft-store-on-windows/,,Welcoming AI to the Microsoft Store on Windows,"We wouldn’t be where we are today without the developer community. Together, we’ve been on a journey to reimagine an open app store and provide a better experience for Windows customers. It’s because of this partnership that the Microsoft Store on Windows is now used by over one billion customers with more than 50% of new Windows 11 customers engaging with the Microsoft Store in the first 30 days.

The momentum of Windows customers is a testament to the growth in quality content from our passionate community of developers, who have more than doubled the number of Win32 and PWA apps since last year. Engaging PWAs like Snapchat and ESPN, sophisticated native apps like Spark Mail, Adobe Photoshop and Lightroom, Capture One, Bilibili and WhatsApp, along with Android apps like Epic Seven, Best Fiends, and Blink, are truly what makes the Microsoft Store the best place to find the right content, whether for productivity, entertainment or creativity. There are many more apps to recognize, including the winners of the Microsoft Store Awards 2023 which can be found here.

Today, we are proud to share the next phase of our journey for the Microsoft Store on Windows and announce new experiences, features and tools. We are focused on building an open store that is ready for the new AI era, and to provide developers with new tools like Microsoft Store Ads to reach even more customers.

Microsoft Store opens the doors to AI

The world around us is changing every day. As AI disrupts existing workflows and creates exciting new opportunities for customers, we see an opportunity to evolve and think differently about the role of the Microsoft Store on Windows. It’s not just a place to download an app or a game, but rather, it should serve as a resource to educate customers about how they can be more productive, achieve their tasks, and discover new content.

Introducing the AI Hub, a new curated section in the Microsoft Store where we will promote the best AI experiences built by the developer community and Microsoft. This is a space where we will educate customers on how to start and expand their AI journey, inspiring them to use AI in everyday ways to boost productivity, spark creativity and so much more. For example, you will be able to use AI to express your creativity through Luminar Neo and Lensa, master your video and audio with Descript, Krisp and Podcastle, present your ideas with Gamma and Copy.ai, build your resume with Kickresume, generate your voice with Play.ht, or even plan your trip with Tripnotes. All the content will be tested for security, family safety, and device compatibility – so you are always in control. This feature will soon be available in the Microsoft Store. If you are an AI developer and interested in being featured in the AI Hub, let us know here.

Customers can take advantage of AI-Generated review summary. This new feature summarizes customer reviews and provides a concise summary highlighting the topline details. We know customers use the Microsoft Store to view and gather community feedback when considering and choosing new apps and games. However, especially with popular apps that have thousands of reviews, sifting through each one can take time. Supported by AI, this feature is designed to make the customer experience even more seamless. AI-Generated review summaries will soon be available in the Microsoft Store.

Microsoft Store AI-Generated keywords: Coming soon to preview, we will introduce a new developer tool in Partner Center that leverages AI to generate and suggest Search Tags for apps. We are using AI to consume your metadata, as well as other signals, and help you improve the discoverability of your app in the Microsoft Store search results. Based on popular demand, we are also introducing the ability to select multiple categories per app, which will further improve discoverability and help you reach more customers. Learn more here.

Reach more customers with new developer tools and expanded services

Earlier this year, we announced the availability of Microsoft Store Ads in search results and shared plans to expand the experience to premium ad placements in search. In just two months, we have seen more developers adopt this new channel and receive positive results. Miracle Games experienced a 25% increase in app installs compared to before at a CPI that is 90% lower than on other advertising channels. Learn more about Miracle Games story here.

Today, we are excited to release new services that will help developers connect to more customers and address some of the most popular developer feedback:

Microsoft Store Ads is expanding in more ways than one

Starting next month, Microsoft Store Ads will be discoverable in Bing.com search results, along with Microsoft Store search results. To take advantage of these capabilities, create a Store Ads Campaign in Microsoft Advertising. We are also making available a new Attribution SDK for MSIX apps and coming soon for Win32 and PWAs. Learn more here.

Developers now have the option to display rich advertising in the spotlight section in the Microsoft Store. This provides a new large and high-traffic surface for advertisers and supports video ad formats. If you are interested in participating in the pilot program, please submit a request here.

Starting in June, Microsoft Store Ads will expand beyond the U.S. market, supported by Microsoft Advertising, to more than 150 regions worldwide. Advertisers with a presence in other countries will soon be able to leverage this channel to achieve their acquisition goals.

Keeping customers engaged across devices has just gotten easier

Retention is another key challenge for developers. Last year, we announced a feature that allows customers to easily transition apps from one device to another.

Today, we are introducing a new backup and restore capability on Windows that helps keep customers engaged across devices. When customers transition from a Windows 10 or 11 device to their new Windows 11 device, the icons for Store apps will automatically get restored right where they had them – on the Start menu and Taskbar. This new feature is in preview and available to Windows Insiders today. To learn more about how to ensure the best experience when restoring apps, learn more here.

Over the last two years, we continue to see a growth of developers publishing PWAs or Win32 apps. We are excited to bring new capabilities for PWAs, faster certification for Win32 apps and opening Android app submissions to all developers:

PWAs remain a top priority in the Microsoft Store, and we continue to invest in open-source tools to help developers. New capabilities are available to help expand your audience through Windows Widgets and Edge Sidebar PWAs . In addition, the Digital Goods API will soon be available enabling PWAs published to the Microsoft Store to accept in-app purchases and streamline the checkout process. To learn more and leverage the new capabilities, visit pwabuilder.com.

. In addition, the Digital Goods API will soon be available enabling PWAs published to the Microsoft Store to accept in-app purchases and streamline the checkout process. To learn more and leverage the new capabilities, visit pwabuilder.com. Due to popular demand, today we are making available a suite of certification tests for Win32 app developers that can be run offline and will provide guidance on how to address potential certification issues. This will create more predictability in your submission and reduce the certification turnaround time by up to 50%. Learn more here.

that can be run offline and will provide guidance on how to address potential certification issues. This will create more predictability in your submission and reduce the certification turnaround time by up to 50%. Learn more here. Any developer with an Amazon Appstore Developer account can now submit their apps for distribution on Windows 11 devices. To best prepare your app for a smooth testing and publishing experience, review thedeveloper resources for handling window resizing and implementing native mapping in the new form factor. The Windows Subsystem for Android continue to get better, with support for Android 13, launch and runtime performance improvements, and new features like Picture in Picture and memory management. Learn more here.

Today’s AI announcements ventured the Microsoft Store on Windows into a new and unexplored era. Developers and customers continue to be at the core of everything we do. We look forward to listening to your feedback in the months ahead, so we can continue to build a better experience for all."
Microsoft_News,https://azure.microsoft.com/en-us/blog/introducing-microsoft-fabric-data-analytics-for-the-era-of-ai/,,Introducing Microsoft Fabric: The data platform for the era of AI,"Today’s world is awash with data—ever-streaming from the devices we use, the applications we build, and the interactions we have. Organizations across every industry have harnessed this data to digitally transform and gain competitive advantages. And now, as we enter a new era defined by AI, this data is becoming even more important.

Generative AI and language model services, such as Azure OpenAI Service, are enabling customers to use and create everyday AI experiences that are reinventing how employees spend their time. Powering organization-specific AI experiences requires a constant supply of clean data from a well-managed and highly integrated analytics system. But most organizations’ analytics systems are a labyrinth of specialized and disconnected services.

And it’s no wonder given the massively fragmented data and AI technology market with hundreds of vendors and thousands of services. Customers must stitch together a complex set of disconnected services from multiple vendors themselves and incur the costs and burdens of making these services function together.

Introducing Microsoft Fabric

Today we are unveiling Microsoft Fabric—an end-to-end, unified analytics platform that brings together all the data and analytics tools that organizations need. Fabric integrates technologies like Azure Data Factory, Azure Synapse Analytics, and Power BI into a single unified product, empowering data and business professionals alike to unlock the potential of their data and lay the foundation for the era of AI.

Watch a quick overview:

What sets Microsoft Fabric apart?

Fabric is an end-to-end analytics product that addresses every aspect of an organization’s analytics needs. But there are five areas that really set Fabric apart from the rest of the market:

1. Fabric is a complete analytics platform

Every analytics project has multiple subsystems. Every subsystem needs a different array of capabilities, often requiring products from multiple vendors. Integrating these products can be a complex, fragile, and expensive endeavor.

With Fabric, customers can use a single product with a unified experience and architecture that provides all the capabilities required for a developer to extract insights from data and present it to the business user. And by delivering the experience as software as a service (SaaS), everything is automatically integrated and optimized, and users can sign up within seconds and get real business value within minutes.

Fabric empowers every team in the analytics process with the role-specific experiences they need, so data engineers, data warehousing professionals, data scientists, data analysts, and business users feel right at home.

Fabric comes with seven core workloads:

Data Factory (preview) provides more than 150 connectors to cloud and on-premises data sources, drag-and-drop experiences for data transformation, and the ability to orchestrate data pipelines.

provides more than 150 connectors to cloud and on-premises data sources, drag-and-drop experiences for data transformation, and the ability to orchestrate data pipelines. Synapse Data Engineering (preview) enables great authoring experiences for Spark, instant start with live pools, and the ability to collaborate.

enables great authoring experiences for Spark, instant start with live pools, and the ability to collaborate. Synapse Data Science (preview) provides an end-to-end workflow for data scientists to build sophisticated AI models, collaborate easily, and train, deploy, and manage machine learning models.

provides an end-to-end workflow for data scientists to build sophisticated AI models, collaborate easily, and train, deploy, and manage machine learning models. Synapse Data Warehousing (preview) provides a converged lake house and data warehouse experience with industry-leading SQL performance on open data formats.

provides a converged lake house and data warehouse experience with industry-leading SQL performance on open data formats. Synapse Real-Time Analytics (preview) enables developers to work with data streaming in from the Internet of Things (IoT) devices, telemetry, logs, and more, and analyze massive volumes of semi-structured data with high performance and low latency.

enables developers to work with data streaming in from the Internet of Things (IoT) devices, telemetry, logs, and more, and analyze massive volumes of semi-structured data with high performance and low latency. Power BI in Fabric provides industry-leading visualization and AI-driven analytics that enable business analysts and business users to gain insights from data. The Power BI experience is also deeply integrated into Microsoft 365, providing relevant insights where business users already work.

in Fabric provides industry-leading visualization and AI-driven analytics that enable business analysts and business users to gain insights from data. The Power BI experience is also deeply integrated into Microsoft 365, providing relevant insights where business users already work. Data Activator (coming soon) provides real-time detection and monitoring of data and can trigger notifications and actions when it finds specified patterns in data—all in a no-code experience.

You can try these experiences today by signing up for the Microsoft Fabric free trial.

2. Fabric is lake-centric and open

Today’s data lakes can be messy and complicated, making it hard for customers to create, integrate, manage, and operate data lakes. And once they are operational, multiple data products using different proprietary data formats on the same data lake can cause significant data duplication and concerns about vendor lock-in.

OneLake—The OneDrive for data

Fabric comes with a SaaS, multi-cloud data lake called OneLake that is built-in and automatically available to every Fabric tenant. All Fabric workloads are automatically wired into OneLake, just like all Microsoft 365 applications are wired into OneDrive. Data is organized in an intuitive data hub, and automatically indexed for discovery, sharing, governance, and compliance.

OneLake serves developers, business analysts, and business users alike, helping eliminate pervasive and chaotic data silos created by different developers provisioning and configuring their own isolated storage accounts. Instead, OneLake provides a single, unified storage system for all developers, where discovery and sharing of data are easy with policy and security settings enforced centrally. At the API layer, OneLake is built on and fully compatible with Azure Data Lake Storage Gen2 (ADLSg2), instantly tapping into ADLSg2’s vast ecosystem of applications, tools, and developers.

A key capability of OneLake is “Shortcuts.” OneLake allows easy sharing of data between users and applications without having to move and duplicate information unnecessarily. Shortcuts allow OneLake to virtualize data lake storage in ADLSg2, Amazon Simple Storage Service (Amazon S3), and Google Storage (coming soon), enabling developers to compose and analyze data across clouds.

Open data formats across analytics offerings

Fabric is deeply committed to open data formats across all its workloads and tiers. Fabric treats Delta on top of Parquet files as a native data format that is the default for all workloads. This deep commitment to a common open data format means that customers need to load the data into the lake only once and all the workloads can operate on the same data, without having to separately ingest it. It also means that OneLake supports structured data of any format and unstructured data, giving customers total flexibility.

By adopting OneLake as our store and Delta and Parquet as the common format for all workloads, we offer customers a data stack that’s unified at the most fundamental level. Customers do not need to maintain different copies of data for databases, data lakes, data warehousing, business intelligence, or real-time analytics. Instead, a single copy of the data in OneLake can directly power all the workloads.

Managing data security (table, column, and row levels) across different data engines can be a persistent nightmare for customers. Fabric will provide a universal security model that is managed in OneLake, and all engines enforce it uniformly as they process queries and jobs. This model is coming soon.

3. Fabric is powered by AI

We are infusing Fabric with Azure OpenAI Service at every layer to help customers unlock the full potential of their data, enabling developers to leverage the power of generative AI against their data and assisting business users to find insights in their data. With Copilot in Microsoft Fabric in every data experience, users can use conversational language to create dataflows and data pipelines, generate code and entire functions, build machine learning models, or visualize results. Customers can even create their own conversational language experiences that combine Azure OpenAI Service models and their data and publish them as plug-ins.

Copilot in Microsoft Fabric builds on our existing commitments to data security and privacy in the enterprise. Copilot inherits an organization’s security, compliance, and privacy policies. Microsoft does not use organizations’ tenant data to train the base language models that power Copilot.

Copilot in Microsoft Fabric will be coming soon. Stay tuned to the Microsoft Fabric blog for the latest updates and public release date for Copilot in Microsoft Fabric.

4. Fabric empowers every business user

Customers aspire to drive a data culture where everyone in their organization is making better decisions based on data. To help our customers foster this culture, Fabric deeply integrates with the Microsoft 365 applications people use every day.

Power BI is a core part of Fabric and is already infused across Microsoft 365. Through Power BI’s deep integrations with popular applications such as Excel, Microsoft Teams, PowerPoint, and SharePoint, relevant data from OneLake is easily discoverable and accessible to users right from Microsoft 365—helping customers drive more value from their data

With Fabric, you can turn your Microsoft 365 apps into hubs for uncovering and applying insights. For example, users in Microsoft Excel can directly discover and analyze data in OneLake and generate a Power BI report with a click of a button. In Teams, users can infuse data into their everyday work with embedded channels, chat, and meeting experiences. Business users can bring data into their presentations by embedding live Power BI reports directly in Microsoft PowerPoint. Power BI is also natively integrated with SharePoint, enabling easy sharing and dissemination of insights. And with Microsoft Graph Data Connect (preview), Microsoft 365 data is natively integrated into OneLake so customers can unlock insights on their customer relationships, business processes, security and compliance, and people productivity.

5. Fabric reduces costs through unified capacities

Today’s analytics systems typically combine products from multiple vendors in a single project. This results in computing capacity provisioned in multiple systems like data integration, data engineering, data warehousing, and business intelligence. When one of the systems is idle, its capacity cannot be used by another system causing significant wastage.

Purchasing and managing resources is massively simplified with Fabric. Customers can purchase a single pool of computing that powers all Fabric workloads. With this all-inclusive approach, customers can create solutions that leverage all workloads freely without any friction in their experience or commerce. The universal compute capacities significantly reduce costs, as any unused compute capacity in one workload can be utilized by any of the workloads.

Explore how our customers are already using Microsoft Fabric

Ferguson

Ferguson is a leading distributor of plumbing, HVAC, and waterworks supplies, operating across North America. And by using Fabric to consolidate their analytics stack into a unified solution, they are hoping to reduce their delivery time and improve efficiency.

“Microsoft Fabric reduces the delivery time by removing the overhead of using multiple disparate services. By consolidating the necessary data provisioning, transformation, modeling, and analysis services into one UI, the time from raw data to business intelligence is significantly reduced. Fabric meaningfully impacts Ferguson’s data storage, engineering, and analytics groups since all these workloads can now be done in the same UI for faster delivery of insights.” —George Rasco, Principal Database Architect, Ferguson

See Fabric in action at Ferguson:

T-Mobile

T-Mobile, one of the largest providers of wireless communications services in the United States, is focused on driving disruption that creates innovation and better customer experiences in wireless and beyond. With Fabric, T-Mobile hopes they can take their platform and data-driven decision-making to the next level.

“T-Mobile loves our customers and providing them with new Un-Carrier benefits! We think that Fabric’s upcoming abilities will help us eliminate data silos, making it easier for us to unlock new insights into how we show our customers even more love. Querying across the lakehouse and warehouse from a single engine—that’s a game changer. Spark compute on-demand, rather than waiting for clusters to spin up, is a huge improvement for both standard data engineering and advanced analytics. It saves three minutes on every job, and when you’re running thousands of jobs an hour, that really adds up. And being able to easily share datasets across the company is going to eliminate so much data duplication. We’re really looking forward to these new features.” —Geoffrey Freeman, MTS, Data Solutions and Analytics, T-Mobile

Aon

Aon provides professional services and management consulting services to a vast global network of customers. With the help of Fabric, Aon hopes that they can consolidate more of their current technology stack and focus on adding more value to their clients.

“What’s most exciting to me about Fabric is simplifying our existing analytics stack. Currently, there are so many different PaaS services across the board that when it comes to modernization efforts for many developers, Fabric helps simplify that. We can now spend less time building infrastructure and more time adding value to our business.” —Boby Azarbod, Data Services Lead, Aon

What happens to current Microsoft analytics solutions?

Existing Microsoft products such as Azure Synapse Analytics, Azure Data Factory, and Azure Data Explorer will continue to provide a robust, enterprise-grade platform as a service (PaaS) solution for data analytics. Fabric represents an evolution of those offerings in the form of a simplified SaaS solution that can connect to existing PaaS offerings. Customers will be able to upgrade from their current products into Fabric at their own pace.

Get started with Microsoft Fabric

Microsoft Fabric is currently in preview. Try out everything Fabric has to offer by signing up for the free trial—no credit card information is required. Everyone who signs up gets a fixed Fabric trial capacity, which may be used for any feature or capability from integrating data to creating machine learning models. Existing Power BI Premium customers can simply turn on Fabric through the Power BI admin portal. After July 1, 2023, Fabric will be enabled for all Power BI tenants.

Microsoft Fabric resources

If you want to learn more about Microsoft Fabric, consider:

Signing up for the Microsoft Fabric free trial.

Visiting the Microsoft Fabric website.

Exploring the Fabric technical documentation.

Exploring Fabric through the Guided Tour."
Microsoft_News,https://blogs.bing.com/search/may_2023/Bing-at-Microsoft-Build-2023,,Bing at Microsoft Build 2023: Continuing the Transformation of Search,"A little more than 100 days ago, Microsoft introduced the world to your copilot for the Web with a new AI-powered Bing and Edge, beginning the transformation of the largest software category in the world—search. We’ve seen great progress in that short time, with people now doing things they couldn’t do with traditional search engines to be more productive and creative. Bing users have engaged in more than half a billion chats, created more than 200 million images with Bing Image Creator, while daily downloads of the Bing mobile app have increased 8x since launch.



Today, at the Microsoft Build conference, we’re taking the next steps to further expand how people can interact with search and how developers can build on our AI platform. I’m pleased to share three key updates for Bing: The integration of Bing Search into ChatGPT, a common plugin platform with OpenAI and new plugin partners, and the expanded integration of Bing Chat across Microsoft’s copilots. Today’s updates create greater opportunities for developers and more magical experiences for people as we continue the transformation of search.



Bringing the new Bing to ChatGPT



Foundational to our progress with the new Bing is our fantastic partnership with OpenAI. I’m pleased to announce we are bringing Bing to ChatGPT as the default search experience.



ChatGPT will now have a world-class search engine built-in to provide timelier and more up-to-date answers with access from the web. Now, ChatGPT answers can be grounded by search and web data and include citations so you can learn more—all directly from within chat. The new experience is rolling out to ChatGPT Plus subscribers starting today and will be available to free users soon by simply enabling a plugin which brings Bing to ChatGPT.

Bing search default experience in ChatGPT



Accelerating the Bing ecosystem and supercharging with plugins



As we talked about today at Build, Microsoft and OpenAI are jointly committing to support and grow the AI plugins ecosystem by embracing interoperability. This means developers can now use one platform to build and submit plugins that work across both consumer and business surfaces, including ChatGPT, Bing, Dynamics 365 Copilot, Microsoft 365 Copilot, and Windows Copilot.



As part of this shared plugin platform, Bing is adding to its support for plugins. In addition to previously announced plugins for OpenTable and Wolfram Alpha, today we’re thrilled to welcome Expedia, Instacart, Kayak, Klarna, Redfin, TripAdvisor, and Zillow to the Bing ecosystem. With plugins built right into chat, across desktop and mobile, Bing makes relevant recommendations based on your conversation. For example, you can use the OpenTable plugin to ask about restaurants or related topics. This becomes even more powerful on mobile when you’re on the go with the Bing mobile app.



We are excited for the new opportunities this creates for developers and consumers alike. More scenarios include:

With Expedia, travelers will enjoy conversational trip planning for a seamless experience to facilitate memorable travel.

With Instacart, you’ll soon be able to take the dinner menu Bing helped you plan, turn it into a shopping list, and place an order to get the ingredients delivered directly to your door from your favorite grocery retailer. You can adjust quantities and make other changes before placing the order—keeping you in control.

Kayak’s plugin will act as a virtual travel assistant, bringing some of Kayak’s most popular features to life in new and more conversational ways.

Klarna will offer a highly personalized and intuitive shopping experience by providing curated product recommendations to users who ask for shopping advice and inspiration, along with links to shop those products via Klarna’s search and compare tool.

With Redfin, you will be able to describe your ideal home in everyday terms and Bing Chat will find listings that suit your needs, saving you from searching through endless listings.

The Tripadvisor plugin will help hundreds of millions of people each month become better travelers by leveraging the world’s largest travel guidance platform.

With Zillow, you’ll have a built-in real estate expert giving your Bing search a boost with additional housing and market information.

Instacart plugin in Bing Chat

Additionally, Bandsintown, Bohita, Cloudflare, Coupert, Fareportal, FiscalNote, Golden, Lexi Shopper, Likewise, Noteable, One Word Domains, PromptPerfect, Shopify, Skyscanner, Spotify, Spotnana, and Trip.com are enabling plugins for Bing Chat.



Bing plugin partners



All these experiences will be delivered within Bing chat or the Edge sidebar across desktop and mobile in the coming weeks.



Integrating Bing across Microsoft’s copilots



With today’s announcement of Windows Copilot, we’re excited to bring the power of Bing Chat in a more robust way to Windows 11. Windows Copilot, together with Bing Chat (including the shared plugin platform with Bing and OpenAI), enables those plugins to be enhanced through applications on Windows. This makes it easier than ever to get personalized answers, relevant suggestions, and take quick actions. Windows Copilot will be persistent next to any of your apps and will support the same plugins to enhance your chat experience. To learn more, visit the Windows Blog.



In addition to Windows, we’re excited to share that our common plugin platform will also be natively integrated into Microsoft Edge. Microsoft Edge continues to be your copilot for the web—the first browser to integrate AI-powered search. To learn more, visit the Edge blog.



These past 100 days have been critical in the development of the new era of AI-powered search. As we see people engage with Bing and Edge in profoundly new ways, it’s clear the transformation of search is well underway. We’re excited to continue to expand what’s possible with today’s announcements. If you haven’t tried the new Bing yet, visit bing.com and download the mobile app on your phone to get started.



- Yusuf Mehdi



"
Microsoft_News,https://www.microsoft.com/en-us/microsoft-365/blog/2023/05/23/empowering-every-developer-with-plugins-for-microsoft-365-copilot/,,Empowering every developer with plugins for Copilot for Microsoft 365,"Generative AI models are ushering in the next frontier in interactions between humans and computers. Just like graphical user interfaces brought computing within reach of hundreds of millions of people three decades ago, next-generation AI will take it even further, making technology more accessible through the most universal interface—natural language.

Microsoft’s approach to generative AI is focused on keeping humans at the center and augmenting human agency. It’s not an autopilot approach, but rather a design ethos that we call Copilot to tackle the growing volume of digital debt that is taking attention away from innovation and sapping our productivity. According to Microsoft’s latest Work Trend Index research, the inflow of data, emails, meetings, and notifications has outpaced our ability to process it all. Workers are spending two full days of the work week managing email and attending meetings—just to keep up. While 49 percent of people said they’re worried that AI will replace their jobs, even more—70 percent—would delegate as much work as possible to AI to lessen their workloads.

Today, I’m excited to announce extensibility for Copilot for Microsoft 365 with plugins. With this announcement, we’re empowering every developer to integrate their apps and services into Copilot for Microsoft 365. Together, we can reach hundreds of millions of people where they work every day to create a whole new way of work.

Copilot for Microsoft 365: Your copilot for work

Earlier in March, we announced Copilot for Microsoft 365 which brings the power of next-generation AI to Microsoft 365 products like Microsoft Teams, Outlook, and more. Microsoft 365 products are among the leading productivity, communications, and collaboration solutions in the market today.

Copilot for Microsoft 365 combines the power of foundation models with your data in Microsoft Graph and Microsoft 365 apps to turn your words into the most powerful productivity tool on the planet. You experience Copilot for Microsoft 365 in two ways: in-app assistance and cross-app intelligence to unleash creativity, unlock productivity, and uplevel skills.

The success of our products, like Teams, with more than 300 million active users, would not be possible without our vibrant community of developers and partners. You’ve been a key part of this journey, building the ecosystem with us, with apps that run on and extend our products. As I look at this next-generation AI opportunity, I’m most excited about what we can do together.

Plugins for Copilot for Microsoft 365

Copilot in Bing Learn more

At Microsoft Build 2023 today, we’re announcing a joint commitment from Microsoft and OpenAI to support and grow the AI plugins ecosystem. We are embracing an open standard for plugins that integrates across OpenAI’s ChatGPT and Microsoft Copilot.

Copilot in Windows Read about it

Today, we’re announcing the extensibility model for Copilot for Microsoft 365 with plugins. Developers can now integrate their apps and services into Copilot for Microsoft 365 with plugins to reach hundreds of millions of people where they work every day. Plugins are tools that augment the capabilities of AI systems, enabling them to interact with APIs from other software and services to retrieve real-time information, incorporate company and other business data, and perform new types of computations.

There are three types of plugins for Copilot for Microsoft 365: ChatGPT plugins, Teams message extensions, and Microsoft Power Platform connectors—enabling developers to use existing software and tooling investments and skills.

Customers in the Copilot for Microsoft 365 Early Access Program will have access to more than 50 plugins from partners including Atlassian, Adobe, ServiceNow, Thomson Reuters, Moveworks, and Mural. Thousands of additional line-of-business and third-party plugins will be enabled in the coming months as we integrate existing Teams message extensions and Microsoft Power Platform connectors with Copilot for Microsoft 365. This extensive ecosystem of plugins for Copilot for Microsoft 365 surfaced in the tools used every day for work will bring unprecedented value to our mutual customers as we transform how work gets done together.

With Teams Toolkit for Visual Studio, Visual Studio Code, and CLI, developers can create Teams message extensions today that will function as plugins for Copilot for Microsoft 365. We are introducing new capabilities in Teams Toolkit to make it easy to create, test, and debug plugins. Developers can bring any API described by the OpenAPI specification to Copilot for Microsoft 365 quickly with the plugin creation experience in Teams Toolkit, available in private preview today.

Developers can control and customize the user experience when their plugin is invoked through Adaptive Cards. Based on the metadata in the OpenAPI specification, Teams Toolkit scaffolds a plugin containing a manifest and declarative Adaptive Cards that define the Copilot user experience. Developers can further customize the manifest and cards to fit their scenario, such as configuring authentication settings, before testing their plugin in Copilot.

See the new tooling in action below, and sign up for the developer early access program to try it out.

Supercharge your data with Semantic Index for Copilot

Microsoft Graph is the gateway to customers’ productivity and collaboration data, as well as their compliance, security, and privacy policies. Copilot grounds the user prompts and responses with the Microsoft Graph data and inherits security and permissions at runtime. This enables an approach to security and governance that our customers control. Furthermore, the data stays in the customers’ tenant and is not used for training Microsoft’s foundation Models.

Microsoft Graph Connectors are Generally Available Learn more

The recently announced Semantic Index for Copilot is a sophisticated map of user and company data and powers how Microsoft Graph data is surfaced to Copilot. It computes vector embeddings from Microsoft Graph data to capture semantics and similarities around content and users and enables fast semantic search by Copilot across billions of items in a vector index. Developers can bring their data to Microsoft Graph with Graph connectors to take advantage of the Semantic Index for Copilot to deliver more personalized and actionable responses.

In addition to productivity and collaboration data in Microsoft Graph, Copilot for Microsoft 365 can now also access structured data from Microsoft Dynamics 365 and Microsoft Power Platform stored in Microsoft Dataverse. This means copilot responses will be grounded in your business data in addition to user data in Microsoft Graph. Customers in the Copilot for Microsoft 365 Early Access Program will be able to try out this capability as we roll out Copilot for Microsoft 365 in the program. Developers can import data into Dataverse through Microsoft Power Platform connectors. Watch a demo below of what’s possible with access to business data in Dataverse. Read this blog to learn more.

Copilot for Microsoft 365 extensibility in action

Developers will play a vital role in defining new patterns of work as users experience Copilot for Microsoft 365 with their integrated apps and services. The demo below shows the simulated scenario of a user at Dentsu Inc., an integrated marketing solutions and agency service company, harnessing the power of Copilot for Microsoft 365 together with a plugin for Atlassian’s Jira, a line-of-business Dentsu app plugin for sourcing media assets, and data from Atlassian’s Confluence integrated using a Microsoft Graph connector. Copilot for Microsoft 365 used Teams message extensions for Jira and Dentsu’s line-of-business app—no new code was written. You can see the full demo here:

Accelerating success for every developer

With the new extensibility model for Copilot for Microsoft 365 with plugins, we are enabling developers to easily participate in the AI opportunity and reach hundreds of millions of Microsoft 365 users, using their existing expertise, code, and tools. Microsoft is committed to ensuring your success across the entire app life cycle. That’s why we are bootstrapping extensibility for Copilot for Microsoft 365 by grounding it with the Teams and Microsoft 365 platform and programs. Developers extending Copilot for Microsoft 365 will benefit from tooling, distribution, management, commerce, and enterprise readiness of the Teams and Microsoft 365 platform.

Our goal is to maximize developer productivity, app reach, app discovery, and revenue. Developers with existing Teams message extensions will not have to write new code to extend Copilot for Microsoft 365, and developers can easily create new plugins with Teams Toolkit for Visual Studio. Plugins can be configured, published, and managed in the Developer Portal for Teams. Developers can take advantage of the App Compliance Automation Tool and Microsoft 365 App Compliance Program to speed up IT approvals and reach more users. To increase user discovery, developers can take advantage of platform capabilities like link unfurling and contextual app exposure in surfaces such as chat, channels, and meetings in Teams. Finally, our commercial marketplace enables developers to monetize their plugins.

Learn more about Copilot for Microsoft 365

We are excited for this opportunity we have together with developers and partners to shape the future of work with AI. Copilot for Microsoft 365 is entering the Early Access Program and customers will soon be able to try the extensibility we are announcing at Microsoft Build. Here’s what developers and partners can do today to get ready for Copilot:

Build a Teams message extension to get your plugin for Copilot for Microsoft 365.

Build a Microsoft ­­Graph connector and bring your data into Semantic Index for Copilot.

Sign up for the developer early access program to build plugins for Copilot for Microsoft 365.

Access all the resources and tools mentioned above.

More innovations to build apps

We have many exciting announcements beyond Copilot extensibility that help you build apps for all the new ways to work. Here are a few highlights.

Live Share SDK Now generally available

Effective collaboration and cocreation can be challenging in hybrid work. With the Live Share SDK, now generally available, developers can build Live Share capabilities into their apps without writing any dedicated back-end code, taking real-time collaboration in Teams meetings to the next level. When apps are built for Live Share, meeting participants can annotate, edit, zoom in and out, and interact with shared content in a variety of other ways in the Teams meeting stage.

Microsoft Mesh In private preview today

It’s easy to feel disconnected from your colleagues in remote and hybrid work. Avatars for Microsoft Teams is rolling out to general availability in phases starting this week and offers an alternative to the binary option of video or no video and features customizable avatars and reactions. Avatars give users the option of a camera break, while encouraging engagement and fun with your coworkers. You can transform your everyday meetings to have a sense of natural copresence with immersive spaces for Microsoft Teams, now in private preview. Immersive spaces for Microsoft Teams can be accessed through a personal computer (PC) or virtual reality (VR) headset, with the ability to easily connect with other participants regardless of whether they join a Teams meeting using video or as an avatar, or in the immersive space directly. Developers and creators can build custom, immersive experiences for the workplace with Microsoft Mesh, available in private preview starting today. Mesh gives developers the tools to create shared experiences that extend beyond the bounds of the physical world and help foster a sense of connection and belonging regardless of where workers are located, using a PC or VR headset.

To read more about these and other announcements, please visit our developer blog."
Microsoft_News,https://blogs.windows.com/windowsdeveloper/2023/05/23/bringing-the-power-of-ai-to-windows-11-unlocking-a-new-era-of-productivity-for-customers-and-developers-with-windows-copilot-and-dev-home/,,Bringing the power of AI to Windows 11 – unlocking a new era of productivity for customers and developers with Windows Copilot and Dev Home,"The team and I are pumped to be back at Build with the developer community this year.

Over the last year, Windows has continued to see incredible growth fueled by Windows 11 adoption. In fact, one of the most exciting areas driving that growth for Windows has been developers themselves, with a 24% YoY increase in monthly devices used for development.

AI is the defining technology of our time and developers are at the forefront of this transformation. With the right tools we can empower developers and our shared customers to shape the future and leave their mark on the world. We are just starting to see the incredible impact AI is having across industries and in our own daily lives. Today, the team and I are excited to share the next steps we are taking on our journey with Windows 11, to meet this new age of AI.

We are introducing Windows Copilot , making Windows 11 the first PC platform to announce centralized AI assistance to help people easily take action and get things done.

, making Windows 11 the first PC platform to announce centralized AI assistance to help people easily take action and get things done. We are extending Bing Chat plugins to Windows, enabling developers to integrate their apps within Windows Copilot to better serve their customers and increase engagement on native Windows applications.

enabling developers to integrate their apps within Windows Copilot to better serve their customers and increase engagement on native Windows applications. We are introducing new Hybrid AI loop to support AI development across platform, and across Azure to client with new silicon support from AMD, Intel, Nvidia and Qualcomm.

to support AI development from AMD, Intel, Nvidia and Qualcomm. We are introducing Dev Home designed to help every developer become more productive on Windows.

designed to help every developer become more productive on Windows. We are introducing new AI features and experiences in the Microsoft Store on Windows.

We can’t wait to share more with you tomorrow during our Windows keynote, be sure to register for Build and tune in!

Introducing Windows Copilot for Windows 11

We’re thrilled to introduce Windows Copilot. Windows is the first PC platform to provide centralized AI assistance for customers. Together, with Bing Chat and first- and third-party plugins, you can focus on bringing your ideas to life, completing complex projects and collaborating instead of spending energy finding, launching and working across multiple applications.

Invoking Windows Copilot is familiar and easy – the button is front and center on your taskbar – simple to find and use. Once open, the Windows Copilot side bar stays consistent across your apps, programs and windows, always available to act as your personal assistant. It makes every user a power user, helping you take action, customize your settings and seamlessly connect across your favorite apps. The things you love about Windows – copy/paste, Snap Assist, Snipping Tool, personalization – they are all right there for you, along with every other feature on the platform, and they only get better with Windows Copilot. For example, you can not only copy and paste, but also ask Windows Copilot to rewrite, summarize or explain your content.

Just like you would with Bing Chat, you can ask Windows Copilot a range of questions from simple to complex. If I want to call my family in Cyprus, I can quickly check the local time to make sure I’m not waking them up in the middle of the night. If I want to plan a trip to visit them in Cyprus, I can ask Windows Copilot to find my family flights and accommodations for mid-winter break.

With Bing and ChatGPT plugins in Windows Copilot, people will not only have access to augmented AI capabilities and experiences, but you as developers will also have new ways to reach and innovate for our shared customers. We welcome you to be part of the Windows Copilot journey by continuing to invest in Bing and ChatGPT plugins so your investments will carry forward to Windows Copilot.

Windows Copilot will start to become available in preview for Windows 11 in June, stay tuned and sign up here to get updates from the team.

Empowering every Windows 11 developer to be an AI developer

This is an incredible time to be a developer on Windows. The possibilities across industries – healthcare, finance, education, tech, and others – are endless. We continue to invest in important tools to democratize how apps will be built for the new era of AI; whether you’re developing on x86/x64 or Arm64 we want to make it easy for you to bring AI powered experiences in Windows apps across cloud and edge.

If you are just getting started with AI or if you are wondering where to start, Microsoft and Windows are here to help you on that journey. Today, we are announcing the Windows AI Library, which will house a curated collection of ready to use machine learning models and APIs that will help jumpstart your AI development. We will share more details on the availability and preview dates in the coming weeks.

Last year at Build, we announced Hybrid Loop, a new development pattern that enables hybrid AI scenarios across Azure and client devices. Today, we are excited to share that our vision has become a reality using ONNX Runtime as the gateway to Windows AI and Olive, a toolchain we created to ease the burden on you when optimizing models for varied Windows and other devices. With ONNX Runtime, third-party developers have access to the same tools we use internally to run AI models on Windows or other devices across CPU, GPU, NPU, or hybrid with Azure.

ONNX Runtime now supports the same API for running models on the device or in the cloud, enabling hybrid inferencing scenarios where your app can use local resources when possible and switch to the cloud when needed. With the new Azure EP preview, you can connect to models deployed in AzureML or even to the Azure OpenAI service. With just a few lines of code you can specify the cloud endpoint and define your criteria for when to use the cloud. This gives you more control over costs and user experience, as Azure EP gives you the flexibility to choose between using the larger model in the cloud or the smaller local model at runtime.

You can also optimize your models for different hardware targets with Olive, an extensible toolchain that combines cutting edge techniques for model compression, optimization and compilation. And you can use ONNX Runtime across platforms like Windows, iOS, Android and Linux, so your Windows AI investment can extend to all your app platforms.

Both ONNX Runtime and Olive contribute to the velocity of getting your AI models deployed into apps. ONNX Runtime makes it easier for you to create amazing AI experiences on Windows and other platforms, with less engineering effort and better performance.

Extending our vision for an AI powered future in collaboration with our partners

Windows 11 has the largest and most powerful ecosystem of GPUs in the world with more than 200M+ AI capable discrete GPUs. Windows PCs like Surface Studio 2+, and PCs built by partners such as Acer, ASUS, Dell, HP, Lenovo and Samsung are powered by NVIDIA GPUs. Developers can leverage these GPUs today to run cutting-edge transformer models like Dolly 2.0, Stable Diffusion and NVIDIA’s NeMo that are pre-optimized for Windows.

NPUs (Neural Processing Units) are purpose-built accelerators to run AI models efficiently. Our partners are continuing to innovate and deliver – like Qualcomm with the Snapdragon 8cx Gen3 Compute Platform which today enables Windows devices including the Surface Pro 9 5G and the Windows Dev Kit 2023. With Olive & ONNX Runtime you can target Qualcomm AI Engine Direct SDK to run AI models on the 8cx Gen 3 compute platform NPU.

We are excited to see all our silicon partners bring more Windows devices with NPUs to the market later this year. AMD recently made early access of Ryzen™ AI software available to developers to run AI models on AMD Ryzen™ 7040 Series processors with Ryzen™ AI. Intel previewed their new Meteor Lake product, an all-new chiplet SoC architecture that will feature Intel’s first integrated AI engine which will scale across the Windows ecosystem starting later this year and will also make available developer tools, including ONNX Runtime support enabled through OpenVino-EP and DirectML-EP.

Partners such as WhatsApp, Luminar Neo and Camo are achieving incredible leaps in performance and unlocking new end-user experiences by leveraging NPUs to run their AI models. Bring your apps to the Windows platform and leverage ONNX Runtime to deliver AI experiences like Camo. We can’t wait to see what the Windows developer community will create with these new AI toolchains and NPU hardware advancements.

New experiences designed to help every developer become more productive on Windows 11

Life as a developer involves constantly juggling manual dev machine set up with too many clicks, multiple tool sign-ins, navigating sub-optimal filesystem performance and context switching, and we know that these disruptions can significantly impact your productivity. Today, we’re excited to announce new features and improvements across all stages of the development cycle on Windows.

Introducing Dev Home: Your new productivity companion

With a renewed focus on your productivity, we are announcing a new home for developers on Windows – Dev Home. Dev Home is a new experience in Windows 11, now available in preview, that gets you back in the zone and streamlines your workflow with features such as WinGet configuration for easier and faster setup, Dev Drive for enhanced filesystem performance and a new customizable dashboard to track all your workflows and tasks in one place. Dev Home makes it easy to connect to GitHub and set up your machine to code for the repos you care about, easily installing the tools and packages you need. Dev Home can also configure your coding environments in the cloud using Microsoft Dev Box and GitHub Codespaces. With Dev Home, designed by and for developers, you now have your ultimate productivity companion so you can focus on what you do best – writing code. Download the preview of the Dev Home in the Microsoft Store today. Learn more about Dev Home

Unattended and reliable dev machine setup: Reducing set up time from days to hours

Get ready-to-code in just a few clicks with the new WinGet configuration. This unattended, reliable and repeatable mechanism allows you to skip the manual effort of setting up a new machine or onboarding a new project and removes the worry of searching for the right version of software, packages, tools and frameworks to download or settings to apply. WinGet configuration reduces this manual and error-prone process down to a single command with a WinGet configuration file. Just run `winget configure ` in the command prompt and when it’s done, you are ready to code! Learn more about WinGet configuration

Introducing Dev Drive: A new storage volume tailor-made for developers: supercharged for performance and security

We know you often deal with repositories containing many thousands of files and directories, and historically this has presented a challenge for heavy I/O operations such as builds.

Today, we are announcing Dev Drive – a new type of storage volume, tailor-made for developers, with a file system that delivers both performance and security.

Dev Drive is based on the Resilient File System, which, combined with a new performance mode capability in Microsoft Defender for Antivirus, offers up to 30% file system improvement in build times for file I/O scenarios. The new performance mode is more secure for your workloads than folder or process exclusions, providing an ultimate solution to balance security with performance.

Dev Home makes it effortless to set up Dev Drive as part of the environment setup process. It is supercharged to host project source code, working folders and package caches. Dev Drive is available in preview later this week. Create a Dev Drive now.

Efficiently track your workflows on a new customizable dashboard in Dev Home

Dev Home also helps you manage any type of project you’re working on – Windows, cloud, web, mobile or AI – providing all the information you need, right at your fingertips, in one customizable dashboard. You can enhance the Dev Home experience by adding GitHub widgets to efficiently track all coding tasks or pull requests and projects from one central location, and system widgets to track CPU and GPU performance. We are collaborating with Team Xbox to bring the GDK to Dev Home to make it easy to get started with game creation. Looking to add your own custom-built extensions? You can do this on Dev Home.

Dev home is open source. We value community input on the experience, and we want to build this with you. Contribute and engage with us at the GitHub repository

Dev Home is in preview starting today, you can install Dev Home from the Microsoft Store today.

Your favorite tool, Windows Terminal is getting smarter with GitHub Copilot X

Users of GitHub Copilot will be able to take advantage of natural language AI both inline and in an experimental chat experience to recommend commands, explain errors and take actions within the Terminal application. We are also experimenting with GitHub Copilot powered AI in other developer tools like WinDBG to help you complete your tasks with less toil.

Join the GitHub Copilot Chat waitlist to gain access to these features as they become available.

Reducing toil and unlocking the fun and joy of development on Windows with new features and improvements

The team has listened closely to what improvements are top of mind for you, including improvements to the Taskbar:

You can now quickly identify and access any instance of each app housed in the taskbar with just one click. All instances of the app are ungrouped with labels on the taskbar. You can now hide your Time and Date with a setting on the taskbar. With this setting, users will be able to hide the time to remain focused, capture screen recordings without having to edit to hide time and date. The feature is located in the time and date settings page in Windows Settings. Quickly and easily shut down applications with a simple right click on the app directly from the taskbar without opening the Task Manager.

In addition…

We have added native support for additional archive formats, including tar, 7-zip, rar, gz and many others using the libarchive open-source project. You now can get improved performance of archive functionality during compression on Windows.

We are adding tab tear-out to Windows Terminal so that you can easily organize your different shells into windows according to your needs.

Continuing to innovate and accelerate development for Windows on Arm

In the past year, we launched the Windows Dev Kit 2023, and Arm native versions of Visual Studio and .NET to help accelerate development on Arm. Windows is continuing this momentum and welcoming more third-party Windows apps, middleware partners and Open-Source Software natively to Arm. Learn how to add Arm support for your apps.

Visual Studio 17.6 now ships with MAUI support for Arm.

Visual Studio 17.71 Preview 1 now ships with support for Linux development with C++.

LLVM v12.0 and onwards for cross compile and native compile options for Arm.

Node 20.0.0 is available from April with native Arm support.

WiX installer v4.0 is available to create native installers for Arm.

New middleware projects that have released in the last 12 months: Qt 6.2, CMake 3.24, Bazel, 5.1, OpenSSL 3.0, OpenBLAS, 0.3.21, Python 3.11.

Unity Player: Unity Player is now generally available for Windows on Arm natively. Developers using the game engine will be able to easily target Windows on Arm devices to get native performance on current and future titles.

Unity Player is now generally available for Windows on Arm natively. Developers using the game engine will be able to easily target Windows on Arm devices to get native performance on current and future titles. Additional solutions are coming soon to Arm64 For example GNU GCC, Flutter & Dart, PyTorch, GIMP.

Beyond Microsoft’s investment in the Arm platform there are many developers that see the value of Arm native support and have released Arm64 native versions of their experiences to give their customers the best experience.

Here are just a few of the recent products launched:

And many more with plans to release in the near future:

New features to keep your users engaged

Lighted accessories have been on the rise and can add energy and emotion to your PC experience. Today, many of these accessories rely on third-party apps and integrations that are highly fragmented. With Dynamic Lighting, Windows users will be able to effortlessly set up and customize their devices with RGB lights directly from Windows Settings. It has never been easier to help all your RGB accessories seamlessly work together for Windows apps. This month, we are making the Dynamic Lighting preview available to Windows Insiders so that developers and hardware partners alike can experiment with new integrations for RGB accessories and components.

New features and experiences in the Microsoft Store on Windows

We are committed to not only providing you with the best tools to build great apps, but we are also enhancing the Microsoft Store, an open platform on Windows that provides the reach and growth that you seek.

Today, we’re pleased to announce new AI-powered features, expanded Microsoft Store Ads and new tools to help you reach your customers:

Microsoft Store AI H ub: Coming soon, we are introducing a dedicated section in the Microsoft Store on Windows that will curate the best AI experiences built by the developer community and Microsoft.

Coming soon, we are introducing a dedicated section in the Microsoft Store on Windows that will curate the best AI experiences built by the developer community and Microsoft. Microsoft Store AI-Generated keywords: To help optimize app discovery, we are introducing a new tool in Partner Center that leverages AI to generate and suggest search tags for apps to improve discoverability.

To help optimize app discovery, we are introducing a new tool in Partner Center that leverages AI to generate and suggest search tags for apps to improve discoverability. AI- Generated review summary: We are making it faster and easier for customers to scan reviews for apps by using the power of AI to compile thousands of reviews into a simple summary, enabling customers to discover new content with ease.

We are making it faster and easier for customers to scan reviews for apps by using the power of AI to compile thousands of reviews into a simple summary, enabling customers to discover new content with ease. Microsoft Store Ads: Beginning in June, Microsoft Store Ads will expand its footprint beyond the U.S., to more than 150 regions worldwide. You will also have more options to reach customers with a new premium, high-traffic spotlight placement in the Store and Bing.com search results.

Beginning in June, Microsoft Store Ads will expand its footprint beyond the U.S., to more than 150 regions worldwide. You will also have more options to reach customers with a new premium, high-traffic spotlight placement in the Store and Bing.com search results. Backup and Restore Apps: To help you retain your customers when they switch devices, we are enhancing the backup and restore experience for apps. This update is in preview and is available to Windows Insiders today.

To learn more about what we announced in the Microsoft Store on Windows today, including new AI-powered experiences and developer tools, visit this blog post.

Building on and for the future of Windows, together

It’s an exciting time to be a developer, even more so on Windows, and we’re thrilled to be on this journey with our you. From the moment you open your device, you’ll have the ultimate productivity tools at your fingertips, empowering you to do your best work. With the incredible momentum that’s building around this new era of AI, we can’t wait to see what you will create next.

We want to empower you to focus your time on creating and building – writing code that only you can write. With our renewed focus on supercharging developer productivity, we believe Windows now provides the best platform for you to create cutting edge experiences for your customers and is also the best platform for you to reach those customers, all with minimal cost and effort. We are humbled to be on this journey with you.

To learn more about these incredible new features, explore our new Windows Developer Center bringing our news and resources all into one location for you. For our Windows Insiders, you’ll be able to start accessing a set of these new features later this week in an Insider Preview Build. And be sure to check out our various sessions throughout Microsoft Build to learn more about everything we announced.

Update, May 24, 2023: This blog post was updated to add additional detail on the AI library"
Microsoft_News,https://blogs.windows.com/msedgedev/2023/05/23/microsoft-edge-build-2023-innovations-in-ai-productivity-management-sidebar-apps/,,"Microsoft Edge: Your AI-powered browser, innovating for businesses and developers","This year at Build, we’re raising the bar on what a browser can and should do in today’s digital world to help you, your business, and the sites and web apps you create to stay at the forefront. Check out the latest innovations below to learn how Microsoft Edge will take your work and your organization’s productivity to the next level.

Jump to the following sections to learn more:

Powerful AI advancements change the nature of web browsing

With our mission to be the best browser for business, we are harnessing the power of AI to help you and your organization to stay on the cutting edge. Microsoft Edge continues to be your copilot for the web—the first to integrate AI-powered search, and the only one with Bing built-in. And our vision is to empower organizations with enterprise-compliant AI – with a commitment to delivering new capabilities in ways that meet our existing commitments to data security and privacy in the enterprise. Over the last few months, you may have seen Microsoft announced AI-powered innovations, such as the new Bing with its chat and compose capabilities, Bing Image Creator, and most recently, Microsoft 365 Copilot, which is designed for business use. Today, we’re excited to announce that Microsoft 365 Copilot, currently in private preview, will be natively integrated into Microsoft Edge.

Microsoft 365 Copilot offers new capabilities that combine the power of large language models, Microsoft 365 apps, and your data in the Microsoft Graph—such as your calendar, emails, chats, documents, and more—to do things you’ve never been able to do before. For example: You can type natural language requests like “Tell my team how we updated the product strategy today,” and Microsoft 365 Copilot will generate a status update based on the morning’s meetings, emails and chat threads. In combination with Edge, Microsoft 365 Copilot becomes even more intuitive by following the context of what you’re looking at in the browser to provide better answers. For example, as you’re looking at a file your colleague shared, you can simply ask, “What are the key takeaways from this document?” Watch our new video to learn more.

We’re also adding support for plugins in Microsoft 365 Copilot, with a simple user experience in Edge to discover and enable new plugins. Developers can build experiences that enable people to interact with their apps using human language to ask Microsoft 365 Copilot and Bing Chat for answers and actions from connected services. In fact, Microsoft is embracing the same open plugin standard that OpenAI introduced for ChatGPT, helping to ensure interoperability across ChatGPT and the breadth of Microsoft’s copilot offerings. Plugins for Microsoft’s copilot offerings include ChatGPT and Bing plugins, as well as Microsoft Teams message extensions and Power Platform connectors. New partners are coming to the platform – read more here. For developers, learn more in our Build session.

We’re also bringing the power of AI to your existing workflows to make finding information easier and writing simpler while you’re in the browser. Microsoft Search will soon surface contextually relevant files and SharePoint sites in the address bar based on relevance and your activity, and the Find on Page (Ctrl+F) experience is improving with Smart Find. Rolling out worldwide now, Smart Find helps correct syntactic and semantic errors to provide accurate information about the page’s content. And with text prediction, users can write faster with fewer mistakes. Text prediction is currently rolling out in the US, India, and Australia in English and will be available soon in Chinese and Japanese. Our goal with these innovations is to help you work smarter, not harder. Learn more about these AI innovations and more in our latest video.

Microsoft Edge gets a new look and feel

You may notice in our images and GIFs throughout this blog that Edge looks and feels a little different. This is a purposeful evolution inspired by you, our users. Your feedback shaped our goals to create a browsing experience that is aesthetically pleasing and easy to use in today and tomorrow’s digital scenarios, while feeling familiar. We drew from the modern elegance of Windows 11, with its rounded corners, translucent backgrounds, and fluid animations, and made subtle usability changes. We moved the profile icon to a new location for functional benefit, to make it easier to add, change, and manage your account. There are also structural changes, such as a new container system, so you can more easily view multiple items at once. As you start to see changes come through, we hope the new look and feel will help you to confidently and joyfully use the browser in old and new ways.

Learn more about the new look and feel for Edge here.

The new dedicated work experience – Microsoft Edge for Business

To more fully realize our mission to deliver the best browser for business, we’re evolving Microsoft Edge to have a dedicated work experience with its own visual elements, including an adjusted icon, your organization’s name, and other visual cues. This new experience is called Microsoft Edge for Business. With the rich set of enterprise controls, security, and productivity features that you’re already familiar with, Edge for Business is designed to help meet the evolving security landscape while empowering users to work effectively. Microsoft Edge for Business is planned to be the standard browser experience for organizations, activated by an Azure Active Directory (AAD) login.

Edge for Business also addresses problems created by hybrid work, where the lines between work and personal have been blurred. Users want privacy and separation in their browsing so personal data like browsing history and passwords aren’t synced to their organization. Meanwhile, IT Pros want to maintain their organization’s security posture. As a result, organizations end up supporting multiple browsers so users can separate their browsing activities, often at the cost of increasing the organization’s surface area for cyberattacks and creating a cumbersome user experience.

This calls for a new browser model that enhances users’ privacy while maintaining crucial, enterprise-grade controls set at the organizational level. Microsoft Edge for Business honors the needs of both end users and IT Pros as the browser that automatically separates work and personal browsing into dedicated browser windows with their own separate caches and storage locations, so information stays separate. Work-related sites, such as Microsoft 365 apps and services and sites requiring work login, automatically open in the work browser window. A growing set of popular sites automatically open in the personal browser window. Once enabled, users will be able to seamlessly and automatically flow back and forth between the work and personal browser windows, depending on the site. Users can designate additional sites for work or personal use in settings.

For IT Pros, this new, dedicated Edge experience can reduce the surface area for cyberattacks, heightening the organization’s security posture, since it offers the opportunity to streamline down to one browser for all use cases. Admins can designate controls and security for Microsoft Edge for Business with enterprise capabilities such as built-in data loss prevention*, information rights management, and feature availability. With users separating their work and personal content, personal data can be excluded from enterprise sync, which happens in the work browser window. This gives users the privacy they want. At the same time, IT maintains controls over the security and compliance posture of Microsoft Edge, whether work or personal.

Microsoft Edge for Business is in preview today on managed devices. Microsoft Edge for Business is also coming to unmanaged devices in the coming months, so stay tuned to join the preview. Visit this page about Microsoft Edge for Business to learn more.

*requires E5 licensing

Microsoft Edge Workspaces rolling out to everyone in the next few months

Microsoft Edge is designed for how your remote employees work together today. Keeping everyone on the same page is often tough, especially when you’re working on so many files at once and content is constantly being updated and shared. With Microsoft Edge Workspaces, everyone can view the same project websites and latest working files in one place as a shared set of browser tabs. Since our announcement at Ignite, thousands of customers have used Edge Workspaces in preview to organize their projects and stay in sync.

Today, we’re excited to announce that Edge Workspaces will be moving out of preview and will become generally available to everyone in the next few months. If you and your organization want to use Edge Workspaces today, you can still join the public preview.

Using Edge Workspaces is easy: simply create a workspace dedicated to your project, open project links as browser tabs, and share the workspace so everyone is working off the same set of websites and files. You can add or delete tabs in the workspace at any time, and it all happens in real-time so everyone can easily see the whole picture. Plus, it’s secure – if protected files/apps are open in tabs, only people with access can view. Edge Workspaces helps users save time and energy searching for the latest working files and helps teams stay better connected and productive in their workdays.

Simplified Microsoft Edge management in the Microsoft 365 admin center

With users spending more time in their workday in the browser, you need a comprehensive but simple browser management solution. Introducing the Edge management service – a new, dedicated and simplified management experience for Microsoft Edge within the Microsoft 365 admin center, available in preview over the next few months. This tool has been long requested by IT admins to simplify browser management and will allow IT admins to manage group policies and extensions with a simplified, intuitive UI. Admins can set policies through toggles and drop-down menus instead of the complexity of configuring JSON values, which helps reduce errors. This solution is another option for managing Edge that lives alongside Intune and other major endpoint solutions. It’s a great option for customers who don’t have dedicated IT resources or companies of any size that are looking for an experience designed specifically for managing Edge for Business.

Global admins and Edge admins can create and manage policies and extensions and assign these configurations to Azure AD groups using the intuitive UI. In the extensions tab, admins can access Edge Add-ons to see ratings, search for, add, and delete extensions, as well as view user extension requests, all in one easy-to-navigate place.

Customers currently using the Edge management service in private preview tell us they like the ease of use, simple UI, time savings, and granularity of controls, but this is just the beginning. More will be added to this tool over time, to bring IT admins more granular and intuitive controls and continue to lighten the load of browser management.

Access corporate resources from anywhere with Microsoft Edge on mobile

In a hybrid world, access to corporate resources is important wherever your users may be, so Edge for Business also provides a secure, managed experience on mobile iOS and Android devices. Edge for Business offers a key differentiator for mobile phone and tablet users: its flexibility in enabling seamless and secure access to corporate resources. Per-account VPN enables users with corporate accounts to seamlessly access internal resources. Moreover, when Zero Trust is adopted by enterprises, the out-of-the-box support for Microsoft Azure AppProxy helps users access internal resources from wherever they are without a VPN.

Edge for Business on mobile also now supports Shared Device Mode, which offers frontline workers a streamlined experience when multiple users are sharing a single device across shifts.

It’s also getting easier to manage and deploy Microsoft Edge on mobile. In addition to integrated support in Microsoft Intune, Edge for Business on mobile devices recently became compatible with other major endpoint management solutions.

Increase the reach and usability of your progressive web apps (PWAs) with the sidebar in Edge

If you’re a developer, you know how challenging it can be to get your apps discovered by users. With integration into the Microsoft Edge sidebar, that’s getting a lot easier. The sidebar is home to the new Bing, which is drawing new users in every day, with its AI-powered search, chat, and creation. Sidebar also allows users to easily use their favorite web apps, including third-party apps like Instagram, WhatsApp, and Messenger, alongside primary browser tabs or desktop windows, minimizing the need to switch contexts. Don’t miss out on new opportunities to reach users as web browsing evolves.

Web developers can now modify their site’s web app manifest to build experiences that are tailored for Microsoft Edge’s sidebar. And the best part is, it only requires a couple lines of code. In the case of Instagram, the app already had this, so adding sidebar support only required an update to one line. Sites that support the sidebar are also promoted for user discovery and pinning within the sidebar, allowing web developers to reach new audiences and support new multi-tasking scenarios.

Watch our new video for more information on the integration of PWAs with the sidebar.

Learn more about the benefits of PWA app development and start building PWAs for the Edge sidebar.

We know it can be overwhelming with so many features to look at in DevTools, which is why we’ve created Focus Mode for you. Focus Mode is an experimental feature that provides a refreshed, simplified interface for Microsoft Edge DevTools. We provide maximum customizability across the Activity Bar and Quick View, so you can customize your most-used tools without compromising on the robust feature set of 33 tools.

Focus Mode is expected to be generally available this year. Learn more here.

Another experimental feature that we’re excited to share is the JSON Viewer. In the past, you may have relied on other browser extensions or tools to format JSON data. Now with JSON Viewer, you only need to use the Microsoft Edge browser to inspect your JSON data.

To enable this feature, go to edge://flags and enable the JSON Viewer flag. Navigate to any JSON resource on the web or a JSON file on disk using your browser. JSON Viewer is expected to be generally available this year.

We’ve continued to invest in advanced and powerful debugging techniques. Now, you can take screenshots even faster with the Memory tool and new features like enhanced traces and selector stats. A new feature is the ability to see unminified file, function, and object names in the Performance and Memory tools, so we strongly recommend loading your sourcemaps in DevTools, such as from Azure Artifacts Symbol Server, to take advantage of these useful capabilities.

Learn more about these dev tools in our new video.

WebView2 Benefits Coming to HoloLens 2 and Xbox

Microsoft Edge WebView2 is a great way to get the benefits of both web and native features in your app, such as extensive code-sharing between platforms, access to the web ecosystem and talent pool, as well as native capabilities. For example, the Microsoft Teams team evaluated their tech stack and chose WebView2 because of the benefits of security, reusable architecture, debugging tools, and memory savings. Based on internal research and testing, the Teams team saw up to a 20% memory reduction when using new APIs such as SetMemoryUsageTargetLevel. Leading global technology company TeamViewer also uses WebView2 to streamline the development technologies for their desktop and web applications, giving them tools to test and analyze UI and back-end challenges in a more efficient manner. Learn more about TeamViewer’s success with WebView2 here.

We’re excited to announce that the WebView2 Preview is available in HoloLens 2 Insider Preview today, and it will be available for Xbox later this year. WebView2 support on Xbox also enables media app developers to migrate from the old EdgeHTML WebView and brings significant improvements such as better remote debugging experience, better performance, and support for modern web features. On HoloLens 2, WebView2 enables developers to display spatially aware, app-integrated, and dynamic web content in 3D applications.

Review WebView2 documentation, and share your feedback with us on our feedback GitHub.

Learn more about the WebView2 preview in our new video.

V8 improvements enhance JavaScript tracing and Enhanced Security Mode

V8 is an open-source high-performance JavaScript and Web Assembly engine developed by the Chromium project, a fork of which is used in Microsoft Edge. V8 interprets, JIT-compiles and executes ECMAScript and WebAssembly.

We’re excited to announce improvements to ETW diagnostics viewed in Windows Performance Analyzer. Now you can see JavaScript stack frames in ETW traces for JIT-compiled JavaScript functions. The following image of a WPA session highlights the stack frames for JavaScript functions.

Another new feature in Microsoft Edge is the Web Assembly interpreter for Enhanced Security Mode scenarios. Enhanced Security Mode (ESM) in Microsoft Edge mitigates memory-related vulnerabilities by disabling just-in-time (JIT) JavaScript compilation and enabling additional operating system protections for the browser. Developers should be aware that the WebAssembly interpreter running in ESM might result in a lower than expected level of performance. If that’s a concern for you, you can add your site as an exception to opt out of ESM for site users.

Microsoft Quick Authentication library facilitates the sign-in process for users

On many websites, web developers include authentication mechanisms from different authentication providers using constructs like “Sign in with ________”.

Today, we’re excited to announce that you can use the Microsoft Quick Authentication library to authenticate users using their Microsoft Account (MSA). This library can be used to sign in users in any browser using the same credentials used when accessing Microsoft products and cloud services like Outlook, OneDrive, and Xbox LIVE. This functionality works in all browsers, but provides a streamlined one-click sign-in experience when signing in with Microsoft Edge.

To use the Microsoft Quick Authentication library, include a small snippet of HTML (or JavaScript) code to create a sign-in button or prompt MSA users, as shown in the samples and demos. When users sign in, our code securely authenticates them using the existing MSAL.js library and provides the necessary details for you to sign them in.

Digital goods API support for in-app purchases is coming to Microsoft Edge Progressive Web Apps (PWAs) published on Microsoft Store

One of the most sought-after web standards for browsers is the ability to offer and purchase digital goods through an integrated in-app purchase experience. Currently, the Digital Goods API allows web applications to get information about their digital products and user purchase details managed by a digital store. Combined with the Payment Request API, users can also purchase digital products.

Today, we are excited to announce that users will be able to make in-app purchases from the Microsoft Store within Microsoft Edge PWA apps. The Digital Goods API and the purchase process flow, coming soon to Edge on Windows 11, provides a fully integrated experience with Microsoft Store Billing.

And coming soon, developers of PWA apps that are published in the Microsoft Store will be able to use the Digital Goods API to query their digital product details, view existing purchases, check past purchase history, consume a purchase, and use the Payment Request API to facilitate the payment flow between the Microsoft Store and users.

We’ll have more to share about the availability of the Digital Goods API soon – watch this space!

Thanks for joining us

Whether you’re an organization looking to improve productivity or a developer looking to build a great experience for your users, the browser is essential in today’s digital world, and Microsoft Edge is here as your AI-powered browser. Thank you to all our customers for your stories, excitement, and feedback. We look forward to seeing how you use these innovations and to bringing you more in the future!"
Microsoft_News,https://blogs.microsoft.com/blog/2023/05/23/microsoft-build-brings-ai-tools-to-the-forefront-for-developers/,,Microsoft Build brings AI tools to the forefront for developers,"You only need two simple letters to accurately convey the major shift in the technology space this year: A and I. Beyond those letters, however, is a complex, evolving and exciting way in which we work, communicate and collaborate. As you will see, artificial intelligence is a common thread as we embark on Microsoft Build, our annual flagship event for developers.

It’s already been a landmark year for the industry, starting in January with the announcement of an extension of our partnership with OpenAI to accelerate AI breakthroughs and to ensure these benefits are broadly shared with the world. And in February, Microsoft announced an all-new, AI-powered Bing search engine and Edge browser to transform the largest software category in the world – search.

Since then, developments have accelerated at a rapid pace, with several key milestones along the way, including:

Greater availability of Azure OpenAI Service with added support for ChatGPT and OpenAI’s groundbreaking GPT-4 model.

with added support for ChatGPT and OpenAI’s groundbreaking GPT-4 model. Copilots across a wide range of users, including Dynamics 365 Copilot, Microsoft 365 Copilot and Copilot for Power Platform.

across a wide range of users, including Dynamics 365 Copilot, Microsoft 365 Copilot and Copilot for Power Platform. Expansion of a new AI-powered Bing to the Windows 11 taskbar, mobile and Skype; Bing Image Creator to chat; and a full open preview of the platform, no waitlist required.

This is just the beginning of the new era of AI. That’s why Microsoft Build is so important. During this event, we’ll be showcasing how AI is redefining what and how developers build, as well as how AI is changing the future of work.

Before we get into the news, let’s talk about two concepts we are discussing at length during Microsoft Build: copilots and plugins.

A copilot is an application that uses modern AI and large language models (LLMs) like GPT-4 to assist people with complex tasks. Microsoft first introduced the concept of a copilot nearly two years ago with GitHub Copilot, an AI pair programmer that assists developers with writing code, and we continue to release copilots across many of the company’s core businesses.

We believe the copilot represents both a new paradigm in AI-powered software and a profound shift in the way that software is built – from imagining new product scenarios, to the user experience, the architecture, the services that it uses and how to think about safety and security.

Plugins are tools first introduced for ChatGPT, and more recently Bing, which augment the capabilities of AI systems, enabling them to interact with application programming interfaces (APIs) from other software and services to retrieve real-time information, incorporate company and other business data, perform new types of computations and safely take action on the user’s behalf. Think of plugins as the connection between copilots and the rest of the digital world.

With that said, let’s focus on the news and announcements we’re unveiling during Microsoft Build.

Growing the AI plugin ecosystem

Microsoft is announcing that we will adopt the same open plugin standard that OpenAI introduced for ChatGPT, enabling interoperability across ChatGPT and the breadth of Microsoft’s copilot offerings.

Developers can now use one platform to build plugins that work across both consumer and business surfaces, including ChatGPT, Bing, Dynamics 365 Copilot and Microsoft 365 Copilot.

And if you want to develop and use your own plugins with your AI application built on Azure OpenAI Service, it will, by default, be interoperable with this same plugin standard. This means developers can build experiences that enable people to interact with their apps using the most natural user interface: the human language.

As part of this shared plugin platform, Bing is adding to its support for plugins. In addition to previously announced plugins for OpenTable and Wolfram Alpha, we will also have Expedia, Instacart, Kayak, Klarna, Redfin and Zillow, among many others in the Bing ecosystem.

In addition to the common plugin platform, Microsoft is announcing that Bing is coming to ChatGPT as the default search experience. ChatGPT will now have a world-class search engine built-in to provide more up-to-date answers with access from the web. Now, answers are grounded by search and web data and include citations so users can learn more, all directly from within chat. The new experience is rolling out to ChatGPT Plus subscribers starting today and will be available to free users soon by simply enabling a plugin.

Developers can now extend Microsoft 365 Copilot with plugins

We’re also announcing that developers can now integrate their apps and services into Microsoft 365 Copilot with plugins.

Plugins for Microsoft 365 Copilot include ChatGPT and Bing plugins, as well as Teams message extensions and Power Platform connectors – enabling developers to leverage their existing investments. And developers will be able to easily build new plugins for Microsoft 365 Copilot with the Microsoft Teams Toolkit for Visual Studio Code and Visual Studio. Developers can also extend Microsoft 365 Copilot by bringing their data into the Microsoft Graph, contextualizing relevant and actionable information with the recently announced Semantic Index for Copilot.

More than 50 plugins from partners will be available for customers as part of the early access program, including Atlassian, Adobe, ServiceNow, Thomson Reuters, Moveworks and Mural, with thousands more available by the general availability of Microsoft 365 Copilot.

New Azure AI tooling to help developers build, operationalize deploy their own next-generation AI apps

It starts with our new Azure AI Studio. We’re making it simple to integrate external data sources into Azure OpenAI Service. In addition, we’re excited to introduce Azure Machine Learning prompt flow to make it easier for developers to construct prompts while taking advantage of popular open-source prompt orchestration solutions like Semantic Kernel.

In Azure OpenAI Service, which brings together advanced models including ChatGPT and GPT-4, with the enterprise capabilities of Azure, we’re announcing updates to enable developers to deploy the most cutting-edge AI models using their own data; a Provisioned Throughput SKU that offers dedicated capacity; and plugins that simplify integrating other external data sources into a customer’s use of Azure OpenAI Service. We now have more than 4,500 customers using Azure OpenAI Service.

Building responsibly together

At Microsoft, we’ve been committed to developing AI technology that has a beneficial impact and earns trust, while also sharing our own learnings and building new tools and innovations that help developers and businesses implement responsible AI practices in their own work and organizations. At Build, we’re introducing several new updates, including Azure AI Content Safety, a new Azure AI service to help businesses create safer online environments and communities. As part of Microsoft’s commitment to building responsible AI systems, Azure AI Content Safety will be integrated across Microsoft products, including Azure OpenAI Service and Azure Machine Learning.

We’re also introducing new tools to Azure Machine Learning, including expanding Responsible AI dashboard support for text and image data, in preview, enabling users to evaluate large models built with unstructured data during the model building, training and/or evaluation stage. This helps users identify model errors, fairness issues and model explanations before models are deployed, for more performant and fair computer vision and natural language processing (NLP) models. And prompt flow, in preview soon, provides a streamlined experience for prompting, evaluating and tuning large language models. Users can quickly create prompt workflows that connect to various language models and data sources and assess the quality of their workflows with measurements such as groundedness to choose the best prompt for their use case. Prompt flow also integrates Azure AI Content Safety to help users detect and remove harmful content directly in their flow of work.

In addition, Microsoft announced new media provenance capabilities coming to Microsoft Designer and Bing Image Creator in the coming months that will enable users to verify whether an image or video was generated by AI. The technology uses cryptographic methods to mark and sign AI-generated content with metadata about its origin.

Introducing Microsoft Fabric, a new unified platform for analytics

Today’s world is awash with data, constantly streaming from the devices we use, the applications we build and the interactions we have. And now, as we enter a new era defined by AI, this data is becoming even more important. Powering organization-specific AI experiences requires a constant supply of clean data from a well-managed and highly integrated analytics system. But most organizations’ analytics systems are a labyrinth of specialized and disconnected services.

Microsoft Fabric is a unified platform for analytics that includes data engineering, data integration, data warehousing, data science, real-time analytics, applied observability and business intelligence, all connected to a single data repository called OneLake.

It enables customers of all technical levels to experience capabilities in a single, unified experience. It is infused with Azure OpenAI Service at every layer to help customers unlock the full potential of their data, enabling developers to leverage the power of generative AI to find insights in their data.

With Copilot in Microsoft Fabric in every data experience, customers can use conversational language to create dataflows and data pipelines, generate code and entire functions, build machine learning models or visualize results. Customers can even create their own conversational language experiences that combine Azure OpenAI Service models and their data and publish them as plugins.

Accelerating an AI-powered future through partners

Our customers benefit from our partner collaborations, such as with NVIDIA, that enable organizations to design, develop, deploy and manage applications with the scale and security of Azure. NVIDIA will accelerate enterprise-ready generative AI with NVIDIA AI Enterprise Integration with Azure Machine Learning. Omniverse Cloud, only available on Azure, enables organizations to aggregate data into massive, high-performance models, connect their domain-specific software tools and enable multi-user live collaboration across factory locations. NVIDIA GPUs leveraging ONNX Runtime & Olive toolchain will support the implementation of accelerating AI models without needing a deeper knowledge of the hardware.

New capabilities for Microsoft Dev Box

Microsoft Dev Box, an Azure service that gives developers access to ready-to-code, project-specific dev boxes that are preconfigured and centrally managed, is introducing several new capabilities to enhance the developer experience and boost productivity. While in preview, we’ve seen many customers experimenting with Dev Box, and we’ve migrated more than 9,000 developers internally to the service for day-to-day software development.

Now, we’ve added additional features and capabilities, including customization using configuration-as-code and new starter developer images in Azure Marketplace that provide dev teams with ready-to-use images that can be customized further for specific dev team needs. Additionally, developers can now manage custom environments from a specialized developer portal, Azure Deployment Environments. Dev Box general availability will begin in July.

Unveiling a new home for developers on Windows 11 with Dev Home

Dev Home will launch at Microsoft Build in preview as a new Windows experience developers can get from the Microsoft Store.

Dev Home makes it easy to connect to GitHub and configure cloud development environments like Microsoft Dev Box and GitHub Codespaces. Dev Home is open source and fully extensible, enabling developers to enhance their experience with a customizable dashboard and the tools they need to be successful.

Introducing Windows Copilot for Windows 11

Last fall at our Windows and Surface launch, Chief Product Officer Panos Panay talked about the power of AI to unlock new interaction models on the PC with Windows Studio Effects and DALL-E 2 in Microsoft Designer, and at CES he talked about how AI is going to reinvent the way people get things done on Windows.

This brings us to Windows Copilot.

Windows will be the first PC platform to centralize AI assistance with the introduction of Windows Copilot. Together, with Bing Chat and first- and third-party plugins, users can focus on bringing their ideas to life, completing complex projects and collaborating instead of spending energy finding, launching and working across multiple applications.

This builds on the integration we released into Windows 11 back in February that brought the new AI-powered Bing to the taskbar.

A preview of Windows Copilot will start to become available for Windows 11 in June.

As you can see, it’s going to be a busy time at Microsoft Build. To give you a sense of what developers are going to experience at the event, we’re expecting approximately 200,000 registered attendees, with 350 sessions and more than 125 hours of content over two days. In total, we’ll announce more than 50 new products and features.

For more information, make sure to watch keynotes on demand from Microsoft Chairman and CEO Satya Nadella, Kevin Scott and Scott Guthrie on Day 1. On Day 2, watch the keynotes anchored by Rajesh Jha and Panos Panay. Additionally, you can explore all the news and announcements in the Book of News and read more stories and news about products from Microsoft Build here:

RELATED:

Watch Microsoft Build keynotes and view videos and photos

Microsoft outlines framework for building AI apps and copilots; expands AI plugin ecosystem

Bing at Microsoft Build 2023: Continuing the Transformation of Search

Empowering every developer with plugins for Microsoft 365 Copilot

Bringing the power of AI to Windows 11 – unlocking a new era of productivity for customers and developers with Windows Copilot and Dev Home

Build next-generation, AI-powered applications on Microsoft Azure

Introducing Microsoft Fabric: Data analytics for the era of AI

Tags: AI, Azure AI Content Safety, Azure OpenAI Service, Bing, copilots, developers, Microsoft 365 Copilot, Microsoft Build, plugins, Windows 11"
Microsoft_News,https://news.microsoft.com/en-in/features/with-help-from-next-generation-ai-indian-villagers-gain-easier-access-to-government-services/,,"With help from next-generation AI, Indian villagers gain easier access to government services","Biwan, Haryana, INDIA – In this arid farming village about two hours by car south of New Delhi, there are many needs.

One farmer needed help applying for pensions for his aged parents. Another wanted to know why his government assistance payments mysteriously stopped – and how to restart them. A university student needed a scholarship to fund her studies.

They all turned to Jugalbandi, a new generative AI-driven chatbot on mobile devices for government assistance. It can understand questions in multiple languages, whether spoken or typed. It retrieves information on relevant programs – usually written in English – and relays it back in local language.

In India, the language of government, business and public life is English, but it is spoken by just 11% of the 1.4 billion population. Some government documents are also in Hindi, spoken by 57% of Indians. That leaves vast numbers of the population unable to access government programs because of language barriers.

While the Jugalbandi chatbot is still new, it could one day offer all Indians easy access to information in local language through a mobile phone, instead of having to head to the local community service center and stand in line just to get basic information.

“We saw this Jugalbandi as a kind of ‘chatbot plus plus’ because it’s like a personalized agent,” said Abhigyan Raman, a project officer at AI4Bharat, an open-source language AI center based at the Indian Institute of Technology Madras in Chennai that is a collaborator on the chatbot.

“It understands your exact problem in your language and then tries to deliver the right information reliably and cheaply, even if that exists in some other language in a database somewhere.”

Vandna, a first-year university student, used the Jugalbandi chatbot to find out about scholarships she is eligible for. Photo by Nikhil Mehta for Microsoft.

One of those who tested the chatbot is Vandna, an 18-year-old from Biwan who is a freshman at the Government College in the nearby village of Ferozepur Jhirka.

Vandna’s mother is a community health worker. Her father is ill and unable to work. The teenager is teaching part-time at a local elementary school to help pay for college.

When community volunteers introduced Jugalbandi to people in her village, in early April, she remembers typing her question in Hindi: “What kind of scholarships are available for me?” She added her course of study: Political Science, Hindi and History.

The chatbot replied with a list of central and state government programs. She picked one and asked about eligibility criteria. Jugalbandi provided those and also told her what documents she needed to support the application.

A traditional web search would have given her a long list of links to plow through, she said.

“Jugalbandi gives me one answer at a time,” she said in Hindi. “It’s easier to understand.” She applied for a scholarship in mid-April and is waiting to hear back.

Click here to load media

The name Jugalbandi refers to a duet between two musicians in Indian classical music where they riff off each other to create something new together. The Jugalbandi AI assistant is powered by language models from AI4Bharat, a government-backed initiative, and reasoning models from Microsoft Azure OpenAI Service. It is accessed through the mobile messaging system WhatsApp, which is widely used in India, and the duet in this case is the conversation between the user and the chatbot.

It is part of the fast-growing field of generative AI tools that can synthesize vast troves of data to generate text, images and more. In this case, the AI chatbot has fine-tuned these models using data from Indian government databases that are being uploaded one by one. Using Azure OpenAI Service also helps ensure data security and includes features such as responsible AI protections that allow entities to filter inappropriate content.

Since Jugalbandi was introduced to villagers in Biwan in early April, it has expanded to cover 10 of India’s 22 official languages and 171 of a total of approximately 20,000 government programs, said Smita Gupta, a lawyer who works for OpenNyAI, a collaborative whose mission is to bring greater access to law and justice through AI. It is one of several groups working on the chatbot.

This is just the beginning.

In the future, such chatbots could be used for any interaction between a person and an institution, whether a patient seeking medical information in Urdu or someone retrieving English-language court documents in Tamil. Once connected to computer interfaces in government departments, citizens could theoretically complete an application just by speaking or typing.

India’s complexity makes it a test bed for multilingual settings everywhere.

“If you can solve and build for India,” said Gupta, “you can solve and build for the world.”

Smita Gupta of OpenNyAI talks about uses for the Jugalbandi app with farmers Abdullah Khan and Sapat Khan. Photo by Probohadh Singh for Microsoft.

India has myriad government schemes and welfare programs, each with its own criteria and requirements. Official websites can be hard to navigate – or impossible if you can’t read or write or don’t know English. Getting precise answers early means fewer trips to the government service centers in each village for help and fewer trips home to retrieve missing documents.

India also has a track record of building digital public goods and rolling them out at scale.

More than a decade ago, the government launched Aadhaar, a 12-digit biometric identity system that can be linked to services such as banking, mobile phones and government services. A few years ago, it built a Unified Payments Interface for digital payments, which now sees 8.9 billion transactions a month.

In July 2022, the Indian government launched Bhashini to provide language solutions as digital public goods. The goal is to enable Indians to access the internet and digital services in their own language by drawing on emerging technologies such as AI to develop products and services through an ecosystem of start-ups, industry, academia and government. Research groups like the Indian Institutes of Technology, the International Institute of Information Technology and the Center for Development of Advanced Computing are all experimenting to augment the Bhashini platform.

AI4Bharat is one such research group. It has received funding from Nilekani Philanthropies, started by the co-founder of software giant Infosys Nandan Nilekani and his wife Rohini, as well as from Microsoft.

Pratyush Kumar, co-principal investigator at AI4Bharat and a principal researcher at Microsoft Research India, said the team initially explored how to translate legal judgments, working with the Supreme Court of India. They also worked with schools and colleges to transcribe videos and add subtitles, which can help children learn more effectively.

At the same time, organizations like OpenNyAI were thinking of applications on the ground. “We brainstormed a bit,” said Kumar.

One of the results was Jugalbandi.

Abdullah Khan uses the Jugalbandi chatbot to find information on government aid. Photo by Probohadh Singh for Microsoft.

This is how it works: A villager sends a text or audio message to a WhatsApp number, which initiates the Jugalbandi bot. That is transcribed to text using the AI4Bharat speech recognition model. That in turn is translated to English by the Bhashini translation model trained by AI4Bharat. Based on the prompt, Azure OpenAI Service’s model retrieves information on the relevant government scheme. The answer is translated to Hindi. That is then synthesized with the AI4Bharat text-to-speech model and sent back to WhatsApp – and the villager’s ear.

Building a chatbot used to be a complex task, requiring a flow chart. “Whereas now, with a bit of language tech, the government can just upload documents and it works,” said Kumar. “This democratizes not just who consumes this but also who produces it.”

Jugalbandi uses GPT models via Azure OpenAI Service.

There remain rough edges. “Sometimes these models do make errors. They are probabilistic machines,” Kumar said. “We need people to try them out with different inputs to see different responses. And if there are errors, to flag them. People still play an important role to see what works and what doesn’t work.”

That’s where organizations like Gram Vaani come in. The Delhi-based social enterprise has been working with farmers for years, providing agricultural news and a tech platform for requests for help and grievances, all through basic cellphones.

Its Mobile Vaani interactive voice platform has three million users across northern and central India. Local volunteers work one-on-one with those who need help.

Jugalbandi “can really scale a lot of our work,” said Aaditeshwar Seth, co-founder of Gram Vaani.

Gram Vaani’s community volunteers are evaluating the chatbot for integration with Mobile Vaani. The villagers are also giving feedback on improvements they would like to see.

Abdullah Khan, a 26-year-old farmer in Biwan, has used Jugalbandi to help fellow farmers find out about government financial assistance programs.

He has a suggestion. Besides farming, many people in Biwan drive trucks for a living. There’s no union and no benefits.

“Something that supports drivers will be helpful,” said Khan. He suggested Jugalbandi help figure out requirements for applying for drivers’ licenses, and even facilitate the application itself so drivers don’t have to pay middlemen to do so.

As more people think of more uses for the chatbot, Raman of AI4Bharat predicts adoption will speed up. For example, OpenNyAI is working on how the chatbot can help domestic workers and garbage collectors in Bengaluru understand their legal rights.

“This is revolutionary for people who could not interact with tech because of language barriers,” said Raman.

Top image: Abdullah Khan, left, shows the Jugalbandi chatbot to fellow farmer Sapat Khan, right. Photo by Probohadh Singh for Microsoft."
Microsoft_News,https://news.microsoft.com/apac/features/taiwan-brings-in-generative-ai-to-help-students-learn-english/,,Taiwan brings in generative AI to help students learn English,"New Taipei City, TAIWAN – Teachers often report that students learning English tend to read and write better than they speak, as shyness and a lack of practice can hinder the ability to converse. Now, a chatbot funded by Taiwan’s Ministry of Education and running on next-generation large language models offers a way for K-12 students to get that practice, and in a more engaging way than was previously possible.

The kids in Claire Mei Ling Wu’s English class at Er Chong Junior High School in Sanchong District, New Taipei City, began using the CoolE Bot soon after it was launched in late December.

Wu has been teaching English for over 25 years. Her classroom is decorated with a world map and national flags. There are boxes of knickknacks – gifts from pen pals in Japan, India and as far away as the U.S. state of Alaska.

“Sometimes when they are shy, they don’t dare to speak up,” Wu said. However, if they can remain at their desks and speak “person-to-AI,” Wu said, they are more comfortable than coming to the front of the class or standing in front of the teacher.

With the chatbot, which uses Azure OpenAI Service and other Microsoft AI technologies, students can pick one of many preset conversation topics – asking a doctor or photographer about their work, for example, or role-playing as a detective to solve a mystery – and off they go. While older chatbots could only provide answers that were preloaded into the system, next-gen AI can generate responses on its own.

The chatbot can also assess pronunciation, accuracy and fluency, and students can practice as many times as they like to raise their score.

If they are stumped, they can click on the “AI” button and the chatbot will suggest a question to keep the conversation flowing. A content filter keeps things from veering into inappropriate territory. If a student types or says a swear word, or something sexual, the chatbot answers in red type: “Improper input. Please try again.”

The CoolE Bot can converse with students on a range of set topics. Claire Mei Ling Wu, an English teacher at Er Chong Junior High School, demonstrates how the bot assesses speaking skills such as pronunciation and fluency, and filters inappropriate prompts. Photos by Billy H.C. Kwok for Microsoft.

“It is interesting, and I can learn English from it,” said student Eva Zi Yu Huang, 13, eyes peeking out between long black bangs and a blue surgical mask.

Taiwan has set a goal of becoming bilingual in Chinese and English by 2030 as its economy shifts from traditional manufacturing to more data or cloud driven businesses, where the global language tends to be English. There are regional competitive pressures. For example, Taiwan competes economically with places like Hong Kong and Singapore, former British colonies where English is widely spoken.

“We want to help our students quickly enhance their English skills to compete with other countries,” said Howard Hao Jan Chen, an English professor at National Taiwan Normal University (NTNU).

In Taiwan, English classes are compulsory in public schools for one or two hours a week starting in third grade – with some schools starting as early as first grade, and that expands to up to four hours a week in high school.

That’s not a lot of time to master a language with a whole different script, grammar and pronunciation. Common mistakes in English include dropping articles, which don’t exist in Chinese – omitting “a” or “the” – and mixing up of tenses. Practice helps, but it can be hard to find someone to do that with when you’re surrounded by Chinese speakers.

In 2015, Chen and his team launched a website called Cool English to help Taiwan’s schoolkids learn English using technology. The government-sponsored website now has about 1.5 million registered users from Taiwan and beyond.

“The way that teachers teach is by reading books and listening to various materials through the Internet. But the focus is not on speaking,” said Scott Suen, a software engineer on the Cool English team. “Most Taiwanese students can pass exams and get a very high score, but if we are put in a native English environment, we have a hard time communicating with foreigners.”

To help facilitate more conversation practice, the team built its first chatbot using an older AI-based programming language.

“We quickly found it very problematic,” said Chen. “You have to type in all the possible answers for a question raised by students – thousands of sentences to reply to students intelligently. It’s not AI. It’s really labor.”

Worse, he added: “We don’t know what kinds of questions students want to ask! Students won’t want to play with this kind of silly tool.”

The project went dormant for a while. In 2022, the team heard about next-generation large language models. “We saw, wow, this is really something!” Chen said. “It was very robust. The answers are much more meaningful.”

Click here to load media

The CoolE Bot, introduced in December, sits on the Cool English website. It uses advanced language models as part of Microsoft’s Azure OpenAI Service to engage students in conversation about a set of scenarios. The language is adjustable for different ages and proficiency levels.

The CoolE Bot uses Microsoft Azure Cognitive Service Speech capabilities including text-to-speech and speech-to-text. Students can pick multiple voices with American or British accents. And Azure provides the data security that’s particularly important when technology is used in this setting.

“It’s a closed loop Azure subscription,” said Sean Pien, general manager of Microsoft Taiwan. “All conversation, finetuning and materials are within this secure domain.”

So far, about 30,000 students a month are currently using the chatbot, racking up a total of one million conversations a month.

The team is now working on improvements, including adding avatars and new scenarios for conversations. In the future, as more advanced models are available, the tool will also be able to correct errors, Chen said.

Recently, Wu’s class used the chatbot to prepare for a video call with counterparts in Bahrain, where the goal was to practice English and learn about each other.

Seventh-grade English students in Taiwan interact with counterparts in Bahrain during a call to practice English and share information about their respective cultures. Photo by Billy H.C. Kwok for Microsoft.

During the call, the Taiwanese kids tackled some big words with ease.

“The National Palace Museum has about 700,000 pieces of Chinese imperial artworks, making it one of the largest collections in the world,” said Eva, the seventh grader, in front of her class as well as the Bahrain students onscreen.

“The Longshan Temple in Taipei is a religious, political and military center in Taipei City and has become an attraction for foreign tourists in the post-war period,” a boy with spectacles named Frank Pan said.

When one student stumbled over the word “reservoir,” a chorus of voices helped her out.

After the kids played an online quiz together, the Taiwanese students were excited to ask questions they had written down for the Bahrain students.

“Are there any deserts in your country?”

“Is your school a boys’ school?”

“What kind of transportation do you have in your country?”

“Have you drunk bubble tea?”

And more.

Top image: Eva Zi Yu Huang, 13, and fellow English students in Taiwan compete in an online quiz with counterparts in Bahrain. Photo by Billy H.C. Kwok for Microsoft."
Microsoft_News,https://news.microsoft.com/source/features/ai/microsoft-outlines-framework-for-building-ai-apps-and-copilots-expands-ai-plugin-ecosystem/,,Microsoft outlines framework for building AI apps and copilots; expands AI plugin ecosystem,"Remember when software wasn’t connected to the internet? Didn’t think so. In a handful of years, this will also be true for software that doesn’t come with an intelligent copilot assistant, according to Kevin Scott, Microsoft’s chief technology officer.

A copilot is an application that uses modern AI and large language models to assist you with a complex cognitive task – from writing a sales pitch or catching up on a missed meeting to generating images for a presentation or planning a themed dinner party.

Microsoft introduced the concept of a copilot nearly two years ago with GitHub Copilot, an AI pair programmer that assists developers with writing code. This year, Microsoft rolled out copilot experiences across its core products and services, from the AI-powered chat in Bing that’s changing how people search the internet to Microsoft 365 Copilot, GitHub Copilot X, Dynamics 365 Copilot, Copilot in Microsoft Viva and Microsoft Security Copilot.

Today at the annual Microsoft Build developers conference, Microsoft announced that it has expanded this ecosystem of Microsoft Copilots to include Copilot in Power BI and Copilot in Power Pages in preview, Copilot in Microsoft Fabric, available in preview soon, and Windows Copilot, which will start to become available for preview in June. The company also introduced new features that will help developers build their own copilots and next-generation AI applications. This includes new tools called plugins that make copilots more useful by allowing them to interact with other software and services.

“You may look at Bing Chat and think this is some super magical complicated thing, but Microsoft is giving developers everything they need to get started to go build a copilot of their own,” Scott said. “I think over the coming years, this will become an expectation for how all software works.”

Expanding the plugin ecosystem

OpenAI introduced ChatGPT plugins in March. Microsoft announced plugins for Bing earlier this month. That technology allows ChatGPT and Bing Chat to help you find and book a restaurant reservation using an OpenTable plugin, for example.

Today, Microsoft is adopting the same open plugin standard that OpenAI introduced for ChatGPT, enabling interoperability across ChatGPT and the breadth of Microsoft’s copilot offerings. That means developers can now use one platform to build plugins that work across both business and consumer surfaces, including ChatGPT, Bing, Dynamics 365 Copilot, Microsoft 365 Copilot and Windows Copilot. Microsoft also announced it is bringing Bing to ChatGPT as the default search experience.

As part of this shared plugin platform, Bing is adding to its support for plugins. In addition to the ones previously announced for OpenTable and Wolfram Alpha, it will also have Expedia, Instacart, Kayak, Klarna, Redfin, TripAdvisor and Zillow among many others in the Bing ecosystem.

In addition, developers will now be able to extend Microsoft 365 Copilot with plugins. Plugins for Microsoft 365 include ChatGPT and Bing plugins, as well as Teams message extensions and Power Platform connectors – enabling developers to leverage their existing investments. And developers will be able to easily build new plugins with the Microsoft Teams Toolkit for Visual Studio Code and Visual Studio.

How plugins work

At Microsoft Build, the company showcased an AI development framework that helps developers build their own copilot. This stack includes support for plugins that augment the capabilities of AI systems by allowing them to retrieve real-time information, incorporate company or other business data, perform new types of computations and safely take action on the user’s behalf.

At root, think of plugins as a bridge. This could be a bridge between a large language model that was trained on public data from the internet and all the data that a company may keep privately about its benefits. The plugin is the bridge that gives the copilot access to those files when it answers a question from an employee at the company.

Similarly, a plugin could serve as a bridge between a large language model and a website or back-end system that a company uses to book business travel, enabling the copilot to make arrangements for a salesperson’s trip to San Francisco that are in line with the company’s travel policy.

Plugins make copilots more useful by allowing them to interact with other software and services. Graphic courtesy of Microsoft.

“A plugin is about how you, the copilot developer, give your copilot or an AI system the ability to have capabilities that it’s not manifesting right now and to connect it to data and connect it to systems that you’re building,” Scott said. “I think there’s going to eventually be an incredibly rich ecosystem of plugins.”

Expanding the plugin ecosystem

Developers will also be able to create, test and deploy their own plugins in a number of ways – to eventually deploy for use with Microsoft Copilots and to augment the capabilities of their own applications built with generative AI technology.

For example, a developer at a large corporation may want the Microsoft 365 Copilot to be able to access the company’s contracts with customers and vendors in order to ask questions about how certain legal issues were handled in the past. To do that, the developer needs to connect the Microsoft 365 Copilot with the private database of legal files, which requires the documents to be encoded, indexed and stored in such a way that they can be searched.

“That’s a pattern of how you would load information into the model,” said John Montgomery, Microsoft corporate vice president of program management for the AI platform. “And that’s where plugins come in. What a plugin does is it says ‘Hey, we want to make that pattern reusable and set some boundaries about how it gets used.’”

Microsoft is releasing a set of capabilities to facilitate the creation of plugins that work across its copilot surfaces. Visual Studio Code, GitHub Copilot and GitHub Codespaces will make it simple for developers to create, debug and deploy new plugins, for example, and Azure AI will add capabilities to run and test plugins on private enterprise data. Once created, these plugins will work across Microsoft’s Copilot experiences."
Microsoft_News,https://blogs.bing.com/search/may_2023/Continuing-to-deliver-new-AI-innovation-in-Bing-and-Edge-this-week,,Continuing to deliver new AI innovation in Bing and Edge this week,"New features rolling out this week



Bing app updates

SwiftKey app updates

Edge app updates

Skype app updates

It’s only been 100 days since Microsoft introduced the world to a new era of search powered by AI. In that time, we’ve continuously shipped new features that add real value based on our preview testers’ feedback. Our goal and focus remain the same – to provide the innovations that transform search for everyone, whether you’re an existing fan or trying Bing for the first time.Today, we’re taking the next steps in this journey with new mobile-first experiences that match our desktop capabilities and bring visual updates across Bing.New features announced in early May are beginning to flight. This week, the Bing experience on both desktop and mobile will get much richer with videos, Knowledge Cards, graphs, better formatting, and social sharing capabilities all coming to chat.Also, chat history is rolling out across desktop and mobile. With chat history now on mobile, you can simply hit the clock-inspired icon at the top of your existing chat to see a list of recent activity. This feature will also be available on desktop soon.There’s never been more excitement for Bing mobile; we’re seeing an 8x increase in daily downloads since launching the new Bing as people worldwide incorporate their AI copilot on the go. To make those mobile experiences even richer, we’re introducing new features coming soon to the Bing, SwiftKey, Edge, and Skype apps.– Widgets are a great way to get timely information at a glance, or directly access features in your favorite apps. This week, we’re launching a new Bing Chat widget that you can add to your iOS or Android home screen (quick setup instructions here and here ). Soon, you’ll be able to click the Bing icon to land directly in the new Bing Chat experience, or click the microphone icon to verbally ask a question.– Another common request is to enable continuous conversations across platforms, and we’re excited to announce that it’s available today. The ability to continue desktop conversations on mobile, and vice versa, means you can ask Bing to write you a recipe for a spring salad recipe, then continue the conversation at the grocery store when they’re out of asparagus and you need a substitute, then learn more about fava bean preparation back at home.This feature is flighting and will be available to everyone on iOS and Android within the next week. To access this feature, click on the answer on desktop, then select phone icon in the options menu to view the QR Code. Scan it to open on your phone.– We’re excited to bring the new Bing to new users around the world. We’ve increased the country and language support for voice input, and improved the quality for non-English chats, so now you can choose from a variety of languages and voices to tailor experience to your tastes and needs.– SwiftKey is your go-to keyboard that puts AI-powered Bing at your fingertips; you can use it to search and chat with Bing from within your favorite mobile apps, as well as change the tone or reframe your messages before you hit send.Today we’re excited to extend these capabilities to include the Compose feature in SwiftKey, which will now draft text for you according to the parameters you suggest – not just the subject matter but also the message tone, format, and length. If you dread paperwork and administrative tasks, let the Compose feature do the heavy lifting for you. You can use it to, for example, write an email to a service provider asking for a resolution on an issue. Quickly edit the drafted email to ensure details are correct, and then send it and continue with your day.This feature will begin rolling out today; use it by clicking the Bing icon in the ribbon above the SwiftKey keyboard. It will be available to all users across iOS and Android within the next two weeks. This functionality is also available on desktop via the Edge sidebar – We’re also excited to announce that our AI-powered translator is now built right into the SwiftKey keyboard, making staying in touch with friends and family worldwide even easier. Like Compose, all you need to do is click the Bing icon in the ribbon above the SwiftKey keyboard. From there, click Translate, and you can choose the languages to translate to and from. It includes translation in any language Bing supports. Type or paste the text, and it will drop the translated text right into the message field for you to send. It’s already available on Android and will be available to all users, including iOS, worldwide within the next week.– The recently-launched SwiftKey Tone feature has now added two new Tones – Witty and Funny! Together these AI-powered features let you draft the right message, with the appropriate tone, for everything from tweaking a funny one-liner to drafting an important work email from scratch.On Edge mobile, you will soon be able to ask questions in Bing Chat related to content on the mobile page you are viewing, or ask Bing to summarize it. Say you are looking through recipes for your next dinner gathering. With Bing Chat in the Edge mobile app, you can simply tap on the Chat icon on the bottom navigation bar and ask what wine would pair best with the recipe you’re viewing. You can also ask follow-up questions until you have exactly what you need. With this feature, while reading an article or document online, you can also tap the Bing Chat icon and ask Chat to summarize the content for you – so you can get info quicker while you’re on the go!– Bing will soon be able to quickly provide deep context for any text in the Edge mobile app. For example, you may be reading the news and are unsure about a specific historical event being referenced. Simply highlight the text in question and select Bing from the options menu. This will open a conversation with Bing, which you can use to explain more about the topic with cited sources and clearly summarized text.Both of these new experiences will become available to all users worldwide soon.– Now every group chat in Skype can include the new AI-powered Bing. For example, if you have a long existing conversation with friends brainstorming places of interest, you could ask Bing to list all the options discussed and generate new similar ideas. All you have you do is tag @Bing directly – no need for participants to search for Bing to add it to their contacts. This feature is rolling out to users currently and will be available to everyone within a few days.This is just the start of the next 100 days of AI-powered Bing. The next stop is Build , where we will share more about how developers can take advantage of the Bing AI platform to broaden their reach and bring new benefit to everyone across PC and mobile.- Divya Kumar, Global Head of Marketing | Search & AI"
Microsoft_News,https://www.microsoft.com/en-us/worklab/experimenting-with-ai-as-a-creative-collaborator,,Experimenting with AI as a Creative Collaborator,"Sign up for the WorkLab newsletter to get the latest AI research, insights, and trends delivered straight to your inbox.

The 2023 Microsoft Work Trend Index report, “ Will AI Fix Work? ,” landed just weeks after the launch of Bing Image Creator , a new design tool powered by an advanced version of DALL-E. When it came to creating art for the report, the team saw a unique opportunity to explore how a human artist would incorporate it into their process. Would it help generate ideas? What prompts would be most effective? And how would using AI as a co-collaborator impact the final product?



The artist for the job: Los Angeles-based Jon Han . Han specializes in creating exciting futuristic worlds without the usual dystopian tropes. Because the report data showed that most people are eager for AI to help ease the weight of work, his style felt like exactly the right approach to bring the findings of the WTI report to life.

Jon started by feeding prompts into Bing Image Creator, testing how he could collaborate with it. Using AI inspired a more iterative approach than what’s typical, because playing around with it was quick and easy. “The process for this project was an experimental one,” he says. “Just trying to see what it’s capable of.”

Here, Han takes us inside that process.

Prompt 1: Person looking on a bridge of panels showing different landscapes

Jon Han: In my usual process, I read a creative brief, think about the concept and visualize it in my head. So in the early stage here, I wanted to see how the tool works with concepting ideas, and contrast that with my usual process. I wanted to see how the image creator would visualize what I’m thinking.

You can see that the tool is using lots of photo-reference images, but generally my work is not as stiff—it’s more abstract. So I started trying to push it to go to the specifics that I was looking for visually.

Prompt 2: Person in the foreground + in front are geometric panels that are materializing digitally

Jon Han: Here I shifted away from bridges and tried to push for a more abstract image and a digital effect. I liked the shapes of the panels and the digital feel. But it looked too much like a sci-fi movie. I needed a happier mood.

Prompt 3 Person in the foreground + in front are geometric panels that are materializing digitally + panels come together to create a lush landscape

Jon Han: This time, I added in ‘lush landscape,’ which made the image more atmospheric, not so dark and digital. But the temperature of the picture was a little too cool. I put in the word “warm,” and it came out like everything was on fire. Much like any other tool, like Photoshop or oil painting software, there’s tricks to some of this stuff, where certain prompts create certain types of images. So there’s a learning curve to figuring out how to do these minor adjustments to get the specifics you want.

Prompt 4: Person in the foreground + in front are geometric panels that are materializing digitally + panels come together to create a lush landscape + in the style of jon han

Jon Han: This time I added my name to the prompt to see if it would be able to reference my particular style based on my published illustrations. Adding my name made the person smaller and got the right point of view, seeing the person from the back. I do a lot of compositions where I do a small figure in a landscape. But it didn’t feel hyper-referenced to my work, so that was good.

There are a lot of mixed feelings among artists on AI-generated images, concerns whether these systems could be referencing artists’ work without copyright. I tried to steer away from anything that looks like an artist I know. But one thing about this tool, compared to other AI tools I’ve tried, is that it didn’t seem like it was referencing someone’s work. This was a good endpoint for the concepting stage.

Concept sketch created by Jon Han

Jon Han: After those rounds of experimentation I had a clear image in my head of what I wanted, so I created this concept sketch by hand. The complete picture I wanted to create was too complex to communicate to the image creator. So rather than bring AI-generated images directly into this sketch, I decided to use the tool [or the AI] in later stages to generate options for particular elements of the illustration, like trees or sky.

Normally, you might do an internet search for photos of things like that, for reference. An art teacher once taught me: never use the first few images from an internet search as your reference, because everyone’s going to use those. So with the image creator, it’s nice that these are going to be generated a different way.

Final illustration created by Jon Han

Jon Han: Before creating the full-color illustration, I used the image creator to test different sky colors. I also tried pixelated trees and wireframe trees, looking for something interesting that doesn’t have too much of an AI feel to it. This was all experimentation, finding limitations, and experiments with control.

Han says that for a lot of people, AI image creators are “kind of like a surprise box.” In his experience, they’re most useful when you don’t know exactly what you want. In a case where a creator already has the image they want in their head, an image generator can be good for iterating specific elements.



We are only just beginning to see how next-generation AI can fit into the creative process, and it will certainly look different for every artist and creator. From the prompts people use to guide the tools to the degree that AI does—or does not—influence the final product, everything is up for exploration."
Microsoft_News,https://www.linkedin.com/pulse/announcing-new-ai-capabilities-microsoft-cloud,,Announcing new AI capabilities in Microsoft Cloud for Nonprofit,"By Justin Spelhaug Vice President, Tech for Social Impact, Microsoft Philanthropies

Today we’re excited to announce powerful new AI tools and capabilities in Microsoft Cloud for Nonprofit that will help nonprofit organizations accelerate their missions. While AI could be used across many parts of a nonprofit organization, putting AI to work to amplify fundraising and marketing efforts allows nonprofit professionals to spend more time working with the communities they serve. It’s a practical place to start our AI journey together and solves issues common to almost every nonprofit on the planet.

The confluence of widespread economic uncertainty and rapid technological change has made this a particularly challenging moment for nonprofits. With inflation running at about twice the rate of income growth for nonprofits and the threat of recession looming, nonprofits are scrambling to sustain their level of impact with shrinking budgets. Meanwhile, even as technology enters a brand-new era of AI-driven change, many nonprofits struggle with outdated technology that impacts their ability to engage with donors and volunteers and deliver effective programs and services to constituents.

Here at Microsoft’s Tech for Social Impact, part of Microsoft Philanthropies, we believe AI offers profound opportunities as a resource for nonprofits in their quest to serve communities. Our commitment is to work closely with nonprofits and their partners to develop AI capabilities that help nonprofits address the biggest challenges they face while building their capacity for greater success in the future. AI is a mission accelerator, a time-saver, and a powerful assistant for many critical roles.

Microsoft tools for AI-fueled fundraising and marketing

According to the National Council of Nonprofits, one-third of nonprofits in the United States report job vacancy rates of 20 percent or higher, and this is at a time when the number of donors is decreasing. As a result, nonprofits are focusing more on increasing donation size and emphasizing recurring gifts while also looking outside their traditional donor pools to reach new audiences and new generations of donors. That’s why we have created new capabilities in Microsoft Cloud for Nonprofit that can help nonprofits improve their fundraising and marketing while also helping reduce costs and increase operational effectiveness. Specifically, these capabilities will help with:

Optimizing fundraising: Nonprofit leaders and their Boards need to understand the status of fundraising activities and goals so they can quickly respond to a changing environment for charitable giving. We’re introducing a new Fundraising performance dashboard that offers up-to-date interactive views of campaign performance, donor conversion, and other fundraising analytics using real time data, all built on Power BI’s industry-leading data visualization platform. Donor-centric marketing: With Dynamics 365 Marketing, nonprofit marketers will be able to use plain language queries to segment donors, volunteers, and other constituents, and identify how donors prefer to be contacted and when they prefer to contribute. Dynamics 365 Marketing streamlines the generation of donor and volunteer acknowledgements, newsletters, program information, and other communications. And because it takes advantage of the Nonprofit Common Data Model, it includes integration of data to help drive more personalized engagement is seamless and easy. Improving engagement: By bringing Viva Sales AI Copilot capabilities into Microsoft Cloud for Nonprofit’s Fundraising and Engagement, nonprofits will get AI-based tools that help automate communications and generate personalized, highly relevant communications, reminders, and recommendations that that will enable nonprofits to stay connected and deepen engagement with donors. We’ve also integrated AI-based capabilities of Teams Premium into Fundraising and Engagement that will help nonprofits improve productivity and make sure donors, constituents, and staff get notes, next steps, and email follow ups after their meetings. Understanding the likelihood to donate: We’re also announcing a new AI-powered donor propensity model inside Fundraising and Engagement that will help organizations leverage their data to understand who is most likely to donate. Over the next few months, we’ll work with a select group of nonprofits to develop and refine the model, with plans to make it available in the second half of calendar year 2023. You can find out more about the private preview at our June 22nd webinar - register here.

With the new capabilities we are announcing today, we hope to help nonprofits of every size and in every part of the world achieve remarkable results like these. By taking advantage of easy-to-use AI-powered solutions, nonprofits can better understand supporters, increase donor loyalty and lifetime giving, and tailor fundraising to individual donor preferences, all while safeguarding the integrity of sensitive data.

While we’re just beginning to understand how AI can help nonprofits drive change in the world, we’re already seeing impressive examples of its benefits. For example, The Contingent, an organization entrusted with foster family recruitment for the entire state of Oregon, saw adoption inquiries rise double digits after investing in Microsoft’s Cloud for Nonprofit. And now they have expanded their Every Child Initiative to Arkansas and Indiana, which aims to increase the recruitment and retention of families willing to open their homes to children in crisis.

The power of partnership

Working closely with partners is foundational to how Microsoft delivers technology and ensures it’s tailored to the requirements of different industries and business sectors. This is no different with the nonprofit sector, which is why we’re working directly with many partners to create technology solutions to help nonprofits achieve their missions more effectively and efficiently.

To ensure smooth and efficient payment and donations, we are delivering integrations with Microsoft partners Soapbox Engage, Fundraise Up, and Classy to enable seamless reconciliation and reporting through end-to-end donation, revenue, and transaction management. We are also working with Blackbaud to jointly deliver integration with Blackbaud’s Online Giving solution to include a payments offering augmenting Microsoft’s Fundraising and Engagement tools. Finally, we’re partnering with Submittable to align its grantmaking and Corporate Social Responsibility solutions into our nonprofit solutions to complete the end-to-end journey from funding to reporting.

And we are building an AI-powered Humanitarian Data Insights Tool to help humanitarian organizations better plan and resource their aid operations in collaboration with DataKind. A number of humanitarian organizations, most notably Save the Children, will contribute insights and provide valuable feedback to help ensure the tool is created in a context-appropriate and sustainable way. This tool utilizes large language models to help organizations get insights, trends, and understanding out of their data so they can more efficiently and effectively respond to needs around the world. An early version of this and other open-source, AI-powered solutions for humanitarian aid organizations will be available later in 2023, with the final version available in 2024.

Too, to further help nonprofits build a safer and more resilient world, we have created a toolkit of ready-made solutions for disaster preparedness and response, including AI tools to assess damage, Teams to coordinate emergency operations, and volunteer management to organize emergency workers.

In an effort to reduce time to deployment and enhance nonprofit systems of management, we have an extensive list of implementation, data migration, and additional payment partners at the ready to help nonprofits, including Ambit Group. Barhead, Brennan IT, Heller, Kerv, m-Hance, MISSION CRM, PICnet, Prolan Solutions & Akquinet, RSM, Synalis, threshold.world, Valorem, and Wipfli, and many more.

Finally, we are launching new AI and cloud open-source tools and resources in the Innovation Hub GitHub repository, designed to facilitate the rapid development of frameworks for specific nonprofit challenges. These include the Nonprofit Virtual Assistant for Teams, engineered by Valorem Reply, which uses natural language prompts to assist nonprofit fundraisers in generating four essential templates. Additionally, the Donor Engagement Assistant, contributed by RSM, uses AI to create communications that reflect donor information, history, and program fundraising goals. And the Fundraising Proposal Assistant from threshold.world helps fundraisers draft personalized fundraising proposals with OpenAI in the Microsoft Cloud for Nonprofit, enabling them to reach more prospective donors.

What’s next

Each and every one of the AI-based solutions outlined in this post conforms to Microsoft’s Principles for Responsible AI. Just as important as going fast is going carefully. We commit to living the principles of transparency, fairness, privacy, and security.

The world is changing quickly, which is why we’re moving fast to help nonprofits change along with it, using new capabilities and tools to help them solve vast global problems or uniquely local ones. This is just the start."
Microsoft_News,https://news.microsoft.com/source/features/ai/students-turn-to-ai-for-ideas-to-improve-lives-at-this-years-imagine-cup/,,Students turn to AI for ideas to improve lives at this year’s Imagine Cup,"Lakshmi Narke is motivated by the disease that killed her friend and claims the lives of 1.5 million people every year. Syntiche Musawu wants to help people like her brother, who struggles with isolation due to a condition that disrupts how his brain understands what he’s hearing. Tyler Kim knows the challenge of learning a new language and wants to make education more accessible.

All three students are among the thousands of participants in this year’s Imagine Cup, Microsoft’s global competition for students to dream and build new ways of using technology to improve lives. In its 21-year history, the annual event has drawn more than 2 million students from 160 countries to compete for prizes including cash, mentorship and training.

This year, much of the innovation energy revolves around AI, with the vast majority of students using it to spark ideas, from training AI models to detect diseases to using cognitive APIs to help people with disabilities.

“Students want to make the world better by addressing and eventually solving serious problems, and the availability of AI is empowering them to do it,” says Charlotte Yarkoni, Microsoft president of Commerce and Ecosystems, which includes student developer programs.

“The increase in AI-powered projects in Imagine Cup this year shows us the potential of AI — the students you see working with AI now could soon create the next innovation we can’t live without.”

Here’s a look at some of the teams using AI, including the top three teams — TAWI, Eupnea and CS-M Tool — who made it to the 2023 Imagine Cup World Championship. That event was held at Microsoft Build 2023 with TAWI named as the winner.

TAWI

Growing up in Congo, Musawu watched her younger brother struggle with an auditory processing disorder that affected his ability to comprehend speech, leading to difficulties in school and social isolation.

“My brother doesn’t feel confident to communicate if there is background noise, but I think we can help,” says Musawu, a computer science student at the United States International University-Africa in Kenya.

She and her team are now building an app called TAWI to help people with the disorder communicate more easily. It leverages speech recognition tools from Azure Cognitive Services and OpenAI Whisper to enhance speech, reduce background noise and transcribe speech to text in real time.

TAWI team members (left to right) Syntiche Musawu, Zakariya Hussein Hassan, Muna Numan Said and John Onsongo Mabeya (photo courtesy of TAWI)

Users can connect the app to regular earphones, making the solution more affordable, accessible and discreet than traditional hearing aids. They can also read transcribed speech on their phone.

Focused on inclusivity, the team is working with AI models to process different languages, accents and background noise, from crosstalk and air conditioners to wind, rain and rural animals.

“We want to serve people in all kinds of environments and conditions,” whether they’re at school, in an office or living on a farm, says team member Zakariya Hussein Hassan.

Eupnea

Most tuberculosis (TB) deaths occur in countries with less accessible health care, causing delayed testing and treatment. A common skin test is particularly challenging as it involves two visits for an injection and a review a few days later.

Lakshmi Narke and her team hope their app, Eupnea, will encourage people to see a doctor earlier by quickly assessing a user’s risk for TB.

Eupnea team members (left to right) Chidroop Iyyhappan, Lakshmi Narke and Aditya Sreerama (photo courtesy of Eupnea)

Users can photograph their injection site with a coin on their arm and Eupnea, powered by Azure Cognitive Services’ vision tools, calculates risk by measuring the size of the skin’s reaction with the coin as a reference, the students say. Another AI algorithm is designed to analyze a few seconds of coughing.

“AI can reduce the cost of making multiple trips to the doctor, who can review the results and save a life and limit exposure to other people,” says Chidroop Iyyhappan, a computer science graduate student at University of California, Irvine.

The team also wants to help people complete the long treatment required for TB through a gamified system and a community that pairs people for emotional support with Azure Machine Learning.

The students grew up in India, which has the world’s highest burden of TB and is where Narke’s friend passed away.

“We have lost friends and family to this disease and witnessed its impact on communities,” says Narke, also a computer science graduate student at UC Irvine. “With AI, we are trying to save lives one breath at a time.”

CS-M Tool

Cardiovascular diseases are the leading cause of death globally, but most are considered preventable, a challenge in low- and middle-income countries where health care and early detection are less accessible.

A team of high school students in Thailand is building a screening tool they say can help people check themselves for potential signs of heart disease. With a modified stethoscope connected to a phone, the CS-M Tool (short for Cardiac Self-Monitoring Tool) will be able to analyze a user’s heartbeat to provide risk levels for cardiovascular diseases, the team says. The students also plan to incorporate conversational AI to answer basic health questions."
Microsoft_News,https://news.microsoft.com/apac/features/not-if-but-when-why-japans-panasonic-connect-is-going-all-in-on-ai/,,Not if but when: Why Japan’s Panasonic Connect is going all in on AI,"In mid-February, as most of the world was just starting to understand the potential power of generative AI models, Panasonic Connect, a part of Japanese electronics giant Panasonic Group, rolled out its own version of an AI assistant to all 12,500 employees in Japan, from its CEO to the most junior staff.

Panasonic Connect, that focuses on business-to-business solutions, called the AI assistant ConnectAI and encouraged its use for everyday tasks, from drafting emails to gathering information to writing computer code.

The idea was for ConnectAI to help with the labor and legwork that can eat up an office worker’s day, to free them to come up with ideas and solutions. ConnectAI was built with Microsoft Azure OpenAI Service.

“We believe all business professionals will use AI on a daily basis,” said Hiroki Mukaino, senior manager of IT and digital strategy at Panasonic Connect, headquartered in Tokyo. “Our choice was not whether to use AI or not, but when to start using it.”

Generative AI tools, which are built on large language models (LLMs) that synthesize vast troves of data to generate text, images and more, are seen as the biggest technological leap since the advent of the internet and smart phones. Because the technology is so new and powerful and, as with any new technology, can deliver imperfect results, many companies have been unsure how to adopt it.

Japan has the oldest population in the world, with almost a third of its population of 125 million over the age of 65. The National Institute of Population and Social Security Research estimated in 2019 that Japan’s population will shrink to 106 million in 30 years. Unemployment today is a mere 2.6 percent.

Seen against this labor demographic decline, generative AI is one way of “increasing employee productivity,” said Mukaino. “AI allows us to focus on creative tasks that only humans can do.”

Panasonic Connect opted to create its own version of its AI assistant, built with Azure OpenAI Service, instead of a free offering, to help ensure data security. Azure OpenAI Service, which allows developers to use generative AI models for enterprise applications, also includes other features such as responsible AI protections that allow companies to filter inappropriate content. Panasonic Connect also noted that a bespoke AI assistant also allows the company to track and analyze use, and plan upgrades, such as creating more personalized experiences.

ConnectAI was rolled out on February 17, 2023, and the number of queries has grown rapidly. In the first month, employees posted 55,380 questions, or just under 2,000 a day. Today, ConnectAI gets 5,000 questions per day, said Mukaino.

Click here to load media

The AI assistant is accessed through a URL and employees simply type out a question in natural language. They were given minimal training and advised that they should write queries in the form of full questions, rather than the search terms most people are used to. Employees were also given sample questions for reference.

“Our assumption was it would be used mainly by the IT department and tech staff, but the reality is adoption is across legal and accounting also,” said Mukaino.

Users come from across generations, with everyone from early career to senior employees using it, Mukaino said.

Panasonic Connect’s CEO Yasuyuki Higuchi even used it to draft a speech to welcome new employees.

In the future, “humans will concentrate on highly advanced work, rather than fairly simple work,” said Higuchi. “I think this is necessary.”

Panasonic Connect’s CEO Yasuyuki Higuchi used ConnectAI to draft a welcome speech for new employees. Photo by Kosuke Koyama for Microsoft.

It is early days and any impact on productivity is so far anecdotal. An employee in the legal division, for example, told Mukaino she no longer needs to spend an hour reading a long legal document. She now spends less than 10 minutes reading a summary generated by ConnectAI.

Yusuke Takiguchi, a manager in the IT and digital department, said he regularly sends out employee IT surveys, which include multiple choice as well as free text. His team of three used to spend a week or more analyzing the free text results to understand what IT issues people were having. ConnectAI can give them that analysis in an hour.

Takiguchi noted that despite the huge number of daily queries logged, the IT team received zero calls for help on how to use the AI assistant. Employees were experimenting on their own and, in some cases, organizing ConnectAI brainstorming sessions within departments. “My conclusion is that it is very easy to use without any IT capability,” Takiguchi said.

Mukaino said he’s pleased with how many employees are using the technology, and his biggest concern has been to ensure that there is always an employee involved in creating the final output. Because AI systems are new and mostly built on past data, he said, answers should be vetted to ensure they are accurate and there should always be what’s known in the industry as a “human in the loop.”

“It is just a kind of advice. The final output has to be made by a human,” he said.

The tech department is now exploring the next iteration, including how to create a more personalized experience for customers and employees. For example, a customer service representative may soon be able to use ConnectAI to answer questions on product specifications when a customer asks. The team is also considering how ConnectAI can be used as a teaching tool to train employees on new skills.

“We are now talking to Microsoft specialists on how to embed our internal system to this system,” said Mukaino. “New AI tech is coming to us every day. I hope that in 2023, we will implement internal info capability and also new info capability.”

Top image: Hiroki Mukaino, senior manager of IT and digital strategy at Panasonic Connect. Photo by Kosuke Koyama for Microsoft."
Microsoft_News,https://news.microsoft.com/en-in/features/generative-ai-can-make-travel-services-more-accessible-to-millions-of-indians-sanjay-mohan-group-cto-makemytrip/,,"Generative AI can make travel services more accessible to millions of Indians: Sanjay Mohan, Group CTO, MakeMyTrip","MakeMyTrip is India’s leading online travel company that also owns the Goibibo and Redbus travel apps. To date, more than 62 million people have planned and booked their travel from these apps. Three out of 10 domestic travelers book their flight tickets via MakeMyTrip’s group of apps.

Earlier today, MakeMyTrip announced its collaboration with Microsoft for introducing voice-assisted booking in Indian languages on its platform powered by Azure OpenAI Service. The company says generative AI will make their platform more inclusive and accessible to more customers across the country.

Microsoft Stories India caught up with Sanjay Mohan, MakeMyTrip’s CTO, to find out how generative AI has the potential to transform how people plan their travel and enable MakeMyTrip to serve its customers better.

Edited excerpts from the interview follow:

How do you envision generative AI transforming the travel industry?

Let’s backtrack a little bit and understand what generative AI is good at, especially with large language models. The first opportunity is summarizing content from a large database. The entire travel industry sits on a huge corpus of travel data, and it becomes a daunting task of making sense of it.

The second is conversational capabilities. Holiday planning, for instance, is a nuanced purchase where several things must come together to compose a package and every customer has their own preferences. By making the flow conversational with generative AI, we can elicit the right responses from customers and better understand their preferences. Customers too will have a better experience if they are able to use conversation as the medium of engagement on the platform.

The third one, which I find is the most interesting, is adding voice to this entire flow, especially Indian languages. It can make travel services more accessible. It will open the industry to new audiences – the next 100-200 million users in India – who are not very comfortable with English but are fluent in their language, and who are more comfortable interacting with voice than navigating a complex app on their phone. It will also improve accessibility for users with disabilities who are unable to use an app effectively.

Can you provide specific examples of how generative AI will enhance customer experience on MakeMyTrip’s platform?

At MakeMyTrip, we have a huge corpus of user-generated content, like hotel reviews for every category of traveler. Everyone has a different context for travel, and they are all looking for something specific in a hotel. A family with kids might look for a hotel with a swimming pool and play area with activities for kids, a couple on their honeymoon might look for an infinity pool or a solo traveler might be looking for adventurous things to do. Generative AI can help us provide contextual summarization of user-generated reviews. We’re experimenting with providing summaries of reviews from other customers who have stayed at those hotels that are relevant to a user’s context to help them with their purchase decision.

We’re building conversational capabilities to put people at ease before they make a holiday purchase. It’s very inclusive for people who are nervous about interacting on an app and they can get a lot of their questions answered while providing us with context, such as the kind of hotels they are looking for, the activities they’d like to do, the kind of meals they want to have and so on. Once all these considerations are sorted out via the conversation, we can suggest a few holiday packages that best suit the needs of this particular customer.

Finally, we’re experimenting with voice too, starting with booking flights and holidays in English and Hindi with other Indian languages to follow.

How will generative AI impact the role of human travel agents or customer service representatives in the booking and planning process on MakeMyTrip’s platform? How do you intend to provide a seamless experience that combines AI with human expertise?

We look at these chatbots as an intelligent aide to our human agents. The basic set of questions that an agent would typically ask will now be asked by these chatbots to qualify a lead and assess the purchase intent. For example, questions like weather in a city, a good time to visit a certain place or queries on visa requirements can be answered by the chatbot.

In some cases, it will recommend a product to the customer to purchase right then and there. And that happens on our app too, if one of our packages fit the customer’s prerequisites that’s the result that comes up. But some holiday purchases are very nuanced, and people want to customize it quite a bit. They want to talk to a human agent to clarify their doubts or seek more information before they make the final purchase. That is where the conversational bot comes in handy.

The way I see it, and the way we are building it, is that these chatbots will be very smart assistants for our holiday experts so that they will get more qualified leads that they can close better. We believe the productivity and efficiency of our human agents will get a significant boost as a result.

What measures is MakeMyTrip taking to safeguard customer data and ensure the privacy and security of information collected and utilized by generative AI algorithms?

The data collected by these chatbot interfaces stay completely within our systems, just like the data that we collect in our apps, which is strictly “need-only.” Therefore, the privacy and security guardrails that we employ in our usual apps applies here as well. The collected data is just as safe as the data that one would volunteer on our app’s shopping flows.

Why did MakeMyTrip choose Microsoft Azure as the platform for its generative AI solutions?

We looked at several options that are out there today, and we chose Azure because of the entire bouquet of services on Azure Cognitive Services – be it voice-to-text, text-to-voice or rich vernacular language capability. In order to provide a smooth, seamless experience to our customers, we elected to partner with the one that had the most comprehensive set of services to build an end-to-end capability. Azure Cognitive Services fit the bill completely.

Additionally, there are benefits to collaborating with a trusted partner like Microsoft, who add yet another layer of assurance with their “responsible AI” mindset.

What are the potential challenges or limitations of implementing generative AI in the travel industry, and how is MakeMyTrip working to overcome them?

It’s still a very nascent technology and I see three challenges at the moment.

Given the kind of industry we are in, people want to see photos of the hotels they plan to stay at or videos of the places they plan to visit. Voice or text interfaces alone will not suffice. We need a multimodal chatbot interface that I don’t think anyone in the industry has been able to figure out yet. It’s a hard problem from a user interaction perspective and we’re using the initial few launches to learn what works best for our customers, in a controlled set of experiments.

With conversational chatbots, voice support for languages needs to be refined for the colloquial usage of the language, something that a customer in a small town or village in India would speak or understand. Some experiments with colloquial and Hinglish kind of usage will also help us fine-tune the interaction.

And finally, as we do for every other feature that we launch, the performance characteristics of the feature have to be world-class before we roll this out to 100 percent of our customer base. The new feature has to work well for all our customers. This is no different from what we do with every new feature we launch – we would just be following our standard roll out process here as well.

Looking ahead, what possibilities do you see for leveraging generative AI to create innovative travel solutions?

The pace of progress in generative AI is really fast, so I’m assuming that we will not be talking in years, but quarters or months.

These are still early days, but my vision is to have voice interactions in all popular languages that people speak in India. And if it’s colloquial, it makes services accessible to more people. Anyone in India would be able to use our platform.

This also has the potential to make services accessible for people who have limitations with manual dexterity, vision, literacy etc. and will enable them to interact in the mode that works best for them."
Microsoft_News,https://news.microsoft.com/annual-wti-2023%20,,Announcing Microsoft 365 Copilot Early Access Program and the 2023 Annual Work Trend Index,"In March, we introduced the world to Microsoft 365 Copilot – your copilot for work. We’re excited to share the next step in our journey as we bring Copilot to more customers and introduce new capabilities. We’re also releasing new data and insights from our 2023 Annual Work Trend Index on how work is changing in the era of AI."
Microsoft_News,https://www.microsoft.com/en-us/worklab/podcast/how-ai-will-change-the-way-you-work,,How AI Will Change the Way You Work,"ELISE HU: Marcus Wohlsen is a journalist, author, and head of editorial at the storytelling firm Godfrey Dadich Partners. He has worked with Microsoft and other clients to envision a future shaped by the latest advances in artificial intelligence. He’s here to help us understand how this moment fits into the broader history of AI’s development, and how we can expect AI to change the world of work for all of us.

ELISE HU: Hey, Marcus. Thanks for doing this.

MARCUS WOHLSEN: Hey, Elise. My pleasure.

ELISE HU: You’ve spent a lot of time covering the tech industry and the history of artificial intelligence. What is your sense of what’s happening in this moment?

MARCUS WOHLSEN: As a journalist who has been covering the rise of AI, especially over the last decade, we’re in a moment now of pretty stunning disruption—it’s a word that gets overused, but I think it’s important to recognize it when it’s actually occurring. And I think the way that we know that, in one way, is that these changes and these emerging capabilities of these large language models are happening at a pace that even the most optimistic researchers didn’t predict themselves.

ELISE HU: This all seems so novel and new to us right now, but couldn’t you make the case that all of us have already integrated AI into our everyday lives? Been using it long before these particular developments, right?

MARCUS WOHLSEN: Right. The most useful application of AI in my life, without a doubt, is maps. GPS-based, turn-by-turn direction maps. And what I don’t think we recognize anymore, because it’s so effective and useful and easy, is that every time we ask for directions, a computer is making a prediction about the best way to get there—based on the available data, based on traffic, based on distance, based on speed limits, traffic signals. All of those are data points. And what the AI system is doing in the background is judging probabilities. People spend their time thinking about AI and ask, well, what is AI? Well, it’s anything we can’t quite do yet with machines. When something becomes everyday, like using turn-by-turn directions and GPS-enabled maps, we’re not amazed by that anymore, and it sort of blends in to our everyday lives. What we’re mostly talking about now when we talk about AI, are actually these large language models that are generating these rich textual answers to questions that we pose or to prompts or to requests. Those models are actually still fundamentally operating on the same principle, on a really basic, oversimplified level. Today’s chatbots are predicting based on the prompt that I give it. What’s the word that’s most likely to come next? And it’s basing this on pretty much the biggest dataset of all, which is the entire internet. And so it’s weighing probabilities and spitting out an output. It just so happens that because of a mix of the size of the dataset, unprecedented power of the computing that’s available now, and the sophistication of the models, that probability engine is giving us outputs that start to feel indistinguishable from a human response.

ELISE HU: Marcus, it’s obviously hard to think about how large language model machine learning works without sort of equating it to how the human brain works. Is that why the conversation tends to be on whether AI has achieved sentience, or when it will achieve sentience?

MARCUS WOHLSEN: Right. So it’s very easy to fall into this conversation about whether these large language models are, quote unquote, intelligent. Not that it’s not a question worth considering, but given the speed at which these tools are becoming available to everyone, I think it becomes sort of like a side conversation, because for all intents and purposes, these large language models, they feel intelligent to us. If it feels like there’s a person on the other end of it, I think we’re going to respond to it that way. And so the question really becomes more, okay, now that we have this, what are we going to do with it?

ELISE HU: What are we going to do with it?

MARCUS WOHLSEN: Well, already there are some very practical applications. One of the promises of these large language models of next-generation AI is that they’ll, for instance, be able to summarize meetings—and not just summarize them in kind of a generic way, but each one of us will be able to use these tools to find out specifically what mattered to us. Similarly with onboarding. Onboarding is a process that is really about knowledge gathering and knowledge transmission. The real power of these tools is the ability to have what amounts to a conversation that’s informed by the specific data of my organization. And to be clear, that’s what I’m talking about now, is when you’re putting to use tools like Microsoft’s Copilot tool, the large language models that are out there in general, are primarily pulling from information that’s available on the internet. One of the powerful promises of these in an applied setting is, for instance, in the use of a tool like Copilot, is being able to use the kind of overall ability of these models to interact with us using natural language, but have that interaction being informed by the specific information, by the specific data that is unique to me, that is unique to my organization. Another use case there: Let’s say you’ve been on vacation for a week and you come back to an inbox that’s just stuffed with hundreds of emails and, you know, imagine being able to go into your inbox and just ask the AI agent to pull out the action steps that I need to take, or to say, what’s the status of this particular project? So in the context of work, in the context of knowledge work specifically, I’ve been thinking about AI as this kind of relevance engine. It has this amazing ability to personalize the information that we consume, and that’s because we can talk with it in the way that we talk with one another.

ELISE HU: Well, as a business proposition, let’s just return to the fact that AI is only ever as capable as the data that has fed it. And so what about those who might be hearing this conversation, especially about personalization for workers? What about data privacy?

MARCUS WOHLSEN: Data privacy is a huge issue when it comes to AI. Privacy, issues of consent, issues of data governance—these are all issues that organizations, they’re familiar with them. But it really reaches a whole other level with these large language models. Their usefulness is kind of predicated on the amount and the quality of the data that they consume. But security, privacy, consent, governance—if those aren’t addressed in a very proactive way, it seems like it would be very easy for data to seep into the models where people have access to it who shouldn’t, or people who did not consent to have their data used are finding that it’s been incorporated into them in the first place. So yeah, these are issues that are a big deal right now and issues that leaders and organizations really need to be thinking about very actively.

ELISE HU: Is the way that AI augments our human abilities similar to past technological advancements?

MARCUS WOHLSEN: I think there are some similarities when it comes to augmenting human capabilities. If you think about, say, the calculator, it allowed us to make mathematical calculations faster. If you think about the car, it allowed people to get from one place to another faster and more independently. I think when you look at AI, there is greater efficiency, but it really goes much more to the heart of how we think and how we create. And I think we don’t really know yet what all the potential is there to transform how we do things. But I think that likely there’s a transformation on the horizon that is more profound and fundamental than what some earlier technologies were able to make possible.

ELISE HU: What do you think that looks like, Marcus?

MARCUS WOHLSEN: One of the things that is going to start to become really pervasive as AI becomes more widespread is that we probably aren’t going to start with a blank page in the way that we used to. You know, what do we do? We have a blank page and we need to do some research. So we go online and we do a search and we get a list of web pages and we investigate. Now, already, you can simply pose a question and the AI tool will give you an answer. It might not be the right answer, but you’re going to have something there to start with. I think that, especially for teenagers and younger who aren’t going to really remember the time before these tools were available, it’s going to seem strange to them not to do that.

ELISE HU: Yeah, will we need to learn how to write anymore?

MARCUS WOHLSEN: Right. There is something, I think, something that you lose in a sense if you are simply relying on the machine to do the writing. But more importantly than that is that somebody is always still going to have to evaluate the quality of whatever it is that the machine creates. There are some researchers from the University of Toronto who wrote a great book called Prediction Machines , where they really pose this question of what humans are still going to be necessary for in a world where these systems are as smart as they seem to be now. And what it comes down to is judgment. The machine ultimately still isn’t something that exists in the world in the way that it is able to, quote unquote, know whether this piece of writing is useful, is relevant, is something that we need—is good. A machine can simulate that kind of judgment. But again, it’s still just running these probabilities and making predictions based on data that fundamentally is data that comes from us. This is all us feeding these machines with information that it’s giving back. It’s still on us to figure out whether what we’re making with these things is any good, whether it matters, whether we need it or not.

ELISE HU: What are you most excited about, or what do you find most promising that you’ve seen from the applications?

MARCUS WOHLSEN: I have a colleague who was trying to think through roles and responsibilities in a particular team, and they just asked the AI and the AI shared some ideas. You can take them or leave them, but it gives you a starting point. It gives you a way to kind of kickstart a conversation. I’ve heard of people using AI to create business plans, to create work back schedules. I can tell you a personal story. My son wrote an essay for his English class—and I actually saw him doing some of the writing so I can vouch for the fact he was actually writing it himself. But he fed it to ChatGPT after it was done, and he read back to us what it said, and it gave him an evaluation of the essay. It gave its assessment of what he did well, of providing relevant examples, of providing context, connecting it to personal experience. It said, here are a couple of things that could maybe make it stronger. Oh, and also there are a couple of typos. And in getting that feedback, he learned something, and it also gave him the confidence to turn the essay in because he wasn’t sure if it was good enough. But he thought, basically, after getting that assessment, he was like, yeah, I think this is all right. So it really was really fascinating to me to see that use of AI as this thought partner, as this conversation partner. But I think most importantly, not in a way that’s like substituting for doing the work. It’s not, AI, could you write me this essay and I’m going to cut and paste it and turn it in. What these large language models enable is a new form of interaction with our machines. We can interface with our computers without learning a special language. We can simply interact in the most natural way we know how, which is to use our own voices.

ELISE HU: So beyond the ethical considerations that we talked about a little earlier, what other advice do you want to leave leaders with as we meet this moment for large language models?

MARCUS WOHLSEN: I think for leaders in organizations wrestling with how to make use of it effectively, you really have to appreciate the level of disruption that this represents. Disruption is a word that gets way overused in tech and in business. And so it makes it hard to recognize, I think sometimes, when a real disruption has occurred. I think this is one of them. And so that means needing to have a truly open mind. Leaders themselves need to actually use these tools to see what they’re capable of. You can’t just listen to podcasts about it. You have to do it. And what you also have to do is be comfortable with everybody in your organization using it. The kind of experimentation that’s necessary in order for innovation to happen. It can be challenging, but you’re not really going to be able to grapple with that in an intelligent way unless you try it.

ELISE HU: Well, what an opportunity, too, to get to chart the future. Marcus, thank you so much.

MARCUS WOHLSEN: Great. Thank you.

ELISE HU: Thank you again to Marcus Wohlsen. And that’s it for this episode of WorkLab , the podcast from Microsoft. Please subscribe and check back for the next episode, where we’ll be checking in with Jared Spataro, Microsoft’s Corporate Vice President for Modern Work, on the most important findings and insights from the company’s new Work Trend Index. If you’ve got a question you’d like us to pose to leaders, drop us an email at worklab@microsoft.com, and check out the WorkLab digital publication, where you’ll find transcripts of all our episodes, along with thoughtful stories that explore the ways we work today. You can find all of it at Microsoft.com/WorkLab. As for this podcast, rate us, review, and follow us wherever you listen. It helps us out a lot. The WorkLab podcast is a place for experts to share their insights and opinions. As students of the future of work, Microsoft values inputs from a diverse set of voices. That said, the opinions and findings of our guests are their own, and they may not necessarily reflect Microsoft’s own research or positions. WorkLab is produced by Microsoft with Godfrey Dadich Partners and Reasonable Volume. I’m your host, Elise Hu. My co-host is Mary Melton. Sharon Kallander and Matthew Duncan produced this podcast. Jessica Voelker is the WorkLab editor."
Microsoft_News,https://news.microsoft.com/source/features/ai/the-art-of-the-prompt-how-to-get-the-best-out-of-generative-ai/,,The art of the prompt: How to get the best out of generative AI,"“I compare it to the early days of search engines — there was an art to choosing the right keywords to get good results and, over time, both the users and the search engine got better at understanding each other,” she said. “This is the same paradigm. Over time, both we as users and the machine learning models will understand each other better.”

As generative AI tools become increasingly popular for work and play, it’s helpful to know how to get the most out of them. Crafting the right prompt is essential, but it can be a give-and-take. Here are a few of Marsman’s top tips and tricks for writing effective prompts.

Be specific

You had a stunning image in your mind, but when you told Bing Image Creator to make it real, the result wasn’t at all what you imagined. What gives?

It’s essential to provide as much detail as possible when writing prompts, especially when it comes to images, Marsman said. One key element she likes to provide is style. Tell the model to produce the image as a pencil sketch, for example, or an oil painting, or a cartoon. Point of view and lighting are also attributes to consider. In an image of a baseball stadium, are you looking down from the stands, or on the field, or a bird’s-eye view from above?

In the “underwater palace” example, Marsman added the phrase “high-quality digital art” to her prompt. Without it, the image wouldn’t have had the same level of detail, she said.

Include details like style, point of view and lighting when writing prompts to generate images. Image courtesy of Microsoft.

Marsman was pleased with the output. But don’t be afraid to iterate, she added. Flipping around the order of words in the prompt will bring different elements to the foreground. If she had wanted to add mermaids as the focus, for example, she could have listed “mermaids” first.

Use the right model for the right job

If you’re looking for stories, poems, jokes or other imaginative answers, use the “more creative” mode of Bing Chat.

But if you’re looking for just the facts, use the “more precise” mode. This will yield succinct and fact-based responses, Marsman said. “Balanced” mode is the default and works well for most scenarios, she added.

Fact-check

Bing combines powerful AI models with its immense search index for results that are current, cited and conversational. But one downside of generative AI models is that they can occasionally generate plausible-sounding answers that are, in fact, wrong. Here are a few tips to help make sure that reasonable-sounding output is indeed true:

Use the “more precise” conversation style in Bing Chat. This model tends to do better at grounding its responses in the source material from the web.

Read the references carefully. You can click into the citations and verify that the model correctly interpreted the text.

Tell the model to summarize specific information rather than asking an open-ended question. For example, instead of asking, “what is the theory of general relativity,” you could frame your prompt as “summarize the key concepts of general relativity in one paragraph.” This can help guide the model to generate more accurate and relevant responses, Marsman said.

Tailor results through different points of view

You can get better answers from a chatbot by telling it how you want it to provide answers. For example, if you want a simple explanation of quantum mechanics, you can ask AI-powered Bing to “explain it to me like I’m in 8th grade.” But if you’re savvy with the jargon and nitty-gritty of the topic, you can ask it to act like a college professor or a technical trainer. This way, you can adjust the Bing Chat’s voice and level of understanding to suit your needs.

You can adjust a Bing Chat’s voice and level of understanding to suit your needs. Image courtesy of Microsoft.

When you want to change the conversation, use the “New topic” button

If you want to ask follow-up questions on the same topic in Bing Chat, it’s best to keep the current conversation going. When you want to switch topics, hit the “New topic” button. This gives the model a clean slate — it won’t get confused and merge unrelated topics.

You can specify length

Do you want a succinct answer or a long tale? You can specify the length — two sentences, for example, or two paragraphs — and guide the model accordingly. And if the chatbot stops before you’re satisfied, you can always prompt it to “go on.”

Don’t forget formatting

AI-powered Bing can present data and information from multiple sources across the web and in a variety of different ways to improve understanding. For example, tables and outlines can help users see information in a structured format. Similarly, diagrams and flow charts can help users visualize complex data, making it easier to understand and interpret.

AI-powered Bing can present data and information from multiple sources and in a variety of different ways. Image courtesy of Microsoft.

Leverage your Copilot for writing good code

Remember that the model is trained with many programming languages, so asking simply to accomplish a coding task could result in any number of programming languages being used. Specify the programming language you want. You should also include any other relevant contextual information, such as libraries, APIs or frameworks you are using. You can also mention context from already-written code, like “the user’s input is stored in a variable called x.”

Don’t forget to always run and test your code!

If at first you don’t succeed, prompt again

It’s important to remember that prompting AI to generate responses is not an exact science, and that iteration is key, Marsman said. The beauty of creating prompts is that you can try multiple approaches to see what works best. Don’t be afraid to experiment with different lengths, tones and voices. If the initial results aren’t what you’re looking for, try tweaking your prompt and running it again. With practice, you’ll get better at guiding the model to the results you want.

Related links:

Read more: Prompts for communicators using the new AI-powered Bing

Learn more: ExplAIning AI: The fundamentals and the frontiers

Top image: A digital image of an underwater palace created by Bing Image Creator. Image courtesy of Microsoft."
Microsoft_News,https://blogs.microsoft.com/blog/2023/05/04/announcing-the-next-wave-of-ai-innovation-with-microsoft-bing-and-edge/,,Announcing the next wave of AI innovation with Microsoft Bing and Edge,"Just three months ago, we unveiled the new AI-powered Microsoft Bing and Edge to reinvent the future of search with your copilot for the web. We aimed to tackle a universal problem with traditional search – that nearly half of all web searches go unanswered, resulting in billions of people’s searches falling short of the mark. We launched the new Bing to bring you better search results, answers to your questions, the ability to create and compose, and with a new level of ease of use by being able to chat in natural language. Bing combines powerful large language models like OpenAI’s GPT-4 with our immense search index for results that are current, cited and conversational – something you can’t get anywhere else but on Bing. This is fundamentally changing the way people find information.

In just 90 days, our customers have engaged in over a half a billion chats, using chat features to get summarized answers to help them with everything from finding the best place to travel for someone with pollen allergies, to organizing the last 10 years of worldwide volcanic activity into a table. We have also seen people create over 200 million images with Bing Image Creator. All up, Bing has grown to exceed 100 million daily active users and daily installs of the Bing mobile app have increased 4X since launch. As a result we are seeing growth of Bing share and it follows the eight straight quarters of growth in our Microsoft Edge browser share. We’re excited about continuing to make Bing more accessible by its introduction to the Windows taskbar, reaching over half a billion customers every month.

Entering the next generation of AI-powered search

Today I’m thrilled to share we are moving to the next generation of AI-powered Bing and Edge to transform the largest category of software in the world – search – by greatly expanding the vision and capabilities we think of as Your Copilot for the Web. This next generation is defined by:

Opening up Bing to more people by moving from Limited Preview to Open Preview and eliminating the waitlist for trial.

Moving from text-only search & chat to one that is incredibly more visual with rich image/video answers and coming shortly, new multimodal support.

Moving from single use chat/search sessions to multi-session productivity experiences with chat history and persistent chats within Edge.

Opening up platform capabilities so developers and third parties can build on top of Bing to help people take actions on their queries and complete tasks.

Click here to load media



Bing now in Open Preview

Thanks to tremendous customer adoption, engagement and feedback, we’re ready to take the next step and are announcing the new Bing is now in Open Preview and no longer has a waitlist. This means that it will now be easier than ever for everyone to try the new Bing and Edge by simply signing into Bing with your Microsoft Account.

Making search more visual

We know from research that the human brain processes visual information about 60,000 times faster than text, making visual tools a critical way people search, create and gain understanding. Bing has always been known for its visual experiences including features like Knowledge Cards and visual search. And now we’re delivering those same experiences in chat. We’re introducing richer, more visual answers including charts and graphs and updated formatting of answers, helping you find the information you seek more easily.

Click here to load media

The above video shows visual improvements to Bing chat.

We recently announced the integration of Bing Image Creator into the new Bing chat experience making Bing the only search experience with the ability to generate both written and visual content in one place, from within chat. And today, I’m excited to share that we are expanding Image Creator to all languages in Bing – that’s more than 100 languages – so now you can create images in your native language.

Click here to load media

Video showing Bing Image Creator.

We’re also beginning our journey to a redesigned Microsoft Edge where one in four Bing chats originate. Edge continues to be your copilot for the web, the first to use AI, and the only browser with Bing built-in. As these changes begin to roll out, you’ll begin to see a sleeker and enhanced user interface including a streamlined look, rounded corners, organized containers and semi-transparent visual elements.

Lastly, we’re expanding what’s possible with multi-modal capabilities and are beginning the work to incorporate visual search in chat so you will be able to upload images and search the web for related content.

Making search more productive

Two of the most requested features we’ve heard are maintaining access to your chat history and being able to share and export. Starting shortly, you’ll be able to pick up where you left off and return to previous chats in Bing chat with chat history. And when you want to dig into something deeper and open a Bing chat result, your chat will move to your Edge sidebar, so you can keep your chat on hand while you browse. Over time, we’re exploring making your chats more personalized by bringing context from a previous chat into new conversations.

Click here to load media

Chat history video.

Click here to load media

Persistent chat video.

Starting soon, we’re also adding export and share functionalities into chat. For times when you want to easily share your conversation with others in social media or continue iterating on a newly discovered idea, you can export it directly – the format stays the same to make an easy transition to continue in collaborative tools like Microsoft Word.

Chat in Microsoft Edge will also soon have improved summarization capabilities for long documents, including PDFs and longer-form websites, making it easier to consume dense online content. We are also introducing Edge actions. Available in the coming weeks, people will soon be able to lean on AI to complete even more tasks with fewer steps. For example, if you want to watch a particular movie, actions in Edge will find and show you options in chat in the sidebar and then play the movie you want from where it’s available. Edge mobile will also soon include page context, so you can ask questions in Bing chat related to the mobile page you’re viewing. The compose feature in sidebar can also now tailor drafts based on feedback you give like tone, length, phrasing and more.

Click here to load media

Edge actions video.

Click here to load media

Compose video.

Moving from a product to a platform

The new AI-powered Bing has already helped people more easily find or create what they are looking for, making chat a great tool for both understanding and taking action. The integration of Image Creator saves you time by completing the task of creating the image you need right within chat.

We’ll soon build third-party plug-ins into the Bing chat experience creating a platform for developers. For example, if you’re researching the latest restaurant for dinner in Bing chat, it will leverage OpenTable to help you find and book a reservation. Or, with Wolfram|Alpha, you can create powerful visualizations and get answers to complex science, math and human-curated data-based questions directly from Bing chat. We are working with our partners at OpenAI to make it easier and as consistent as possible for developers to take advantage of this opportunity. We believe these types of skills are a game-changer in the reinvention of search and to advance opportunities for developers in search. We look forward to sharing more details at Microsoft Build later this month.

Click here to load media

Bing actions.

Continuing to build in the open, responsibly

As we’ve said from the beginning, responsible AI is at the center of every new experience we build with the new Bing and Edge. And getting the new Bing into preview so we can learn from real-world testing and feedback has been critical to our success and ability to expand the experience to more users. We believe innovating and learning in the open is part of a responsible approach. But we don’t stop there. Together with our partners at OpenAI, we’ve continued to implement safeguards to defend against harmful content based on what we’re learning and seeing in preview. Our teams continue to work to address issues such as misinformation and disinformation, content blocking, data safety and preventing the promotion of harmful or discriminatory content in line with our AI principles. Learn more here about our approach to responsible AI with the new Bing.

If you haven’t tried the new Bing and Edge yet, now is the time to experience firsthand how we’re reinventing search with your copilot for the web. We’ll also continue our thoughtful and measured approach of gathering feedback and making rapid adjustments in preview. We continue to use this feedback to make weekly changes to the preview by incorporating the most requested features and updates and adding new experiences along the way. Experience the future of search by visiting bing.com today or downloading the Bing mobile app in your favorite app store.

Tags: AI, Bing, Bing Image Ceator, Microsoft Edge"
Microsoft_News,https://www.microsoft.com/en-us/research/blog/ai-and-the-future-of-health/,,AI and the Future of Health,"The emergence of increasingly capable large-scale AI models, such as the recently released GPT-4, is one of the most significant advances in computing in decades. These innovations are rapidly transforming every aspect of the value we get from technology, as demonstrated through Microsoft’s integration of GPT-4 into Bing, Edge, Microsoft 365, Power Platform, GitHub, and other offerings. More recently, Nuance has announced DAX Express, which uses a unique combination of conversational, ambient, and generative AI to automatically draft clinical notes after patient visits – helping to reduce care providers’ cognitive burdens and increase the joy of practicing medicine (whilst releasing time for care).

We are at an inflection point for the use of AI in healthcare – one of society’s most critical sectors. The significance of this moment is reflected in Peter Lee’s recent article in the New England Journal of Medicine on the potential future clinical applications of GPT-4. At Microsoft Research’s Health Futures organization, the multidisciplinary group dedicated to discovery in this space, we see this as the continuation of a journey, and a major milestone in the long process of innovating to help address the greatest challenges in healthcare.

In this blog, we will share some of our research team’s work to make healthcare more data-driven, predictive, and precise – ultimately, empowering every person on the planet to live a healthier future.

Enabling precision medicine and connected care

We are today at a unique moment in history where medicine, biology, and technology are converging on a large scale. This presents immense possibilities to revolutionize healthcare and the practice of medicine with the aid of trustworthy AI. While we embrace the potential of AI, we understand that the practice of medicine is an intricate balance of “art” and “science.” We recognize and honor the enduring physician-patient relationship, which is fundamental and timeless. Our diverse team comprises researchers, scientists, engineers, biotechnologists, designers, social scientists, strategists, healthcare experts, and medical professionals who collaborate globally and inclusively to reimagine and transform the lives of the patients and public we serve.

As we consider how technologies have shaped the practice of medicine over the centuries, from the individual to the ecosystem level, we are reminded that no technology exists in a vacuum. Our core understanding of biological systems is rapidly evolving, and with it, our understanding of what technologies are relevant and useful. Simultaneously, the use of technology across the health and life science industries, and the way healthcare is delivered, are also rapidly changing – reshaping our traditional healthcare delivery model from one of diagnosis and treatment, to one that prioritizes prevention and precise individualized care.

Spotlight: On-demand video AI Explainer: Foundation models ​and the next era of AI Explore how the transformer architecture, larger models and more data, and in-context learning have helped advance AI from perception to creation. Watch video Opens in a new tab

Recent advancements in machine learning and AI have fueled computational technologies that allow us to aggregate complex inputs from multiple data sources, with the potential to derive rich insights that rapidly expand our knowledge base and drive deeper discovery and faster innovation. At the same time, it remains an open question how to best use and regulate these technologies in real-world settings and at scale across healthcare and the life sciences. Nonetheless, we believe that we are on a path to delivering on the goal of precision medicine – a change in clinical practice which will be enabled by precision diagnostics, precision therapeutics, and connected care technologies.

To achieve this goal, we seek to collaborate with health and life sciences organizations with a similar appetite for transformation, complementary expertise, and a commitment to propel the change required. We are also engaged with the broader community in pursuing responsible and ethical use of AI in healthcare. Our diverse team has been successful in bridging the gap between the fields of medicine, biology and chemistry on one hand, and computing on the other. We act as “translators” between these fields, and through a process of ongoing collaboration and feedback, we have discovered new challenges and innovative solutions.

Below are some examples of our collaborative research approach:

Multimodal foundation models for medicine: an example from radiology

The field of biomedicine involves a great deal of multimodal data, such as radiology images and text-based reports. Interpreting this data at scale is essential for improving care and accelerating research. Radiology reports often compare current and prior images to track changes in findings over time. This is crucial for decision making, but most AI models do not take into account this temporal structure. We are exploring a novel self-supervised framework that pre-trains vision-language models using pairs of reports and sequences of images. This includes handling missing or misaligned images and exploiting temporal information to learn more efficiently. Our approach, called BioViL-T, achieves state-of-the-art results on several downstream tasks, such as report generation, and interpreting disease progression by focusing on relevant image regions across time. BioViL-T is part of ongoing collaboration with our colleagues at Nuance to develop scalable and flexible AI solutions for radiology that can empower care providers and augment existing workflows.

Project InnerEye: Democratizing Medical Imaging AI

Project InnerEye (opens in new tab) is a research project that is exploring ways in which machine learning has the potential to assist clinicians in planning radiotherapy treatments so that they can spend more time with their patients. Project InnerEye has been working closely with the University of Cambridge and Cambridge University Hospitals NHS Foundation Trust to make progress on this problem through a deep research collaboration. To make our research as accessible as possible, we released the InnerEye Deep Learning Toolkit (opens in new tab) as open-source software. Cambridge University Hospitals NHS Foundation Trust and University Hospitals Birmingham NHS Trust (opens in new tab) led an NHS AI in Health and Care Award to evaluate how this technology could potentially save clinicians’ time, reduce the time between the scan and commencing treatment, and scale this to more NHS Trusts. Any clinical use of the InnerEye machine learning models remains subject to regulatory approval.

Immunomics: Decoding the Immune System to Diagnose Disease

The human immune system is an astonishing diagnostic engine, continuously adapting itself to detect any signal of disease in the body. Essentially, the state of the immune system tells a story about virtually everything affecting a person’s health. What if we could “read” this story? Our scientific understanding of human health would be fundamentally advanced. More importantly, this would provide a platform for a new generation of precise medical diagnostics and treatment options. We are partnering with Adaptive Biotechnologies to develop the machine learning and biotechnology tools that will allow us to realize this dream.

Fundamental advances towards new medicines and therapeutics

Protein Engineering

Several research groups are delving into the potential of machine learning to enhance our comprehension of proteins and their pivotal role in various biological processes. We are also using AI to design new proteins for therapeutics and industry. By applying machine learning to extract patterns from databases of sequences, structures, and properties, Microsoft hopes to train models that can make protein engineering by directed evolution more efficient, and directly generate proteins that will perform desired functions. The ability to generate computationally distinct yet viable protein structures holds tremendous promise for uncovering novel biological insights and developing targeted therapies for previously untreatable illnesses.

Investigating the Cancer Microenvironment through Ex Vivo Research

Microsoft is working on ways to identify specific characteristics of cancer cells and their surrounding microenvironments that might be targeted for treatment. By studying how cancer cells and their surroundings interact with each other, the team aims to create a more precise approach to cancer treatment that takes into account both genetic and non-genetic factors.

Accelerating biomedical research

Microsoft and the Broad Institute – combining their expertise in genomics, disease research, cloud computing and data analytics – are developing an open-source platform to accelerate biomedical research using scalable analytical tools. The platform is built on top of the Broad Institute’s Terra platform, providing a user-friendly interface for accessing and analyzing genomic data. Leveraging Microsoft’s Azure cloud computing services, the platform will enable secure storage and analysis of large datasets. Additionally, the platform will incorporate machine learning and other advanced analytical tools to help researchers gain insights into complex diseases and develop new treatments.

Advancing clinical interpretation and exploration through multimodal language models

In the quest for precision medicine and accelerating biomedical discovery, Microsoft is committed to advancing the state of the art in biomedical natural language processing (NLP). A crucial factor in future-facing, data-driven health systems is the accessibility and interpretability of multimodal health information. To meet this need, Microsoft has laid a solid foundation across multiple modalities in biomedical NLP building on our deep research assets in deep learning and biomedical machine reading.

One significant achievement is our development and application of large language models (LLMs) in biomedicine. Microsoft was among the first to create and assess the applicability of LLMs, such as PubMedBERT and BioGPT, which are highly effective in structuring biomedical data. However, to address the inherent limitations of LLMs, Microsoft is developing methods to teach them to fact-check themselves and provide fine-grained provenance. Additionally, Microsoft is exploring ways to facilitate efficient verification with humans in the loop.

Besides text, other modalities such as radiology images, digital pathology slides, and genomics contain valuable health information. Microsoft is developing multimodal learning and fusion methods that incorporate these modalities. These methods include predicting disease progression and drug response, with the ultimate goal of delivering safe and high-quality healthcare.

Observational data in biomedicine is often plagued by confounders, making it challenging to draw causal relationships. To overcome this obstacle, Microsoft is developing advanced causal methods that correct implicit biases and scale biomedical discovery. These methods will allow Microsoft to leverage real-world evidence and contribute to the creation of more effective healthcare delivery systems. For our end-to-end biomedical applications, we have made exciting progress in deep collaborations with Microsoft partners such as The Jackson Laboratory and Providence St. Joseph Health.

Empowering everyone to live a healthier future

Microsoft has pursued interdisciplinary research that enables people to reach the full potential of their health for many years, but we’ve never been more excited about the possibilities than we are today. The latest developments in AI have inspired us to accelerate our efforts across these and many other projects, and we look forward to even more innovation and collaboration in this new era.

Opens in a new tab"
Microsoft_News,https://blogs.microsoft.com/on-the-issues/2023/05/01/responsible-ai-standards-principles-governance-progress/,,Reflecting on our responsible AI program: Three critical elements for progress,"Last week, at Responsible AI Leadership: Global Summit on Generative AI, co-hosted by the World Economic Forum and AI Commons, I had the opportunity to engage with colleagues from around the world who are thinking deeply and taking action on responsible AI. We gain so much when we come together, discuss our shared values and goals, and collaborate to find the best paths forward.

A valuable reminder for me from these and recent similar conversations is the importance of learning from others and sharing what we have learned. Two of the most frequent questions I received were, “How do you do responsible AI at Microsoft?”, and “How well placed are you to meet this moment?” Let me answer both.

At Microsoft, responsible AI is the set of steps that we take across the company to ensure that AI systems uphold our AI principles. It is both a practice and a culture. Practice is how we formally operationalize responsible AI across the company, through governance processes, policy requirements, and tools and training to support implementation. Culture is how we empower our employees to not just embrace responsible AI but be active champions of it.

When it comes to walking the walk of responsible AI, there are three key areas that I consider essential:

1. Leadership must be committed and involved: It’s not a cliché to say that for responsible AI to be meaningful, it starts at the top. At Microsoft, our Chairman and CEO Satya Nadella supported the creation of a Responsible AI Council to oversee our efforts across the company. The Council is chaired by Microsoft’s Vice Chair and President, Brad Smith, to whom I report, and our Chief Technology Officer Kevin Scott, who sets the company’s technology vision and oversees our Microsoft Research division. This joint leadership is core to our efforts, sending a clear signal that Microsoft is committed not just to leadership in AI, but leadership in responsible AI.

The Responsible AI Council convenes regularly, and brings together representatives of our core research, policy, and engineering teams dedicated to responsible AI, including the Aether Committee and the Office of Responsible AI, as well as senior business partners who are accountable for implementation. I find the meetings to be challenging and refreshing. Challenging because we’re working on a hard set of problems and progress is not always linear. Yet, we know we need to confront difficult questions and drive accountability. The meetings are refreshing because there is collective energy and wisdom among the members of the Responsible AI Council, and we often leave with new ideas to help us advance the state-of-the-art.

2. Build inclusive governance models and actionable guidelines: A primary responsibility of my team in the Office of Responsible AI is building and coordinating the governance structure for the company. Microsoft started work on responsible AI nearly seven years ago, and my office has existed since 2019. In that time, we learned that we needed to create a governance model that was inclusive and encouraged engineers, researchers, and policy practitioners to work shoulder-to-shoulder to uphold our AI principles. A single team or a single discipline tasked with responsible or ethical AI was not going to meet our objectives.

We took a page out of our playbooks for privacy, security, and accessibility, and built a governance model that embedded responsible AI across the company. We have senior leaders tasked with spearheading responsible AI within each core business group and we continually train and grow a large network of responsible AI “champions” with a range of skills and roles for more regular, direct engagement. Last year, we publicly released the second version of our Responsible AI Standard, which is our internal playbook for how to build AI systems responsibly. I encourage people to take a look at it and hopefully draw some inspiration for their own organization. I welcome feedback on it, too.

3. Invest in and empower your people: We have invested significantly in responsible AI over the years, with new engineering systems, research-led incubations, and, of course, people. We now have nearly 350 people working on responsible AI, with just over a third of those (129 to be precise) dedicated to it full time; the remainder have responsible AI responsibilities as a core part of their jobs. Our community members have positions in policy, engineering, research, sales, and other core functions, touching all aspects of our business. This number has grown since we started our responsible AI efforts in 2017 and in line with our growing focus on AI.

Moving forward, we know we need to invest even more in our responsible AI ecosystem by hiring new and diverse talent, assigning additional talent to focus on responsible AI full time, and upskilling more people throughout the company. We have leadership commitments to do just that and will share more about our progress in the coming months.

Organizational structures matter to our ability to meet our ambitious goals, and we have made changes over time as our needs have evolved. One change that drew considerable attention recently involved our former Ethics & Society team, whose early work was important to enabling us to get where we are today. Last year, we made two key changes to our responsible AI ecosystem: first, we made critical new investments in the team responsible for our Azure OpenAI Service, which includes cutting-edge technology like GPT-4; and second, we infused some of our user research and design teams with specialist expertise by moving former Ethics & Society team members into those teams. Following those changes, we made the hard decision to wind down the remainder of the Ethics & Society team, which affected seven people. No decision affecting our colleagues is easy, but it was one guided by our experience of the most effective organizational structures to ensure our responsible AI practices are adopted across the company.

A theme that is core to our responsible AI program and its evolution over time is the need to remain humble and learn constantly. Responsible AI is a journey, and it’s one that the entire company is on. And gatherings like last week’s Responsible AI Leadership Summit remind me that our collective work on responsible AI is stronger when we learn and innovate together. We’ll keep playing our part to share what we have learned by publishing documents such as our Responsible AI Standard and our Impact Assessment Template, as well as transparency documents we’ve developed for customers using our Azure OpenAI Service and consumers using products like the new Bing. The AI opportunity ahead is tremendous. It will take ongoing collaboration and open exchanges between governments, academia, civil society, and industry to ground our progress toward the shared goal of AI that is in service of people and society.

Tags: Azure, Bing, ChatGPT, Responsible AI"
Microsoft_News,https://www.microsoft.com/en-us/microsoft-365/blog/2023/04/27/microsoft-designer-expands-preview-with-new-ai-design-features/,,Microsoft Designer: Get inspired with new AI features,"Creativity is more important to individuals than ever before. This reflects a trend that has added more than 165 million creators to the global creator economy in just the last three years.1 As a result, people demand tools that help them to be both productive and creative. Microsoft 365 strives to empower individuals to achieve great things by constantly evolving our products to meet their changing needs. We continue to demonstrate this commitment with new tools that help unleash creativity and imagination by enabling any type of digital ideation and creation—no professional skills required. Today, we’re excited to announce we’re removing the waitlist and adding an expanded set of features to the Microsoft Designer preview. With new AI technology at the core, Microsoft Designer simplifies the creative journey by helping you get started quickly, augment creative workflows, and overcome creative roadblocks.

Microsoft Designer Create one-of-a-kind images, get the inspiration you're looking for, and make your content stand out. Get started today

From ideation to creation, Microsoft Designer is built to assist you at each stage of the creative process. As we originally announced in October 2022, Microsoft Designer can help quickly create stunning visuals, social media posts, invitations, and more using cutting-edge generative AI technology. Since October, the AI models have steadily improved, and we’ve worked to weave these powerful capabilities throughout the Designer canvas in even more delightful ways while keeping you in control. Moreover, for those moments of inspiration that strike while browsing the web, Designer is one click away within the Microsoft Edge sidebar. The seamless integration of Designer in Edge marks the first step in this journey. We’re excited for future integrations to come.

Spark new ideas and unleash creativity in less time with Microsoft Designer

Designer leverages cutting-edge generative AI technology to assist and empower every person to get started on new ideas, create unique and high-quality graphics in less time, and uplevel content, with or without a background in design.

Here’s what you can do today

Get started with your ideas in Designer by simply describing what you want. Powered by generative AI technology, get one-of-a-kind images, including accompanying text and visuals, and design suggestions to meet your needs.

Writing text to accompany your designs has never been easier. Simply type a phrase that captures your thoughts and quickly get copy suggestions—from headlines to short texts—with font suggestions that pair with your design. Need help creating clever captions or hashtags? Now, Designer can help you instantly generate written captions and hashtags that are more relevant for social media posts. Leveraging generative AI, the tool now offers suggestions you can choose from to assist in crafting the perfect captions and witty hashtags that align with your design.

Based on customer feedback, we also made updates in the app to help customize and resize designs more easily. This new feature enables you to change the original design canvas size to a different size while automatically shifting the elements of the design to seamlessly fit. Resize your posts to up to 20 different social media layout sizes across Instagram, Facebook, LinkedIn, and more.

To help your designs stand out, you can now create animated visuals in Designer. Adding a pop of motion helps you bring your creations to life instantly with animated backgrounds, engaging emotions, and text with transitions applied automatically with the help of AI technology.

Visit our Designer website to try the updated version of the Designer app in preview for free and have first access to additional features coming soon.2

Disclaimer: Actual UI may differ.

Stay in your creative workflow with Designer in Edge

Designer was built with you in mind. You can use the app to spark creativity, refine and customize designs, and create high-quality content in less time using the latest DALL∙E and generative AI. With Designer in Edge, we are bringing these capabilities into the web browser, too. It’s built natively into the Edge sidebar and can be accessed by clicking on the Designer icon, making Edge the first and only browser with an integrated, AI-powered graphic design app. You can create unique designs instantly by simply describing the graphic you want. You don’t need to leave the page you’re on, switch windows, or download an extension to your browser to start working on an idea when creativity strikes. With Designer in Edge, you can also create high-quality, unique content without interrupting your workflow. As you’re drafting a post on Facebook, Twitter, and Pinterest, Designer in Edge will provide AI-powered design suggestions to include in your post, which you can customize and publish without ever leaving your browser window.

Coming soon to Microsoft Designer

Disclaimer: Screens simulated.

Refining a design is an important step in fully actualizing an idea. Fill, Expand background, Erase, and Replace background are new features coming soon to Designer.

If you have a graphic that needs something specifically in the corner, use Fill by circling the spot and placing the object you want there in a flash and with the help of AI.

by circling the spot and placing the object you want there in a flash and with the help of AI. Do you feel like there could be more to your picture? Expand background leverages AI to help you automatically fill in the rest of the picture and offer a more compelling landscape that frames your image.

leverages AI to help you automatically fill in the rest of the picture and offer a more compelling landscape that frames your image. If there’s an object or person you didn’t intend to be in a graphic, use Erase by simply brushing over the object to remove it and automatically get another image generated to replace the space.

Disclaimer: Screens simulated.

Rather be at the beach than in your home office? Use Replace background to quickly remove your current background and replace it with another that you desire.

We will continue to evolve and add value to the Designer experience while maintaining our high security and privacy standards.

Looking ahead

At Microsoft, we’re committed to harnessing the power of innovative technology to expand what’s possible for all. You can try the Microsoft Designer expanded public preview for free by visiting our website or logging into your Microsoft account.2 The preview of Designer in Edge is rolling out to Edge and can be accessed through the sidebar by clicking the “+” icon to enable it.

1Adobe “Future of Creativity” Study: 165M+ Creators Joined Creator Economy Since 2020, Adobe. August 25, 2022.

2The current free preview does not include all planned features to come; we will be adding more over time. Once the app is ready for general availability, it will be available both as a free app and with more premium features available to Microsoft 365 Personal and Family subscribers."
Microsoft_News,https://blogs.microsoft.com/blog/2023/04/24/the-era-of-ai-how-the-microsoft-cloud-is-accelerating-ai-transformation-across-industries/,,The era of AI: How the Microsoft Cloud is accelerating AI transformation across industries,"This past quarter has put a spotlight on advancements in generative AI, and the possibilities of its application to deliver pragmatic business outcomes. For organizations around the world, there is incredible opportunity to enhance products and services while unlocking innovation and business value to help shape the future of industry. The pace and scale of technological innovation happening today is unprecedented and breathes optimism into a demanding economy. Those leveraging the Microsoft Cloud — the most trusted, comprehensive and integrated cloud — are best positioned to take advantage of these advancements. As leaders look to embrace AI, it becomes more critical than ever to prioritize having a data-driven business, fortified with digital and cloud capabilities. This approach will help organizations leverage generative AI as an accelerant to transformation. From Rogers improving connectivity for Canadians through automation and AI to the Ministry of Education in the United Arab Emirates developing an AI tutor for students, the possibilities are both limitless and part of today’s realities.

Modernizing manufacturing operations in the cloud to boost efficiency, lower costs and increase security



Mercedes-Benz is leveraging conversational AI capabilities within Azure OpenAI Service to deliver best-in-class customer service with Mercedes Virtual Assistant, while Austrian construction company Strabag is building a risk management solution that improves operational efficiency to save time and reduce financial losses. Coca-Cola Hellenic Bottling Company is continuing to scale its finance and supply chain operations on Azure while lowering enterprise applications costs. Australian-based Graintech estimates a 68% reduction in carbon emissions and reduced travel spending by using HoloLens and Teams to enable remote work and collaboration. FUJIFILM built its Cash Application service using Azure AI and Dynamics 365 to automate 20% of its manual invoicing processes. MAPEI is better engaging its customers with self-service tools while saving costs by consolidating its sales, customer service and marketing systems in the cloud. Belgian manufacturer Picanol Group is promoting tighter integrations between IT and operations by managing and securing its entire IT environment on the Microsoft Cloud. U.K.-based Kier Group is lowering infrastructure costs by consolidating its on-premises environment and migrating 90% of its server workloads to Azure. Krones is improving productivity and security for employees while protecting its globally distributed endpoints and over 6,400 patents by upgrading to Windows 11 Enterprise. Seeing an opportunity to embrace AI and IoT technology to mitigate supply chain disruptions, Liebherr-Components co-developed a turnkey security solution with Reycom AG using Defender for IoT.

Transforming retail experiences for consumers with AI and data-driven insights

To accelerate product launches and enhance customer service, Unilever has adopted Azure as its primary cloud platform and become a cloud-only enterprise by partnering with Accenture and Microsoft in one of the largest cloud migrations in the consumer goods industry. Campari Group is leveraging Dynamics 365 Copilot capabilities to increase the impact of its marketing campaigns by creating more personalized content and deeper customer insights. To launch the largest autonomous store chain in Europe, Żabka is creating frictionless customer journeys using AI-powered real-time computer vision technology from AiFi and Microsoft Cloud for Retail for store analytics and insights. Retailers like Canadian Tire and IFCO are leveraging Power BI to better understand product performance and develop detailed forecasts for customers. Sakata is automating price updates to reduce cumbersome manual processes, resulting in times savings of more than 60%. In Ukraine, retail technology company IPLAND is applying automated machine learning to increase image recognition speed and data collection for consumer goods companies looking to optimize their in-store product displays. Northern Tool + Equipment is providing intelligent customer experiences that guarantee faster and more reliable delivery times by working with real-time data within Microsoft Supply Chain Center.

Reinventing financial services through cloud capabilities and co-innovation

To democratize access to financial services in Mexico, Finvero is utilizing cloud and AI solutions to provide simpler, friendlier and more agile experiences for users. Leveraging support from the Microsoft for Startups program, Australia-based Thriday is freeing up time for small business owners by simplifying administrative tasks and improving financial management solutions using AI and machine learning. At its Hack Day event, AustralianSuper co-created a solution with Microsoft to reduce its manual effort for onboarding advisers by 90% in just two weeks. India’s largest private-sector bank, HDFC Bank, is using the Microsoft Cloud to securely modernize its data landscape to scale information management and data analytics. In Israel, global solutions provider Sapiens has cut its time to market in half — reducing operational overhead by at least 40% — by automating its development life cycle and delivery processes with Azure. In Brazil, ClearSale is combining advanced AI and human intelligence to ensure e-commerce purchases aren’t being made by scammers or hackers, and Cielo is making it easier to securely optimize access time for new suppliers — reducing the onboarding time needed from 60 days to two hours or less.

Advancing sustainability progress across transportation and energy industries with data and automation

To help organizations reduce water consumption and identify greenhouse gas emission savings, Ecolab has expanded its partnership with Microsoft, combining its digital platform capabilities with the Microsoft Cloud for Sustainability. Serving more than 1.4 million passengers in the U.K., public transportation provider FirstGroup is supporting its sustainability goals and making it easier to collaborate and solve problems by centralizing the visibility and management of its hybrid and multicloud environments with Azure Arc. In Germany, rail transportation leader Deutsche Bahn is building upon its commitment to a cleaner transportation infrastructure for the country by using Dynamics 365 to organize, analyze and visualize its data with the help of partner proMX. Greece-based company Public Power Corporation cut carbon emissions by over 99% while reducing its total cost of ownership by 30% by integrating its data sources on Azure. To enhance productivity for workers across the world, Norway-based Aker Solutions moved its global data center to the cloud and realized an estimated 40% reduction in CO2 emissions. To meet growing customer needs, German energy company EnBW automated its operations to make it possible to manage 10,000 renewable energy plants with only 20 employees.

Empowering professional services companies with cutting edge data and generative AI solutions

To achieve its mission of saving 1 million lives every year by 2030, Laerdal Medical is integrating is integrating Azure Speech Services into its training programs to create more immersive, real-life simulations between patients and providers. Amdocs is empowering service providers to improve end-user experiences across all channels and applications with its Customer Engagement Platform that combines best-in-class cloud, AI and telco technologies. ZS Associates is accelerating its new project launches by 75% through better access to collaboration and data tools using Azure and Microsoft 365. In Australia, KPMG is giving employees access to a proprietary version of ChatGPT within Teams so employees can safely explore and use the technology to drive innovation, boost efficiencies and improve the people experience. EY has developed a generative AI chatbot to modernize payroll employee care that can answer complex questions. Hungary-based digital solutions provider BPiON is deploying and maintaining applications almost 10 times faster — allowing the cloud-native company to expand its operational infrastructure to two new countries in less than a day.

I believe the only way to navigate uncertainty is through continued and accelerated innovation, and Microsoft itself is no exception. We have been delivering AI solutions for customers successfully over the last several years using cognitive services, machine learning and digital twins. Moving forward, we will infuse generative AI capability into our consumer and commercial offerings to deliver copilot capability for all services that our customers know and love across the Microsoft Cloud. Additionally, we will work with our partners, start-ups, digital natives and our customers to enable them to leverage these same capabilities in their own solutions. I am excited to see what our customers will create with generative AI in partnership with us. Together, we can apply the world’s most advanced AI models to meet business imperatives responsibly, securely and with the confidence that can only be achieved with the Microsoft Cloud.

Tags: AI, AI GPT, Azure, Azure AI, Azure OpenAI Service, Microsoft 365, Microsoft AI, Microsoft and GPT, Microsoft Cloud, Microsoft Copilot, Microsoft Dynamics 365 Copilot, Microsoft Generative AI, Microsoft HoloLens, Microsoft Supply Chain Center, Microsoft Teams, Power BI"
Microsoft_News,https://www.microsoft.com/en-us/worklab/podcast/how-leaders-will-use-ai-to-unleash-creativity,,How Leaders Will Use AI to Unleash Creativity,"ELISE HU: On today’s show, John Maeda. John Maeda is a Vice President of Design and Artificial Intelligence at Microsoft, and in his richly varied career, he’s also been a professor, an author, a college president, and a business executive. His digital artwork, books, lectures, research, and teaching have explored how digital technology can empower creativity. So we have a wide-ranging chat today about this moment that we’re in for AI. So without further ado, my conversation with John Maeda.

ELISE HU: Thanks for coming on the show.

JOHN MAEDA: Glad to be here.

ELISE HU: And you recently made this big career move to join Microsoft.

JOHN MAEDA: Well, when I was in high school, I tried to apply for an internship at Microsoft and I didn’t get in. So luckily they didn’t ask me the same questions decades later, and I’m in.

ELISE HU: Well, welcome. There’s so much to talk about when it comes to AI, especially recent breakthroughs in large language models. It’s being called an inflection point. We’re hearing that a lot, or a Cambrian explosion. So why?

JOHN MAEDA: Well, I kind of chuckle when I keep reading things like inflection, Precambrian, or whatever. All these giant ways to say the whole world has shifted. I think it’s just the perfect example of the Moore’s Law effect, that the idea of doubling doesn’t seem like a big deal when it’s like one becomes two, two becomes four, four becomes eight, eight becomes 16. But the iteration, 30 or 40 of a Moore’s Law build—it’s like ketchup, the old kind of ketchup in the glass bottle where it just all plops out and you’re like, Whoa, where did this glob ketchup come from, because you’ve been holding the bottle over your head. The doubling feels very big.

ELISE HU: What are the implications?

JOHN MAEDA: Well, the implications are exciting because this technology is actually kind of useful. I think it introduces a new kind of scratch-your-head moment. Everything was command line based in the seventies and eighties: type in text and it does something for you. And then there was this graphic user interface boom, where suddenly you were able to use a mouse and use a computer. It was democratizing. Ironically, this means they’re going back to the command line, which is so interesting. But this is something that has been long foreseen, already a very common user experience pattern in China, for instance, with a WeChat world. So I think it was inevitable that we’d end up here.

ELISE HU: And when you mean that everything’s kind of returning to the command line, can you talk a little bit about that?

JOHN MAEDA: Well, I spent six years writing a book called How to Speak Machine , and the entire thesis was it’d be really good for people who don’t understand how computer science and AI works to understand the mechanics, the physics underneath it. And at the end of the book, I realized it wasn’t about how to speak machine, but how to speak human. Now we speak in natural language, English or whatever language you like. We’re speaking human to the machine.

ELISE HU: John Maeda, Wired magazine has said that Maeda is to design what Warren Buffett is to finance. I’m not going to ask you to have to, you know, respond to that particular quote, but I’d love to know, because you are so deeply embedded and considered a real leader in the designer community, how is the larger design community thinking about the potential and pitfalls of AI?

JOHN MAEDA: I feel that design today is going to play an important role in this LLM AI world, with the perspective on ethics, what matters. Trust. These kinds of ideas, which have been embedded in great products are now going to have to be better than ever when it comes to this new kind of AI. If you think of the Triangle of Engineering, product and design for technology products where, you know, product really has to carry that business role, has to make money, has to grow, preferably. And engineering is playing the role of, does it work or does it not work? Does the bridge stand by itself? Okay, it worked. Design tends to be stuck in a role where, like, is the bridge pretty enough, which is sometimes pretty important when you’re competing against other bridges. It also plays an important role in, does it look like it’s not going to fall down? And or, you know I just discovered that a certain kind of stone really is not good to take from the earth. Is this bridge made of that kind of stone? Then I actually don’t want to cross it. And I think that design cares about these dimensions. Not just the aesthetics, the beauty, but the aesthetics of the ethics inside any experience you encounter, in a way that a product person doesn’t have to care about as much and an engineer doesn’t have to care about as much. They care about it, but it isn’t in their ‘jobs to be done’ list.

ELISE HU: Huh. Well, let’s talk about some of these ethical concerns. What would you say are the questions that researchers, designers, companies grappling with AI and its potential—what needs to be worked out still most pressingly?

JOHN MAEDA: Well, there’s so many levels to that. You know, like, I’m creating the new design and tech report for South by Southwest, and I look back at the last nine years.

ELISE HU: Yeah.

JOHN MAEDA: In 2017, I noticed that Microsoft was really high-centered around responsible AI, inclusive design. And there’s one value that’s fairly simple but important, is the value of transparency, not like just see through, but do I understand it? And I think at a very basic level, understanding large language model AI, how it actually works, scientists are still trying to figure that out. But even for the general person to help them understand how it works is an important thing for design to do.

ELISE HU: How will people be able to use, beyond just these chatbots right now, but other programs to increase their creativity and their productivity?

JOHN MAEDA: Ah. In this age of AI, there’s a simple way to be less fearful of it. Ask yourself, What do you not actually like doing in your job? Like, gather all that information into a chart or summarize it for my boss. Versus, What do you want to really keep? There are things that I enjoyed doing—thinking about the strategy of something and how it might unfold. Think of ways to be able to do things 10 times faster than I ever thought possible, therefore, I can actually do 10x more. So on one hand, greater productivity because you’re doing what you are most productive and excited about. And also productivity, like, hey, I didn’t want to do that thing in the first place. So it’s all gone.

ELISE HU: I understand you have a metaphor you’ve been using, a scissors metaphor, to talk about AI. What is it?

JOHN MAEDA: Oh, well, you know, I held on to this thing from my early days of trying to understand artificial intelligence in the eighties. This work, from a person named Herbert Simon, he’s a Carnegie Mellon AI legend, but interestingly, he received a Nobel Prize in economics. And he had this phrase that always stuck with me about how the way to think of intelligence is, it’s two blades of a scissor. One blade of the scissors is cognition, and the other blade is context. And when you slice, slice, slice those two together, rub them together, it creates what feels like intelligence, which is what’s happened with large language model AI.

ELISE HU: It’s not just cognition that computers can handle now, it’s context.

JOHN MAEDA: Well, this amazing cognition blade arrived. And now we can just, like, rub context against it. Like, I could take the last eight things we said to each other—the context—rub it against the cognition blade and say, Hey, what did we talk about?

ELISE HU: Yeah, sum up the themes of our conversation.

JOHN MAEDA: It does that. A cognition blade is like, ready to go, boss. And the context is just pouring our information on top of it. And voila.

ELISE HU: Is AI capable of creativity itself, or does it just facilitate human creativity?

JOHN MAEDA: The best way I’ve heard this technology described is, it’s like a parrot, but it’s an awfully good parrot. It doesn’t just repeat back things you said to it, it can repeat back things that a lot of people in the world have said. So is it creative on its own? No. Can it make you more creative? Well, the answer is, every time you expose yourself to new information, do you get more creative? Yeah. So it’s a way to accelerate your own creativity.

ELISE HU: Well, we are asking a variety of people like you, experts in their field, as well as civilians, how they’re using AI in just their everyday lives. So what is it for you?

JOHN MAEDA: Well, as you discover how to leverage this odd technology, you find that, wow, that’s easy. Like, I always use Python, the programming language Python, to do things fast. Like, oh, I’ve got to sort this document this way, I’m going to write a Python code or whatever. Now, I just give it to the model and say, Hey, this is all the stuff I have, the context. Can you now categorize these things? And it’s like magic, voila. Or I’m trying to figure this thing out and I want 10 different perspectives, so can you be someone who’s a botanist? Can you be someone who is a shopkeeper? So it’s like running user research studies very quickly.

ELISE HU: Yeah.

JOHN MAEDA: With fictional people, they’re better than a persona, actually. You can talk with them.

ELISE HU: Oh, that’s interesting. Do you have kind of a dream scenario for where things look two to five years from now?

JOHN MAEDA: I think that we’re already seeing elements of how this model-based work that we do, whether the model is language-based or it’s image-based or interaction-based, it’s going to affect how we do things. When we make images or image with text or video, basically everything we do to communicate, I think it’s going to make it a lot easier for us to do the part that we usually only do if we’re not tired, you know? I mean, how many things have you made where you’re like, Oh my gosh, all this planning, here I go, do it. Okay, I did it. Well, I’m really tired. I don’t know what it’s going to be like, but I feel like I’m going to do the part that I actually thought I should be doing at the very end, but I got too tired.

ELISE HU: I feel like it could increase our body of knowledge too, right, to be able to see so many things in different ways or look around the corners that we were too tired to look around.

JOHN MAEDA: Oh, 100 percent. This whole list of things that we can do better, that I keep asking myself, What do I not like to do now? What can I Marie Kondo out of my brain? And now what if I had more time? What would I do instead?

ELISE HU: Yeah. Okay, so let’s talk a little bit about leaders of organizations and leadership. What should leaders, or what could they do, to harness this potential of AI, not just for themselves, but also for their teams?

JOHN MAEDA: I think what’s really powerful for leaders is the ability to listen broadly. Because the only way for leaders to listen right now, generally speaking, is through one-on-ones, which do not scale.

ELISE HU: Those are just their lieutenants, though, right? It’s not a foot soldier.

JOHN MAEDA: Well, you know, the good leaders skip levels and actually break the rules and, like, talk to everyone. I like those kinds of leaders because it creates individual bonds of trust, which means the organization can usually move faster because of that. However, it takes a lot of time. So, ultimately, you have the other choice, which is surveys. As we know, the best part of those surveys is the fill-in-the-blank part. In the past we only had word clouds, but now, bosses can talk to all of that feedback and say, Tell me about the time I let you all down. Tell me about the time that you felt really proud to be here. So it’s like doing Q&A, 24/7.

ELISE HU: Yeah. And the potential for being able to take those learnings and apply them, or change direction or come up with a new vision, are really endless.

JOHN MAEDA: It basically lets them save time to do the part that they probably were hired to do, but they could never do because the logistics of being able to communicate through a hierarchy are tremendous, as you know.

ELISE HU: Okay. More broadly, John, you have spoken a lot on what corporations and corporate leaders can learn from entrepreneurs or more scrappy start-ups. What can they learn?

JOHN MAEDA: I felt that there are these start-up companies and there are the grown-up companies. And the irony is that start-ups want to end up like the grown-ups, but, you know, the grown-ups are always like, Gee, I wish I was a start-up again. So I think that both can learn from each other. But the biggest thing one can learn from an entrepreneur is proximity to the customer, because it’s like a car with no walls, barely wheels. It’s got a jagged steering wheel. It’s like, Ouch. And the customer’s like, hey, I don’t like this, all the time. Whereas if you’re in a large corporation, you’re kind of like in an SUV or a bus or a jumbo jet. And so you really can’t feel the customer and how they are experiencing what you’re providing to them. So, learn from entrepreneurs how to listen to the customer, and that goes to the beauty of these new LLM AI systems. It means that the CEO or any different level of a corporation can actually begin to talk with customers, effectively, 24/7—understand what they’re thinking from all the customer support data that they get, which if I were a customer support professional, I would think, Wow, thank goodness it’s not just me hearing this. It’s my boss, my boss’s boss, my boss’s boss. Entrepreneurs are great with customers and that’s where they’ll learn.

ELISE HU: Okay, so for the listeners out there who are excited about the potential of AI and a lot of the things that we have talked about, where should they start?

JOHN MAEDA: Well, they should first start by trying this stuff out. I think that I have presented to a variety of audiences of all sizes, and I’ll ask, Hey, you know, who’s used this thing, ChatGPT, before? Who uses it every day? Like, who’s never heard of it? And ultimately, there are those who have not heard of it. The second thing is to break that transparency barrier, because what people are afraid of is they don’t really understand it at all. I like to point out that the only letter you have to care about in C-H-A-T G-P-T is the P. The P stands for pre-trained . So what that means is you’re getting out-of-the-box, powerful machine learning. As you know, in the old days, the only way to get AIML was to have a lot of data, because you had to train it. What’s different this time is, it comes pre-trained. It’s like a puppy that arrives, like able to do everything. And so you’re freaked out. You’re like, Whoa, this AI comes pre-trained? And then once you get over that cognitive hurdle, you discover it can do a lot of things you didn’t expect. And so, try it out. Learn from it. Learn how prompts work, learn how context works. Take the scissor blades and start snip, snip, snipping. I think the other thing that’s actionable is to help everyone in their organization understand that change is always a scary thing. And this is a change that really is a giant blob of ketchup coming out, maybe the whole bottle came out all at once. And so the next reaction is like, Hey, I don’t like ketchup. Ketchup is not good for you. You know, that kind of feeling. And so every organization should ask the question. Let’s first understand it. Let’s try it. Let’s learn what the cons list are, like, pros and cons. Let’s look at the pros and just kind of adapt as quickly as possible to what we want to use and what we don’t want to use. Because this technology is much like the world wide web’s emergence. I’m not sure if you were like me, but when someone showed me a homepage, I was like, Nah, never going to take off. Like a month and a half later, well, gotta build a homepage. So it’s like that, I think.

ELISE HU: John, you mentioned that you are neuroatypical, and so many folks out there are. So I’d love to know what potential you see for AI and accessibility.

JOHN MAEDA: Well, I like the fact that I can talk to it and share things, and I can ask it, Hey, can you make that more sense to the majority of people? And I think that it is a wonderful translator and interpreter of things. I’m also high on the autistic spectrum, so sometimes I can’t read emotion very well. So I can ask it to tell me, like, what does this mean? Like what’s the downlow? And that’s extremely helpful.

ELISE HU: I love that. Okay. Thanks so much.

JOHN MAEDA: Well, thanks for having me.

ELISE HU: Thanks again to John Maeda. I loved that conversation. And that’s it for this episode of the WorkLab podcast from Microsoft. Please subscribe and check back for the next episode. If you’ve got a question you’d like us to pose to leaders, drop us an email at worklab@microsoft.com. And check out the WorkLab digital publication, where you will find transcripts of all our episodes, along with thoughtful stories that explore the ways we work today. You can find all of it at Microsoft.com/WorkLab. As for this podcast, please rate us, review, and follow us wherever you listen. It helps us out. The WorkLab podcast is a place for experts to share their insights and opinions. WorkLab is produced by Microsoft with Godfrey Dadich Partners and Reasonable Volume. I’m your host, Elise Hu. Mary Melton is our correspondent. Sharon Kallander and Matthew Duncan produced this podcast. Jessica Voelker is the WorkLab editor. Okay, until next time."
Microsoft_News,https://news.microsoft.com/europe/2023/04/20/working-with-microsoft-zegna-adds-ai-to-digital-toolkit-to-engage-clients/,,"Working with Microsoft, Zegna adds AI to digital toolkit to engage clients","Working with Microsoft, Zegna adds AI to digital toolkit to engage clients

Since 1910, the Italian fashion house Zegna has built its reputation on high-quality fabrics, particularly cashmere and wool, and a refined expression of elegance for men.

The company’s latest moves are accelerating its commitment to meeting the needs of clients where they live – which is more and more in the digital domain.

Zegna unveiled an upgraded version of its ZEGNA X system developed with Microsoft technology that personalizes the shopping experience using data tools and artificial intelligence (AI).

ZEGNA X 360 connects style consultants with customers online. The system allows for a personalized shopping experience using a 360 “configurator” that makes it possible to see how different combinations of clothing work together. The company also announced it was investing further in its relationship with Microsoft and working together to find ways to use AI in other aspects of its operations.

After a two-year trial period, the ZEGNA X system has already accounted for about 45 percent of revenue from Zegna boutiques, according to Edoardo Zegna, chief marketing, digital and sustainability officer of ZEGNA Group. Clients can order custom-tailored clothing and have the clothes delivered anywhere within four weeks, sometimes less.

We spoke to Zegna about how he sees the company adopting AI and other technologies to improve its client service, efficiency and commitment to sustainability. The conversation has been edited for clarity and length.

Did you imagine 10 years ago you would be doing this kind of bespoke tailoring using digital tools?

If you go back 15 years, there was this idea of luxury brands having a status or an ego. … There was this idea of ‘I am luxury, I am fashion, I’ll decide if I want to let you in or not.’ It made you almost intimidated to walk into a store.

I think this has shifted completely. I think the idea that we should be waiting for the customer is completely obsolete. Instead, we should be trying to be part of his life, and if we want to be part of his life we need to try to understand how he lives, what he likes, how he likes to be contacted.

Style consultants used to keep this information in a little notebook. The big shift happened 10 to 15 years ago when luxury companies decided to become data companies, creating ways to reach the customer as well as creating products for a specific customer.

How do you maintain the idea of luxury in the digital sphere?

It’s very personal contact. It’s less intimidating, it’s more like a connection you’re making. The way I like to see it is that there is a difference between “service” and “clientelling.” Service is about getting a product from place A to place B. Clientelling is about how are you going to make the customer feel unique, how are you going to make him feel important?

Zegna was one of the first fashion brands to embrace sustainability as an ethos, and to look for ways to cut waste. How does the use of new technology fit into that?

One of the reasons we’re working with Microsoft is how we can have AI help streamline and personalize.

Being able to predict at a higher rate the products that a customer may need will clearly create less waste. Ultimately transportation will happen way less. Instead of shipping clothing from a warehouse to the store, they can just ship from the warehouse.

How to make things sustainable goes through the entire value chain of the product. How can we be more and more net zero on the creation of every single product? That can extend to the way fabric is cut and to how waste fabric and thread can be reused.

What are your hopes for how AI could improve your operations?

Currently, we use Azure to do all our CRM (customer relation management), data gathering, reporting, analytics and predictive analytics as a whole. We will be moving all our IT infrastructure into the cloud starting in July.

But I think the next stage, and that is why we’re making this announcement, and this is why we’re working closely with Microsoft, is the next stages of personalization. … how do we improve the relationship with the customer. What is the likelihood of them responding to a short text or rather a long text? What sort of images do they respond to?

Lastly, we have committees working around production. How can we improve the efficiency of all of that based on timings of deliveries, optimization of spaces and so forth. AI is very much the future of basically every single industry I would say.

Is there a contradiction between Zegna’s dedication to its traditions and using cutting-edge technology?

I would say absolutely not. Ultimately there is magic in luxury, or in clothing, or in anything artistic. There is the power of emotion. And that emotion cannot be synthesized from an algorithm. It’s something that you have to give – on top of the sheer data that you have. The secret and the success are the combination of art and science. One doesn’t replace the other.

Top image: A virtual “fitting room” where customers can try on clothes in the virtual world. Photo by Zegna."
Microsoft_News,https://www.microsoft.com/en-us/worklab/work-trend-index/the-new-performance-equation-in-the-age-of-ai,,The New Performance Equation in the Age of AI,"Download the one pager The New Performance Equation in the Age of AI

A Amid economic uncertainty and the transition to flexible work, leaders are under pressure to increase productivity in flexible work and do more with less. At the same time, next-generation AI is changing the game for how organizations gain a competitive advantage. In this dynamic environment, employee engagement may not seem like a priority. New research tells a different story. mid economic uncertainty and the transition to flexible work, leaders are under pressure to increase productivity in flexible work and do more with less. At the same time, next-generation AI is changing the game for how organizations gain a competitive advantage. In this dynamic environment, employee engagement may not seem like a priority. New research tells a different story.

To help understand the ongoing business impact of engagement—and what drives it—we analyzed surveys of more than three million employees at more than 200 companies across industries and looked at the combined stock price movement of these companies throughout 2022.

The findings are clear. High employee engagement correlates with stronger financial performance. And companies with highly engaged employees focus on two things: they create clarity via intentional employee communications and goal setting, and they use data to build a powerful “feedback flywheel” to continuously improve over time.

Companies with highly engaged workforces had better financial outcomes, outperforming the S&P 500 after a year.

The analysis shows that employee engagement is a key part of the performance equation. To move the bottom line, we need more than productivity alone. Think of engagement and productivity as mutually reinforcing, with one multiplying the other: When you are engaged in your work, you are more productive. When you are productive, you are more engaged in your work.

Let’s take a closer look.

Three key findings:

Employee engagement matters to the bottom line—especially amid economic uncertainty. Clear communications and goals unlock employee engagement. To sustain engagement, build a feedback flywheel.

The new performance equation Both engagement and productivity drive performance—and they are mutually reinforcing Illustration by Valerio Pellegrini

1. Employee engagement matters to the bottom line—especially amid economic uncertainty.

Research shows that organizations that doubled down on employee engagement in times of economic uncertainty performed twice as well financially as organizations that deprioritized it—with the most engaged outperforming the S&P 500 at the end of the year. On average, each additional point of engagement reported by employees correlated with a +$46,511 difference in market cap per employee. Put simply, companies with highly engaged workforces had better financial outcomes. Leaders need to treat employee engagement with the same strategic importance as business and financial outcomes.

Engagement Is Critical to Your Bottom Line A comparison of 2022 financial portfolio returns of the top 10% highest engagement scoring companies against the bottom 10% lowest engagement scoring companies shows that highly engaged companies outperformed the least engaged companies. Engagement levels determined by employee survey responses from over three million employees, collected from January 1, 2022 to December 31, 2022, which were analyzed for employee sentiment. Illustration by Valerio Pellegrini

Take action:

Measure and report on employee engagement as you do financial metrics—in town halls, at board meetings, and in annual reports.

Adopt an organization-wide manager framework that helps leaders develop skills and adopt a growth mindset around engagement.

Communicate that engagement is a business imperative—for instance, by creating an engagement-related goal for managers.

Give managers access to data to help them take action on improving communication, employee engagement, and productivity.

Adopt a digital employee experience that leverages next-generation AI and data-driven insights.

2. Clear communication and goals unlock employee engagement.

In a more distributed, flexible work world, managers and leaders lack the skills and tools to communicate, mobilize, and engage people effectively—and those skills and tools are more critical than ever. At the least engaged organizations, nearly one in four employees are not sure what they should focus on. On the flip side, employees at highly engaged organizations are 46 percent more likely to see their organizations as strong communicators, 37 percent more likely to express confidence in leadership, and 16 percent more likely to be clear on what to focus on than the least engaged organizations. Clear communication also has an impact on retention. Employees who report that their company does a bad job of communicating are twice as likely to leave their organization compared with employees who cite good communication.

To respond, leaders need to provide intentional communication that meets people where they are—in the flow of work. As our data has shown previously, clarity is key. Without it, employees face challenges in prioritizing work and they lose sight of why their work matters.

“Employees at highly engaged organizations are 46% more likely to see their organizations as strong communicators. ”

Take action:

Create clear priorities at the leadership level and use goals like OKRs to help everyone focus on those priorities. Equip leaders with modern communication tools that meet employees where they are in the flow of work. Use next-generation AI and data-driven analytics to increase the effectiveness of communications.

3. To sustain engagement, build a feedback flywheel.

To build and sustain engagement, leaders need agile and ongoing systems for gathering and responding to employee feedback and driving change. Employees at highly engaged organizations are 40 percent more likely to have confidence that their feedback will lead to action, and they’re 56 percent more likely to say their organizations continually improve processes. Diversity of opinion matters—a key differentiator between organizations with high and low engagement is whether employees feel that diverse perspectives are valued.



On their own, traditional linear feedback systems are no longer enough to get a pulse on how employees are doing and improve organizational processes over time. The key is to combine employee feedback with behavioral data from productivity and collaboration signals and sentiment in communities to build a “feedback flywheel”—a continuous loop in which this rich combination of data is gathered, analyzed, and turned into actions that get communicated back to employees and implemented across the organization.

Take action:

Make sure your listening strategy is comprehensive—incorporate relevant direct and indirect signals. Leverage AI to analyze the data collected, gain a more thorough understanding of patterns, and accelerate time to action. Empower managers to create their own feedback flywheels to drive meaningful change within their teams, and ensure key metrics are in place to measure impact. Set accountability measures that help employees trust that action will be taken. Be transparent about how feedback will be used, and provide clear next steps.

The way forward

This latest research shows definitively what many leaders know intuitively: a workforce that is energized and empowered is more likely to be productive and high performing. As next-generation AI begins to change the talent landscape and re-engineer skilling for the workforce, the winners in both the financial and labor markets will be the organizations that take critical action now."
Microsoft_News,https://news.microsoft.com/source/features/digital-transformation/how-truveta-is-using-data-and-ai-to-improve-patient-care-and-save-lives/,,How Truveta is using data and AI to improve patient care and save lives,"The team of researchers sought answers to an important question: How often do women in the United States who have preeclampsia — high blood pressure during pregnancy — also experience heart failure, and does race factor into the situation?

Fewer than three weeks after launching their study, the researchers at Truveta, a collective of U.S. health systems, uncovered a startling finding: Black women are twice as likely to experience preeclampsia-related heart failure as white women.

Previous research had linked preeclampsia to heart failure, but the Truveta study, which included data on almost 500,000 women, was the first to uncover the extent of the danger facing Black women with the condition.

Conducting that type of research would typically take months, possibly more than a year, to gather the data and secure the necessary permissions, says Charlotte Baker, lead researcher on the study.

Charlotte Baker.

“It was unbelievably fast,” says Baker, Truveta’s director of epidemiology. “And that means we were able to get those answers and immediately start discussions with clinicians about what we should do about this issue and how we should use this information.”

Such is the promise of Truveta, a Bellevue, Washington-based company founded in 2020 with a mission of saving lives with data. Its health data and analytics solution, Truveta Studio, includes complete and de-identified medical data from more than 80 million patients served by Truveta’s 28 health system members, which operate more than 20,000 clinics and 700 hospitals across the United States.

Health care data is often fragmented, inaccessible and messy, making research slow and cumbersome. Much of the available data on patients comes from insurance claims and does not provide a comprehensive view of overall health. The data might identify that a patient had a procedure but say nothing about the outcome, or confirm a diagnosis but provide no information about symptoms.

Truveta trained a large language model to aggregate data from 28 leading health systems in the U.S., including complete information from patients’ electronic health records — from diagnoses to medications and test results — to provide a representative view of patient care across the United States. This data is combined with data on mortality, social drivers of health and claims data to provide a complete, de-identified picture of a patient’s journey.

Truveta Studio includes complete and de-identified medical data from more than 80 million patients across the U.S.

Using Truveta Studio, which is built on Azure and updated daily, researchers can quickly gain insights on almost any medical condition, drug or device, and drill down to focus on a specific patient population.

The platform de-identifies patient data and uses Truveta’s AI model to standardize the diverse medical terminology used by doctors and health systems — COVID-19, for example, can be defined in many terms and with different codes, making it difficult for researchers to capture a patient population without knowing what those various definitions are.

AI also enables Truveta to access the rich information that is normally locked in clinician’s notes, critical details such as a patient’s disease progression, symptoms and response to medication. A data set might include a medication a patient took and a resulting side effect, but the two factors would not be linked in the data, only in a doctor’s note. Truveta Studio so far includes more than 2.5 billion of those notes and the number is quickly growing.

Click here to load media

“Having that information from clinical notes available to search will be game-changing,” says Dr. Guilford Parsons, chief of operational analytics at Providence, one of Truveta’s founding members. “That’s the kind of information that we don’t see unless we have access to notes or entities extracted from the notes. There just isn’t a place other than the notes that you can reliably find that.”

Truveta has announced partnerships with biopharma giant Pfizer for COVID research and medical device manufacturer Boston Scientific, which is using Truveta data to gain insights on various devices and conditions, including peripheral artery disease.

Truveta’s own research team has released studies on a range of timely issues, including the link between long COVID-19 and mental health, rates of respiratory syncytial virus (RSV) hospitalization, and in the wake of Buffalo Bills defensive back Damar Hamlin’s on-field collapse in January 2023, a look at how often cardiac arrest occurs while playing sports. The latter study, Baker says, was done in less than a week.

Truveta, based in Bellevue, Washington, was founded in 2020 with four initial health system members.

“In my previous life as an academic researcher, it would have taken me more than three years to answer that question,” she says. “I happen to know that because I was working on a similar question.”

Truveta started as an idea within Providence around 2018 to compile a data set from health care providers and make it available to researchers. The need for better health data became starkly evident during the early days of the coronavirus pandemic, when a lack of timely information made it hard to know how to treat COVID-19 patients.

“We were in hospitals treating a lot of patients with essentially no data,” says Dr. Nick Stucky, Truveta’s vice president of research and a practicing infectious diseases doctor and researcher at Providence. “Essentially, we were flying blind for quite a while. That really accelerated the creation of Truveta.”

For Stucky, the granularity and scale of Truveta’s data offers tremendous value for understanding infectious diseases; as a physician, he also sees potential for Truveta to provide insights and inform clinical decision-making.

Nick Stucky.

“We’re all seeing part of the whole puzzle, but there’s so much value in the large data set to be able to see the whole of the system,” he says. “Time is patient life, and the way this can accelerate findings is going to save lives.”

Terry Myerson, Truveta’s CEO and a former Microsoft executive, co-founded the company in 2020 with Providence, Advocate Health, Tenet Health and Trinity Health. Other health systems quickly got on board, and the company launched Truveta Studio in November 2022, making the platform available to health systems and life sciences researchers.

To develop its AI model, Truveta hired a team of informaticists and medical terminologists, clinicians across multiple disciplines, to train and validate it. Truveta’s model is now smart enough to apply natural language processing to clinician notes to recognize relationships between concepts. A researcher studying heart disease, for example, could see when a particular medication is not working or when medical images show changes that could require a different treatment.

Guilford Parsons.

By normalizing medical terminology across health systems, Truveta enables health systems to collaborate, Parsons says, and to conduct their own research with a much larger patient population. He mentions a study that Providence, which operates 51 hospitals across five Western states, released in 2021 on the rare side effects of myocarditis and pericarditis, types of heart inflammation, following COVID-19 vaccinations.

“If we had done that study on Truveta, we probably would have been able to publish even faster and across a greater population,” Parsons says. “Truveta has done a great job of normalizing the data types that are always at high risk for incompatibility, especially if you look across our different systems.”

Truveta is aiming to help researchers study patient care and improve health disparities. The company was intentional about bringing on health system members that represent racially and ethnically diverse populations across all 50 states and includes social drivers of health (SDOH) in its data. Truveta recently expanded its data set to 45 SDOH attributes including housing stability, education and social support.

Mitchell Cornet, vice president of public health, community vaccines and strategic partnerships for New York-based Northwell Health, a Truveta member, says including those determinants in Truveta’s data is key to understanding the circumstances that can impact overall health. A woman who doesn’t have transportation, he points out, will have a harder time getting to doctor’s visits than a woman who does, and is therefore less likely to get sufficient prenatal care.

Mitchell Cornet.

“Having SDOH in Truveta’s data is going to be beneficial for researchers because they’re going to see what some of these intrinsic factors are that could potentially be leading what the data tells you,” he says. “I think that’s critical. Truveta is a voice for those who can’t be heard, because they have a platform that thousands and thousands of people can access.”

Truveta’s research team is now expanding its study on preeclampsia-related heart failure to look at how factors such as disability or the number of children women have might impact their risk. The issue is a personal one for Truveta’s Baker, who lost a friend and colleague to the condition shortly after giving birth.

Truveta, Baker says, has been able to combine technical knowhow with clinical expertise to provide a large-scale data set that can be used across health systems, life sciences, government and academia to improve the health of Americans.

“Truveta has this unique share of data that is really going to be the difference-maker in how we move forward clinical medicine and public health, and I think it’s overdue,” she says. “I’m fascinated to get to answer some questions with that information and be able to make a difference. That’s what we’re there for — saving lives with data.”

MEDICAL DEVICE DISCLAIMER: Microsoft Azure, including any of its component technologies, is intended for general-purpose use and is not intended or made available: (1) as a medical device; (2) for the diagnosis of disease or other conditions, or in the cure, mitigation, treatment or prevention of a disease; or (3) as a substitute for the professional clinical advice, opinion, or judgment of a treating healthcare professional. Microsoft Azure has not been evaluated by the U.S. FDA or similar regulatory agency as a medical device, and users of Microsoft Azure are responsible for ensuring the regulatory compliance of their use or any solution they build using Microsoft Azure.

Top photo by Getty Images E+ collection. All other photos courtesy of Truveta and Northwell Health."
Microsoft_News,https://news.microsoft.com/2023/04/17/microsoft-and-epic-expand-strategic-collaboration-with-integration-of-azure-openai-service/,,Microsoft and Epic expand strategic collaboration with integration of Azure OpenAI Service,"Microsoft and Epic expand strategic collaboration with integration of Azure OpenAI Service

REDMOND, Wash., and VERONA, Wis. — April 17, 2023 — Microsoft Corp. and Epic on Monday announced they are expanding their long-standing strategic collaboration to develop and integrate generative AI into healthcare by combining the scale and power of Azure OpenAI Service1 with Epic’s industry-leading electronic health record (EHR) software. The collaboration expands the long-standing partnership, which includes enabling organizations to run Epic environments on the Microsoft Azure cloud platform.

This co-innovation is focused on delivering a comprehensive array of generative AI-powered solutions integrated with Epic’s EHR to increase productivity, enhance patient care and improve financial integrity of health systems globally. One of the initial solutions is already underway, with UC San Diego Health, UW Health in Madison, Wisconsin, and Stanford Health Care among the first organizations starting to deploy enhancements to automatically draft message responses.

“A good use of technology simplifies things related to workforce and workflow,” said Chero Goswami, chief information officer at UW Health. “Integrating generative AI into some of our daily workflows will increase productivity for many of our providers, allowing them to focus on the clinical duties that truly require their attention.”

Another solution will bring natural language queries and interactive data analysis to SlicerDicer, Epic’s self-service reporting tool, helping clinical leaders explore data in a conversational and intuitive way.

“Our exploration of OpenAI’s GPT-4 has shown the potential to increase the power and accessibility of self-service reporting through SlicerDicer, making it easier for healthcare organizations to identify operational improvements, including ways to reduce costs and to find answers to questions locally and in a broader context,” said Seth Hain, senior vice president of research and development at Epic.

Leading industry experts have highlighted the urgent need for health systems and hospitals to address intense pressures on costs and margins. Approximately half of U.S. hospitals finished 2022 with negative margins as widespread workforce shortages and increased labor expenses, as well as supply disruptions and inflationary effects, caused expenses to meaningfully outpace revenue increases.2 Industry participants recognize that achieving long-term financial sustainability through increased productivity and technological efficiency is a mission-critical strategic priority.3

“The urgent and critical challenges facing healthcare systems and their providers demand a comprehensive approach combining Azure OpenAI Service with Epic’s industry-leading technology,” said Eric Boyd, corporate vice president, AI Platform, Microsoft. “Our expanded partnership builds on a long history of collaboration between Microsoft, Nuance and Epic, including our work to help healthcare organizations migrate their Epic environments to Azure. Together we can help providers deliver significant clinical and business outcomes leveraging the power of the Microsoft Cloud and Epic.”

When creating technologies that can change the world, Microsoft believes organizations need to ensure that the technology is used responsibly. Microsoft is committed to creating responsible AI by design that is guided by a core set of principles: fairness, reliability and safety, privacy and security, inclusiveness, transparency, and accountability. Microsoft is putting those principles into practice across the company to develop and deploy AI that will have a positive impact on society, taking a cross-company approach through cutting-edge research, best-of-breed engineering systems, and excellence in policy and governance.

Visit the Microsoft, Nuance and Epic booths at the 2023 HIMSS Global Health Conference in Chicago to learn more about new and enhanced AI-powered solutions and areas of shared innovation.

About Epic

Epic develops software to help people get well, help people stay well, and help future generations be healthier. Visit www.epic.com/about.

About Microsoft

Microsoft (Nasdaq “MSFT” @microsoft) enables digital transformation for the era of an intelligent cloud and an intelligent edge. Its mission is to empower every person and every organization on the planet to achieve more.

1 Azure and Azure OpenAI Service, including any of its component technologies, is intended for general-purpose use and is not intended or made available: (1) as a medical device; (2) for the diagnosis of disease or other conditions, or in the cure, mitigation, treatment or prevention of a disease; or (3) as a substitute for the professional clinical advice, opinion, or judgment of a treating healthcare professional. Azure and Azure OpenAI Service has not been evaluated by the U.S. FDA or similar regulatory agency as a medical device, and users of Azure and Azure OpenAI Service are responsible for ensuring the regulatory compliance of their use or any solution they build using Azure and Azure OpenAI

2 “National Hospital Flash Report,” report by Kaufman Hall, January 2023; “The Current State of Hospital Finances: Fall 2022 Update,” report by the American Hospital Association, Sept. 15, 2022

3 “Health Care Has a Purpose and Productivity Crisis,” report by Boston Consulting Group, Dec. 5, 2022; “2023 forecast: 7 immediate and long-term priorities for hospital leaders,” Fierce Healthcare, Dec. 21, 2022; “Positioning for Competitive Advantage and Financial Resilience,” Health Management Academy, February 2022

For more information, press only:

Microsoft Media Relations, WE Communications for Microsoft, (425) 638-7777, [email protected]

Anna McCann, Epic Systems, (608) 271-9000, [email protected]

Note to editors: For more information, news and perspectives from Microsoft, please visit the Microsoft News Center at http://news.microsoft.com. Web links, telephone numbers and titles were correct at time of publication but may have changed. For additional assistance, journalists and analysts may contact Microsoft’s Rapid Response Team or other appropriate contacts listed at https://news.microsoft.com/microsoft-public-relations-contacts."
Microsoft_News,https://blogs.bing.com/search/april-2023/Easily-access-the-new-AI-powered-Bing-across-your-favorite-mobile-apps,,Easily access the new AI-powered Bing across your favorite mobile apps,"SwiftKey: Chat, Search, and Tone

Bing App: gender debias in translator functionality

Skype: expanded access to the new Bing in group chats

Microsoft Start: another way to experience the new Bing

Bing recently hit 100M daily users (and 100M chats )! Today, we’re excited to share new AI-powered experiences that extend these capabilities to millions of additional people across devices and around the globe!In recent weeks, we’ve added a variety of new ways to access and interact with the new Bing. Today, we are announcing yet another, with powerful updates to SwiftKey that put the Bing AI experience one touch away across any iOS or Android mobile experience that supports a third-party keyboard.An updated SwiftKey represents a growing set of access points and improvements to Bing experiences, including new updates to existing app integrations spanning Bing, Skype, Microsoft Start, and Microsoft Edge apps.SwiftKey has been part of the Microsoft family since 2016. It has millions of users around the world who love it for its AI-powered predictive text technology, which makes texting without typos easier, even when you’re in a rush or multi-tasking. Upon download, SwiftKey lets you set it as your default keyboard on both iOS and Android (the app includes easy-to-follow instructions to help you get there in just a few steps), so you can access it across all your favorite apps, from email apps to social media and more. SwiftKey lets you choose up to five languages to integrate into your keyboard.Bing integrates in three major ways – Search, Chat, and Tone. The update is available today. Once you’ve got the update, you’ll see the Bing icon above the keyboard. From there you can click on the exact feature you’d like to use; Chat, Tone, or Search.With the Chat functionality, you can access the new Bing on the go for more detailed queries. It can help if everybody’s cracking jokes in the chat and you need a clever pun, or you’re new to the area and are texting some new friends to propose a good local restaurant.With the Tone feature, you can communicate more effectively by using AI to customize your in-progress text to fit any situation. Whether you struggle to be formal in your work emails, or you’re learning a new language and want help with the nuances of word choice, the Tone feature has got you covered, with tones to make your words sound more professional, casual, polite, or concise enough for a social post.With the Search functionality, you can quickly search the web from your keyboard, without switching apps. This can help while you’re talking to a friend and mid-conversation, you want to look up relevant information like the weather, restaurants near you, or stock prices.These new features in SwiftKey are accessible in all markets where the new Bing is available; anyone can use Search now, while accessing Tone and Chat requires that you sign into your Microsoft Account that has been approved to access the new Bing preview.The translator functionality in the mobile Bing app now offers alternative masculine and feminine translations when translating from English to Spanish, French, or Italian, to promote inclusivity and to avoid gender bias. This feature allows users to choose the gendered translation that best fits their context and is helpful for well-intentioned speakers of all proficiency levels.As we recently announced , the new Bing is in Skype! Since that release we’ve expanded access, so everyone in a group can chat with the new Bing in the context of that conversation; only one person in the group needs to have access to the preview!This means as a group you can use the new Bing from within the Skype app just like you’d use the new Bing on desktop; you can use it to, for example, settle a debate, help plan a group trip, or find a restaurant for you all to meet at in person. To get started, search for ‘Bing in Skype’ in your Skype contacts and add it to a group chat, just like you would any other contact!Just like on desktop, the new Bing chat responses in the Skype app which reference facts are cited with web links to sources, so you can double-check where the information is coming from.These updates are available in all markets where the new Bing is available.The new Bing is now available via the Microsoft Start app too, for users who have cleared the waitlist . The Start app keeps you up to speed on the things you care about, all in one app. The personalized news feed, including premium content from hundreds of global publishers, keeps you informed and entertained, and the sports scores, weather forecasts, stock prices, shopping deals and more give you everything you need to know to start your day.We rely on so many mobile apps in our daily lives whether it be for work, personal needs, and everything in between, so we want to put AI-powered Bing features at your fingertips in ways that mean the most to you.We hope you’re as excited by these updates as we are and as always, we appreciate your feedback!Divya Kumar – Sr. Director, Search & AI Marketing"
Microsoft_News,https://news.microsoft.com/europe/features/in-france-schools-warm-to-systems-with-ai-that-increase-comfort-reduce-energy-use/,,"In France, schools warm to systems with AI that increase comfort, reduce energy use","About 470 students between the ages of 11 and 15 attend the College Pierre de Ronsard in the small Loire Valley town of Mer. In terms of French school buildings, this one is newer and more energy efficient than most.

The 11-year-old middle school is well-insulated, and has windows with double-pane glass.

But it wasn’t always comfortable inside. For many years, because of a strong north-south exposure, it was impossible to maintain consistent temperature room-by-room.

Tania Julien, building manager at College Pierre de Ronsard in Mer, France. Photo by Chris Welsch for Microsoft.

“We couldn’t regulate the heating,” says Tania Julien, the building manager. “Sometimes part of the building was too hot, sometimes too cold.”

In its efforts to create a comfortable learning environment for students and teachers, the school became a pioneer in using “smart building” technology. After a process of trial and error and much improvement in technology, the school has become a strong example of how the Internet of Things (IoT) and predictive artificial intelligence (AI) can not only make buildings more comfortable but achieve significant energy savings.

Sebastien Depeyre is the director of buildings for the department of Loir-and-Cher in central France (a French department is something like a state). To address the problems at the school, he agreed to work together with Vertuoz, a subsidiary of the French company ENGIE, in installing and refining a new system to regulate the temperature room-by-room.

“Our objective was not so much to save energy,” recalls Depeyre, “but really to make it comfortable to use.”

According to the European Commission, about 40 percent of all energy consumed goes into heating and lighting buildings in Europe, and about 75 percent of them are energy inefficient, meaning much of that energy is wasted. The story of the College Pierre de Ronsard is instructive: Its experiment in smart-building technology not only addressed the issue of comfort but saved more than 20 percent per year on its energy bill.

The process was not always smooth. “We went through a bit of a rough patch at first. It was a little difficult because there were things we had to build together, but that was part of the game and part of the value in having a partner,” Depeyre says.

To achieve control of the heat room-by-room, the school installed wireless, battery-free sensors to detect temperature and the presence of people in every room, and wireless controls on each radiator so that they can be operated remotely. In the first version of the system, the sensors sent data via radio waves to a computer and control system on site, which was adjusted manually.

A few years after the first version was installed, the system is much refined. The data makes its way the cloud platform where a system designed by Vertuoz uses Azure IoT and machine learning to monitor and adjust the atmosphere in the building room-by-room. If no one is present, the heat lowers. In an occupied classroom, a steady 19 degrees Celsius (66 degrees Fahrenheit) is produced, keeping students and teachers comfortable. Ventilation can also be adjusted to improve air quality.

Sebastien Depeyre, director of buildings for the Department of Loir-et-Cher. Photo by Chris Welsch for Microsoft.

“Above all, it’s an AI system that says, well, I know that part of the building reacts this way, and another that way. We give it objectives and it knows what to do,” Depeyre says.

Now, Vertuoz Control systems, like the one at the College Pierre de Ronsard, have been installed in more than 350 buildings in France, and Vertuoz is monitoring more than 90,000 buildings. According to Frederic Gailliot, marketing director for Vertuoz , the use of Vertuoz solutions saves about 250,000 tons of carbon dioxide emissions each year. The company says the average energy savings is about 25 percent, and those savings pay for the cost of the system within three to five years.

Gailliot says about one third of public buildings in Europe are schools, and many of them were built before high standards of energy efficiency were written into building codes. Solutions like Vertuoz Control can deliver results without the expense or time required to renovate.

“The problem is, how do you create value in the short term?” he asks. “The digital solutions are an incredible response to the current challenges for global energy efficiency.”"
Microsoft_News,https://news.microsoft.com/de-de/siemens-and-microsoft-drive-industrial-productivity-with-generative-artificial-intelligence/,,Siemens and Microsoft drive industrial productivity with generative artificial intelligence,"Siemens and Microsoft drive industrial productivity with generative artificial intelligence

Siemens’ new Teamcenter app for Microsoft Teams to use AI, boosting productivity and innovation throughout a product lifecycle.

Azure OpenAI Service powered assistant can augment the creation, optimization and debugging of code in software for factory automation.

Industrial AI to enable visual quality inspection on the shop floor.

Siemens and Microsoft are harnessing the collaborative power of generative artificial intelligence (AI) to help industrial companies drive innovation and efficiency across the design, engineering, manufacturing and operational lifecycle of products. To enhance cross-functional collaboration, the companies are integrating Siemens’ Teamcenter® software for product lifecycle management (PLM) with Microsoft’s collaboration platform Teams and the language models in Azure OpenAI Service as well as other Azure AI capabilities. At Hannover Messe, the two technology leaders will demonstrate how generative AI can enhance factory automation and operations through AI-powered software development, problem reporting and visual quality inspection.

“The integration of AI into technology platforms will profoundly change how we work and how every business operates,” said Scott Guthrie, executive vice president, Cloud + AI, Microsoft. “With Siemens, we are bringing the power of AI to more industrial organizations, enabling them to simplify workflows, overcome silos and collaborate in more inclusive ways to accelerate customer-centric innovation.”

Connecting shop floor workers with teams across business functions through AI-powered collaborative apps

With the new Teamcenter app for Microsoft Teams, anticipated later in 2023, the companies are enabling design engineers, frontline workers and teams across business functions to close feedback loops faster and solve challenges together. For example, service engineers or production operatives can use mobile devices to document and report product design or quality concerns using natural speech. Through Azure OpenAI Service, the app can parse that informal speech data, automatically creating a summarized report and routing it within Teamcenter to the appropriate design, engineering or manufacturing expert. To foster inclusion, workers can record their observations in their preferred languages which is then translated into the official company language with Microsoft Azure AI. Microsoft Teams provides user-friendly features like push notifications to simplify workflow approvals, reduce the time it takes to request design changes and speed up innovation cycles. The Teamcenter app for Microsoft Teams can enable millions of workers who do not have access to PLM tools today to impact the design and manufacturing process more easily as part of their existing workflows.

Keeping factories running with AI-powered automation software engineering

Siemens and Microsoft are also collaborating to help software developers and automation engineers accelerate the code generation for Programmable Logic Controllers (PLC), the industrial computers that control most machines across the world’s factories. At Hannover Messe, the companies are demonstrating a concept for how OpenAI’s ChatGPT and other Azure AI services can augment Siemens’ industrial automation engineering solutions. The showcase will highlight how engineering teams can significantly reduce time and the probability of errors by generating PLC code through natural language inputs. These capabilities can also enable maintenance teams to identify errors and generate step-by-step solutions more quickly.

“Powerful, advanced artificial intelligence is emerging as one of the most important technologies for digital transformation,” said Cedrik Neike, Member of the Managing Board of Siemens AG and CEO Digital Industries. “Siemens and Microsoft are coming together to deploy tools like ChatGPT so we can empower workers at enterprises of all sizes to collaborate and innovate in new ways.”

Finding and preventing product defects with industrial AI

Detecting defects in production early is critical to prevent costly and time-consuming production adjustments. Industrial AI like computer vision enables quality management teams to scale quality control, identify product variances easier and make real-time adjustments even faster. In Hanover, teams will demonstrate how, using Microsoft Azure Machine Learning and Siemens’ Industrial Edge, images captured by cameras and videos can be analyzed by machine learning systems and used to build, deploy, run and monitor AI vision models on the shop floor.

This collaboration is part of the longstanding strategic relationship between Siemens and Microsoft, built on over 35 years of joint innovation with thousands of customers. Other areas of collaboration include Senseye on Azure, enabling companies to run predictive maintenance at enterprise scale and support for customers that seek to host their business applications in the Microsoft Cloud to run solutions from the Siemens Xcelerator open digital business platform, including Teamcenter, on Azure. Siemens is also partnering with Microsoft as part of its zero trust strategy.

Contact for journalists

Microsoft Media Relations: WE Communications for Microsoft, (425) 638-7777, [email protected]

Siemens Digital Industries Software PR Team: [email protected]

About Microsoft

Microsoft (Nasdaq “MSFT” @microsoft) enables digital transformation for the era of an intelligent cloud and an intelligent edge. Its mission is to empower every person and every organization on the planet to achieve more.

Tags: artificial intelligence, Azure OpenAI, ChatGPT, Collaboration, Hannover Messe, Manufacturing, Microsoft Teams, Siemens"
Microsoft_News,https://www.microsoft.com/en-us/research/blog/building-toward-more-autonomous-and-proactive-cloud-technologies-with-ai/,,Building toward more autonomous and proactive cloud technologies with AI,"Cloud Intelligence/AIOps blog series

In the first blog post in this series, Cloud Intelligence/AIOps – Infusing AI into Cloud Computing Systems, we presented a brief overview of Microsoft’s research on Cloud Intelligence/AIOps (AIOps), which innovates AI and machine learning (ML) technologies to help design, build, and operate complex cloud platforms and services effectively and efficiently at scale. As cloud computing platforms have continued to emerge as one of the most fundamental infrastructures of our world, both their scale and complexity have grown considerably. In our previous blog post, we discussed the three major pillars of AIOps research: AI for Systems, AI for Customers, and AI for DevOps, as well as the four major research areas that constitute the AIOps problem space: detection, diagnosis, prediction, and optimization. We also envisioned the AIOps research roadmap as building toward creating more autonomous, proactive, manageable, and comprehensive cloud platforms.

Vision of AIOps Research

Autonomous Proactive Manageable Comprehensive Fully automate the operation of cloud systems to minimize system downtime and reduce manual efforts. Predict future cloud status, support proactive decision-making, and prevent bad things from happening. Introduce the notion of tiered autonomy for infusing autonomous routine operations and deep human expertise. Span AIOps to the full cloud stack for global optimization/management and extend to multi-cloud environments.

Starting with this blog post, we will take a deeper dive into Microsoft’s vision for AIOps research and the ongoing efforts to realize that vision. This blog post will focus on how our researchers leveraged state-of-the-art AIOps research to help make cloud technologies more autonomous and proactive. We will discuss our work to make the cloud more manageable and comprehensive in future blog posts.

Autonomous cloud

Motivation

Cloud platforms require numerous actions and decisions every second to ensure that computing resources are properly managed and failures are promptly addressed. In practice, those actions and decisions are either generated by rule-based systems constructed upon expert knowledge or made manually by experienced engineers. Still, as cloud platforms continue to grow in both scale and complexity, it is apparent that such solutions will be insufficient for the future cloud system. On one hand, rigid rule-based systems, while being knowledge empowered, often involve huge numbers of rules and require frequent maintenance for better coverage and adaptability. Still, in practice, it is often unrealistic to keep such systems up to date as cloud systems expand in both size and complexity, and even more difficult to guarantee consistency and avoid conflicts between all the rules. On the other hand, engineering efforts are very time-consuming, prone to errors, and difficult to scale.

Microsoft Research Podcast Collaborators: Holoportation™ communication technology with Spencer Fowers and Kwame Darko Spencer Fowers and Kwame Darko break down how the technology behind Holoportation and the telecommunication device being built around it brings patients and doctors together when being in the same room isn’t an easy option and discuss the potential impact of the work. Listen now Opens in a new tab

To break the constraints on the coverage and scalability of the existing solutions and improve the adaptability and manageability of the decision-making systems, cloud platforms must shift toward a more autonomous management paradigm. Instead of relying solely on expert knowledge, we need suitable AI/ML models to fuse operational data and expert knowledge together to enable efficient, reliable, and autonomous management decisions. Still, it will take many research and engineering efforts to overcome various barriers for developing and deploying autonomous solutions to cloud platforms.

Toward an autonomous cloud

In the journey towards an autonomous cloud, there are two major challenges. The first challenge lies in the heterogeneity of cloud data. In practice, cloud platforms deploy a huge number of monitors to collect data in various formats, including telemetry signals, machine-generated log files, and human input from engineers and users. And the patterns and distributions of those data generally exhibit a high degree of diversity and are subjected to changes over time. To ensure that the adopted AIOps solutions can function autonomously in such an environment, it is essential to empower the management system with robust and extendable AI/ML models capable of learning useful information from heterogeneous data sources and drawing right conclusions in various scenarios.

The complex interaction between different components and services presents another major challenge in deploying autonomous solutions. While it can be easy to implement autonomous features for one or a few components/services, how to construct end-to-end systems capable of automatically navigating the complex dependencies in cloud systems presents the true challenge for both researchers and engineers. To address this challenge, it is important to leverage both domain knowledge and data to optimize the automation paths in application scenarios. Researchers and engineers should also implement reliable decision-making algorithms in every decision stage to improve the efficiency and stability of the whole end-to-end decision-making process.

Over the past few years, Microsoft research groups have developed many new models and methods for overcoming those challenges and improving the level of automation in various cloud application scenarios across the AIOps problem spaces. Notable examples include:

Detection: Gandalf and ATAD for the early detection of problematic deployments; HALO for hierarchical faulty localization; and Onion for detecting incident-indicating logs.

Diagnosis: SPINE and UniParser for log parsing; Logic and Warden for regression and incident diagnosis; and CONAN for batch failure diagnosis.

Prediction: TTMPred for predicting time to mitigate incidents; LCS for predicting the low-capacity status in cloud servers; and Eviction Prediction for predicting the eviction of spot virtual machines.

Optimization: MLPS for optimizing the reallocation of containers; and RESIN for the management of memory leak in cloud infrastructure.

These solutions not only improve service efficiency and reduce management time with more automatous design, but also result in higher performance and reliability with fewer human errors. As an illustration of our work toward a more autonomous cloud, we will discuss our exploration for supporting automatic safe deployment services below.

Exemplary scenario: Automatic safe deployment

In online services, the continuous integration and continuous deployment (CI/CD) of new patches and builds are critical for the timely delivery of bug fixes and feature updates. Because new deployments with undetected bugs or incompatible issues can cause severe service outages and create significant customer impact, cloud platforms enforce strict safe-deployment procedures before releasing each new deployment to the production environments. Such procedures typically involve multi-stage testing and verification in a sequence of canary environments with increasing scopes. When a deployment-related anomaly is identified in one of these stages, the responsible deployment is rolled back for further diagnosis and fixing. Owing to the challenges of identifying deployment-related anomalies with heterogeneous patterns and managing a huge number of deployments, safe-deployment systems administrated manually can be extremely costly and error prone.

To support automatic and reliable anomaly detection in safe deployment, we proposed a general methodology named ATAD for the effective detection of deployment-related anomalies in time-series signals. This method addresses the challenges of capturing changes with various patterns in time-series signals and the lack of labeled anomaly samples due to the heavy cost of labeling. Specifically, this method combines ideas from both transfer learning and active learning to make good use of the temporal information in the input signal and reduce the number of labeled samples required for model training. Our experiments have shown that ATAD can outperform other state-of-the-art anomaly detection approaches, even with only 1%-5% of labeled data.

At the same time, we collaborated with product teams in Azure to develop and deploy Gandalf, an end-to-end automatic safe deployment system that reduces deployment time and increases the accuracy of detecting bad deployment in Azure. As a data-driven system, Gandalf monitors a large array of information, including performance metrics, failure signals and deployment records. It also detects anomalies in various patterns throughout the entire safe-deployment process. After detecting anomalies, Gandalf applies a vote-veto mechanism to reliably determine whether each detected anomaly is caused by a specific new deployment. Gandalf then automatically decides whether the relevant new deployment should be stopped for a fix or if it’s safe enough to proceed to the next stage. After rolling out in Azure, Gandalf has been effective at helping to capture bad deployments, achieving more than 90% precision and near 100% recall in production over a period of 18 months.

Flow of Automatic Safe Deployment System

Proactive cloud

Motivation

Traditional decision-making in the cloud focuses on optimizing immediate resource usage and addressing emerging issues. While this reactive design is not unreasonable in a relatively static system, it can lead to short-sighted decisions in a dynamic environment. In cloud platforms, both the demand and utilization of computing resources are undergoing constant changes, including regular periodical patterns, unexpected spikes, and gradual shifts in both temporal and spatial dimensions. To improve the long-term efficiency and reliability of cloud platforms, it is critical to adopt a proactive design that takes the future status of the system into account in the decision-making process.

A proactive design leverages data-driven models to predict the future status of cloud platforms and enable downstream proactive decision-making. Conceptually, a typical proactive decision-making system consists of two modules: a prediction module and a decision-making module, as displayed in the following diagram.

In the prediction module, historical data are collected and processed for training and fine-tuning the prediction model for deployment. The deployed prediction model takes in the online data stream and generates prediction results in real time. In the decision-making module, both the current system status and the predicted system status, along with other information such as domain knowledge and past decision history, is considered for making decisions that balance both present and future benefits.

Toward proactive design

Proactive design, while creating new opportunities for improving the long-term efficiency and reliability of cloud systems, does expose the decision-making process to additional risks. On one hand, thanks to the inherent randomness in the daily operation of cloud platforms, proactive decisions are always subjected to the uncertainty risk from the stochastic elements in both running systems and the environments. On the other hand, the reliability of prediction models adds another layer of risks in making proactive decisions. Therefore, to guarantee the performance of proactive design, engineers must put mechanisms in place to address those risks.

To manage uncertainty risk, engineers need to reformulate the decision-making in proactive design to account for the uncertainty elements. They can often use methodological frameworks, such as prediction+optimization and optimization under chance-constraints, to incorporate uncertainties into the target functions of optimization problems. Well-designed ML/AL models can also learn uncertainty from data for improving proactive decisions against uncertainty elements. As for risks associated with the prediction model, modules for improving data quality, including quality-aware feature engineering, robust data imputation, and data rebalancing, should be applied to reduce prediction errors. Engineers should also make continuous efforts to improve and update the robustness of prediction models. Moreover, safeguarding mechanisms are essential to prevent decisions that may cause harm to the cloud system.

Microsoft’s AIOps research has pioneered the transition from reactive decision-making to proactive decision-making, especially in problem spaces of prediction and optimization. Our efforts not only lead to significant improvement in many application scenarios traditionally supported by reactive decision-making, but also create many new opportunities. Notable proactive design solutions include Narya and Nenya for hardware failure mitigation, UAHS and CAHS for the intelligent virtual machine provisioning, CUC for the predictive scheduling of workloads, and UCaC for bin packing optimization under chance constraints. In the discussion below, we will use hardware failure mitigation as an example to illustrate how proactive design can be applied in cloud scenarios.

Exemplary scenario: Proactive hardware failure mitigation

A key threat to cloud platforms is hardware failure, which can cause interruptions to the hosted services and significantly impact the customer experience. Traditionally, hardware failures are only resolved reactively after the failure occurs, which typically involves temporal interruptions of hosted virtual machines and the repair or replacement of impacted hardware. Such a solution provides limited help in reducing negative customer experiences.

Narya is a proactive disk-failure mitigation service capable of taking mitigation actions before failures occur. Specifically, Narya leverages ML models to predict potential disk failures, and then make decisions accordingly. To control risks associated with uncertainty, Narya evaluates candidate mitigation actions based on the estimated impacts to customers and chooses actions with minimum impact. A feedback loop also exists for collecting follow-up assessments to improve prediction and decision modules.

Hardware failures in cloud systems are often highly interdependent. Therefore, to reduce the impact of predictions errors, Narya introduces a novel dependency-aware model to encode the dependency relationship between nodes to improve the failure prediction model. Narya also implements an adaptive approach that uses A/B testing and bandit modeling to improve the ability to estimate the impacts of actions. Several safeguarding mechanisms in different stages of Narya are also in place to eliminate the chance of making unsafe mitigation actions. Implementation of Narya in Azure’s production environment has reduced the node hardware interruption rate for virtual machines by more than 26%.

Our recent work, Nenya, is another example for proactive failure mitigation. Under a reinforcement learning framework, Nenya fuses prediction and decision-making modules into an end-to-end proactive decision-making system. It can weigh both mitigation costs and failure rates to better prioritize cost-effective mitigation actions against uncertainty. Moreover, the traditional failure mitigation method usually suffers from data imbalance issues; cases of failure form only a very small portion of all cases, which have mostly healthy situations. Such data imbalance would introduce bias to both the prediction and decision-making process. To address this problem, Nenya adopts a cascading framework to ensure that mitigation decisions are not made with heavy costs. Experiments with Microsoft 365 data sets on database failure have proved that Nenya can reduce both mitigation costs and database failure rates compared with existing methods.

Future work

As management systems become more automated and proactive, it is important to pay special attention to both the safety of cloud systems and the responsibility to cloud customers. The autonomous and proactive decision system will depend heavily on advanced AI/ML models with little manual effort. How to ensure that the decisions made by those approaches are both safe and responsible is an essential question that future work should answer.

The autonomous and proactive cloud relies on the effective data usage and feedback loop across all stages in the management and operation of cloud platforms. On one hand, high-quality data on the status of cloud systems are needed to enable downstream autonomous and proactive decision-making systems. On the other hand, it is important to monitor and analyze the impact of each decision on the entire cloud platform in order to improve the management system. Such feedback loops can exist simultaneously for many related application scenarios. Therefore, to better support an autonomous and proactive cloud, a unified data plane responsible for the processing and feedback loop can take a central role in the whole system design and should be a key area of investment.

As such, the future of cloud relies not only on adopting more autonomous and proactive solutions, but also on improving the manageability of cloud systems and the comprehensive infusion of AIOps technologies over all stacks of cloud systems. In future blog posts, we will discuss how to work toward a more manageable and comprehensive cloud.

Opens in a new tab"
Microsoft_News,https://www.microsoft.com/en-us/worklab/how-6-experts-use-next-generation-ai,,How 6 Experts Use Next-Generation AI,"Pamela Mishkin knows nothing about forestry. So when the OpenAI researcher, who spends her days studying AI policy and safety, needed to learn how AI would affect forestry workers, she turned to the technology she works with every day.

“I put some dense documents about forestry into the model,” she says. “Then I asked it to extract the sections that were most relevant to my question.” It’s research that would have otherwise taken her hours, completed far more quickly with next-generation AI.

We’ve grown used to the background AI that gives us recommendations for what to watch, read, and buy. Now, with powerful new foundation models and accessible natural language interfaces, we’re entering a new phase of AI —one that empowers us to create, not just consume. To learn more, we spoke to six AI experts about how they use next-generation AI at work, from saving time to thinking differently to making speeches a little more bejeweled.

Jaime Teevan, Microsoft Chief Scientist

“I take all my pre-read documents—you know, you’re going into a meeting and you’ve got a bunch of documents you have to read—and summarize them as poems. I did it once or twice as a gimmick, but then I realized I actually process the information better—and it makes the process of preparing for a meeting a little bit joyful.”

Erik Brynjolfsson, Director of the Digital Economy Lab at the Stanford Institute for Human-Centered AI

“I had to give a talk at the National Bureau of Economic Research, and I asked GPT-3 to help me write my remarks. For fun, I had it rewrite my draft in the style of Taylor Swift. It made this absolutely amazing poem with these terrific metaphors that I had never heard before. Everybody at the conference thought it was just riotously fun and insightful. Combining academic work with a little bit of art sparked new ways of thinking about things. Ever since then, I’ve been listening a little bit more to Taylor Swift because I was like, ‘Wow, that was some pretty good poetry there.’”

Sumit Chauhan, Microsoft CVP, Office Product Group

“I’m getting ready for an off-site, and I have to write this paper about AI. There is so much information about it in emails, in documents, in PowerPoints. I said to Microsoft 365 Copilot , ‘Generate me a document with a framing, business plan, monetization, and go-to-market for AI.’ It searched all my relevant documents and emails and generated an outline, so I had a starting point. Without it, I probably would’ve spent an entire week preparing. Now I have the time to step back and think about how I should structure the conversation, the higher-level strategy. It’s giving me the creative space to think about it.”

Eric Horvitz, Microsoft Chief Scientific Officer

“Nature had a piece recently exploring why there was an unexpected jump in levels of methane in the atmosphere during the pandemic. I input the whole paper into the model and asked numerous questions, including, ‘Imagine that the hypotheses of these authors are incorrect. What else might be going on to explain this data?’ And the system came up with a beautiful set of alternate hypotheses that we might want to check. That session, and many others I’ve had in the realm of scientific exploration, shows how the system can serve as a scientific advisory copilot on some of the hardest problems we face.”

Pamela Mishkin, researcher at OpenAI

“I have a very different communication style than my manager. I’m very New York, off-the-cuff and quick, and she’s more by the book. I’ll ask ChatGPT to rewrite things in her style. I can ask it to double-check an email I’ve written to make sure that it’s clear—that it comes off as professional. I think it helps tone down my New York-ness when I’m communicating with Californians.”

Sam Schillace, Microsoft Deputy CTO

“I was in a Teams meeting, and we turned on closed captioning. The model—an internal experiment—took the closed captions and structured them into a Loop document. So at the end of the meeting, we didn’t just get a transcription, we got: ‘Here’s all the questions asked, all the answers that were given. Here’s all the stuff that was referenced and here’s a snippet of any document that referenced that.’ We got this nicely structured log of the meeting to refer back to.”

Just as today we can’t imagine computing without a keyboard, mouse, or the internet, in the future, we won’t be able to imagine work without AI copilots that help us summarize, reason, and communicate. This is just the beginning of a whole new way of working—and what we can accomplish with it."
Microsoft_News,https://news.microsoft.com/source/shortform/people-of-ai-from-basketball-to-poetry-how-microsoft-employees-use-ai-to-save-time-and-find-joy/,,People of AI: See how these Microsoft employees use AI to save time and find joy,"Chauhan says she had a “moment of wow” when she realized how much AI tools such as the new Microsoft 365 Copilot could help — especially in removing “drudgery” from daily work, like summarizing her email inbox or compiling multiple reports into one synopsis to share with colleagues.

"
Microsoft_News,https://news.microsoft.com/europe/features/ai-training-program-helps-close-gender-gap-bringing-fresh-faces-to-europes-digital-workforce/,,"AI training program helps close gender gap, bringing fresh faces to Europe’s digital workforce","When she entered a technology university in Valence, France to study computer science, Audrey Roumieux was in a first-year group of 84 students. Six of them were women.

“We had no problem finding each other,” she recalls with a laugh. “In the class of 84 people I was one of the first people to be spotted.”

She says that aside from an occasional tasteless joke from her male classmates, she thrived at the university. “I don’t see any real reason why there are few women in IT because I am just as capable as a man to do my job.”

Roumieux went on to another year of university in Marseille and then to an internship at a cancer research center that was developing machine learning models to detect cancer cells. She became fascinated by the technology; it was statistically better at the task than the doctors.

“It’s almost like magic, and I wanted so much to know what’s behind it,” she says. “I wanted to continue my studies, and that’s when I discovered the Microsoft AI School by Simplon.”

Roumieux was in the first class of the school, which opened in 2018 to help women, refugees, people with disabilities and those seeking second careers enter the world of AI. She now works as a data engineer for Avanade, a company formed by Microsoft and Accenture in a joint venture in 2000.

The Microsoft AI School by Simplon is part of Microsoft’s efforts to bring more diversity to the digital workforce and to fill significant labor and gender gaps. A 2021 report by the European Commission estimates that Europe will need 20 million information and communications technology (ICT) specialists by 2030. Right now, there are 8.4 million ICT specialists working in the European Union, and 81.5 percent of them are men.

In this effort, Microsoft has partnered with Simplon, a social enterprise that specializes in digital training for jobseekers from diverse backgrounds. Simplon has schools in France, Belgium, Ivory Coast, Gabon, Morocco, Senegal, Tunisia, Jordan and India. The company’s schools have trained more than 25,000 people, about 40 percent of them women and about 44 percent without full or any college degrees.

France’s national unemployment agency is the main conduit for new trainees in the AI program (and Simplon’s other digital training programs in France as well). Jobseekers with interest and potential are encouraged to enter the program, and the French government pays most of the tuition.

Click here to load media

Louise Joly is the administrator of the AI program at Simplon, which is celebrating its five-year anniversary in March. There are now 20 of these AI schools in France, which have trained about 900 people, about 33 percent of them women. Joly says that Simplon has long wanted to reach gender parity in its classes, but that a variety of barriers holding back women have made it hard to reach that goal.

“At Simplon, we’re less concerned about the reasons behind that glass ceiling than finding a solution,” she says. To that end, it created prequalification course for women only in the AI program, which she says has resulted in a higher completion rate.

She also cites the schools’ hands-on methodology for its success in placing its students into good jobs. Participants in the AI training spend four months in the classroom, seven hours per day. Then they spend a year in an apprenticeship at a company, with one week in class and three weeks on the job. Simplon works with companies to create and continuously improve the training program. Companies select candidates for apprenticeships from Simplon from the beginning of the training program. In this way, Simplon supports companies in a non-traditional recruitment process – producing strong recruits outside of the normal channels, such as level of education, professional background and previous experience.

Laurent Cetinsoy is a professor in the Microsoft AI School by Simplon in Paris, and he is an advocate of the school’s hands-on approach.

“The idea is, if you want to learn tennis, the best way is not by hearing some old guy speaking about tennis for three hours,” he says. “We try to put the student into action as soon as possible, but that doesn’t mean I don’t explain things.”

Even during the intense class portion of the course, Cetinsoy says, the participants work on real projects.

In the first year of the program, he says, the class helped an inventor improve a machine that recycles plastic immediately to be used in an attached 3D printer to create new objects. Class members used AI in training the machine to recognize and sort the plastic by type. “We had the luck to see [Microsoft Chairman and CEO] Satya Nadella visit the school at this time, and he really liked the project,” he says.

Stan Briand graduated from the AI School in February of 2022 after a year spent in an apprenticeship at LACROIX in Rennes. There, he developed a system using AI and the Internet of Things (IoT) to help detect leaks in the water system of the town of Nevers.

“On average in France pipelines are leaking 22 to 25 percent, so about one fourth of the clean water we produce for drinking goes back into nature,” Briand says. “This is due to multiple factors, but the most important one is the pipelines are aging. Aside from the environmental waste, this loss costs huge amounts of money.”

The system Briand developed takes data from 200 sensors that detect water flow in the Nevers water network and uses an AI algorithm to analyze it. The AI helps pinpoint where leaks are most likely to be found. Scrutinizing that data was taking up well over an hour a day for a worker at the water utility. Briand says the job now takes five minutes and frees up time for other critical maintenance tasks.

“France and some other countries are having problems with drought,” making water resources more precious, Briand says. “This is a step toward solving those kinds of issues, so it’s really rewarding.” The system he created is now in use at a second municipal water system and will be deployed to others.

Briand’s supervisor at LACROIX is Reynholds Reinette. During Briand’s one-year apprenticeship, he showed skill and initiative in developing the water anomaly detection system, Reinette says, and it was an easy decision to hire him.

“The project was great, and we wanted to continue working on it,” Reinette says. He says LACROIX recently hired another Microsoft AI School by Simplon graduate in Rennes and will have another apprentice from the school starting later in the spring.

Before training as an AI specialist, Briand taught English in Chengdu, China, and eventually became an administrator at the national level for a group of English-language schools. He computerized the administration system and became fascinated with what he could do with data. When he moved back to France, he decided to seek out training to enter the world of computer programming.

“At that time, I felt that the AI field would require a lot of experience, a lot of math background and basically I thought it would be too hard for me to get into that,” he recalls. “But the Microsoft-Simplon school doesn’t require that much math or even a master level in technology. So, I applied, I passed a few tests, and I got in.”

Cetinsoy, the AI professor, echoes Briand, saying that the most important factors for success in the program are motivation and willingness to work very hard.

“You need an analytical mind and an analytical view to solve problems,” he says. “Good programming skills are more important than being a crack at math.”

Click here to load media

Microsoft and Simplon have collaborated on another training program that just began in November of 2022: A specialization in cybersecurity, another area where more capable workers are urgently needed in Europe and elsewhere. In the past three months, high-profile cyberattacks on telecommunications networks in Portugal, government servers in Poland and oil facilities in Germany, Belgium and the Netherlands highlight the problem.

The Cybersecurity School is at the heart of Microsoft’s Cybersecurity Skills Plan in France, which aims to support the training of 10,000 new cybersecurity professionals by the end of 2025.

Sixteen students in the first class of the program have completed their coursework and are beginning 16-month apprenticeships at seven different companies in France.

When Roumieux finished her period of intensive coursework at the Microsoft AI School by Simplon, she began an apprenticeship at Azeo, which turned into a full-time job. Azeo was later bought by Avanade.

She says she likes many things about her job, among them that her clients and their needs are varied; she’s always learning something new. She’s worked on creating ways to analyze and visualize sales data for a large wine and spirits corporation. For an advertising firm, she helped create a program to automatically send emails to clients who chronically make late payments. She’s currently working on organizing and visualizing data for a company that runs company cafeterias and distributes meal cards.

“For me technology is a way to help people in their lives and their businesses,” she says. That belief comes from personal experience, she says.

“I am dyslexic, and when I was little, I was given a little computer to help me with spelling and grammar,” she says. She saw that computer as an ally and realized its potential for solving all kinds of problems.

“Clearly, when someone gave me that little computer, it helped me a lot, and I told myself that’s a tool that helps people, and why not see if I could work with it to do the same for others.”

Top image: Audrey Roumieux, data engineer at Avanade in Paris and one of the first graduates of the Microsoft AI School by Simplon. Photo by Chris Welsch for Microsoft.

Read this story in French here: Un programme de formation à l’IA qui encourage la diversité dans le secteur du numérique – News Centre (microsoft.com)"
Microsoft_News,https://www.microsoft.com/en-us/research/blog/ai-and-the-future-of-health/,,AI and the Future of Health,"The emergence of increasingly capable large-scale AI models, such as the recently released GPT-4, is one of the most significant advances in computing in decades. These innovations are rapidly transforming every aspect of the value we get from technology, as demonstrated through Microsoft’s integration of GPT-4 into Bing, Edge, Microsoft 365, Power Platform, GitHub, and other offerings. More recently, Nuance has announced DAX Express, which uses a unique combination of conversational, ambient, and generative AI to automatically draft clinical notes after patient visits – helping to reduce care providers’ cognitive burdens and increase the joy of practicing medicine (whilst releasing time for care).

We are at an inflection point for the use of AI in healthcare – one of society’s most critical sectors. The significance of this moment is reflected in Peter Lee’s recent article in the New England Journal of Medicine on the potential future clinical applications of GPT-4. At Microsoft Research’s Health Futures organization, the multidisciplinary group dedicated to discovery in this space, we see this as the continuation of a journey, and a major milestone in the long process of innovating to help address the greatest challenges in healthcare.

In this blog, we will share some of our research team’s work to make healthcare more data-driven, predictive, and precise – ultimately, empowering every person on the planet to live a healthier future.

Enabling precision medicine and connected care

We are today at a unique moment in history where medicine, biology, and technology are converging on a large scale. This presents immense possibilities to revolutionize healthcare and the practice of medicine with the aid of trustworthy AI. While we embrace the potential of AI, we understand that the practice of medicine is an intricate balance of “art” and “science.” We recognize and honor the enduring physician-patient relationship, which is fundamental and timeless. Our diverse team comprises researchers, scientists, engineers, biotechnologists, designers, social scientists, strategists, healthcare experts, and medical professionals who collaborate globally and inclusively to reimagine and transform the lives of the patients and public we serve.

As we consider how technologies have shaped the practice of medicine over the centuries, from the individual to the ecosystem level, we are reminded that no technology exists in a vacuum. Our core understanding of biological systems is rapidly evolving, and with it, our understanding of what technologies are relevant and useful. Simultaneously, the use of technology across the health and life science industries, and the way healthcare is delivered, are also rapidly changing – reshaping our traditional healthcare delivery model from one of diagnosis and treatment, to one that prioritizes prevention and precise individualized care.

Spotlight: On-demand video AI Explainer: Foundation models ​and the next era of AI Explore how the transformer architecture, larger models and more data, and in-context learning have helped advance AI from perception to creation. Watch video Opens in a new tab

Recent advancements in machine learning and AI have fueled computational technologies that allow us to aggregate complex inputs from multiple data sources, with the potential to derive rich insights that rapidly expand our knowledge base and drive deeper discovery and faster innovation. At the same time, it remains an open question how to best use and regulate these technologies in real-world settings and at scale across healthcare and the life sciences. Nonetheless, we believe that we are on a path to delivering on the goal of precision medicine – a change in clinical practice which will be enabled by precision diagnostics, precision therapeutics, and connected care technologies.

To achieve this goal, we seek to collaborate with health and life sciences organizations with a similar appetite for transformation, complementary expertise, and a commitment to propel the change required. We are also engaged with the broader community in pursuing responsible and ethical use of AI in healthcare. Our diverse team has been successful in bridging the gap between the fields of medicine, biology and chemistry on one hand, and computing on the other. We act as “translators” between these fields, and through a process of ongoing collaboration and feedback, we have discovered new challenges and innovative solutions.

Below are some examples of our collaborative research approach:

Multimodal foundation models for medicine: an example from radiology

The field of biomedicine involves a great deal of multimodal data, such as radiology images and text-based reports. Interpreting this data at scale is essential for improving care and accelerating research. Radiology reports often compare current and prior images to track changes in findings over time. This is crucial for decision making, but most AI models do not take into account this temporal structure. We are exploring a novel self-supervised framework that pre-trains vision-language models using pairs of reports and sequences of images. This includes handling missing or misaligned images and exploiting temporal information to learn more efficiently. Our approach, called BioViL-T, achieves state-of-the-art results on several downstream tasks, such as report generation, and interpreting disease progression by focusing on relevant image regions across time. BioViL-T is part of ongoing collaboration with our colleagues at Nuance to develop scalable and flexible AI solutions for radiology that can empower care providers and augment existing workflows.

Project InnerEye: Democratizing Medical Imaging AI

Project InnerEye (opens in new tab) is a research project that is exploring ways in which machine learning has the potential to assist clinicians in planning radiotherapy treatments so that they can spend more time with their patients. Project InnerEye has been working closely with the University of Cambridge and Cambridge University Hospitals NHS Foundation Trust to make progress on this problem through a deep research collaboration. To make our research as accessible as possible, we released the InnerEye Deep Learning Toolkit (opens in new tab) as open-source software. Cambridge University Hospitals NHS Foundation Trust and University Hospitals Birmingham NHS Trust (opens in new tab) led an NHS AI in Health and Care Award to evaluate how this technology could potentially save clinicians’ time, reduce the time between the scan and commencing treatment, and scale this to more NHS Trusts. Any clinical use of the InnerEye machine learning models remains subject to regulatory approval.

Immunomics: Decoding the Immune System to Diagnose Disease

The human immune system is an astonishing diagnostic engine, continuously adapting itself to detect any signal of disease in the body. Essentially, the state of the immune system tells a story about virtually everything affecting a person’s health. What if we could “read” this story? Our scientific understanding of human health would be fundamentally advanced. More importantly, this would provide a platform for a new generation of precise medical diagnostics and treatment options. We are partnering with Adaptive Biotechnologies to develop the machine learning and biotechnology tools that will allow us to realize this dream.

Fundamental advances towards new medicines and therapeutics

Protein Engineering

Several research groups are delving into the potential of machine learning to enhance our comprehension of proteins and their pivotal role in various biological processes. We are also using AI to design new proteins for therapeutics and industry. By applying machine learning to extract patterns from databases of sequences, structures, and properties, Microsoft hopes to train models that can make protein engineering by directed evolution more efficient, and directly generate proteins that will perform desired functions. The ability to generate computationally distinct yet viable protein structures holds tremendous promise for uncovering novel biological insights and developing targeted therapies for previously untreatable illnesses.

Investigating the Cancer Microenvironment through Ex Vivo Research

Microsoft is working on ways to identify specific characteristics of cancer cells and their surrounding microenvironments that might be targeted for treatment. By studying how cancer cells and their surroundings interact with each other, the team aims to create a more precise approach to cancer treatment that takes into account both genetic and non-genetic factors.

Accelerating biomedical research

Microsoft and the Broad Institute – combining their expertise in genomics, disease research, cloud computing and data analytics – are developing an open-source platform to accelerate biomedical research using scalable analytical tools. The platform is built on top of the Broad Institute’s Terra platform, providing a user-friendly interface for accessing and analyzing genomic data. Leveraging Microsoft’s Azure cloud computing services, the platform will enable secure storage and analysis of large datasets. Additionally, the platform will incorporate machine learning and other advanced analytical tools to help researchers gain insights into complex diseases and develop new treatments.

Advancing clinical interpretation and exploration through multimodal language models

In the quest for precision medicine and accelerating biomedical discovery, Microsoft is committed to advancing the state of the art in biomedical natural language processing (NLP). A crucial factor in future-facing, data-driven health systems is the accessibility and interpretability of multimodal health information. To meet this need, Microsoft has laid a solid foundation across multiple modalities in biomedical NLP building on our deep research assets in deep learning and biomedical machine reading.

One significant achievement is our development and application of large language models (LLMs) in biomedicine. Microsoft was among the first to create and assess the applicability of LLMs, such as PubMedBERT and BioGPT, which are highly effective in structuring biomedical data. However, to address the inherent limitations of LLMs, Microsoft is developing methods to teach them to fact-check themselves and provide fine-grained provenance. Additionally, Microsoft is exploring ways to facilitate efficient verification with humans in the loop.

Besides text, other modalities such as radiology images, digital pathology slides, and genomics contain valuable health information. Microsoft is developing multimodal learning and fusion methods that incorporate these modalities. These methods include predicting disease progression and drug response, with the ultimate goal of delivering safe and high-quality healthcare.

Observational data in biomedicine is often plagued by confounders, making it challenging to draw causal relationships. To overcome this obstacle, Microsoft is developing advanced causal methods that correct implicit biases and scale biomedical discovery. These methods will allow Microsoft to leverage real-world evidence and contribute to the creation of more effective healthcare delivery systems. For our end-to-end biomedical applications, we have made exciting progress in deep collaborations with Microsoft partners such as The Jackson Laboratory and Providence St. Joseph Health.

Empowering everyone to live a healthier future

Microsoft has pursued interdisciplinary research that enables people to reach the full potential of their health for many years, but we’ve never been more excited about the possibilities than we are today. The latest developments in AI have inspired us to accelerate our efforts across these and many other projects, and we look forward to even more innovation and collaboration in this new era.

Opens in a new tab"
Microsoft_News,https://www.microsoft.com/en-us/research/blog/ai-and-the-future-of-health/,,AI and the Future of Health,"The emergence of increasingly capable large-scale AI models, such as the recently released GPT-4, is one of the most significant advances in computing in decades. These innovations are rapidly transforming every aspect of the value we get from technology, as demonstrated through Microsoft’s integration of GPT-4 into Bing, Edge, Microsoft 365, Power Platform, GitHub, and other offerings. More recently, Nuance has announced DAX Express, which uses a unique combination of conversational, ambient, and generative AI to automatically draft clinical notes after patient visits – helping to reduce care providers’ cognitive burdens and increase the joy of practicing medicine (whilst releasing time for care).

We are at an inflection point for the use of AI in healthcare – one of society’s most critical sectors. The significance of this moment is reflected in Peter Lee’s recent article in the New England Journal of Medicine on the potential future clinical applications of GPT-4. At Microsoft Research’s Health Futures organization, the multidisciplinary group dedicated to discovery in this space, we see this as the continuation of a journey, and a major milestone in the long process of innovating to help address the greatest challenges in healthcare.

In this blog, we will share some of our research team’s work to make healthcare more data-driven, predictive, and precise – ultimately, empowering every person on the planet to live a healthier future.

Enabling precision medicine and connected care

We are today at a unique moment in history where medicine, biology, and technology are converging on a large scale. This presents immense possibilities to revolutionize healthcare and the practice of medicine with the aid of trustworthy AI. While we embrace the potential of AI, we understand that the practice of medicine is an intricate balance of “art” and “science.” We recognize and honor the enduring physician-patient relationship, which is fundamental and timeless. Our diverse team comprises researchers, scientists, engineers, biotechnologists, designers, social scientists, strategists, healthcare experts, and medical professionals who collaborate globally and inclusively to reimagine and transform the lives of the patients and public we serve.

As we consider how technologies have shaped the practice of medicine over the centuries, from the individual to the ecosystem level, we are reminded that no technology exists in a vacuum. Our core understanding of biological systems is rapidly evolving, and with it, our understanding of what technologies are relevant and useful. Simultaneously, the use of technology across the health and life science industries, and the way healthcare is delivered, are also rapidly changing – reshaping our traditional healthcare delivery model from one of diagnosis and treatment, to one that prioritizes prevention and precise individualized care.

Spotlight: On-demand video AI Explainer: Foundation models ​and the next era of AI Explore how the transformer architecture, larger models and more data, and in-context learning have helped advance AI from perception to creation. Watch video Opens in a new tab

Recent advancements in machine learning and AI have fueled computational technologies that allow us to aggregate complex inputs from multiple data sources, with the potential to derive rich insights that rapidly expand our knowledge base and drive deeper discovery and faster innovation. At the same time, it remains an open question how to best use and regulate these technologies in real-world settings and at scale across healthcare and the life sciences. Nonetheless, we believe that we are on a path to delivering on the goal of precision medicine – a change in clinical practice which will be enabled by precision diagnostics, precision therapeutics, and connected care technologies.

To achieve this goal, we seek to collaborate with health and life sciences organizations with a similar appetite for transformation, complementary expertise, and a commitment to propel the change required. We are also engaged with the broader community in pursuing responsible and ethical use of AI in healthcare. Our diverse team has been successful in bridging the gap between the fields of medicine, biology and chemistry on one hand, and computing on the other. We act as “translators” between these fields, and through a process of ongoing collaboration and feedback, we have discovered new challenges and innovative solutions.

Below are some examples of our collaborative research approach:

Multimodal foundation models for medicine: an example from radiology

The field of biomedicine involves a great deal of multimodal data, such as radiology images and text-based reports. Interpreting this data at scale is essential for improving care and accelerating research. Radiology reports often compare current and prior images to track changes in findings over time. This is crucial for decision making, but most AI models do not take into account this temporal structure. We are exploring a novel self-supervised framework that pre-trains vision-language models using pairs of reports and sequences of images. This includes handling missing or misaligned images and exploiting temporal information to learn more efficiently. Our approach, called BioViL-T, achieves state-of-the-art results on several downstream tasks, such as report generation, and interpreting disease progression by focusing on relevant image regions across time. BioViL-T is part of ongoing collaboration with our colleagues at Nuance to develop scalable and flexible AI solutions for radiology that can empower care providers and augment existing workflows.

Project InnerEye: Democratizing Medical Imaging AI

Project InnerEye (opens in new tab) is a research project that is exploring ways in which machine learning has the potential to assist clinicians in planning radiotherapy treatments so that they can spend more time with their patients. Project InnerEye has been working closely with the University of Cambridge and Cambridge University Hospitals NHS Foundation Trust to make progress on this problem through a deep research collaboration. To make our research as accessible as possible, we released the InnerEye Deep Learning Toolkit (opens in new tab) as open-source software. Cambridge University Hospitals NHS Foundation Trust and University Hospitals Birmingham NHS Trust (opens in new tab) led an NHS AI in Health and Care Award to evaluate how this technology could potentially save clinicians’ time, reduce the time between the scan and commencing treatment, and scale this to more NHS Trusts. Any clinical use of the InnerEye machine learning models remains subject to regulatory approval.

Immunomics: Decoding the Immune System to Diagnose Disease

The human immune system is an astonishing diagnostic engine, continuously adapting itself to detect any signal of disease in the body. Essentially, the state of the immune system tells a story about virtually everything affecting a person’s health. What if we could “read” this story? Our scientific understanding of human health would be fundamentally advanced. More importantly, this would provide a platform for a new generation of precise medical diagnostics and treatment options. We are partnering with Adaptive Biotechnologies to develop the machine learning and biotechnology tools that will allow us to realize this dream.

Fundamental advances towards new medicines and therapeutics

Protein Engineering

Several research groups are delving into the potential of machine learning to enhance our comprehension of proteins and their pivotal role in various biological processes. We are also using AI to design new proteins for therapeutics and industry. By applying machine learning to extract patterns from databases of sequences, structures, and properties, Microsoft hopes to train models that can make protein engineering by directed evolution more efficient, and directly generate proteins that will perform desired functions. The ability to generate computationally distinct yet viable protein structures holds tremendous promise for uncovering novel biological insights and developing targeted therapies for previously untreatable illnesses.

Investigating the Cancer Microenvironment through Ex Vivo Research

Microsoft is working on ways to identify specific characteristics of cancer cells and their surrounding microenvironments that might be targeted for treatment. By studying how cancer cells and their surroundings interact with each other, the team aims to create a more precise approach to cancer treatment that takes into account both genetic and non-genetic factors.

Accelerating biomedical research

Microsoft and the Broad Institute – combining their expertise in genomics, disease research, cloud computing and data analytics – are developing an open-source platform to accelerate biomedical research using scalable analytical tools. The platform is built on top of the Broad Institute’s Terra platform, providing a user-friendly interface for accessing and analyzing genomic data. Leveraging Microsoft’s Azure cloud computing services, the platform will enable secure storage and analysis of large datasets. Additionally, the platform will incorporate machine learning and other advanced analytical tools to help researchers gain insights into complex diseases and develop new treatments.

Advancing clinical interpretation and exploration through multimodal language models

In the quest for precision medicine and accelerating biomedical discovery, Microsoft is committed to advancing the state of the art in biomedical natural language processing (NLP). A crucial factor in future-facing, data-driven health systems is the accessibility and interpretability of multimodal health information. To meet this need, Microsoft has laid a solid foundation across multiple modalities in biomedical NLP building on our deep research assets in deep learning and biomedical machine reading.

One significant achievement is our development and application of large language models (LLMs) in biomedicine. Microsoft was among the first to create and assess the applicability of LLMs, such as PubMedBERT and BioGPT, which are highly effective in structuring biomedical data. However, to address the inherent limitations of LLMs, Microsoft is developing methods to teach them to fact-check themselves and provide fine-grained provenance. Additionally, Microsoft is exploring ways to facilitate efficient verification with humans in the loop.

Besides text, other modalities such as radiology images, digital pathology slides, and genomics contain valuable health information. Microsoft is developing multimodal learning and fusion methods that incorporate these modalities. These methods include predicting disease progression and drug response, with the ultimate goal of delivering safe and high-quality healthcare.

Observational data in biomedicine is often plagued by confounders, making it challenging to draw causal relationships. To overcome this obstacle, Microsoft is developing advanced causal methods that correct implicit biases and scale biomedical discovery. These methods will allow Microsoft to leverage real-world evidence and contribute to the creation of more effective healthcare delivery systems. For our end-to-end biomedical applications, we have made exciting progress in deep collaborations with Microsoft partners such as The Jackson Laboratory and Providence St. Joseph Health.

Empowering everyone to live a healthier future

Microsoft has pursued interdisciplinary research that enables people to reach the full potential of their health for many years, but we’ve never been more excited about the possibilities than we are today. The latest developments in AI have inspired us to accelerate our efforts across these and many other projects, and we look forward to even more innovation and collaboration in this new era.

Opens in a new tab"
Microsoft_News,https://www.microsoft.com/en-us/research/podcast/ai-frontiers-ai-for-health-and-the-future-of-research-with-peter-lee/,,AI Frontiers: AI for health and the future of research with Peter Lee,"In this podcast series, I’ll share conversations with fellow researchers about our initial impressions of GPT-4, the nature of intelligence, and ultimately, how innovations like these can have the greatest benefit for humanity.

Ashley Llorens: I’m Ashley Llorens with Microsoft Research. I’ve spent the last 20 years working in AI and machine learning. But I’ve never felt more fortunate to work in the field than at this moment. Just this month, March 2023, OpenAI announced GPT-4, a powerful new large-scale AI model with dramatic improvements in reasoning, problem-solving, and much more. This model and the models that will come after it represent a phase change in the decades-long pursuit of artificial intelligence.

Today we’re sitting down with Peter Lee, head of Microsoft Research. Peter and a number of MSR colleagues, including myself, have had the privilege of working to evaluate and experiment with GPT-4 and support its integration into Microsoft products.

Peter has also deeply explored the potential application of GPT-4 in health care, where its powerful reasoning and language capabilities could make it a useful copilot for practitioners in patient interaction, managing paperwork, and many other tasks.

Welcome to AI Frontiers.

[MUSIC FADES]

I’m going to jump right in here, Peter. So you and I have known each other now for a few years. And one of the values I believe that you and I share is around societal impact and in particular creating spaces and opportunities where science and technology research can have the maximum benefit to society. In fact, this shared value is one of the reasons I found coming to Redmond to work with you an exciting prospect

Now, in preparing for this episode, I listened again to your discussion with our colleague Kevin Scott on his podcast around the idea of research in context. And the world’s changed a little bit since then, and I just wonder how that thought of research in context kind of finds you in the current moment.

Peter Lee: It’s such an important question and, you know, research in context, I think the way I explained it before is about inevitable futures. You try to think about, you know, what will definitely be true about the world at some point in the future. It might be a future just one year from now or maybe 30 years from now. But if you think about that, you know what’s definitely going to be true about the world and then try to work backwards from there.

And I think the example I gave in that podcast with Kevin was, well, 10 years from now, we feel very confident as scientists that cancer will be a largely solved problem. But aging demographics on multiple continents, particularly North America but also Europe and Asia, is going to give huge rise to age-related neurological disease. And so knowing that, that’s a very different world than today, because today most of medical research funding is focused on cancer research, not on neurological disease.

And so what are the implications of that change? And what does that tell us about what kinds of research we should be doing? The research is still very future oriented. You’re looking ahead a decade or more, but it’s situated in the real world. Research in context. And so now if we think about inevitable futures, well, it’s looking increasingly inevitable that very general forms of artificial intelligence at or potentially beyond human intelligence are inevitable. And maybe very quickly, you know, like in much, much less than 10 years, maybe much less than five years.

And so what are the implications for research and the kinds of research questions and problems we should be thinking about and working on today? That just seems so much more disruptive, so much more profound, and so much more challenging for all of us than the cancer and neurological disease thing, as big as those are.

I was reflecting a little bit through my research career, and I realized I’ve lived through one aspect of this disruption five times before. The first time was when I was still an assistant professor in the late 1980s at Carnegie Mellon University, and, uh, Carnegie Mellon University, as well as several other top universities’, uh, computer science departments, had a lot of, of really fantastic research on 3D computer graphics.

It was really a big deal. And so ideas like ray tracing, radiosity, uh, silicon architectures for accelerating these things were being invented at universities, and there was a big academic conference called SIGGRAPH (opens in new tab) that would draw hundreds of professors and graduate students, uh, to present their results. And then by the early 1990s, startup companies started taking these research ideas and founding companies to try to make 3D computer graphics real. One notable company that got founded in 1993 was NVIDIA (opens in new tab).

You know, over the course of the 1990s, this ended up being a triumph of fundamental computer science research, now to the point where today you literally feel naked and vulnerable if you don’t have a GPU in your pocket. Like if you leave your home, you know, without your mobile phone, uh, it feels bad.

And so what happened is there’s a triumph of computer science research, let’s say in this case in 3D computer graphics, that ultimately resulted in a fundamental infrastructure for life, at least in the developed world. In that transition, which is just a positive outcome of research, it also had some disruptive effect on research.

You know, in 1991, when Microsoft Research was founded, one of the founding research groups was a 3D computer graphics research group that was amongst, uh, the first three research groups for MSR. At Carnegie Mellon University and at Microsoft Research, we don’t have 3D computer graphics research anymore. There had to be a transition and a disruptive impact on researchers who had been building their careers on this. Even with the triumph of things, when you’re talking about the scale of infrastructure for human life, it moves out of the realm completely of—of fundamental research. And that’s happened with compiler design. That was my, uh, area of research. It’s happened with wireless networking; it’s happened with hypertext and, you know, hyperlinked document research, with operating systems research, and all of these things, you know, have become things that that you depend on all day, every day as you go about your life. And they all represent just majestic achievements of computer science research. We are now, I believe, right in the midst of that transition for large language models.

Llorens: I wonder if you see this particular transition, though, as qualitatively different in that those other technologies are ones that blend into the background. You take them for granted. You mentioned that I leave the home every day with a GPU in my pocket, but I don’t think of it that way. Then again, maybe I have some kind of personification of my phone that I’m not thinking of. But certainly, with language models, it’s a foreground effect. And I wonder if, if you see something different there.

Lee: You know, it’s such a good question, and I don’t know the answer to that, but I agree it feels different. I think in terms of the impact on research labs, on academia, on the researchers themselves who have been building careers in this space, the effects might not be that different. But for us, as the consumers and users of this technology, it certainly does feel different. There’s something about these large language models that seems more profound than, let’s say, the movement of pinch-to-zoom UX design, you know, out of academic research labs into, into our pockets. This might get into this big question about, I think, the hardwiring in our brains that when we interact with these large language models, even though we know consciously they aren’t, you know, sentient beings with feelings and emotions, our hardwiring forces us—we can’t resist feeling that way.

I think it’s a, it’s a deep sort of thing that we evolved, you know, in the same way that when we look at an optical illusion, we can be told rationally that it’s an optical illusion, but the hardwiring in our kind of visual perception, just no amount of willpower can overcome, to see past the optical illusion.

And similarly, I think there’s a similar hardwiring that, you know, we are drawn to anthropomorphize these systems, and that does seem to put it into the foreground, as you’ve—as you’ve put it. Yeah, I think for our human experience and our lives, it does seem like it’ll feel—your term is a good one—it’ll feel more in the foreground.

Llorens: Let’s pin some of these, uh, concepts because I think we’ll come back to them. I’d like to turn our attention now to the health aspect of your current endeavors and your path at Microsoft.

You’ve been eloquent about the many challenges around translating frontier AI technologies into the health system and into the health care space in general. In our interview, [LAUGHS] actually, um, when I came here to Redmond, you described the grueling work that would be needed there. I’d like to talk a little bit about those challenges in the context of the emergent capabilities that we’re seeing in GPT-4 and the wave of large-scale AI models that we’re seeing. What’s different about this wave of AI technologies relative to those systemic challenges in, in the health space?

Lee: Yeah, and I think to be really correct and precise about it, we don’t know that GPT-4 will be the difference maker. That still has to be proven. I think it really will, but it, it has to actually happen because we’ve been here before where there’s been so much optimism about how technology can really help health care and in advanced medicine. And we’ve just been disappointed over and over again. You know, I think that those challenges stem from maybe a little bit of overoptimism or what I call irrational exuberance. As techies, we look at some of the problems in health care and we think, oh, we can solve those. You know, we look at the challenges of reading radiological images and measuring tumor growth, or we look at, uh, the problem of, uh, ranking differential diagnosis options or therapeutic options, or we look at the problem of extracting billing codes out of an unstructured medical note. These are all problems that we think we know how to solve in computer science. And then in the medical community, they look at the technology industry and computer science research, and they’re dazzled by all of the snazzy, impressive-looking AI and machine learning and cloud computing that we have. And so there is this incredible optimism coming from both sides that ends up feeding into overoptimism because the actual challenges of integrating technology into the workflow of health care and medicine, of making sure that it’s safe and sort of getting that workflow altered to really harness the best of the technology capabilities that we have now, ends up being really, really difficult.

Furthermore, when we get into actual application of medicine, so that’s in diagnosis and in developing therapeutic pathways, they happen in a really fluid environment, which in a machine learning context involves a lot of confounding factors. And those confounding factors ended up being really important because medicine today is founded on precise understanding of causes and effects, of causal reasoning.

Our best tools right now in machine learning are essentially correlation machines. And as the old saying goes, correlation is not causation. And so if you take a classic example like does smoking cause cancer, it’s very important to take account of the confounding effects and know for certain that there’s a cause-and-effect relationship there. And so there’s always been those sorts of issues.

When we’re talking about GPT-4, I remember I was sitting next to Eric Horvitz the first time it got exposed to me. So Greg Brockman from OpenAI, who’s amazing, and actually his whole team at OpenAI is just spectacularly good. And, uh, Greg was giving a demonstration of an early version of GPT-4 that was codenamed Davinci 3 at the time, and he was showing, as part of the demo, the ability of the system to solve biology problems from the AP biology exam.

And it, you know, gets, I think, a score of 5, the maximum score of 5, on that exam. Of course, the AP exam is this multiple-choice exam, so it was making those multiple choices. But then Greg was able to ask the system to explain itself. How did you come up with that answer? And it would explain, in natural language, its answer. And what jumped out at me was in its explanation, it was using the word “because.”

“Well, I think the answer is C, because, you know, when you look at this aspect, uh, statement of the problem, this causes something else to happen, then that causes some other biological thing to happen, and therefore we can rule out answers A and B and E, and then because of this other factor, we can rule out answer D, and all the causes and effects line up.”

And so I turned immediately to Eric Horvitz, who was sitting next to me, and I said, “Eric, where is that cause-and-effect analysis coming from? This is just a large language model. This should be impossible.” And Eric just looked at me, and he just shook his head and he said, “I have no idea.” And it was just this mysterious thing.

And so that is just one of a hundred aspects of GPT-4 that we’ve been studying over the past now more than half year that seemed to overcome some of the things that have been blockers to the integration of machine intelligence in health care and medicine, like the ability to actually reason and explain its reasoning in these medical scenarios, in medical terms, and that plus its generality just seems to give us just a lot more optimism that this could finally be the very significant difference maker.

The other aspect is that we don’t have to focus squarely on that clinical application. We’ve discovered that, wow, this thing is really good at filling out forms and reducing paperwork burden. It knows how to apply for prior authorization for health care reimbursement. That’s part of the crushing kind of administrative and clerical burden that doctors are under right now.

This thing just seems to be great at that. And that doesn’t really impinge on life-or-death diagnostic or therapeutic decisions. But they happen in the back office. And those back-office functions, again, are bread and butter for Microsoft’s businesses. We know how to interact and sell and deploy technologies there, and so working with OpenAI, it seems like, again, there’s just a ton of reason why we think that it could really make a big difference.

Llorens: Every new technology has opportunities and risks associated with it. This new class of AI models and systems, you know, they’re fundamentally different because they’re not learning, uh, specialized function mapping. There were many open problems on even that kind of machine learning in various applications, and there still are, but instead, it’s—it’s got this general-purpose kind of quality to it. How do you see both the opportunities and the risks associated with this kind of general-purpose technology in the context of, of health care, for example?

Lee: Well, I—I think one thing that has made an unfortunate amount of social media and public media attention are those times when the system hallucinates or goes off the rails. So hallucination is actually a term which isn’t a very nice term. It really, for listeners who aren’t familiar with the idea, is the problem that GPT-4 and other similar systems can have sometimes where they, uh, make stuff up, fabricate, uh, information.

You know, over the many months now that we’ve been working on this, uh, we’ve witnessed the steady evolution of GPT-4, and it hallucinates less and less. But what we’ve also come to understand is that it seems that that tendency is also related to GPT-4’s ability to be creative, to make informed, educated guesses, to engage in intelligent speculation.

And if you think about the practice of medicine, in many situations, that’s what doctors and nurses are doing. And so there’s sort of a fine line here in the desire to make sure that this thing doesn’t make mistakes versus its ability to operate in problem-solving scenarios that—the way I would put it is—for the first time, we have an AI system where you can ask it questions that don’t have any known answer. It turns out that that’s incredibly useful. But now the question is—and the risk is—can you trust the answers that you get? One of the things that happens is GPT-4 has some limitations, particularly that can be exposed fairly easily in mathematics. It seems to be very good at, say, differential equations and calculus at a basic level, but I have found that it makes some strange and elementary errors in basic statistics.

There’s an example from my colleague at Harvard Medical School, Zak Kohane, uh, where he uses standard Pearson correlation kinds of math problems, and it seems to consistently forget to square a term and—and make a mistake. And then what is interesting is when you point out the mistake to GPT-4, its first impulse sometimes is to say, “Uh, no, I didn’t make a mistake; you made a mistake.” Now that tendency to kind of accuse the user of making the mistake, it doesn’t happen so much anymore as the system has improved, but we still in many medical scenarios where there’s this kind of problem-solving have gotten in the habit of having a second instance of GPT-4 look over the work of the first one because it seems to be less attached to its own answers that way and it spots errors very readily.

So that whole story is a long-winded way of saying that there are risks because we’re asking this AI system for the first time to tackle problems that require some speculation, require some guessing, and may not have precise answers. That’s what medicine is at core. Now the question is to what extent can we trust the thing, but also, what are the techniques for making sure that the answers are as good as possible. So one technique that we’ve fallen into the habit of is having a second instance. And, by the way, that second instance ends up really being useful for detecting errors made by the human doctor, as well, because that second instance doesn’t care whether the answers were produced by man or machine. And so that ends up being important. But now moving away from that, there are bigger questions that—as you and I have discussed a lot, Ashley, at work—pertain to this phrase responsible AI, uh, which has been a research area in computer science research. And that term, I think you and I have discussed, doesn’t feel apt anymore.

I don’t know if it should be called societal AI or something like that. And I know you have opinions about this. You know, it’s not just errors and correctness. It’s not just the possibility that these things might be goaded into saying something harmful or promoting misinformation, but there are bigger issues about regulation; about job displacements, perhaps at societal scale; about new digital divides; about haves and have-nots with respect to access to these things. And so there are now these bigger looming issues that pertain to the idea of risks of these things, and they affect medicine and health care directly, as well.

Llorens: Certainly, this matter of trust is multifaceted. You know, there’s trust at the level of institutions, and then there’s trust at the level of individual human beings that need to make decisions, tough decisions, you know—where, when, and if to use an AI technology in the context of a workflow. What do you see in terms of health care professionals making those kinds of decisions? Any barriers to adoption that you would see at the level of those kinds of independent decisions? And what’s the way forward there?

Lee: That’s the crucial question of today right now. There is a lot of discussion about to what extent and how should, for medical uses, how should GPT-4 and its ilk be regulated. Let’s just take the United States context, but there are similar discussions in the UK, Europe, Brazil, Asia, China, and so on.

In the United States, there’s a regulatory agency, the Food and Drug Administration, the FDA, and they actually have authority to regulate medical devices. And there’s a category of medical devices called SaMDs, software as a medical device, and the big discussion really over the past, I would say, four or five years has been how to regulate SaMDs that are based on machine learning, or AI. Steadily, there’s been, uh, more and more approval by the FDA of medical devices that use machine learning, and I think the FDA and the United States has been getting closer and closer to actually having a fairly, uh, solid framework for validating ML-based medical devices for clinical use. As far as we’ve been able to tell, those emerging frameworks don’t apply at all to GPT-4. The methods for doing the clinical validation do not make sense and don’t work for GPT-4.

And so a first question to ask is—even before you get to, should this thing be regulated?—is if you were to regulate it, how on earth would you do it. Uh, because it’s basically putting a doctor’s brain in a box. And so, Ashley, if I put a doctor—let’s take our colleague Jim Weinstein, you know, a great spine surgeon. If we put his brain in a box and I give it to you and ask you, “Please validate this thing,” how on earth do you think about that? What’s the framework for that? And so my conclusion in all of this—it’s possible that regulators will react and impose some rules, but I think it would be a mistake, because I think my fundamental conclusion of all this is that at least for the time being, the rules of application engagement have to apply to human beings, not to the machines.

Now the question is what should doctors and nurses and, you know, receptionists and insurance adjusters, and all of the people involved, you know, hospital administrators, what are their guidelines and what is and isn’t appropriate use of these things. And I think that those decisions are not a matter for the regulators, but that the medical community itself should take ownership of the development of those guidelines and those rules of engagement and encourage, and if necessary, find ways to impose—maybe through medical licensing and other certification—adherence to those things.

That’s where we’re at today. Someday in the future—and we would encourage and in fact we are actively encouraging universities to create research projects that would try to explore frameworks for clinical validation of a brain in a box, and if those research projects bear fruit, then they might end up informing and creating a foundation for regulators like the FDA to have a new form of medical device. I don’t know what you would call it, AI MD, maybe, where you could actually relieve some of the burden from human beings and instead have a version of some sense of a validated, certified brain in a box. But until we get there, you know, I think it’s—it’s really on human beings to kind of develop and monitor and enforce their own behavior.

Llorens: I think some of these questions around test and evaluation, around assurance, are at least as interesting as, [LAUGHS] you know—doing research in that space is going to be at least as interesting as—as creating the models themselves, for sure.

Lee: Yes. By the way, I want to take this opportunity just to commend Sam Altman and the OpenAI folks. I feel like, uh, you and I and other colleagues here at Microsoft Research, we’re in an extremely privileged position to get very early access, specifically to try to flesh out and get some early understanding of the implications for really critical areas of human development like health and medicine, education, and so on.

The instigator was really Sam Altman and crew at OpenAI. They saw the need for this, and they really engaged with us at Microsoft Research to kind of dive deep, and they gave us a lot of latitude to kind of explore deeply in as kind of honest and unvarnished a way as possible, and I think it’s important, and I’m hoping that as we share this with the world, that—that there can be an informed discussion and debate about things. I think it would be a mistake for, say, regulators or anyone to overreact at this point. This needs study. It needs debate. It needs kind of careful consideration, uh, just to understand what we’re dealing with here.

Llorens: Yeah, what a—what a privilege it’s been to be anywhere near the epicenter of these—of these advancements. Just briefly back to this idea of a brain in a box. One of the super interesting aspects of that is it’s not a human brain, right? So some of what we might intuitively think about when you say brain in the box doesn’t really apply, and it gets back to this notion of test and evaluation in that if I give a licensing exam, say, to the brain in the box and it passes it with flying colors, had that been a human, there would have been other things about the intelligence of that entity that are underlying assumptions that are not explicitly tested in that test that then those combined with the knowledge required for the certification makes you fit to do some job. It’s just interesting; there are ways in which the brain that we can currently conceive of as being an AI in that box underperforms human intelligence in some ways and overperforms it in others.

Lee: Right.

Llorens: Verifying and assuring that brain in that—that box I think is going to be just a really interesting challenge.

Lee: Yeah. Let me acknowledge that there are probably going to be a lot of listeners to this podcast who will really object to the idea of “brain in the box” because it crosses the line of kind of anthropomorphizing these systems. And I acknowledge that, that there’s probably a better way to talk about this than doing that. But I’m intentionally being overdramatic by using that phrase just to drive home the point, what a different beast this is when we’re talking about something like clinical validation. It’s not the kind of narrow AI—it’s not like a machine learning system that gives you a precise signature of a T-cell receptor repertoire. There’s a single right answer to those things. In fact, you can freeze the model weights in that machine learning system as we’ve done collaboratively with Adaptive Biotechnologies in order to get an FDA approval as a medical device, as an SaMD. There’s nothing that is—this is so much more stochastic. The model weights matter, but they’re not the fundamental thing.

There’s an alignment of a self-attention network that is in constant evolution. And you’re right, though, that it’s not a brain in some really very important ways. There’s no episodic memory. Uh, it’s not learning actively. And so it, I guess to your point, it is just, it’s a different thing. The big important thing I’m trying to say here is it’s also just different from all the previous machine learning systems that we’ve tried and successfully inserted into health care and medicine.

Llorens: And to your point, all the thinking around various kinds of societally important frameworks are trying to catch up to that previous generation and not yet even aimed really adequately, I think, at these new technologies. You know, as we start to wrap up here, maybe I’ll invoke Peter Lee, the head of Microsoft Research, again, [LAUGHS] kind of—kind of where we started. This is a watershed moment for AI and for computing research, uh, more broadly. And in that context, what do you see next for computing research?

Lee: Of course, AI is just looming so large and Microsoft Research is in a weird spot. You know, I had talked before about the early days of 3D computer graphics and the founding of NVIDIA and the decade-long kind of industrialization of 3D computer graphics, going from research to just, you know, pure infrastructure, technical infrastructure of life. And so with respect to AI, this flavor of AI, we’re sort of at the nexus of that. And Microsoft Research is in a really interesting position, because we are at once contributors to all of the research that is making what OpenAI is doing possible, along with, you know, great researchers and research labs around the world. We’re also then part of the company, Microsoft, that wants to make this with OpenAI a part of the infrastructure of everyday life for everybody. So we’re part of that transition. And so I think for that reason, Microsoft Research, uh, will be very focused on kind of major threads in AI; in fact, we’ve sort of identified five major AI threads.

One we’ve talked about, which is this sort of AI in society and the societal impact, which encompasses also responsible AI and so on. One that our colleague here at Microsoft Research Sébastien Bubeck has been advancing is this notion of the physics of AGI. There has always been a very important thread of theoretical computer science, uh, in machine learning. But what we’re finding is that that style of research is increasingly applicable to trying to understand the fundamental capabilities, limits, and trend lines for these large language models. And you don’t anymore get kind of hard mathematical theorems, but it’s still kind of mathematically oriented, just like physics of the cosmos and of the Big Bang and so on, so physics of AGI.

There’s a third aspect, which more is about the application level. And we’ve been, I think in some parts of Microsoft Research, calling that costar or copilot, you know, the idea of how is this thing a companion that amplifies what you’re trying to do every day in life? You know, how can that happen? What are the modes of interaction? And so on.

And then there is AI4Science. And, you know, we’ve made a big deal about this, and we still see just tremendous just evidence, in mounting evidence, that these large AI systems can give us new ways to make scientific discoveries in physics, in astronomy, in chemistry, biology, and the like. And that, you know, ends up being, you know, just really incredible.

And then there’s the core nuts and bolts, what we call model innovation. Just a little while ago, we released new model architectures, one called Kosmos, for doing multimodal kind of machine learning and classification and recognition interaction. Earlier, we did VALL-E, you know, which just based on a three-second sample of speech is able to ascertain your speech patterns and replicate speech. And those are kind of in the realm of model innovations, um, that will keep happening.

The long-term trajectory is that at some point, if Microsoft and other companies are successful, OpenAI and others, this will become a completely industrialized part of the infrastructure of our lives. And I think I would expect the research on large language models specifically to start to fade over the next decade. But then, whole new vistas will open up, and that’s on top of all the other things we do in cybersecurity, and in privacy and security, and the physical sciences, and on and on and on. For sure, it’s just a very, very special time in AI, especially along those five dimensions.

Llorens: It will be really interesting to see which aspects of the technology sink into the background and become part of the foundation and which ones remain up close and foregrounded and how those aspects change what it means to be human in some ways and maybe to be—to be intelligent, uh, in some ways. Fascinating discussion, Peter. Really appreciate the time today.

Lee: It was really great to have a chance to chat with you about things and always just great to spend time with you, Ashley.

Llorens: Likewise.

[MUSIC]"
Microsoft_News,https://blogs.microsoft.com/eupolicy/2023/03/29/ai-sustainable-farming-future-agriculture-green-deal/,,How AI is helping farmers keep up with sustainable food production,"Nearly 1 in 3 people worldwide lack regular access to adequate food.

Resources once considered plentiful have been hit by the combined effects of an ever-growing world population and climate change, leading to rising global temperatures and extreme weather.

Last year, Europe experienced a summer drought that was believed to be the worst in at least 500 years. In many places across Europe, this was followed by sparse rainfall during winter and water supply now declared “very precarious” by a group of scientists based in Austria, leading some EU governments to pass national water strategies with urgency.

Agriculture is among the sectors most impacted, experiencing poorer harvests and higher production costs. In turn, this is affecting price, quantity and quality of yields. As a strong contributor to water use – accounting for 24% of water withdrawal in the EU – the agricultural sector is now looking towards technology, powered by data and AI, as a route to reducing its water consumption and overall environmental footprint while continuing to nutritiously feed the population more sustainably.

The vital importance of data-led agriculture was the focus for Microsoft’s Chief Technology Officer for Agri-Food, Ranveer Chandra, during the Forum for the Future of Agriculture’s 2023 Annual Conference earlier this week.

“Our goal is to build tools that help all individuals and organizations, including farmers, to achieve more,” Chandra explained during his talk on how we can use technology to grow more food, more sustainably. “The soil is not getting any richer; the water levels are receding; there is climate change – these make the farmers’ life much harder. One approach that can help is that of data-driven agriculture, where our goal is not to replace the farmer but to augment the farmer’s knowledge with data and AI.”

The availability of affordable internet-connected sensors – underpinned by cloud technology, AI and machine learning – enables farmers to capture and track operational data, whether it’s from the soil, equipment or livestock. That data can then help generate insights to apply precision agriculture or predictions farmers can use as they look to improve yields while conserving precious resources, including water.

Using AI technology such as Project FarmVibes.AI, which runs on Microsoft Azure, it is possible to predict and plot the ideal amounts of fertilizer and herbicide required based on the level of soil nutrients, forecast temperatures and wind speeds across their fields, determine the ideal depth to plant seeds or irrigation needs based on soil moisture, and guide how different crops and practices can keep carbon sequestered in the soil.

Through these digital tools, farmers can augment their capabilities and knowledge about their farm with data and AI, helping them to make the best choices for optimizing harvests with the input of minimal resources, including water and fertilizer.

During his talk, Chandra explained that, even though farmers have special knowledge of their farms, often after decades, if not generations of experience, a lot of their decisions, such as when or where to fertilize, are still based on rough estimates. Microsoft’s vision, he said, is augmenting farmer’s knowledge so that they can make much more informed decisions: “Our goal is to remove guesswork and replace it with data and AI.”

Utilizing advanced monitoring systems to track the consumption of water and fertilizers, farms can play a part in addressing the roughly 10% of EU greenhouse gas emissions, including nitrous oxide from fertilizer use, generated by the sector and drive Europe toward the urgent transformation needed to achieve more sustainable food systems.

By better monitoring of greenhouse gas emissions, water use and pollution, the agricultural sector can take action to help Europe reach both its Farm to Fork objectives to reduce the environmental and climate footprint of the EU food system and biodiversity goals as part of the Biodiversity Strategy for 2030. This will be made possible by more robust AI-powered reporting capabilities providing actionable environmental data on a scale once thought impossible.

As consumers and investors increase pressure on companies to be transparent about their agricultural sourcing, sustainability practices and supply-chain due diligence, new processes and standards are required to build trust. Tools such as the recently announced Azure Data Manager for Agriculture help automate how environmental data is captured, stored and analyzed. Farmers need to spend less time and effort on “manually” capturing this data and can report on their environmental progress in a more accurate and detailed fashion.

Transforming the agricultural sector with data-driven innovations also contributes to achieving the EU’s Green Deal and the new Common Agricultural Policy objectives.

The creation of a common European agricultural data space (AgriDataSpace) promises to bring together huge amounts of data from multiple agri-food sources helping to optimize the economic and environmental performance of the farming sector and create additional services for farmers.

Europe is also leading the way to improve soil health and transform food production with ambitious targets to reduce the sector’s environmental footprint. The forthcoming new Soil Health Law will be the first of its kind and its success will depend on measurable, quality data.

A policy framework based on the EU’s vision for a green and digital transformation will support and promote the potential of AI in agriculture and help the sector produce high-quality nutritious food that is grown sustainably.

Tags: AI, EU Green Deal, Sustainability"
Microsoft_News,https://www.microsoft.com/en-us/industry/blog/health/2023/03/28/examining-the-next-wave-of-biopharma/,,Examining the next wave of biopharma,"Elena Bonfiglioli (General Manager, WW Healthcare, Global Pharma and Life Sciences, Microsoft) and Tamara Elias (SVP, Strategy and Business Incubation, Nuance) speak with Delphine Zurkiya (Senior Partner, McKinsey & Company) about bringing data & AI, talent, and expertise together in the biopharmaceutical industry to help patients live longer, healthier lives. They focus on two of the questions posed to the industry in a recent report by McKinsey prior to the recent announcement of GenAI and GPT Foundation Models.1 Their conversation reflects their own views and should not be assumed as any professional (including legal) advice.

Delphine: Our research has shown that there is large untapped potential for digital solutions along the life sciences value chain. How can the tech industry play a larger role in driving patient outcomes and realize the full potential of innovative therapies?

Elena: The pharma industry is exploring many exciting frontiers with healthcare providers, data scientists, and other ecosystem partners. Top of mind for me is helping the pharma industry improve upon the success rate for new therapy development, with only around 12 percent of drugs in clinical trials making it through to regulatory approval today.2

Industry leaders are increasingly using advanced analytics to accelerate drug discovery and development—for example, use of large biomedical datasets and real-world evidence (RWE) for in-silico modeling of human biology—and we are now seeing emerging use cases in foundation models and generative AI.3 Some of these models, like PubMedBERT, could empower biologists in various scenarios of scientific discovery by helping them mine and generate biomedical text.4 Other foundational models encode molecule representations and have the potential to fundamentally change drug discovery not only by predicting which molecules (drug candidates) bind better to certain proteins (disease targets), but also now generating new molecules that can then be tested in the lab. There are many other advances in AI that can help across the care continuum too, such as Text Analytics for Health, which extracts and labels relevant medical information from unstructured texts such as doctor’s notes and electronic health records. This can then be fed back into the discovery and development process to improve treatments.

In addition to AI, the tech industry can help by ensuring all this data can be stored, matched, and available to be analyzed by as many researchers and companies as possible, and done in a way that upholds principles of privacy and security. Terra, a secure biomedical research platform co-developed by the Broad Institute of MIT and Harvard and Verily, provides this capability.

Tamara: Biopharma creates molecules that can save patient lives, but this is just one part of the journey. We need to find the right patients for therapy, monitor those patients while on therapy, and monitor post-therapy to watch for any recurrence. This calls for a continuous journey and not a point solution.

We still see too many non-adherent patients taking less than 80 percent of their prescribed medicine,5 or worse, patients who have delayed medical care all together. Remote patient monitoring technology can really help here. Devices like weight scales, pulse oximeters, blood glucose meters, blood pressure monitors, and wearables can offer clinical decision support by enabling providers with continuous data to better care for patients.

There is also a significant amount of data being captured through medical images across the care continuum. At Nuance, we see AI increasingly being used to support healthcare clinicians with their clinical decision-making (for example with Precision Imaging Network). Research and development (R&D) researchers can use all of this data to improve therapeutic interventions—using AI for biomarker discovery and patient identification and monitoring in clinical trials—and ultimately accelerate time to market.

No company can do this alone. Working with partners who have the data, understand digital touchpoints, and can deploy AI models, we can help patients get what they need at every stage of the journey to achieve the best possible outcomes.

Delphine: This partnership and ecosystem theme is critical. How can biopharma companies rely more on ecosystem partners, create more flexible and resilient operating models, and overcome their preference for owning capabilities and capacity outright?

Elena: Many of the advances in science and technology go beyond the core capabilities of a pharmaceutical company. We’ll see transformational change as AI capabilities are embedded in solutions, which requires collaboration across the ecosystem. Tech players can provide secure and scalable infrastructure, such as cloud, AI, and machine learning toolboxes. Academic institutions, government bodies, and healthcare providers can provide large, curated datasets to supplement those of pharma companies.

McKinsey’s recent research1 confirms my own experience that large talent gaps in data science and engineering can be barriers to innovation. Embedding these new technologies in core capabilities and collaboration tools across an organization will democratize the use of AI, widening the user base beyond data scientists and engineers and promoting innovation. What we believe is going to be the real change is when these enhanced capabilities are embedded in the solutions of many, not in the hands of only a few.

At Microsoft, we value collaboration with our partners to provide the connecting glue so that pharma companies can focus on the science. For example, through our partnership with SOPHiA GENETICS, we are providing secure and scalable cloud infrastructure, coupled with the SOPHiA DDM™ Platform, enabling multimodal data-driven care across a network of more than 750 connected healthcare institutions. So far, the SOPHiA DDM™ Platform has supported the analysis of more than 1.2 million genomic profiles. With each incremental profile, SOPHiA GENETICS’ algorithms become more robust, benefiting patient outcomes.

All of the partners in our ecosystem are pushing the boundaries in different ways. The ability to collaborate and build on these capabilities will be a key driver of change in the years to come.

Tamara: To win in a modern ecosystem, pharma companies will need a different approach to capability building. Two century-old companies come to mind—one medtech that believed it needed to create its own digital capabilities to protect its intellectual property, contrasted to a pharma company that joined a partnership ecosystem to augment digital and AI tooling beyond its core capabilities. The better model is to co-create new solutions to ensure that patients achieve the right outcomes with the molecules biopharma has created and is continuing to create.

Tech players are investing more than pharma companies in tech-related healthcare deals. This underscores what Elena described—to drive innovation, there needs to be a symbiotic relationship between players in the ecosystem: tech players who provide the infrastructure and the intelligence toolkit, pharma companies who push the boundaries in developing innovative therapies, and providers and payors who engage with patients and provide the data to advance science across patient populations, care settings, and patient journeys.

Too often, real-world data is siloed in individual databases. It is often said that there are medicines waiting to be discovered in the rainforest. Well, many innovative therapies are waiting to be discovered in data that we can access today. By leveraging this real-world evidence along with the capabilities of our ecosystem partners—medication adherence players, AI developers, and data companies who are experts at “making the molecule”—allows biopharma to leverage the best of external expertise.

Figuring out what we can do together is relatively easy; deciding how to work together is harder. But we’re truly excited about the advances we’ll make together.

Learn more

You can always get the latest on Microsoft Life Sciences Solutions at our website, and stay informed about Microsoft Cloud for Healthcare by signing up for news and updates.

Life Sciences Solutions Discover how the Microsoft Cloud is helping life sciences organizations accelerate innovation. Explore resources today

Note: Microsoft and McKinsey & Company share ownership and publication rights of this blog post.

1The Helix report: Is biopharma wired for future success? McKinsey & Company.

2Research and Development in the Pharmaceutical Industry, Congressional Budget Office.

3How Foundation Models Can Advance AI in Healthcare, Stanford University.

4Medication Adherence: Improve Patient Outcomes and Reduce Costs, AMA Ed Hub.

5BioGPT: generative pre-trained transformer for biomedical text generation and mining, Oxford Academic."
Microsoft_News,https://blogs.microsoft.com/blog/2023/03/28/introducing-microsoft-security-copilot-empowering-defenders-at-the-speed-of-ai/,,Introducing Microsoft Security Copilot: Empowering defenders at the speed of AI,"The odds are against today’s defenders

Today the odds remain stacked against cybersecurity professionals. Too often, they fight an asymmetric battle against prolific, relentless and sophisticated attackers. To protect their organizations, defenders must respond to threats that are often hidden among noise. Compounding this challenge is a global shortage of skilled security professionals, leading to an estimated 3.4 million openings in the field.

The volume and velocity of attacks requires us to continually create new technologies that can tip the scales in favor of defenders. Security professionals are scarce, and we must empower them to disrupt attackers’ traditional advantages and drive innovation for their organizations.

In the last few months, the world has witnessed a wave of innovation as organizations apply advanced AI to new technologies and use cases. We are ready for a paradigm shift and taking a massive leap forward by combining Microsoft’s leading security technologies with the latest advancements in AI.

Today, at our inaugural Microsoft Secure event, I am delighted to welcome you to the new era of security — shaped by the power of OpenAI’s GPT-4 generative AI — and thrilled to introduce to you Microsoft Security Copilot.

Security Copilot — end-to-end defense at machine speed and scale

Microsoft Security Copilot is the first security product to enable defenders to move at the speed and scale of AI. Security Copilot combines this advanced large language model (LLM) with a security-specific model from Microsoft. This security-specific model in turn incorporates a growing set of security-specific skills and is informed by Microsoft’s unique global threat intelligence and more than 65 trillion daily signals. Security Copilot also delivers an enterprise-grade security and privacy-compliant experience as it runs on Azure’s hyperscale infrastructure.

When Security Copilot receives a prompt from a security professional, it uses the full power of the security-specific model to deploy skills and queries that maximize the value of the latest large language model capabilities. And this is unique to a security use-case. Our cyber-trained model adds a learning system to create and tune new skills. Security Copilot then can help catch what other approaches might miss and augment an analyst’s work. In a typical incident, this boost translates into gains in the quality of detection, speed of response and ability to strengthen security posture.

Security Copilot doesn’t always get everything right. AI-generated content can contain mistakes. But Security Copilot is a closed-loop learning system, which means it’s continually learning from users and giving them the opportunity to give explicit feedback with the feedback feature that is built directly into the tool. As we continue to learn from these interactions, we are adjusting its responses to create more coherent, relevant and useful answers.

Security Copilot also integrates with the end-to-end Microsoft Security products, and over time it will expand to a growing ecosystem of third-party products. So, in short, Security Copilot is not only a large language model, but rather a system that learns, to enable organizations to truly defend at machine speed.

We absolutely believe that security is a team sport, and security should be built with privacy at the core. We’ve built Security Copilot with security teams in mind— your data is always your data and stays within your control. It is not used to train the foundation AI models, and in fact, it is protected by the most comprehensive enterprise compliance and security controls. While remaining private, each user interaction can be easily shared with other team members to accelerate incident response, collaborate more effectively on complex problems and develop collective skills.

Technology that elevates human strengths

Human creativity and knowledge will always be imperative for defense. Security Copilot can augment security professionals with machine speed and scale, so human ingenuity is deployed where it matters most. In delivering this experience, we are guided by three principles:

Simplify the complex.

In security, minutes count. With Security Copilot, defenders can respond to security incidents within minutes instead of hours or days. Security Copilot delivers critical step-by-step guidance and context through a natural language-based investigation experience that accelerates incident investigation and response. The ability to quickly summarize any process or event and tune reporting to suit a desired audience frees defenders to focus on the most pressing work.

In security, minutes count. With Security Copilot, defenders can respond to security incidents within minutes instead of hours or days. Security Copilot delivers critical step-by-step guidance and context through a natural language-based investigation experience that accelerates incident investigation and response. The ability to quickly summarize any process or event and tune reporting to suit a desired audience frees defenders to focus on the most pressing work. Catch what others miss.

Attackers hide behind noise and weak signals. Defenders can now discover malicious behavior and threat signals that could otherwise go undetected. Security Copilot surfaces prioritized threats in real time and anticipates a threat actor’s next move with continuous reasoning based on Microsoft’s global threat intelligence. Security Copilot also comes with skills that represent the expertise of security analysts in areas such as threat hunting, incident response and vulnerability management.

Attackers hide behind noise and weak signals. Defenders can now discover malicious behavior and threat signals that could otherwise go undetected. Security Copilot surfaces prioritized threats in real time and anticipates a threat actor’s next move with continuous reasoning based on Microsoft’s global threat intelligence. Security Copilot also comes with skills that represent the expertise of security analysts in areas such as threat hunting, incident response and vulnerability management. Address the talent gap.

A security team’s capacity will always be limited by the team’s size and the natural limits of human attention. Security Copilot boosts your defenders’ skills with its ability to answer security-related questions – from the basic to the complex. Security Copilot continually learns from user interactions, adapts to enterprise preferences, and advises defenders on the best course of action to achieve more secure outcomes. It also supports learning for new team members as it exposes them to new skills and approaches as they develop. This enables security teams to do more with less, and to operate with the capabilities of a larger, more mature organization.

Unrivaled security capabilities

With Security Copilot, we are taking the agility advantage back to defenders by combining Microsoft leading security technologies with the latest advancements in AI. By working with Security Copilot, organizations get access to an unrivaled depth and breadth of security AI capabilities, including:

Ongoing access to the most advanced OpenAI models to support the most demanding security tasks and applications

to support the most demanding security tasks and applications A security-specific model that benefits from continuous reinforcement, learning and user feedback to meet the unique needs of security professionals;

that benefits from continuous reinforcement, learning and user feedback to meet the unique needs of security professionals; Visibility and evergreen threat intelligence powered by your organization’s security products and the 65 trillion threat signals Microsoft sees every day to ensure that security teams are operating with the latest knowledge of attackers, their tactics, techniques, and procedures;

and the 65 trillion threat signals Microsoft sees every day to ensure that security teams are operating with the latest knowledge of attackers, their tactics, techniques, and procedures; Integration with Microsoft’s end-to-end security portfolio for a highly efficient experience that builds on the security signals;

for a highly efficient experience that builds on the security signals; A growing list of unique skills and prompts that elevate the expertise of security teams and set the bar higher for what is possible even under limited resources.

YouTube Video Click here to load media

Delivering security AI in a responsible way

Without a doubt, AI will transform how organizations around the world interact with security technologies. To achieve their highest potential, security AI solutions must be delivered in a safe, secure and responsible way. With Security Copilot, we reinforce our commitment to impactful and responsible AI practices by innovating responsibly, empowering others, and fostering positive impact.

The cornerstone of this work is our commitment to how Security Copilot handles your data:

Your data is your data. It’s yours to own and control, and yours to choose how you want to leverage and monetize.

It’s yours to own and control, and yours to choose how you want to leverage and monetize. Your data is not used to train or enrich foundation AI models used by others – no one beyond your organization is benefiting from AI trained on your data or business processes.

used by others – no one beyond your organization is benefiting from AI trained on your data or business processes. Your data and AI models are protected at every step by the most comprehensive enterprise compliance and security controls in the industry.

The new era of security

At Microsoft, we believe that security is ultimately about people. With Security Copilot, we are building a future where every defender is empowered with the technologies and expertise that enable them to reach their full potential. Technology will play an essential role on this journey, but successful security is, and will continue to be, a human endeavor.

We’re excited to be on this journey with you and we look forward to sharing more soon. Welcome to the new era of security.

Editor’s note, April 12, 2024: Microsoft Copilot for Security with new capabilities is now available worldwide.

Watch the Microsoft Security Copilot demo >

Microsoft Secure: Explore innovations transforming the future of security

Stay up to date >

Related links:

Meeting the moment: advancing the future through responsible AI

How AI impacts Future of Security

Microsoft Security reaches another milestone — Comprehensive, customer-centric solutions drive results

Reinventing search with a new AI-powered Microsoft Bing and Edge, your copilot for the web

Citations:

Cyber Signals Volume 2

Tags: AI, Microsoft Security Copilot, Security"
Microsoft_News,https://www.microsoft.com/en-us/worklab/podcast/stanford-professor-erik-brynjolfson-on-how-ai-will-transform-productivity,,"WorkLab: Hard Data, Compelling Stories, Vital Insights","Customer Zero

Our Year with Copilot: What Microsoft Has Learned About AI at Work

Getting AI right requires intention, experimentation, and some unexpected heroes. Here’s how you can apply insights from our experience to your own organization."
Microsoft_News,https://cloudblogs.microsoft.com/dynamics365/bdm/2023/03/23/introducing-a-new-era-of-ai-powered-experiences-in-dynamics-365-business-central/,,AI-powered experiences in Dynamics 365 Business Central,"This is an exciting time in the evolution of AI, and you don’t have to look far to see the headlines on ways it is changing the world. From advanced machine learning models to breakthrough natural language technology, new opportunities to use AI to improve the way we work are surfacing daily. AI innovation can free employees from mundane, repetitive tasks and allow them to focus on the work that matters most, increasing job satisfaction and pushing productivity to new heights. According to our recent survey on business trends, 89 percent of those with access to automation and AI-powered tools feel more fulfilled because they can spend time on work that truly matters.1

Microsoft Dynamics 365 Business Central brings the power of AI to small and medium-sized businesses with features that help companies work smarter, adapt faster, and perform better. Let’s explore some of the ways that AI in Business Central is improving how work gets done, including:

Automating repetitive tasks

Improving customer service

Anticipating business challenges

Enhancing decision making

Automate repetitive tasks with Copilot in Business Central

Microsoft Dynamics 365 Copilot introduces the next generation of AI-powered experiences to Microsoft Dynamics 365 business applications. Dynamics 365 Copilot provides AI assistance directly in the flow of work using natural language technology, automating repetitive tasks, and unlocking creativity. Dynamics 365 Copilot is the world’s first copilot in both customer relationship management (CRM) and enterprise resource planning (ERP), ushering in the new age of productivity for businesses of all sizes.

With Copilot in Business Central, product managers can save time and drive sales with engaging AI-generated product descriptions. Banish writer’s block with unique, compelling marketing text created in seconds using product attributes such as color, material, and size. Tailor the descriptions to your brand by choosing a tone of voice, as well as format and length. Complete the process by publishing to Shopify or other ecommerce stores with just a few clicks. Copilot in Business Central makes launching new products fast and easy so you can focus on growing your business. Try Copilot in Business Central today.

Improve customer service with Sales and Inventory Forecasting

In a highly competitive business landscape, effective inventory management can be the key differentiator between a successful business and one that struggles to retain customers and remain profitable. Inventory management is a trade-off between customer service and managing your costs. While low inventory requires less working capital, inventory shortages can lead to missed sales. Using AI, the Sales and Inventory Forecast extension predicts future sales using historical data to help you avoid stockouts. Based on the forecast and inventory levels, the extension helps create replenishment requests to your vendors, helping you save time and improve inventory availability to keep your customers happy.

Anticipate business challenges with Late Payment Predictions

Effectively managing receivables is critical to the overall financial health of a business. The Late Payment Prediction extension can help you reduce outstanding receivables and fine-tune your collections strategy by predicting whether sales invoices will be paid on time. For example, if a payment is predicted to be late, you might decide to adjust the terms of payment or the payment method for the customer. By anticipating late payments and making adjustments, you can better manage and ultimately reduce overdue receivables.

Enhance decision-making with Cash Flow Analysis

Azure AI in Business Central helps you create a comprehensive cash flow forecast with Cash Flow Analysis, enhancing decision-making so you can stay in control of your cash flow. A company’s cash flow indicates its financial solvency and reveals whether the company can meet its financial obligations in a timely manner. To make sure that your company is solvent, a future-oriented planning instrument is necessary. With insights from AI, you can make proactive adjustments to ensure your company’s fiscal health, such as reducing credit when you have a cash surplus or borrowing to mitigate a cash deficit.

Innovate with Business Central

In today’s fast-paced market, AI has become essential for companies looking to stay ahead of the competition. The AI tools built into Business Central can help you improve the end-to-end customer experience, reduce costs, and boost financial success. With the ability to automate repetitive tasks, analyze data, and offer personalized recommendations, Business Central can help you operate more efficiently and grow your business.

Dynamics 365 Business Central Adapt faster, work smarter, and perform better with Business Central. Download the guide

Sources

1 Four Ways Leaders Can Empower People for How Work Gets Done"
Microsoft_News,https://news.microsoft.com/en-gb/2023/03/23/seven-things-to-know-about-responsible-ai/,,Seven things to know about Responsible AI,"Seven things to know about Responsible AI

Artificial intelligence is rapidly transforming our world. Whether it’s ChatGPT or the new Bing, our recently announced AI-powered search experience, there has been a lot of excitement about the potential benefits.

But with all the excitement, naturally there are questions, concerns, and curiosity about this latest development in tech, particularly when it comes to ensuring that AI is used responsibly and ethically. Microsoft’s Chief Responsible AI Officer, Natasha Crampton, was in the UK to meet with policymakers, civil society members, and the tech community to hear perspectives about what matters to them when it comes to AI, and to share more about Microsoft’s approach.

We spoke with Natasha to understand how her team is working to ensure that a responsible approach to AI development and deployment is at the heart of this step change in how we use technology. Here are seven key insights Natasha shared with us.

1. Microsoft has a dedicated Office of Responsible AI

“We’ve been hard at work on these issues since 2017, when we established our research-led Aether committee (Aether is an acronym for AI, Ethics and Effects in Engineering and Research). It was here we really started to go deeper on what these issues really mean for the world. From this, we adopted a set of principles in 2018 to guide our work.

The Office of Responsible AI was then established in 2019 to ensure we had a comprehensive approach to Responsible AI, much like we do for Privacy, Accessibility, and Security. Since then, we’ve been sharpening our practice, spending a lot of time figuring out what a principle such as accountability actually means in practice.

We’re then able to give engineering teams concrete guidance on how to fulfil those principles, and we share what we have learned with our customers, as well as broader society.”

2. Responsibility is a key part of AI design — not an afterthought

“In the summer of 2022, we received an exciting new model from OpenAI. Straightaway we assembled a group of testers and had people probe the raw model to understand what its capabilities and its limitations were.

The insights generated from this research helped Microsoft think about what the right mitigations will be when we combine this model with the power of web search. It also helped OpenAI, who are constantly developing their model, to try to bake more safety into them.

We built new testing pipelines where we thought about the potential harms of the model in a web search context. We then developed systematic approaches to measurement so we could better understand what some of main challenges we could have with this type of technology — one example being what is known as ‘hallucination’, where the model may make up facts that are not actually true.

By November we’d figured out how we can measure them and then better mitigate them over time. We designed this product with Responsible AI controls at its core, so they’re an inherent part of the product. I’m proud of the way in which the whole responsible AI ecosystem came together to work on it.”

3. Microsoft is working to ground responses in search results

“Hallucinations are a well-known issue with large language models generally. The main way Microsoft can address them in the Bing product is to ensure the output of the model is grounded in search results.

This means that the response provided to a user’s query is centred on high-ranking content from the web, and we provide links to websites so that users can learn more.

Bing ranks web search content by heavily weighting features such as relevance, quality and credibility, and freshness. We consider grounded responses to be responses from the new Bing, in which claims are supported by information contained in input sources, such as web search results from the query, Bing’s knowledge base of fact-checked information, and, for the chat experience, recent conversational history from a given chat. Ungrounded responses are those in which a claim is not grounded in those input sources.

We knew there would be new challenges that would emerge when we invited a small group of users to try the new Bing, so we designed the release strategy to be an incremental one so we could learn from early users. We’re grateful for those learnings, as it helps us make the product stronger. Through this process we have put new mitigations in place, and we are continuing to evolve our approach.”

4. Microsoft’s Responsible AI Standard is intended for use by everyone

“In June 2022, we decided to publish the Responsible AI standard. We don’t normally publish our internal standards to the general public, but we believe it is important to share what we’ve learned in this context, and help our customers and partners navigate through what can sometimes be new terrain for them, as much as it is for us.

When we build tools within Microsoft to help us identify and measure and mitigate responsible AI challenges, we bake those tools into our Azure machine learning (ML) development platform so our customers can also use them for their own benefit.

For some of our new products built on OpenAI, we’ve developed a safety system so that our customers can take advantage of our innovation and our learnings as opposed to having to build all this tech for themselves from scratch. We want to ensure our customers and partners are empowered to make responsible deployment decisions.”

5. Diverse teams and viewpoints are key to ensuring Responsible AI

“Working on Responsible AI is incredibly multidisciplinary, and I love that. I work with researchers, such as the team at Microsoft UK’s Research Lab in Cambridge, engineers and policy makers. It’s crucial that we have diverse perspectives applied to our work for us to be able to move forward in a responsible way.

By working with a huge range of people across Microsoft, we harness the full strength of our Responsible AI ecosystem in building these products. It’s been a joy to get our cross-functional teams to a point where we really understand each other’s language. It took time to get to there, but now we can strive toward advancing our shared goals together.

But it can’t just be people at Microsoft making all the decisions in building this technology. We want to hear outside perspectives on what we’re doing, and how we could do things differently. Whether it’s through user research or ongoing dialogues with civil society groups, it’s essential we’re bringing the everyday experiences of different people into our work. It’s something we must always be committed to because we can’t build technology that serves the world unless we have open dialogue with the people who are using it and feeling the impacts of it in their lives.”

6. AI is technology built by humans, for humans

“At Microsoft, our mission is to empower every person and every organisation on the planet to achieve more. That means we make sure we’re building technology by humans, for humans. We should really look at this technology as a tool to amplify human potential, not as a substitute.

On a personal level, AI helps me grapple with vast amounts of information. One of my jobs is to track all regulatory AI developments and help Microsoft develop positions. Being able to use technology to help me summarise large numbers of policy documents quickly enables me to ask follow-up questions to the right people.”

7. We’re currently on the frontiers — but Responsible AI is a forever job

“One of the exciting things about this cutting-edge technology is that we’re really on the frontiers. Naturally there are a range of issues in development that we are dealing with for the very first time, but we’re building on six years of responsible AI work.

There are still a lot of research questions where we know the right questions to ask, but we don’t necessarily have the right answers in all cases. We will need to continually look around those corners, ask the hard questions, and over time we’ll be able to build up patterns and answers.

What makes our Responsible AI ecosystem at Microsoft so strong is that we do combine the best of research, policy, and engineering. It’s this three-pronged approach that helps us look around corners and anticipate what’s coming next. It’s an exciting time in technology and I’m very proud of the work my team is doing to bring this next generation of AI tools and services to the world in a responsible way.”

Ethical AI integration: 3 tips to get started

You’ve seen the technology, you’re keen to try it out – but how do you ensure responsible AI is a part of your strategy? Here are Natasha’s top three tips:

Think deeply about your use case. Ask yourself, what are the benefits you are trying to secure? What are the potential harms you are trying to avoid? An Impact Assessment can be a very helpful step in developing your early product design. Assemble a diverse team to help test your product prior to release and on an ongoing basis. Techniques like red-teaming can help push the boundaries of your systems and see how effective your protections are. Be committed to ongoing learning and improvement . An incremental release strategy helps you learn and adapt quickly. Make sure you have strong feedback channels and resources for continual improvement. Leverage resources that reflect best practices wherever possible.

Find out more: There are a host of resources, including tools, guides and assessment templates, on Microsoft’s Responsible AI principle hub to help you navigate AI integration ethically.

Tags: AI, ethics, responsible AI"
Microsoft_News,https://blogs.microsoft.com/on-the-issues/2023/03/23/ai-nonprofit-chatgpt-fundraising-effectiveness-project/,,AI brings a tech-tonic shift for nonprofits,"AI has been quietly making its way into our lives for years now in everything from speech recognition to streaming sites that point us toward movies we’re likely to enjoy. But it was the recent release of ChatGPT that really got everyone’s attention and made clear just how far-reaching the impact of AI will be in augmenting how we work, learn and live.

And that’s just based on the breakthroughs we’re seeing today.

As a company whose mission is to empower every person and every organization on the planet to achieve more, at Microsoft we recognize the potential of AI to serve as a catalyst for a new era of opportunity and economic growth. But to ensure this economic growth is inclusive, everyone will need some degree of AI fluency to both understand and leverage this technology. Workers at every level and in every industry must have the skills to fully harness AI – to boost their careers, transform their industries and grow their businesses. And nonprofits are perhaps in the best position to harness the power of AI to increase productivity to do more, do it faster and be more inclusive in their work.

This is especially important now. From the work to address the impacts of climate change, to providing humanitarian relief following natural disasters, to delivering services and skills training to people in underserved communities, nonprofits are a lifeline and a source of hope and opportunity.

While nonprofits have always struggled to get the most out of the donations and grants that fund their work, today they operate in the face of unusually strong economic headwinds. For the 1.6 million US-based nonprofits, income growth ranges between 2% to 3% but inflation is currently running at about 6%. This means nonprofit budgets are effectively shrinking, which inevitably translates to reduced community impact. Meanwhile, the Fundraising Effectiveness Project reports that the number of people donating to nonprofits is declining and smaller donors are contributing less. And then there’s the fear that a recession may be looming.

The good news is AI can be a tremendous tool for helping nonprofits increase impact. Even though we are at the beginning of a new era of AI-driven innovation, it’s clear that today’s AI tools can help nonprofits accelerate their missions in a number of critically important ways:

Cost savings. Using AI to automate steps in everything from grant writing to engaging with donors can yield significant cost reductions. Already, we’re seeing examples where generative AI can lower the average unit cost of manual tasks from $15-35 to under $1.

Increased productivity. By automating routine tasks, analyzing large amounts of data, and driving informed, data-driven decisions, AI offers a clear path to expanded effectiveness through greater productivity in a time of tighter budgets.

Higher impact. AI doesn’t replace nonprofit employees. Instead, it empowers them to do more so they can focus on the initiatives that deliver the greatest impact. The timing couldn’t be better as nonprofits are constantly being asked to do more with less.

Today, nonprofits need access to AI solutions that are responsible, accessible, practical, and affordable. That’s why we’re building easy-to-use AI capabilities for nonprofits that focus on fundraising, marketing and program delivery. We look forward to sharing more information about these tools and solutions next week.

We’re also looking at new ways to help nonprofit employees gain the skills they need to harness the power of AI. We’ll do this through investments in comprehensive training programs and by creating a global learning community for nonprofits around the world.

The other day my younger son was playing with ChatGPT and declared it “the future of life!” I’m quite confident humans will always be the future of life, but in an important way, he was spot on. AI will fundamentally change our lives. By putting it in the hands of the nonprofits working to solve the world’s problems and ensuring that AI fluency and skills are universal, I am confident that, together, we can make the world a better place.

Tags: artificial intelligence, ChatGPT, nonprofits"
Microsoft_News,https://news.microsoft.com/source/features/ai/explaining-ai-the-fundamentals-and-the-frontiers/,,Explaining AI: The fundamentals and the frontiers,"You might not realize it, but you probably use artificial intelligence (AI) every day. AI is everywhere, and it’s constantly changing how we work and play.

But how does AI work? And how can we use AI responsibly?

In this series of videos, we’re taking you behind the scenes of Microsoft AI to show how it’s helping us create, learn and innovate.

What is Microsoft’s approach to AI?

Have you ever wondered how artificial intelligence (AI) is helping people create, solve complex problems and benefit their communities? Microsoft has been responsibly developing AI for decades and is using breakthroughs in AI to make life easier for us in everyday ways.

Click here to load media

How Microsoft drives responsible AI

Microsoft is committed to a practice of responsible AI by design, guided by a core set of principles: fairness, reliability and safety, privacy and security, inclusiveness, transparency and accountability. Learn how Microsoft is putting these principles into practice.

Click here to load media

How generative AI can help you create whatever you want

Generative AI is a type of AI that can create everything from images and rap lyrics to social media posts and vacation itineraries. Learn how it works, what it can do and how you can use it to unleash your creativity.

Click here to load media

How Microsoft AI Can Boost Your Productivity and Creativity

Learn how AI can help you overcome writer’s block, curate content, and boost productivity with Microsoft 365 Copilot.

Click here to load media

How Azure Infrastructure Powers Microsoft AI

Find out more about how Azure supercomputing infrastructure is powering the next wave of generative AI tools.

Click here to load media

How Microsoft uses AI for good

Did you know that AI can help save whales, fight heart disease, and make technology more accessible? Learn how Microsoft is investing in AI for Good to create a better world for everyone."
Microsoft_News,https://github.blog/2023-03-22-github-copilot-x-the-ai-powered-developer-experience/,,GitHub Copilot X: The AI-powered developer experience,"At GitHub, our mission has always been to innovate ahead of the curve and give developers everything they need to be happier and more productive in a world powered by software. When we began experimenting with large language models several years ago, it quickly became clear that generative AI represents the future of software development. We partnered with OpenAI to create GitHub Copilot, the world’s first at-scale generative AI development tool made with OpenAI’s Codex model, a descendent of GPT-3.

GitHub Copilot started a new age of software development as an AI pair programmer that keeps developers in the flow by auto-completing comments and code. And less than two years since its launch, GitHub Copilot is already writing 46% of code and helps developers code up to 55% faster.

But AI-powered auto-completion is just the starting point. Our R&D team at GitHub Next has been working to move past the editor and evolve GitHub Copilot into a readily accessible AI assistant throughout the entire development lifecycle. This is GitHub Copilot X—our vision for the future of AI-powered software development. We are not only adopting OpenAI’s new GPT-4 model, but are introducing chat and voice for Copilot, and bringing Copilot to pull requests, the command line, and docs to answer questions on your projects.

With AI available at every step, we can fundamentally redefine developer productivity. We are reducing boilerplate and manual tasks and making complex work easier across the developer lifecycle. By doing so, we’re enabling every developer to focus all their creativity on the big picture: building the innovation of tomorrow and accelerating human progress, today.

Let’s jump in.

Want to see what’s new? Discover GitHub Copilot X—our vision for the future of AI-powered software development. Learn more >

Many developers and companies have already used GitHub Copilot, and it’s helping improve productivity and happiness.

A new AI-powered developer experience 🧑‍💻

A ChatGPT-like experience in your editor with GitHub Copilot Chat: We are bringing a chat interface to the editor that’s focused on developer scenarios and natively integrates with VS Code and Visual Studio. This does far more than suggest code. GitHub Copilot Chat is not just a chat window. It recognizes what code a developer has typed, what error messages are shown, and it’s deeply embedded into the IDE. A developer can get in-depth analysis and explanations of what code blocks are intended to do, generate unit tests, and even get proposed fixes to bugs.

GitHub Copilot Chat builds upon the work that OpenAI and Microsoft have done with ChatGPT and the new Bing. It will also join our voice-to-code AI technology extension we previously demoed, which we’re now calling GitHub Copilot Voice, where developers can verbally give natural language prompts.

Sign up for the technical preview >

Copilot for Pull Requests: You can now sign up for a technical preview of the first AI-generated descriptions for pull requests on GitHub. This new functionality is powered by OpenAI’s new GPT-4 model and adds support for AI-powered tags in pull request descriptions through a GitHub app that organization admins and individual repository owners can install. These tags are automatically filled out by GitHub Copilot based on the changed code. Developers can then review or modify the suggested description.

Enroll your repository in the technical preview >

This is just the first step we’re taking to rethink how pull requests work on GitHub. We’re testing new capabilities internally where GitHub Copilot will automatically suggest sentences and paragraphs as developers create pull requests by dynamically pulling in information about code changes.

We are also preparing a new feature where GitHub Copilot will automatically warn developers if they’re missing sufficient testing for a pull request and then suggest potential tests that can be edited, accepted, or rejected based on a project’s needs.

This complements our efforts with GitHub Copilot Chat where developers can ask GitHub Copilot to generate tests right from their editor—so, in the event a developer may not have sufficient test coverage, GitHub Copilot will alert them once they submit a pull request. It will also help project owners to set policies around testing, while supporting developers to meet these policies.

Get AI-generated answers about documentation: We are launching GitHub Copilot for Docs, an experimental tool that uses a chat interface to provide users with AI-generated responses to questions about documentation—including questions developers have about the languages, frameworks, and technologies they’re using. We’re starting with documentation for React, Azure Docs, and MDN, so we can learn and iterate quickly with the developers and users of these projects.

Join the waitlist >

We’re also working to bring this functionality to any organization’s repositories and internal documentation—so any developer can ask questions via a ChatGPT-like interface about documentation, idiomatic code, or in-house software in their organization and get instant answers.

We know that the benefits of a conversational interface are immense, and we are working to enable semantic understanding of the entirety of GitHub across public and private knowledge bases to better personalize GitHub Copilot’s answers for organizations, teams, companies, and individual developers alike based on their codebase and documentation.

Moving forward, we are exploring the best ways to index resources beyond documentation such as issues, pull requests, discussions, and wikis to give developers everything they need to answer technical questions.

Powered by OpenAI’s new GPT-4 model Our work to rethink pull requests and documentation is powered by OpenAI’s newly released GPT-4 AI model. Even though this model was just released, we’re already seeing significant gains in logical reasoning and code generation. With GPT-4, the state of AI is beginning to catch up with our ambition to create an AI pair programmer that assists with every development task at every point in the developer experience. Moreover, it’s helping GitHub Copilot understand more of a developer’s codebase to offer more tailored suggestions in PRs and better summations of documentation.

Copilot for the command line interface (CLI): Next to the editor and pull request, the terminal is the place where developers spend the most time. But even the most proficient developers need to scroll through many pages to remember the precise syntax of many commands. This is why we are launching GitHub Copilot CLI. It can compose commands and loops, and throw around obscure find flags to satisfy your query.

Join the waitlist >

A demo of GitHub Copilot for CLI.

Let’s build from here 🚀

From reading docs to writing code to submitting pull requests and beyond, we’re working to personalize GitHub Copilot for every team, project, and repository it’s used in, creating a radically improved software development lifecycle. Together with Microsoft’s knowledge model, we will harness the reservoir of data and insights that exist in every organization, to strengthen the connection between all workers and developers, so every idea can go from code to reality without friction. At the same time, we will continue to innovate and update the heart of GitHub Copilot—the AI pair programmer that started it all.

GitHub Copilot X is on the horizon, and with it a new generation of more productive, fulfilled, and happy developers who will ship better software for everyone. So—let’s build from here."
Microsoft_News,https://azure.microsoft.com/en-us/blog/introducing-gpt4-in-azure-openai-service/,,Introducing GPT-4 in Azure OpenAI Service,"At Microsoft, we are constantly discovering new ways to unleash creativity, unlock productivity, and uplevel skills so that more people can benefit from using AI. This is allowing our customers to build the future faster and more responsibly by powering their apps using large-scale AI models. Our collaboration with OpenAI, along with the power of Azure have been core to our journey.

Today, we are excited to announce that GPT-4 is available in preview in Azure OpenAI Service. Customers and partners already using Azure OpenAI Service can apply for access to GPT-4 and start building with OpenAI’s most advanced model yet. With this milestone, we are proud to bring the world’s most advanced AI models—including GPT-3.5, ChatGPT, and DALL•E 2—to Azure customers, backed by Azure AI-optimized infrastructure, enterprise-readiness, compliance, data security, and privacy controls, along with many integrations with other Azure services.

Customers can begin applying for access to GPT-4 today. Billing for all GPT-4 usage begins April 1, 2023, at the following prices:

GPT-4 Prompt Completion 8k context $0.03 per 1,000 tokens $0.06 per 1,000 tokens 32k context $0.06 per 1,000 tokens $0.12 per 1,000 tokens

GPT-4 for every business

While the recently announced new Bing and Microsoft 365 Copilot products are already powered by GPT-4, today’s announcement allows businesses to take advantage of the same underlying advanced models to build their own applications leveraging Azure OpenAI Service.

With generative AI technologies, we are unlocking new efficiencies for businesses in every industry. For instance, see how Azure OpenAI Service can allow bot developers to create virtual assistants in minutes using natural language with Copilot in Power Virtual Agents.

GPT-4 has the potential to take this experience to a whole new level using its broader knowledge, problem-solving abilities, and domain expertise. With GPT-4 in Azure OpenAI Service, businesses can streamline communications internally as well as with their customers, using a model with additional safety investments to reduce harmful outputs.

Companies of all sizes are putting Azure AI to work for them, many deploying language models into production using Azure OpenAI Service, and knowing that the service is backed by the unique supercomputing and enterprise capabilities of Azure. Solutions include improving customer experiences end-to-end, summarizing long-form content, helping write software, and even reducing risk by predicting the right tax data.

Customers are accelerating the adoption of language models

We are just scratching the surface with generative AI technologies and are working to enable our customers to responsibly adopt Azure OpenAI Service to bring real impact. With GPT-4, Epic Healthcare, Coursera, and Coca-Cola plan to use this advancement in unique ways:

“Our investigation of GPT-4 has shown tremendous potential for its use in healthcare. We’ll use it to help physicians and nurses spend less time at the keyboard and to help them investigate data in more conversational, easy-to-use ways.”—Seth Hain, Senior Vice President of Research and Development at Epic

“Coursera is using Azure OpenAI Service to create a new AI-powered learning experience on its platform, enabling learners to get high-quality and personalized support throughout their learning journeys. Together, Azure OpenAI Service and the new GPT-4 model will help millions around the world learn even more effectively on Coursera.”—Mustafa Furniturewala, Senior Vice President of Engineering at Coursera

“Words cannot express the excitement and gratitude we feel as a consumer package goods company for the boundless opportunities that Azure OpenAI has presented us. With Azure Cognitive Services at the heart of our digital services framework, we have harnessed the transformative power of OpenAI’s text and image generation models to solve business problems and build a knowledge hub. But it is the sheer potential of OpenAI’s upcoming GPT-4 multimodal capabilities that truly fills us with awe and wonder. The possibilities for marketing, advertising, public relations, and customer relations are endless, and we cannot wait to be at the forefront of this revolutionary technology. We know that our success is not just about technology but also about having the right enterprise features in place. That’s why we’re proud to have a long-standing partnership with Microsoft Azure, ensuring that we have all the tools we need to deliver exceptional experiences to our customers. Azure OpenAI is more than just cutting-edge technology—it’s a true game-changer, and we’re honored to be a part of this incredible journey.”—Lokesh Reddy Vangala, Senior Director of Engineering, Data and AI, The Coca-Cola Company

Our commitment to responsible AI

As we described in my previous blog, Microsoft has a layered approach for generative models, guided by Microsoft’s Responsible AI Principles. In Azure OpenAI, an integrated safety system provides protection from undesirable inputs and outputs and monitors for misuse. On top of that, we provide guidance and best practices for customers to responsibly build applications using these models, and we expect customers to comply with the Azure OpenAI Code of Conduct. With GPT-4, new research advances from OpenAI have enabled an additional layer of protection. Guided by human feedback, safety is built directly into the GPT-4 model, which enables the model to be more effective at handling harmful inputs, thereby reducing the likelihood that the model will generate a harmful response.

Getting started with GPT-4 in Azure OpenAI Service"
Microsoft_News,https://blogs.microsoft.com/blog/2023/03/21/create-images-with-your-words-bing-image-creator-comes-to-the-new-bing/,,Bing Image Creator comes to the new Bing,"Last month we introduced the new AI-powered Bing and Microsoft Edge, your copilot for the web – delivering better search, complete answers, a new chat experience and the ability to create content. Already, we have seen that chat is reinventing how people search with more than 100 million chats to date. We’ve seen people use chat in a variety of ways, from refining answers to complex questions to using it as a form of entertainment or for creative inspiration. Today we’re taking the chat experience to the next level by making the new Bing more visual.

We’re excited to announce we are bringing Bing Image Creator, new AI-powered visual Stories and updated Knowledge Cards to the new Bing and Edge preview. Powered by an advanced version of the DALL∙E model from our partners at OpenAI, Bing Image Creator allows you to create an image simply by using your own words to describe the picture you want to see. Now you can generate both written and visual content in one place, from within chat.

We know from research that the human brain processes visual information about 60,000 times faster than text, making visual tools a critical way people search, create and gain understanding. Based on Bing data, images are one of the most searched categories – second only to general web searches. Historically, search was limited to images that already existed on the web. Now, there are almost no limits to what you can search for and create.

For those in the Bing preview, Bing Image Creator will be fully integrated into the Bing chat experience, rolling out initially in Creative mode. By typing in a description of an image, providing additional context like location or activity, and choosing an art style, Image Creator will generate an image from your own imagination. It’s like your creative copilot. Just type something like “draw an image” or “create an image” as a prompt in chat to get creating a visual for a newsletter to friends or as inspiration for redecorating your living room.

Bing Image Creator preview will also be available in Microsoft Edge, making it the first and only browser with an integrated AI-powered image generator. To use Bing Image Creator in Edge, simply click the Bing Image Creator icon in the sidebar to create your image or invoke from Bing chat in Edge.

At Microsoft, our teams are guided by our Responsible AI principles and the Responsible AI Standard to help them develop and deploy AI systems responsibly. To curb the potential misuse of Image creator, we are working together with our partner OpenAI, who developed DALL∙E, to deliver an experience that encourages responsible use of Image Creator. We have ensured OpenAI’s safeguards, plus additional protections, have been incorporated into Image Creator. For example, we have put controls in place that aim to limit the generation of harmful or unsafe images. When our system detects that a potentially harmful image could be generated by a prompt, it blocks the prompt and warns the user. We also make it clear that Image Creator’s images are generated by AI, and we include a modified Bing icon in the bottom left corner of each image to help indicate that the image was created using Image Creator. We continue to work closely with OpenAI to build, test and review mitigations for our integrations.

Since making the new Bing available in preview, we have been testing it with people to get real-world feedback to learn and improve the experience. People used it in some ways we expected and others we didn’t. In this spirit of learning and continuing to build new capabilities responsibly, we’re rolling out Bing Image Creator in a phased approach by flighting with a set of preview users before expanding more broadly. We will initially only include Image Creator in the Creative mode of Bing chat and our intention is to make it available in Balanced and Precise mode over time. We are also working on some ongoing optimizations for how Image Creator works in multi-turn chats. We continue to believe the best way to bring these technologies to market is to test them carefully, in the open, where everyone can provide feedback.

New AI-Powered Visual Stories and Knowledge Cards

To support the growing demand for more visual search experiences, we are also making Stories and Knowledge Cards 2.0 available to all Bing users. Stories provide a more engaging way to search and interact with content, offering images and short videos. Also new to Bing users today, Knowledge Cards 2.0 is an AI-powered infographic-inspired experience that provides fun facts and key information at a glance. It’s been updated to include interactive, dynamic content like charts, graphs, timelines, visual stories and more. With these updates and more coming, our goal is to deliver more immersive experiences in Bing and Edge that make finding answers and exploring the web more interesting, useful and fun.

Availability

Bing Image Creator integrated into Bing chat will begin to roll out to Bing preview users on both desktop and mobile starting today. For those not in the new Bing preview, the preview experience of Image Creator is now available at bing.com/create for Bing users around the world in English. We will add more language support over time.

Bing Image Creator is also available in Microsoft Edge from the Image Creator icon in sidebar for both desktop and mobile starting today for Edge users around the world in English. We will also soon integrate Image Creator into Edge from the new Bing button in chat mode in the preview version of Edge.

If you’re not yet in the new Bing preview, you can sign up for the waitlist today. We’re adding more people every day. Thanks for your continued feedback and we look forward to sharing more updates soon.

Tags: AI, Bing, Bing Image Creator, Microsoft Edge, search"
Microsoft_News,https://blogs.microsoft.com/blog/2023/03/20/breaking-new-ground-in-healthcare-with-the-next-evolution-of-ai/,,Breaking new ground in healthcare with the next evolution of AI,"Since the beginning of modern medicine, the arc of innovation has delivered previously unimaginable breakthroughs and treatments that have improved health outcomes and lengthened lifespans. We are now in an era where digital transformation is redefining the way organizations approach patient engagement, care team collaboration and the provider experience. From better access to patient data through electronic health records (EHR) to improved access to healthcare through telemedicine, technology has given providers solutions that enable greater productivity and, most importantly, improve the quality of care available to patients.

But there is an opportunity to do more. The healthcare industry still faces challenges that technology can play a vital role in addressing. Next-generation AI has the potential to revolutionize healthcare by empowering clinicians to focus on personalized patient connections – strengthening the human interaction in medicine, reducing costs, and easing the administrative and cognitive burdens providers face. This is the reason that Microsoft and Nuance joined forces in 2022.

Today we are introducing a new solution, Dragon Ambient eXperience (DAX™) Express, which represents the next breakthrough for healthcare and a major milestone in our journey to automate clinical documentation at scale. DAX Express is an automated clinical documentation application integrated into the workflow that is the first to combine proven conversational and ambient AI with the advanced reasoning and natural language capabilities of OpenAI’s GPT-4. Extending the proven Dragon Medical portfolio of solutions and building on the market-leading DAX ambient solution launched in 2020, DAX Express is the next milestone in Nuance’s long-standing mission to reduce administrative burden and empower clinicians to spend more time taking care of patients and less time on paperwork.

AI solutions at work in healthcare today

Physicians and nurses have been overwhelmed by the administrative demands that come with providing high-quality care. They must navigate complicated coding and billing requirements, manage the cognitive burden to accurately record and recall increasing amounts of patient data, and treat an aging and growing population. As a result, many organizations, including the U.S. Surgeon General and professional medical associations, are urging the development of comprehensive, secure solutions that can be seamlessly integrated into clinical workflows to reduce clinician burnout.

DAX Express tackles this head-on, with advanced automated clinical documentation seamlessly integrated in physicians’ workflows. It’s another proof point of how Microsoft and Nuance’s solutions, backed by industry-defining AI and amplified by the power of the Microsoft Cloud for Healthcare, are reshaping care delivery with measurable and growing outcomes:

Relieving workforce burnout – Our solutions are proven to lead the industry in addressing this seemingly intractable problem – with physicians reporting up to 70% reduction in feelings of burnout and fatigue.

– Our solutions are proven to lead the industry in addressing this seemingly intractable problem – with physicians reporting up to 70% reduction in feelings of burnout and fatigue. Supporting specialty workflows – From surgeons to radiologists, our solutions analyze vast amounts of patient data, deliver workflow automation, facilitate reporting and communication, and provide AI insights that support more informed decision-making, planning and treatment—improving radiologist efficiency by 50% and reducing time-to-intervention by 74%.

– From surgeons to radiologists, our solutions analyze vast amounts of patient data, deliver workflow automation, facilitate reporting and communication, and provide AI insights that support more informed decision-making, planning and treatment—improving radiologist efficiency by 50% and reducing time-to-intervention by 74%. Improving adherence – By analyzing data to uncover findings, simplifying patient and physician communication, and providing comprehensive care plan tracking, our solutions deliver a 52% improvement in follow-up adherence.

– By analyzing data to uncover findings, simplifying patient and physician communication, and providing comprehensive care plan tracking, our solutions deliver a 52% improvement in follow-up adherence. Increasing access to care – Our automated clinical documentation solutions give back time to clinicians who often choose to see more patients, adding five appointments per average clinic day – enabling clinicians to provide their best care to more people.

– Our automated clinical documentation solutions give back time to clinicians who often choose to see more patients, adding five appointments per average clinic day – enabling clinicians to provide their best care to more people. Enhancing patient engagement – AI-powered chatbots are just one example of how AI is providing patients with quick and accessible information using built-in medical knowledge bases and triage protocols, which can trigger seamless handoff from bot interaction to a doctor, nurse or support agent. And, by delivering consistent and contextually relevant patient experiences, healthcare organizations are realizing 30% increases in patient self-service rates and 50% reductions in patient support costs.

Shared mission and complementary capabilities in healthcare

Microsoft and Nuance came together with a shared vision to reshape healthcare: leveraging our unique capabilities to solve the industry’s biggest challenges and equip the entire ecosystem to achieve more. At our core, we believe that technologies like AI, in partnership with clinicians, play a key role in accelerating progress in the industry, making physician and patient experiences more personal and engaging, and helping increase access to care. Our North Star is empowering clinicians to return their focus to patient care – using our proven solutions, combined with their judgment, to reduce cognitive burdens and support better outcomes.

Microsoft and Nuance have for years been ahead of the curve in innovating AI solutions, and organizations large and small have long trusted our responsible, secure applications and infrastructure. Microsoft’s years of strategic investments in research, cloud and AI – including the acquisition of Nuance – have led us to where we are today. Through the Microsoft Cloud for Healthcare, Microsoft is providing responsible, integrated AI capabilities at scale that make it easier to improve the entire healthcare experience. Microsoft is also driving research, incubations and moonshots that drive real-world impact across healthcare and the life sciences. For example, Microsoft Research partners with leading organizations to advance and build infrastructure for emerging precision health modalities and empowers scientists with AI to speed up the discovery and development of breakthrough medicines. And we’re empowering health organizations to tackle some of the toughest challenges in global health with our AI for Health philanthropic program.

Similarly, Nuance has decades of experience developing healthcare solutions used by hundreds of thousands of practitioners that are proven to consistently deliver value for physicians, nurses, radiologists and patients. Nuance has long been at the forefront of innovating conversational and ambient AI in healthcare – most notably with Dragon Medical One and most recently with DAX – and for years has leveraged expertise in large language models, natural language processing and clinical workflows to deliver refined, trusted AI solutions for clinical documentation around the globe. With this new innovation, the Nuance healthcare portfolio gives customers even more flexibility to automate and enhance their clinical documentation workflows with the accuracy and reliability of Dragon Medical One, the customized, full-service experience of DAX, and the immediacy and speed of DAX Express. Together, we are combining the power of Microsoft Azure, a deeply rich health data platform, and robust engineering and AI expertise to deliver outcomes-focused healthcare applications at scale to improve provider and patient experiences.

DAX Express represents the next step in delivering AI technology that provides an immediate, practical and highly accessible entry point for healthcare organizations to adopt at scale a new generation of AI-powered solutions, leveraging their existing investments in trusted Nuance solutions. For the more than 550,000 Dragon Medical users, DAX Express automatically and securely creates draft clinical notes in seconds, available immediately for clinical review and completion, after each patient visit in the exam room or via telehealth patient conversations. Clinicians will benefit from the seamless capabilities of Dragon Medical One, DAX Express, and DAX, which are tightly integrated into the electronic medical record, beginning from pre-visit through post-encounter, reducing cognitive burdens and helping increase the joy of medicine.

Responsible AI in healthcare

DAX Express is developed in alignment with Microsoft’s responsible AI standards, and consistent with our long-standing commitment to data security and privacy, helping to ensure AI systems and solutions that are trustworthy and safe. Microsoft and Nuance believe that while AI in healthcare has the potential to make a lasting, positive impact on the industry and the patients it serves, it is imperative we ensure the technology is used responsibly and transparently. As we have for years, we will continue to work closely with healthcare providers and the broader industry to help ensure AI is used in a way that is ethical and transparent.

Microsoft and Nuance are uniquely positioned to amplify the healthcare industry’s ability to deliver meaningful outcomes with the power of AI. We are proud to be at the cutting edge of healthcare innovation, and we look forward to continuing to help the industry solve healthcare’s biggest challenges.

Tags: AI, healthcare"
Microsoft_News,https://www.microsoft.com/en-us/worklab/ai-a-whole-new-way-of-working,,A Whole New Way of Working,"The big problem at the heart of information overload is relevance. Everyone is inundated with data and information, but only a small sliver of that information contains something that a specific individual needs to know or points to a specific task that person needs to complete. Buried amid a mountain of data is information we can’t afford to miss. With AI, we can unearth what matters in minutes.

To truly focus on the work that matters most, we must first confront information overload—a challenge that only feels more acute in the hybrid era. AI has a powerful part to play here too.

“At its best, work is our expression of how we’re going to shape the world and be shaped by it. But the basic patterns of work today have left our inboxes in charge, not us,” says Jared Spataro, corporate vice president of Modern Work and Business Applications at Microsoft. “AI is going to help us cut through a lot of that and allow us to focus again on the things that matter most.”

This is going to take away the shallow work so that humans can do the deep work that we really crave. ” Nate Boaz VP of People Strategy at Microsoft

Take meetings. Few things in life feel as wasteful as time spent in a meeting you didn’t need to attend. Now, we’ll be able to use AI-powered tools to not just summarize a day’s worth of meetings but highlight and share what’s relevant to a given individual or team. This will help eliminate FOMO and empower people to attend just the meetings that matter, catch up when they’re late, or revisit important points to better address action items. This equals time savings that everyone in an organization can devote to the most impactful work. At scale, this has the potential to drive meaningful productivity gains for every organization.

We’ll also be able to use natural language to distill a week’s worth of emails down to just the salient points—and AI can summarize, remix, and personalize the information in ways that are more useful than ever.

Sumit Chauhan, CVP, Office Product Group, Microsoft: “I think, ultimately, AI will make work more human.”

GitHub research points to the promise of next-generation AI to unlock productivity. In a survey of developers, 88 percent said they were able to get tasks done more quickly using AI-powered GitHub Copilot than without it, and 74 percent said it enabled them to focus on more satisfying work.

“This is going to take away the shallow work so that humans can do the deep work that we really crave,” says Nate Boaz, vice president of people strategy at Microsoft. “This is going to make not only your job better, but you better at your job.”

As these technologies become part of the everyday workflow of individuals and organizations, the world could see a productivity boom on par with the most significant technological disruptions in history.

AI is like... AI is like scissors : one blade is cognition and the other is context. Focusing solely on the technology’s cognitive power, says Microsoft design and AI executive John Maeda, belies the importance of its context—what it knows about the world from the data that goes into it. Only when paired together, he says, are the blades really powerful.

“Bringing the right data to the right place at the right time is something AI excels at,” says Charles Lamanna, corporate vice president of Business Apps and Platform at Microsoft.

“It helps you run your operations more efficiently. It helps you improve your employee experience. It helps you improve the customer experience,” he says. “Those three things define just about every business on earth. And this AI improves all three.”"
Microsoft_News,https://blogs.microsoft.com/blog/2023/03/16/prompts-for-communicators-using-the-new-ai-powered-bing/,,Prompts for communicators using the new AI-powered Bing,"Summary

The new Bing, your AI-powered copilot for the web, is now in preview, and you might be surprised at how much it can help us be better at our craft of communications.

These are some starter prompts to ask Bing, which have helped me and my team in our work over the past few weeks.

If you like the answers you find with Bing, remember to follow-up with the source links for more information.

The new Bing is in preview, and we’re continuing to take feedback and apply those learnings to improve the experience over time.

We’re in the thick of it, for sure. As communications professionals, we’re figuring out what this new age of AI means for us, for our craft, while at the same time trying to explain AI to the world.

In speaking at an event this week in New York on this topic, one of the things I reflected on was the need to bring people along on this change curve. You might start off on the curve like “nope” – as soon as you start seeing stories about these AI advancements, your response is that this is not good for our profession. But then as you dig into it, you feel maybe it’s not a “nope” and move up the curve to “there’s hope.” There are all sorts of things I could do! After all, one of our secret powers as communicators has always been language. And you have this moment and realize, you can accelerate this secret power with AI.

Here’s how I’ve been doing just that with these prompts using the new AI-powered Bing. The results were crazy impressive. Try for yourself by signing up for the preview at bing.com/new and remember to give feedback directly to Bing so we can continue to improve the experience.

Useful information to get started

Choose a conversation style: “More Creative,” “More Balanced” or “More Precise”

The new Bing won’t hesitate to offer some follow-up questions to help hone in on the answer you’re looking for. For example, when you’re using the new Bing to do idea generation, it’s helpful to follow-up by asking it to “give me a few more.”

Related to that, don’t leave Bing hanging! It may have an ancillary topic related to the topic you’re asking about.

Bing will always show you where it’s getting its information, so if you like some of the answers you’re getting and want more details, don’t forget to check out the sources that Bing is pulling from.

Reminder! Avoid putting confidential information in the chat.

Next, on to the prompts.

Media interview prep

This first example comes from The Wall Street Journal reporter Joanna Stern. To prepare for an interview with our Chairman and CEO Satya Nadella, Joanna used the new Bing to help with preparing interview questions. Here’s what she asked Bing:

“In the voice of Joanna Stern, generate a list of 10 interview questions for Satya Nadella about AI and the new Bing”

“Answer question 5 in the voice of <person>”

Since then, I’ve been using similar prompts to prepare for media interviews. For example, in preparing for this On With Kara Swisher podcast episode, here’s a prompt that I used:

“Help me prepare for a podcast interview with Kara Swisher. The topic we’ve agreed to discuss is the rise of Artificial Intelligence tools and services. Based on her most recent writing and podcasts, give me 10 questions I should anticipate.”

Remember, you have enough time to make sure Bing is prepared – so it can help to first ask if it’s familiar with Kara Swisher and her interview style. Then add more details – who is she talking to? Then fire the prompt about the 10 questions.

Media coverage snapshots

It’s been a crazy few weeks of news here at Microsoft and I’ve started using Bing to help me get quick snapshots of media coverage to see how news is landing in the moment. Here are a few examples I pulled recently:

“What’s the latest news about <X> today?”

“What’s the overall tone of these stories?”

“How does this compare with news about <Y> in the same time period?”

This is not a substitute for deeper measurement or analysis, but it’s a surprisingly good first snap when you need something now.

Social media post inspiration

Bing chat is also a great brainstorm idea generator. We’ve experimented using it to get inspiration for our social media posts, especially with “More Creative” mode. Here are some examples that my team has experimented with:

“Generate a few tweets that include <X> information and uses a <Y> tone” (such as “lighthearted tone”)

“Write a LinkedIn post for this blog, <X>”

“Generate a few tweet ideas for <company> about <product feature>”

“Take the following information and turn it into a <X> character tweet / LinkedIn post: <copy and paste text>,” then “Can you write it again but make it more engaging?”

These initial prompts are usually followed by “give me a few more versions.”

Headline generation

There are days when I spend a lot of time writing (and rewriting) the body of a blog post, finally get it to a good place and only then start to wonder, what is my headline? By this point I’ve used up every ounce of creativity and begrudgingly write something somewhat coherent and feel slightly bad about myself. But these days, I feel less bad. While I still spend a lot of time writing (I really do love writing!) now with the new Bing, I’ve been using this prompt to help me generate headlines (a type of writing that I love less). Here’s what I did:

“Suggest a few variations of headlines for the following,”

Copy your text and paste it to the Bing chat

FAQ generation

FAQs is another type of writing I’ve been keen to accelerate with AI. Here’s how I’ve done that:

“Suggest five FAQs for <text or link>”

“Give me a few more”

I hope these prompt examples help you kickstart your own questions and interactions with this incredible new tool.

Happy experimenting!

Tags: AI, Bing, communications, Prompts"
Microsoft_News,https://blogs.microsoft.com/blog/2023/03/16/introducing-microsoft-365-copilot-your-copilot-for-work/,,Introducing Microsoft 365 Copilot – your copilot for work,"Humans are hard-wired to dream, to create, to innovate. Each of us seeks to do work that gives us purpose — to write a great novel, to make a discovery, to build strong communities, to care for the sick. The urge to connect to the core of our work lives in all of us. But today, we spend too much time consumed by the drudgery of work on tasks that zap our time, creativity and energy. To reconnect to the soul of our work, we don’t just need a better way of doing the same things. We need a whole new way to work.

Today, we are bringing the power of next-generation AI to work. Introducing Microsoft 365 Copilot — your copilot for work. It combines the power of large language models (LLMs) with your data in the Microsoft Graph and the Microsoft 365 apps to turn your words into the most powerful productivity tool on the planet.

“Today marks the next major step in the evolution of how we interact with computing, which will fundamentally change the way we work and unlock a new wave of productivity growth,” said Satya Nadella, Chairman and CEO, Microsoft. “With our new copilot for work, we’re giving people more agency and making technology more accessible through the most universal interface — natural language.”

Copilot is integrated into Microsoft 365 in two ways. It works alongside you, embedded in the Microsoft 365 apps you use every day — Word, Excel, PowerPoint, Outlook, Teams and more — to unleash creativity, unlock productivity and uplevel skills. Today we’re also announcing an entirely new experience: Business Chat. Business Chat works across the LLM, the Microsoft 365 apps, and your data — your calendar, emails, chats, documents, meetings and contacts — to do things you’ve never been able to do before. You can give it natural language prompts like “Tell my team how we updated the product strategy,” and it will generate a status update based on the morning’s meetings, emails and chat threads.

With Copilot, you’re always in control. You decide what to keep, modify or discard. Now, you can be more creative in Word, more analytical in Excel, more expressive in PowerPoint, more productive in Outlook and more collaborative in Teams.

Click here to load media

Microsoft 365 Copilot transforms work in three ways:

Unleash creativity. With Copilot in Word, you can jump-start the creative process so you never start with a blank slate again. Copilot gives you a first draft to edit and iterate on — saving hours in writing, sourcing, and editing time. Sometimes Copilot will be right, other times usefully wrong — but it will always put you further ahead. You’re always in control as the author, driving your unique ideas forward, prompting Copilot to shorten, rewrite or give feedback. Copilot in PowerPoint helps you create beautiful presentations with a simple prompt, adding relevant content from a document you made last week or last year. And with Copilot in Excel, you can analyze trends and create professional-looking data visualizations in seconds.

Unlock productivity. We all want to focus on the 20% of our work that really matters, but 80% of our time is consumed with busywork that bogs us down. Copilot lightens the load. From summarizing long email threads to quickly drafting suggested replies, Copilot in Outlook helps you clear your inbox in minutes, not hours. And every meeting is a productive meeting with Copilot in Teams. It can summarize key discussion points — including who said what and where people are aligned and where they disagree — and suggest action items, all in real time during a meeting. And with Copilot in Power Platform, anyone can automate repetitive tasks, create chatbots and go from idea to working app in minutes.

GitHub data shows that Copilot promises to unlock productivity for everyone. Among developers who use GitHub Copilot, 88% say they are more productive, 74% say that they can focus on more satisfying work, and 77% say it helps them spend less time searching for information or examples.

But Copilot doesn’t just supercharge individual productivity. It creates a new knowledge model for every organization — harnessing the massive reservoir of data and insights that lies largely inaccessible and untapped today. Business Chat works across all your business data and apps to surface the information and insights you need from a sea of data — so knowledge flows freely across the organization, saving you valuable time searching for answers. You will be able to access Business Chat from Microsoft 365.com, from Bing when you’re signed in with your work account, or from Teams.

Uplevel skills. Copilot makes you better at what you’re good at and lets you quickly master what you’ve yet to learn. The average person uses only a handful of commands — such as “animate a slide” or “insert a table” — from the thousands available across Microsoft 365. Now, all that rich functionality is unlocked using just natural language. And this is only the beginning.

Copilot will fundamentally change how people work with AI and how AI works with people. As with any new pattern of work, there’s a learning curve — but those who embrace this new way of working will quickly gain an edge.

The Copilot System: Enterprise-ready AI

Microsoft is uniquely positioned to deliver enterprise-ready AI with the Copilot System. Copilot is more than OpenAI’s ChatGPT embedded into Microsoft 365. It’s a sophisticated processing and orchestration engine working behind the scenes to combine the power of LLMs, including GPT-4, with the Microsoft 365 apps and your business data in the Microsoft Graph — now accessible to everyone through natural language.

Grounded in your business data. AI-powered LLMs are trained on a large but limited corpus of data. The key to unlocking productivity in business lies in connecting LLMs to your business data — in a secure, compliant, privacy-preserving way. Microsoft 365 Copilot has real-time access to both your content and context in the Microsoft Graph. This means it generates answers anchored in your business content — your documents, emails, calendar, chats, meetings, contacts and other business data — and combines them with your working context — the meeting you’re in now, the email exchanges you’ve had on a topic, the chat conversations you had last week — to deliver accurate, relevant, contextual responses.

Built on Microsoft’s comprehensive approach to security, compliance and privacy. Copilot is integrated into Microsoft 365 and automatically inherits all your company’s valuable security, compliance, and privacy policies and processes. Two-factor authentication, compliance boundaries, privacy protections, and more make Copilot the AI solution you can trust.

Architected to protect tenant, group and individual data. We know data leakage is a concern for customers. Copilot LLMs are not trained on your tenant data or your prompts. Within your tenant, our time-tested permissioning model ensures that data won’t leak across user groups. And on an individual level, Copilot presents only data you can access using the same technology that we’ve been using for years to secure customer data.

Integrated into the apps millions use every day. Microsoft 365 Copilot is integrated in the productivity apps millions of people use and rely on every day for work and life — Word, Excel, PowerPoint, Outlook, Teams and more. An intuitive and consistent user experience ensures it looks, feels and behaves the same way in Teams as it does in Outlook, with a shared design language for prompts, refinements and commands.

Designed to learn new skills. Microsoft 365 Copilot’s foundational skills are a game changer for productivity: It can already create, summarize, analyze, collaborate and automate using your specific business content and context. But it doesn’t stop there. Copilot knows how to command apps (e.g., “animate this slide”) and work across apps, translating a Word document into a PowerPoint presentation. And Copilot is designed to learn new skills. For example, with Viva Sales, Copilot can learn how to connect to CRM systems of record to pull customer data — like interaction and order histories — into communications. As Copilot learns about new domains and processes, it will be able to perform even more sophisticated tasks and queries.

Committed to building responsibly

At Microsoft, we are guided by our AI principles and Responsible AI Standard and decades of research on AI, grounding and privacy-preserving machine learning. A multidisciplinary team of researchers, engineers and policy experts reviews our AI systems for potential harms and mitigations — refining training data, filtering to limit harmful content, query- and result-blocking sensitive topics, and applying Microsoft technologies like InterpretML and Fairlearn to help detect and correct data bias. We make it clear how the system makes decisions by noting limitations, linking to sources, and prompting users to review, fact-check and adjust content based on subject-matter expertise.

Moving boldly as we learn

In the months ahead, we’re bringing Copilot to all our productivity apps—Word, Excel, PowerPoint, Outlook, Teams, Viva, Power Platform, and more. We’ll share more on pricing and licensing soon. Earlier this month we announced Dynamics 365 Copilot as the world’s first AI Copilot in both CRM and ERP to bring the next-generation AI to every line of business.

Everyone deserves to find purpose and meaning in their work — and Microsoft 365 Copilot can help. To serve the unmet needs of our customers, we must move quickly and responsibly, learning as we go. We’re testing Copilot with a small group of customers to get feedback and improve our models as we scale, and we will expand to more soon.

Learn more on the Microsoft 365 blog and visit WorkLab to get expert insights on how AI will create a brighter future of work for everyone.

And for all the blogs, videos and assets related to today’s announcements, please visit our microsite.

Tags: AI, Microsoft 365, Microsoft 365 Copilot"
Microsoft_News,https://news.microsoft.com/reinventing-productivity/,,Introducing Microsoft 365 Copilot — your copilot for work,"Humans are hard-wired to dream, to create, to innovate. But today, we spend too much time consumed by the drudgery of work, on tasks that zap our time, creativity, and energy. To reconnect to the soul of our work, we don’t just need a better way of doing the same things. We need a whole new way to work.



Today, we are bringing the power of next-generation AI to work. Introducing Microsoft 365 Copilot — your copilot for work. It combines the power of large language models (LLMs) with your data in the Microsoft Graph and the Microsoft 365 apps to turn your words into the most powerful productivity tool on the planet.



Read more"
Microsoft_News,https://blogs.bing.com/search/march_2023/Confirmed-the-new-Bing-runs-on-OpenAI%E2%80%99s-GPT-4,,Confirmed: the new Bing runs on OpenAI’s GPT-4,"Congratulations to our partners at Open AI for their release of GPT-4 today. We are happy to confirm that the new Bing is running on GPT-4, which we’ve customized for search. If you’ve used the new Bing preview at any time in the last five weeks, you’ve already experienced an early version of this powerful model. As OpenAI makes updates to GPT-4 and beyond, Bing benefits from those improvements. Along with our own updates based on community feedback, you can be assured that you have the most comprehensive copilot features available.If you want to experience GPT-4, sign up for the new Bing preview . Once you’re in you’ll be able to use the new Bing to Search, Answer, Chat, and Create at Bing.com.- Yusuf Mehdi"
Microsoft_News,https://blogs.microsoft.com/eupolicy/2023/03/15/responsible-ai-future-principles-techtalk/,,Building responsibility into the future of AI,"2023 is shaping up to be an inflection point for AI. Five years ago, we noted that barely a week went by without a mention of AI in the news. Today, stories of how organizations are finding new ways to use AI to optimize operations, improve health outcomes or advance sustainability goals are more frequent than ever.

And it’s not just companies. Increasingly, AI will permeate into people’s everyday lives, with tools like OpenAI’s ChatGPT and the new AI-powered Bing and Edge, currently in preview, which will help facilitate routine tasks – from drafting emails to planning trips – and give people space to pursue more creative tasks and innovative thinking.

AI’s potential to help people solve all kinds of complex challenges is clear. Yet, like other technologies, AI systems need to be developed responsibly, ensuring that they will function as intended and be used in ways that earn trust.

In our latest #TechTalk, Microsoft’s Chief Responsible AI Officer, Natasha Crampton, joined us for a conversation on the responsible development and use of AI.

In the episode, Natasha explains how Microsoft’s approach to AI is guided by a set of six responsible AI principles: fairness; reliability and safety; privacy and security; inclusiveness; transparency; accountability. Given AI’s transformative potential, she highlights the clear need for the right guardrails that will help secure the beneficial uses of the technology while guarding against its misuse and potential harm.

According to Natasha, “AI systems are built by people, and they’re also used by people. One area that is a very important for us is human AI interaction. How can we make sure that we get the very best out of humans and machines working together. That’s Microsoft’s vision for how we embrace AI. It’s all about how we can amplify human potential. We need to figure out the optimum ways of combining the best of humans and the best of machines.”

With the EU’s AI Act on the horizon, Natasha also touches on the role of regulation to advance AI and make sure AI is developed and deployed responsibly. She suggests steps the act can take to limit high-risk use cases, while continuing to enable innovations that will keep Europe globally competitive.

Watch the full #TechTalk with Natasha Crampton here.

YouTube Video Click here to load media

Tags: #TechTalk, Chat, EU, Europe, Responsible AI"
Microsoft_News,https://blogs.microsoft.com/blog/2023/02/22/the-new-bing-preview-experience-arrives-on-bing-and-edge-mobile-apps-introducing-bing-now-in-skype/,,The new Bing preview experience arrives on Bing and Edge Mobile apps; introducing Bing now in Skype,"Two weeks ago, we introduced the world to the all new AI-powered Bing and Microsoft Edge — your copilot for the web. Since then, based on strong and positive product feedback and engagement, we’ve welcomed more than one million people in 169 countries off the waitlist into the preview. We continue to expand the preview to more people every day. Our preview community is actively using the breadth of new features across Search, Answers, Chat and Creation with total engagement up significantly. Feedback on the new capabilities is positive, with 71% of testers giving the new Bing a “thumbs up” on the new search and answers capabilities. We’re even more excited about the breadth of feedback we are receiving on where and how we can improve and we are acting on it with regular updates.

We’re seeing some interesting use cases and queries in preview testing. I recently learned about a father showing his son the new Bing, and together they discovered and created in a way not easily done with today’s search engines. They started off by creating sci-fi stories using simple prompts in chat, eventually leading to the development of a video game idea where Bing not only helped create a plot, but also generated the code to input directly into Scratch – a visual programming tool. In just a few queries, they captured the wonder and potential of the new Bing and Edge. We are hearing many similar stories on how the new Bing is helping people discover and create in ways previously not possible.

Sign up for the new Bing and Edge mobile apps

In this spirit of learning and continuing to build new capabilities, we’re excited to share today the preview release of the new Bing and Edge mobile apps. We’re beginning to roll out the incredible capabilities of the new Bing and Edge on your smartphone along with some exciting new features, such as voice input. In addition, we are creating a new chat experience, beginning with Skype, to enhance your social communications with your friends and family.

The new Bing and Edge goes mobile; Now introducing voice access

Because we know 64% of searches occur on mobile phones, we are releasing all new Bing and Edge mobile apps to serve as your copilot for the web even when you are away from your desktop.

Imagine an unexpected layover in a new city. As you plan a quick afternoon stop in Tokyo, you ask Bing to help find a place to store your luggage. It then provides tips for navigating the metro system on your way to the famed Shinjuku station. With a few hours to explore, Bing creates a short itinerary, helping you get the most out of your quick visit, and even translates along the way.

Available on iOS and Android today, the Bing mobile app offers a fresh look and experience. Tapping the Bing icon at the bottom will invoke a chat session, where you can engage in all the same ways you can from the desktop. Ask simple or complex questions and receive answers and citations. Choose how you want your answers displayed – bullet points, text or simplified responses. Explore the Bing chat experience to refine your query or compose an email, poem or list.

With the introduction of the new Bing mobile app, we’re adding one of the preview community’s most requested features – voice. Available on mobile and on desktop, voice search provides more versatility in how you can deliver prompts and receive answers from Bing.

In addition, those who have access to the preview will be able to utilize the new Bing experience from the homepage of the Microsoft Edge mobile app.

Bing goes social with Skype

To better assist you when you are collaborating with friends and family, we are introducing AI-powered Bing for Skype. More than 36 million people use Skype daily to connect through phone calls and chats across borders and around the world and the new Bing is going to enable some helpful and fun new scenarios and capabilities.

Imagine having a copilot for your friends and family as you stay connected and plan your next get together. Simply add Bing to the group, as you would any Skype contact, and now you can ask Bing to answer questions and provide information for the entire group. For example, if your family is chatting about the next family reunion, you can simply ask Bing for suggestions on travel destinations, expected weather forecasts and interesting events around your time of travel, and everyone in the chat will get access to the results. When you are catching up with friends, you can ask Bing to simply fetch information from the web, for example, the latest news or last night’s award shows to add to your conversation.

You can choose how you want your answers to be displayed – bullet points, text or a simplified response. Bing can accommodate your preferences. Fluent in more than 100 languages, and capable of translating between them, Bing can offer unique value to this global communications tool.

Available worldwide in preview today, the new Bing in Skype can provide helpful, real-time answers to all your questions. As we learn and fine-tune this amazing new capability, we envision bringing it to other communications apps, like Teams, in the future.

If you’re currently on the Bing preview experience, these features are available to you later today. In the first few days of testing these mobile experiences, you may occasionally find connectivity issues in low-bandwidth situations. We’re aware of the issue and are working on a fix.

If you’re among those awaiting access, we appreciate both your patience and your excitement. We’re working as fast as possible to onboard more people every day. If you’re interested in trying it for yourself, please sign up for the Bing preview today. We hope you enjoy the new capabilities and please keep the feedback coming so we can continue to improve the product for you.

*Skype user interface will vary during initial rollout.

Tags: AI, Bing, Microsoft Edge, skype"
Microsoft_News,https://blogs.microsoft.com/blog/2023/03/06/introducing-microsoft-dynamics-365-copilot/,,"Introducing Microsoft Dynamics 365 Copilot, the world’s first copilot in both CRM and ERP, that brings next-generation AI to every line of business","Today, we’re announcing the next generation of AI product updates across our business applications portfolio, including the launch of the new Microsoft Dynamics 365 Copilot – providing interactive, AI-powered assistance across business functions.

According to our recent survey on business trends, nearly 9 out of 10 workers hope to use AI to reduce repetitive tasks in their jobs. With Dynamics 365 Copilot, organizations empower their workers with AI tools built for sales, service, marketing, operations and supply chain roles. These AI capabilities allow everyone to spend more time on the best parts of their jobs and less time on mundane tasks.

Customer relationship management (CRM) and enterprise resource planning (ERP) systems have long been mission-critical customer and business data sources; however, they frequently require burdensome tasks like manual data entry, content generation and notetaking. Dynamics 365 Copilot takes advantage of recent advancements in generative AI to automate these tedious tasks and unlock the full creativity of the workforce. Dynamics 365 Copilot puts CRM and ERP to work for business users to accelerate their pace of innovation and improve business outcomes in every line of business:

Copilot in Microsoft Dynamics 365 Sales and Viva Sales helps sellers dramatically reduce the time they spend on clerical tasks. AI helps write email responses to customers and can even create an email summary of a Teams meeting in Outlook. The meeting summary pulls in details from the seller’s CRM such as product and pricing information, as well as insights from the recorded Teams call. With sellers spending as much as 66% of their day checking and responding to emails, this presents a significant business upside to give the seller more time with their customers.

helps sellers dramatically reduce the time they spend on clerical tasks. AI helps write email responses to customers and can even create an email summary of a Teams meeting in Outlook. The meeting summary pulls in details from the seller’s CRM such as product and pricing information, as well as insights from the recorded Teams call. With sellers spending as much as 66% of their day checking and responding to emails, this presents a significant business upside to give the seller more time with their customers. Copilot in Dynamics 365 Customer Service empowers agents to deliver exceptional customer care. Dynamics 365 Copilot drafts contextual answers to queries in both chat and email, in addition to providing an interactive chat experience over knowledge bases and case history so this AI-powered expertise is always available to answer questions. We’re also making it easier for customer service departments to build virtual agents in minutes with conversation boosters in Power Virtual Agents , which harnesses the power of Azure OpenAI Service and Bing to provide answers from company websites and internal knowledge bases that you choose.

empowers agents to deliver exceptional customer care. Dynamics 365 Copilot drafts contextual answers to queries in both chat and email, in addition to providing an interactive chat experience over knowledge bases and case history so this AI-powered expertise is always available to answer questions. We’re also making it easier for customer service departments to build virtual agents in minutes with , which harnesses the power of Azure OpenAI Service and Bing to provide answers from company websites and internal knowledge bases that you choose. Copilot in Dynamics 365 Customer Insights and Dynamics 365 Marketing empowers marketers to simplify their workflow in data exploration, audience segmentation and content creation. With Copilot in Dynamics 365 Customer Insights , marketers can curate highly personalized and targeted customer segments by having a dialogue with their customer data platform using natural language. Marketers can receive suggestions about additional segments that may not have been previously considered. This new capability can handle complex calculations and match customers that fit a select profile. Using Copilot in Dynamics 365 Marketing , marketers can describe their customer segment in their own words to create a target segment with the query assist feature. Marketers can also use Dynamics 365 Copilot to effortlessly get inspiration for fresh email campaign content based on a simple request. Copilot makes suggestions based on key topics entered by the marketer, the organization’s existing marketing emails, as well as from a range of internet sources to increase the relevance of generated ideas.

and empowers marketers to simplify their workflow in data exploration, audience segmentation and content creation. Copilot in Dynamics 365 Business Central streamlines the creation of product listings for online commerce. Product attributes such as color, material and size can be used to create compelling product descriptions for online storefronts in seconds. The descriptions can be further tailored by choosing tone of voice, format and length. Business Central customers using Shopify can seamlessly publish the products with descriptions to their Shopify store in just a few clicks.

streamlines the creation of product listings for online commerce. Product attributes such as color, material and size can be used to create compelling product descriptions for online storefronts in seconds. The descriptions can be further tailored by choosing tone of voice, format and length. Business Central customers using Shopify can seamlessly publish the products with descriptions to their Shopify store in just a few clicks. Lastly, Copilot in Microsoft Supply Chain Center, which Microsoft Dynamics 365 Supply Chain Management customers can access, will proactively flag external issues such as weather, financials and geography that may impact key supply chain processes. Predictive insights then surface impacted orders across materials, inventory, carrier, distribution network and more. Supply chain planners can then automatically draft an email generated by Dynamics 365 Copilot to alert impacted partners and mitigate potential disruptions before they happen.

The next era of business applications is being transformed by generative AI. Users will increasingly expect their CRM and ERP applications to include AI-powered expertise. Dynamics 365 Copilot brings the latest AI breakthroughs to every line of business, improving customer experience, employee experience and operational efficiency. Essential to our approach as we bring these latest advancements to customers is our commitment to responsible AI by design – our framework for the safe deployment of AI technologies.

Today’s announcement builds on recent AI momentum across Microsoft 365, Dynamics 365, and the Power Platform. This includes: the next generation of AI capabilities in Microsoft Teams, the collaboration platform for work with more than 280 million monthly active users; Viva Sales, which helps sellers by bringing a sales copilot to their flow of work in Microsoft 365; and Power Apps, enabling citizen developers to write code using natural language.

You can read more about today’s AI announcements from Emily He, CVP, Business Applications and Platform here. Join us on March 16 as we share the next step in our journey to reinvent productivity with AI. You can RSVP for the event on the Microsoft LinkedIn page.

YouTube Video Click here to load media

Tags: AI, CRM, Microsoft Dynamics 365 Copilot, Microsoft Viva"
Microsoft_News,https://news.microsoft.com/source/features/ai/fintech-ai-financial-inclusion-latin-america/,,Bringing financial inclusion to Latin America with fintech and AI,"When Mario Hernández first arrived in Mexico in 2010, he met his wife’s family, exchanged some happy hugs and immediately entered the world of the unbanked.

His Mexican in-laws, Hernández learned, were struggling to obtain a formal loan from any bank, placing them firmly in that nation’s all-cash majority.

Financially, the family is faring better. Mexico, not so much: the World Bank estimates that 63 percent of adults there, nearly 100 million people, lack a bank account and rely solely on the bills tucked in their wallet or stashed in their home to pay for food, shelter, medicine and every other commodity. Across Latin America, seven in 10 people are unbanked or underbanked, according to Latin America Reports, and this has fueled one of the world’s highest rates of income inequality.

“When I saw that in my family, it was, ‘no, I cannot see this,’” says Hernández, who came to Mexico from Spain, where he led a digital banking and payment-processing company. In his new land, Hernández set to work to shrink those disparities, ultimately launching Finvero, a platform that offers credit to consumers through a payment option on e-commerce websites.

“We decided to become a marketplace, so that we could get everyone together and say, ‘Okay guys, we have to solve the problem. It’s going to be a good business for everyone – for the lender, for the merchant, for the shopper,’” Hernández says. “We have to tackle the problem together.”

Today, Finvero, headquartered in Mexico City, and fellow digital natives N5, founded in 2017 in Argentina, and ClearSale, founded in 2001 in Brazil, sit at the forefront of Latin America’s fintech boom, which is transforming online markets across the region, with the goal of guiding millions of once-unbanked consumers into the digital economy.

Finvero describes itself as the first consumer-lending marketplace in Mexico, connecting merchants, lenders and consumers to address that nation’s underserved population. The company says it provides alternative scoring and disbursement of a loan in less than five minutes.

N5’s platform helps banks, insurance providers and other financial services firms transition their legacy systems to the digital world without changing their core technologies. ClearSale offers fraud protection and risk management for multiple industries, including e-commerce, financial services, telecom and others.

Finvero CEO and co-founder Mario Hernández expects more than 3 million people to apply for a loan this year through the company’s credit marketplace. Image by Octavio Hoyos.

All three companies lean heavily on artificial intelligence (AI) to make real-time decisions that aid their clients. And each firm has leveraged Microsoft relationships and technologies to help build their infrastructures, improve their products and gain new customers.

The services provided by ClearSale, N5 and Finvero can collectively address long-standing gaps in the region’s fiscal landscape, says fintech expert Benjamin T. Beasley.

Those vulnerabilities include cash-only, shadow economies that exist across Latin America, such as informal labor markets, street vending and unregistered businesses that, over time, depress wages, raise poverty and weaken governments, according to a blog post published by the World Bank.

“Certainly, fraud protection, avoiding the – often – nightmare of legacy systems, and improving payment- and micro-installment options would all be very helpful in improving the LatAm financial sector,” says Beasley, a tech and finance lawyer based in Utah who represents fintech companies in Latin America and elsewhere. He lived for a time in South America.

“Part of why I find fintech so compelling is that it has the potential to modernize key aspects of economies and financial systems which could have an astonishingly large impact,” Beasley adds.

The number of fintech companies in Latin America has doubled in three years, according to Latin America Reports. What’s more, the collective value of that region’s fintech market has reached $2.1 billion, an increase of more than 4,000%, since 2016, says The Fintech Times.

Two recent events helped spur this boom. Early in the COVID-19 pandemic, some governments in Latin America, including Colombia and Honduras, introduced cash-transfer programs that distributed funds to people through digital wallets or mobile phones. Such initiatives began chipping away at the historical mistrust many people in Latin America hold for banks and governments. During 2020, about 13 million people in the region made their first online transactions, according to Latin America Reports."
Microsoft_News,https://news.xbox.com/en-us/2023/03/10/the-gamers-guide-to-the-new-ai-powered-bing/,,The Gamer’s Guide to the New AI-Powered Bing,"Summary The new AI-powered Bing is now in preview, and you might be surprised at how much it knows about your favorite Xbox and PC games.

These are five starter queries to ask Bing which may help you get more out of your gaming experience.

If you like the answers you find with Bing, remember to follow-up with the source links for more info.

The new Bing is in preview, and we’re continuing to take feedback and apply those learnings to improve the experience over time.

Many of us have used a search engine at some point in our lives to find ways to get an edge in our favorite games. From trying to smite the first boss in Elden Ring, to finding all the Agility Orbs in classic games like Crackdown, or what the best Perks are for Modern Warfare II. But we’ve never had something quite as special as the new AI-powered Bing as our gaming co-pilot and its wealth of tips, trivia, and technical know-how. With the new Bing you get better search, more complete answers to your gaming questions, a new chat experience to explore deeper, and the ability to create content.

The new AI-powered Bing is designed to help you find the information you’re looking for by deciphering intricate questions, with clear answers, coupled with surprisingly in-depth responses. It also knows a hell of a lot about video games. So much so we wanted to really test its gaming knowledge with some hard-hitting questions to see what type of response we’d get. The results, as you can try out for yourself by signing up for the waitlist, were pretty dang impressive.

To help get you started interacting with this new and innovative tool, we’ve collected some effective ways for you to test out the new Bing to help you not only challenge its gaming credentials, but also find potential new ways for you to enjoy some of your favorite games. Remember to share your feedback so we can continue to improve the experience.

Useful Information to Get Started

Don’t worry about trying to be hyper-specific with your question. The new Bing won’t hesitate to offer some follow-up questions to help home in on the answer you’re looking for.

Related to that, don’t leave Bing hanging! It may have an ancillary topic related to the game you’re asking about.

Bing will always show you where it’s getting its information from, so if you like some of the answers you’re getting and want more details, don’t forget to check out the sources that Bing is pulling from. Your next favorite website may be just a click away!

See how creative you can get while talking about gaming with Bing — you may be surprised at some of the results!

Sign up here on Bing to join the waitlist for access to the new Bing.

“Tell me about…”

There are so many unique games to experience on console and PC today. While there’s a lot of information available about which games are the best, sometimes our tastes and what we’re in the mood for might be a bit more specific. Bing can help you distill this down as well, either from the look of a game, who is featured in it, or how long it takes to finish. Here’s a few of the examples to try yourself:

“Tell me about the best cyberpunk-style role-playing games on Xbox.”

“Tell me about the best action games that are 10 hours or less to play.”

“Tell me about the best games with a female protagonist on Xbox.”

“What’s the best ______ for me?”

Strategies come in all shapes and sizes for games, and it’s not hard to find opinions on what the best gear loadouts, characters, and skill tree selections are. But are they the best choices for you? You can start with a basic question, but it’s the follow up interaction which will allow Bing to guide you towards the best choices on how to spec out, or even which games to check out.

Here’s what we asked:

“What loadout should I use in Warzone 2.0 multiplayer?”

“What is the best Overwatch 2 character for me?”

“What are the best perks to use in Cyberpunk 2077?”

“What Xbox Game Pass games might I enjoy?”

“Where can I find…?”

Bing can help you find a lot of things in your favorite games, like where every secret weapon location is in Fortnite, where the Tall Tales journals are in Sea of Thieves, and it can even help you find your car keys (sort of). But what if what you’re looking for isn’t immediately coming to mind. You know the type, like that one quest where there’s that guy who did that one thing with the fire sword that one time? To start drilling this down to help us find the right answer, we asked:

“Where can I find the blue alien lady in Mass Effect 3?”

“Where can I find a list of Fallout 3 quests that begin with the letter J?

“Where can I find that one quest where there’s that guy who did that one thing with the fire sword that one time?” (your follow up responses will be crucial on something like this!)

“Give me a recap…”

On top of their incredible worlds, games can have complex and evolving storylines that may seem a little hard to follow while playing them. Not to mention that we must put that controller down at some point and return to the action another day. Sometimes that day turns into months, maybe even years. So, wouldn’t it be nice to get a recap of how far along you are in a game without having to start over? The new Bing is here to help. Here’s a few examples we pulled from:

“Give me a recap of Ni No Kuni: Wrath of the White Witch up to chapter 4.”

“Give me a recap of Witcher 3 after 20 hours.”

“Give me a recap of every campaign storyline in the Halo series.”

“How do I…?”

While Bing can certainly help us with learning how to defeat the baddest of bad guys in gaming (e.g. ‘How do I defeat Malenia in Elden Ring?’), we wanted to take this in a slightly different direction: What if it could help us learn how to create something tangible from our favorite games? Afterall, leaning how to do something new can be one of the most fun things to do in life, and if it comes from the world of our favorite games, even better! So, we took this to task with a few examples that you can try as well:

“How do I make a cake like the one that appears in Portal?”

“How do I make a toy sword based on a design found in Skyrim?”

“How do I prepare a meal based on the ramen recipes found in Yakuza: Like a Dragon?”

We hope these broad examples help you kickstart your own questions and interactions with this amazing new tool for everyday use (especially gaming). Don’t be afraid to get weird: What games would Marcus Fenix enjoy? Bing has an answer. You can even ask for your own, personalized music festival-style 3-day lineup… but with games coming out this year in place of musical artists.

Just remember to click through to the source of the information so you can discover new and interesting websites that you may have never visited before. If you don’t already have access to the new Bing, join the waitlist here. Happy searching!"
Microsoft_News,https://news.microsoft.com/source/features/ai/how-microsofts-bet-on-azure-unlocked-an-ai-revolution/,,How Microsoft’s bet on Azure unlocked an AI revolution,"Microsoft was decades into its own efforts to develop AI models that help people work with language more efficiently, from the automatic spell checker in Word to AI tools that write photo captions in PowerPoint and translate across more than 100 languages in Microsoft Translator. As these AI capabilities improved, the company applied its expertise in high-performance computing to scale up infrastructure across its Azure cloud that allowed customers to use its AI tools to build, train and serve custom AI applications.

As AI researchers started using more powerful graphics processing units, known as GPUs, to handle more complex AI workloads, they began to glimpse the potential for much larger AI models that could understand nuances so well they were able to tackle many different language tasks at once. But these larger models quickly ran up against the boundaries of existing computing resources. Microsoft understood what kind of supercomputing infrastructure OpenAI was asking for – and the scale that would be required.

“One of the things we had learned from research is that the larger the model, the more data you have and the longer you can train, the better the accuracy of the model is,” said Nidhi Chappell, Microsoft head of product for Azure high-performance computing and AI. “So, there was definitely a strong push to get bigger models trained for a longer period of time, which means not only do you need to have the biggest infrastructure, you have to be able to run it reliably for a long period of time.”

In 2019, Microsoft and OpenAI entered a partnership, which was extended this year, to collaborate on new Azure AI supercomputing technologies that accelerate breakthroughs in AI, deliver on the promise of large language models and help ensure AI’s benefits are shared broadly.

The two companies began working in close collaboration to build supercomputing resources in Azure that were designed and dedicated to allow OpenAI to train an expanding suite of increasingly powerful AI models. This infrastructure included thousands of NVIDIA AI-optimized GPUs linked together in a high-throughput, low-latency network based on NVIDIA Quantum InfiniBand communications for high-performance computing.

The scale of the cloud-computing infrastructure OpenAI needed to train its models was unprecedented – exponentially larger clusters of networked GPUs than anyone in the industry had tried to build, noted Phil Waymouth, a Microsoft senior director in charge of strategic partnerships who helped negotiate the deal with OpenAI.

Nidhi Chappell, Microsoft head of product for Azure high performance computing and AI (left), and Phil Waymouth, Microsoft senior director of strategic partnerships (right). Photo by Dan DeLong for Microsoft.

Microsoft’s decision to partner with OpenAI was rooted in conviction that this unprecedented infrastructure scale would yield results – new AI capabilities, a new type of programming platform – that Microsoft could transform into products and services that offer real benefit to customers, Waymouth said. This conviction fueled the companies’ ambition to overcome any technical challenges to build it and to continue to push boundaries on AI supercomputing.

“That shift from large-scale research happening in labs to the industrialization of AI allowed us to get the results we’re starting to see today,” he said.

This includes search results in Bing that piece together a dream vacation, the chatbot in Viva Sales that drafts marketing emails, GitHub Copilot that draws context from software developers’ existing code to suggest additional lines of code and functions, removing drudgery from computer programming, and Azure OpenAI Service, which provides access to OpenAI’s large language models with the enterprise-grade capabilities of Azure.

“Co-designing supercomputers with Azure has been crucial for scaling our demanding AI training needs, making our research and alignment work on systems like ChatGPT possible,” said Greg Brockman, president and co-founder of OpenAI.

Microsoft and its partners continue to advance this infrastructure to keep up with increasing demand for exponentially more complex and larger models.

For example, today Microsoft announced new powerful and massively scalable virtual machines that integrate the latest NVIDIA H100 Tensor Core GPUs and NVIDIA Quantum-2 InfiniBand networking. Virtual machines are how Microsoft delivers to customers infrastructure that can scale to size for any AI task. Azure’s new ND H100 v5 virtual machine provides AI developers exceptional performance and scaling across thousands of GPUs, according to Microsoft.

Large-scale AI training

The key to these breakthroughs, said Chappell, was learning how to build, operate and maintain literally tens of thousands of co-located GPUs connected to each other on a high-throughput, low-latency InfiniBand network. This scale, she explained, is larger than even the suppliers of the GPUs and networking equipment have ever tested. It was uncharted territory. Nobody knew for sure if the hardware could be pushed that far without breaking.

Graphics Processing Units, known as GPUs, are a key piece of computer hardware that has been optimized for AI workloads. Photo courtesy of Microsoft.

To train a large language model, she explained, the computation workload is partitioned across thousands of GPUs in a cluster. At certain phases in this computation – called allreduce – the GPUs exchange information on the work they’ve done. An InfiniBand network accelerates this phase, which must finish before the GPUs can start the next chunk of computation.

“Because these jobs span thousands of GPUs, you need to make sure you have reliable infrastructure, and then you need to have the network in the backend so you can communicate faster and be able to do that for weeks on end,” Chappell said. “This is not something that you just buy a whole bunch of GPUs, hook them together and they’ll start working together. There is a lot of system level optimization to get the best performance, and that comes with a lot of experience over many generations.”

The system level optimization includes software that enables effective utilization of the GPUs and networking equipment. Over the past several years, Microsoft has developed software techniques that have grown the ability to train models with tens of trillions of parameters, while simultaneously driving down the resource requirements and time to train and serve them in production.

Microsoft and its partners also have been incrementally adding capacity to the GPU clusters, growing the InfiniBand network and seeing how far they can push the datacenter infrastructure required to keep the GPU clusters operating including cooling systems, uninterruptible power supply systems and backup generators, noted Waymouth.

“The reason it worked is because we were building similar systems for our internal teams and there are complementary elements there,” he said. “But the scale at which we were doing it with OpenAI was simply much larger either internally or with external partners.”

Today, this Azure infrastructure optimized for large language model training is available via Azure AI supercomputing capabilities in the cloud, said Eric Boyd, Microsoft corporate vice president for AI Platform. This resource provides the combination of GPUs, networking hardware and virtualization software required to deliver the compute needed to power the next wave of AI innovation.

“We saw that we would need to build special purpose clusters focusing on enabling large training workloads, and OpenAI was one of the early proof points for that,” Boyd said. “We worked closely with them to learn what are the key things they were looking for as they built out their training environments and what were the key things they need.”

“Now, when other people come to us and want the same style of infrastructure, we can give it to them because that’s the standard way we do it,” he added.

AI for everyone

Early in Microsoft’s development of AI-optimized cloud-computing infrastructure, the company focused on specialized hardware to accelerate the real-time calculations AI models make when they are deployed for task completion, which is known as inferencing. Today, inferencing is when an AI model writes the first draft of an email, summarizes a legal document, suggests the menu for a dinner party, helps a software programmer find a piece of code, or sketches a concept for a new toy.

Bringing these AI capabilities to customers around the world requires AI infrastructure optimized for inferencing. Today, Microsoft has deployed GPUs for inferencing throughout the company’s Azure datacenter footprint, which spans more than 60 regions around the world. This is the infrastructure customers use, for example, to power chatbots customized to schedule healthcare appointments and run custom AI solutions that help keep airlines on schedule.

Microsoft has deployed GPUs for inferencing throughout the company’s global Azure datacenter footprint, including this one in Washington state. Photo courtesy of Microsoft.

As trained AI model sizes grow larger, inference will require GPUs networked together in the same way they are for model training in order to provide fast and cost-efficient task completion, according to Chappell. That’s why Microsoft has been growing the ability to cluster GPUs with InfiniBand networking across the Azure datacenter footprint.

“Because the GPUs are connected in a faster network, you can fit larger models on them,” she explained. “And because the model communicates with itself faster, you will be able to do the same amount of compute in a smaller amount of time, so it is cheaper. From an end customer point of view, it’s all about how cheaply we can serve inference.”

To help speed up inferencing, Microsoft has invested in systems optimization with the Open Neural Network Exchange Runtime, or ONNX Runtime, an open-source inferencing engine that incorporates advanced optimization techniques to deliver up to 17 times faster inferencing. Today, ONNX Runtime executes more than a trillion inferences a day and enables many of the most ubiquitous AI powered digital services.

Teams across Microsoft and Azure customers around the world are also using this global infrastructure to fine-tune the large AI models for specific use cases from more helpful chatbots to more accurate auto-generating captions. The unique ability of Azure’s AI optimized infrastructure to scale up and scale out makes it ideal for many of today’s AI workloads from AI model training to inference, according to Boyd.

“We’ve done the work to really understand what it’s like to offer these services at scale,” he said.

Continuing to innovate

Microsoft continues to innovate on the design and optimization of purpose-built AI infrastructure, Boyd added. This includes working with computer hardware suppliers and datacenter equipment manufacturers to build from the ground up cloud computing infrastructure that provides the highest performance, highest scale and the most cost-effective solution possible.

“Having the early feedback lessons from the people who are pushing the envelope and are on the cutting edge of this gives us a lot of insight and head start into what is going to be needed as this infrastructure moves forward,” he said.

This AI-optimized infrastructure is now standard throughout the Azure cloud computing fabric, which includes a portfolio of virtual machines, connected compute and storage resources optimized for AI workloads.

Building this infrastructure unlocked the AI capabilities seen in offerings such as OpenAI’s ChatGPT and the new Microsoft Bing, according to Scott Guthrie, executive vice president of the Cloud and AI group at Microsoft.

“Only Microsoft Azure provides the GPUs, the InfiniBand networking and the unique AI infrastructure necessary to build these types of transformational AI models at scale, which is why OpenAI chose to partner with Microsoft,” he said. “Azure really is the place now to develop and run large transformational AI workloads.”

Related:

Learn more about Microsoft Azure

Read: Microsoft announces new supercomputer, lays out vision for future AI work

Read: Reinventing search with a new AI-powered Bing and Edge, your copilot for the web

Read: From Hot Wheels to handling content: How brands are using Microsoft AI to be more productive and imaginative

Read: How AI makes developers’ lives easier, and helps everybody learn to develop software

Top image: The scale of Microsoft datacenters provides the infrastructure platform for many AI advances, including Azure OpenAI Service and the models that power Microsoft Bing. Photo courtesy of Microsoft.

John Roach writes about research and innovation. Connect with him on LinkedIn."
Microsoft_News,https://aka.ms/NDv5H100Blog,,Azure previews powerful and scalable virtual machine series to accelerate generative AI,"Delivering on the promise of advanced AI for our customers requires supercomputing infrastructure, services, and expertise to address the exponentially increasing size and complexity of the latest models. At Microsoft, we are meeting this challenge by applying a decade of experience in supercomputing and supporting the largest AI training workloads to create AI infrastructure capable of massive performance at scale. The Microsoft Azure cloud, and specifically our graphics processing unit (GPU) accelerated virtual machines (VMs), provide the foundation for many generative AI advancements from both Microsoft and our customers.

“Co-designing supercomputers with Azure has been crucial for scaling our demanding AI training needs, making our research and alignment work on systems like ChatGPT possible.”—Greg Brockman, President and Co-Founder of OpenAI.

Azure’s most powerful and massively scalable AI virtual machine series

Today, Microsoft is introducing the ND H100 v5 VM which enables on-demand in sizes ranging from eight to thousands of NVIDIA H100 GPUs interconnected by NVIDIA Quantum-2 InfiniBand networking. Customers will see significantly faster performance for AI models over our last generation ND A100 v4 VMs with innovative technologies like:

8x NVIDIA H100 Tensor Core GPUs interconnected via next gen NVSwitch and NVLink 4.0

400 Gb/s NVIDIA Quantum-2 CX7 InfiniBand per GPU with 3.2Tb/s per VM in a non-blocking fat-tree network

NVSwitch and NVLink 4.0 with 3.6TB/s bisectional bandwidth between 8 local GPUs within each VM

4th Gen Intel Xeon Scalable processors

PCIE Gen5 host to GPU interconnect with 64GB/s bandwidth per GPU

16 Channels of 4800MHz DDR5 DIMMs

Delivering exascale AI supercomputers to the cloud

Generative AI applications are rapidly evolving and adding unique value across nearly every industry. From reinventing search with a new AI-powered Microsoft Bing and Edge to AI-powered assistance in Microsoft Dynamics 365, AI is rapidly becoming a pervasive component of software and how we interact with it, and our AI Infrastructure will be there to pave the way. With our experience of delivering multiple-ExaOP supercomputers to Azure customers around the world, customers can trust that they can achieve true supercomputer performance with our infrastructure. For Microsoft and organizations like Inflection, NVIDIA, and OpenAI that have committed to large-scale deployments, this offering will enable a new class of large-scale AI models.

“Our focus on conversational AI requires us to develop and train some of the most complex large language models. Azure’s AI infrastructure provides us with the necessary performance to efficiently process these models reliably at a huge scale. We are thrilled about the new VMs on Azure and the increased performance they will bring to our AI development efforts.”—Mustafa Suleyman, CEO, Inflection.

AI at scale is built into Azure’s DNA. Our initial investments in large language model research, like Turing, and engineering milestones such as building the first AI supercomputer in the cloud prepared us for the moment when generative artificial intelligence became possible. Azure services like Azure Machine Learning make our AI supercomputer accessible to customers for model training and Azure OpenAI Service enables customers to tap into the power of large-scale generative AI models. Scale has always been our north star to optimize Azure for AI. We’re now bringing supercomputing capabilities to startups and companies of all sizes, without requiring the capital for massive physical hardware or software investments.

“NVIDIA and Microsoft Azure have collaborated through multiple generations of products to bring leading AI innovations to enterprises around the world. The NDv5 H100 virtual machines will help power a new era of generative AI applications and services.”—Ian Buck, Vice President of hyperscale and high-performance computing at NVIDIA.

Today we are announcing that ND H100 v5 is available for preview and will become a standard offering in the Azure portfolio, allowing anyone to unlock the potential of AI at Scale in the cloud. Sign up to request access to the new VMs..

Learn more about AI at Microsoft"
Microsoft_News,https://azure.microsoft.com/en-us/blog/chatgpt-is-now-available-in-azure-openai-service/,,ChatGPT is now available in Azure OpenAI Service,"Today, we are thrilled to announce that ChatGPT is available in preview in Azure OpenAI Service. With Azure OpenAI Service, over 1,000 customers are applying the most advanced AI models—including Dall-E 2, GPT-3.5, Codex, and other large language models backed by the unique supercomputing and enterprise capabilities of Azure—to innovate in new ways.

Since ChatGPT was introduced late last year, we’ve seen a variety of scenarios it can be used for, such as summarizing content, generating suggested email copy, and even helping with software programming questions. Now with ChatGPT in preview in Azure OpenAI Service, developers can integrate custom AI-powered experiences directly into their own applications, including enhancing existing bots to handle unexpected questions, recapping call center conversations to enable faster customer support resolutions, creating new ad copy with personalized offers, automating claims processing, and more. Cognitive services can be combined with Azure OpenAI to create compelling use cases for enterprises. For example, see how Azure OpenAI and Azure Cognitive Search can be combined to use conversational language for knowledge base retrieval on enterprise data.

Customers can begin using ChatGPT today. It is priced at $0.002/1,000 tokens and billing for all ChatGPT usage begins March 13, 2023.

Real business value

Customers across industries are seeing business value from using Azure OpenAI Service, and we’re excited to see how organizations such as The ODP Corporation, Singapore’s Smart Nation Digital Government Office, and Icertis will continue to harness the power of Azure OpenAI and the ChatGPT model to achieve more:

“The ODP Corporation is excited to leverage the powerful AI technology of ChatGPT from Azure OpenAI Service, made possible through our collaboration with Microsoft. This technology will help [The ODP Corporation] drive continued transformation in our business, more effectively explore new possibilities, and design innovative solutions to deliver even greater value to our customers, partners, and associates. [The ODP Corporation] is building a ChatGPT-powered chatbot to support our internal business units, specifically HR. The chatbot has been successful in improving HR’s document review process, generating new job descriptions, and enhancing associate communication. By utilizing ChatGPT’s natural language processing and machine learning capabilities, [The ODP Corporation] aims to streamline its internal operations and drive business success. Embracing this cutting-edge technology will help increase our competitive edge in the market and enhance our customer experience.”—Carl Brisco, Vice President Product and Technology, The ODP Corporation

“Singapore’s Smart Nation Digital Government Office is constantly looking to empower our public officers with technology to deliver better services to Singaporeans and better ideas for Singapore. ChatGPT and large language models more generally, hold the promise of accelerating many kinds of knowledge work in the public sector, and the alignment techniques embedded in ChatGPT help officers interact with these powerful models in more natural and intuitive ways. Azure OpenAI Service’s enterprise controls have been key to enabling exploration of these technologies across policy, operations, and communication use cases.”—Feng-ji Sim, Deputy Secretary, Smart Nation Digital Government Office, under the Prime Minister’s Office, Singapore

“Contracts are the foundation of commerce, governing every dollar in and out of an enterprise. At Icertis, we are applying AI to contracts so businesses globally can drive revenue, reduce costs, ensure compliance, and mitigate risk. The availability of ChatGPT on Microsoft’s Azure OpenAI service offers a powerful tool to enable these outcomes when leveraged with our data lake of more than two billion metadata and transactional elements—one of the largest curated repositories of contract data in the world. Generative AI will help businesses fully realize the intent of their commercial agreements by acting as an intelligent assistant that surfaces and unlocks insights throughout the contract lifecycle. Delivering this capability at an enterprise scale, backed by inherent strengths in the security and reliability of Azure, aligns with our tenets of ethical AI and creates incredible new opportunities for innovation with the Icertis contract intelligence platform.”—Monish Darda, Chief Technology Officer at Icertis

In addition to all the ways organizations—large and small—are using Azure OpenAI Service to achieve business value, we’ve also been working internally at Microsoft to blend the power of large language models from OpenAI and the AI-optimized infrastructure of Azure to introduce new experiences across our consumer and enterprise products. For example:

• GitHub Copilot leverages AI models in Azure OpenAI Service to help developers accelerate code development with its AI pair programmer.

• Microsoft Teams Premium includes intelligent recap and AI-generated chapters to help individuals, teams, and organizations be more productive.

• Microsoft Viva Sales’ new AI-powered seller experience offers suggested email content and data-driven insights to help sales teams focus on strategic selling motions to customers.

• Microsoft Bing introduced an AI-powered chat option to enhance consumers’ search experience in completely new ways.

These are just a few examples of how Microsoft is helping organizations leverage generative AI models to drive AI transformation.

Customers and partners can also create new intelligent apps and solutions to stand out from the competition using a no-code approach in Azure OpenAI Studio. Azure OpenAI Studio, in addition to offering customizability for every model offered through the service, also offers a unique interface to customize ChatGPT and configure response behavior that aligns with your organization.

Watch how you can customize ChatGPT using System message right within Azure OpenAI Studio.

A responsible approach to AI

We’re already seeing the impact AI can have on people and companies, helping improve productivity, amplify creativity, and augment everyday tasks. We’re committed to making sure AI systems are developed responsibly, that they work as intended, and are used in ways that people can trust. Generative models, such as ChatGPT or DALL-E image generation model, are models that generate new artifacts. These types of models create new challenges; for instance, they could be used to create convincing but incorrect text to creating realistic images that never happened.

Microsoft employs a layered set of mitigations at four levels, designed to address these challenges. These are aligned with Microsoft’s Responsible AI Standard. First, application-level protections that put the customer in charge, for instance, explaining that text output was generated by AI and making the user approve it. Second, technical protections like input and output content filtering. Third, process and policy protections that range from systems to report abuse to service level agreements. And fourth, documentation such as design guidelines and transparency notes to explain the benefits of a model and what we have tested.

We believe AI will profoundly change how we work, and how organizations operate in the coming months. To meet this moment, we will continue to take a principled approach to ensure our AI systems are used responsibly while listening, learning, and improving to help guide AI in a way that ultimately benefits humanity.

Getting started with Azure OpenAI Service

Seth Juarez, Principal Program Manager and co-host of The AI Show, shares top use cases for Azure OpenAI Service and an example chatbot for retail using ChatGPT."
Microsoft_News,https://azure.microsoft.com/en-us/blog/exploring-opensource-capabilities-in-azure-ai/,,Exploring open-source capabilities in Azure AI,"This post was co-authored by Richard Tso, Director of Product Marketing, Azure AI

Open-source technologies have had a profound impact on the world of AI and machine learning, enabling developers, data scientists, and organizations to collaborate, innovate, and build better AI solutions. As large AI models like GPT-3.5 and DALL-E become more prevalent, organizations are also exploring ways to leverage existing open-source models and tools without needing to put a tremendous amount of effort into building them from scratch. Microsoft Azure AI is leading this effort by working closely with GitHub and data science communities, and providing organizations with access to a rich set of open-source technologies for building and deploying cutting-edge AI solutions.

At Azure Open Source Day, we highlighted Microsoft’s commitment to open source and how to build intelligent apps faster and with more flexibility using the latest open-source technologies that are available in Azure AI.

Build and operationalize open-source State-of-the-Art models in Azure Machine Learning

Recent advancements in AI propelled the rise of large foundation models that are trained on a vast quantity of data and can be easily adapted to a wide variety of applications across various industries. This emerging trend provides a unique opportunity for enterprises to build and use foundation models in their deep learning workloads.

Today, we’re announcing the upcoming public preview of foundation models in Azure Machine Learning. It provides Azure Machine Learning with native capabilities that enable customers to build and operationalize open-source foundation models at scale. With these new capabilities, organizations will get access to curated environments and Azure AI Infrastructure without having to manually manage and optimize dependencies. Azure Machine learning professionals can easily start their data science tasks to fine-tune and deploy foundation models from multiple open-source repositories, starting from Hugging Face, using Azure Machine Learning components and pipelines. This service will provide you with a comprehensive repository of popular open-source models for multiple tasks like natural language processing, vision, and multi-modality through the Azure Machine Learning built in registry. Users can not only use these pre-trained models for deployment and inferencing directly, but they will also have the ability to fine-tune supported machine learning tasks using their own data and import any other models directly from the open-source repository.

The next generation of Azure Cognitive Services for Vision

Today, Azure Cognitive Services for Vision released its next generation of capabilities powered by the Florence large foundational model. This new Microsoft model delivers significant improvements to image captioning and groundbreaking customization capabilities with few-shot learning. Until today, model customization required large datasets with hundreds of images per label to achieve production quality for vision tasks. But, Florence is trained on billions of text-image pairs, allowing custom models to achieve high quality with just a few images. This lowers the hurdle for creating models that can fit challenging use cases where training data is limited.

Users can try the new capabilities of Vision underpinned by the Florence model through Vision Studio. This tool demonstrates a full set of prebuilt vision tasks, including automatic captioning, smart cropping, classifying images and a summarizing video with natural language, and much more. Users can also see how the tool helps track movements, analyze environments, and provide real-time alerts.

To learn more about the new Florence model in Azure Cognitive Services for Vision, please check out this announcement blog.

New Responsible AI Toolbox additions

Responsible AI is a critical consideration for organizations building and deploying AI solutions. Last year, Microsoft launched the Responsible AI Dashboard within the Responsible AI Toolkit, a suite of tools for a customized, responsible AI experience with unique and complementary functionalities available on GitHub and in Azure Machine Learning. We recently announced the addition of two new open-source tools designed to make the adoption of responsible AI practices more practical.

The Responsible AI Mitigations Library allows practitioners to experiment with different mitigation techniques more easily, while the Responsible AI Tracker uses visualizations to demonstrate the effectiveness of different mitigations for more informed decision-making. The new mitigations library bolsters mitigation by offering a means of managing failures that occur in data preprocessing. The library complements the toolbox’s Fairlearn fairness assessment tool, which focuses on mitigations applied during training time. The tracker allows practitioners to look at performance for subsets of data across iterations of a model to help them determine the most appropriate model for deployment. When used with other tools in the Responsible AI Toolbox, they offer a more efficient and effective means to help improve the performance of systems across users and conditions. These tools are made open source on GitHub and integrated into Azure Machine Learning.

Accelerate large-scale AI with Azure AI infrastructure

Azure AI Infrastructure provides massive scale-up and scale-out capabilities for the most advanced AI workloads in the world. This is a key factor as to why leading AI companies, including our partners at OpenAI continue to choose Azure to advance their AI innovation on Azure AI. Our results for training OpenAI’s GPT-3 on Azure AI Infrastructure using Azure NDm A100 v4 virtual machines with NVIDIA’s open-source framework, NVIDIA NeMo Megatron, delivered a 530B-parameter benchmark on 175 virtual machines, resulting in a scalability factor of 95 percent. When Azure AI infrastructure is used together with a managed end-to-end machine learning platform, such as Azure Machine Learning, it provides the vast compute needed to enable organizations to streamline management and orchestration of large AI models and help bring them into production.

The full benchmarking report for GPT-3 models with the NVIDIA NeMo Megatron framework on Azure AI infrastructure is available here.

Optimized training framework to accelerate PyTorch model development

Azure is a preferred platform for widely used open-source framework-PyTorch. At Microsoft Ignite, we launched Azure Container for PyTorch (ACPT) within Azure Machine Learning, bringing together the latest PyTorch version with our best optimization software for training and inferencing, such as DeepSpeed and ONNX Runtime, all tested and optimized for Azure. All these components are already installed in ACPT and validated to reduce setup costs and accelerate training time for large deep learning workloads. ACPT curated environment allows our customers to efficiently train PyTorch models. The optimization libraries like ONNX Runtime and DeepSpeed composed within the container can increase production speed up from 54 percent to 163 percent over regular PyTorch workloads as seen on various Hugging Face models.

The chart shows ACPT that combines ONNX Runtime and DeepSpeed can increase production speed up to 54 percent to 163 percent over regular PyTorch workloads.

This month, we’re bringing a new capability to ACPT-Nebula. Nebula is a component in ACPT that can help data scientists to boost checkpoint savings time faster than existing solutions for distributed large-scale model training jobs with PyTorch. Nebula is fully compatible with different distributed PyTorch training strategies, including PyTorch Lightning, DeepSpeed, and more. In saving medium-sized Hugging Face GPT2-XL checkpoints (20.6 GB), Nebula achieved a 96.9 percent reduction in single checkpointing time. The speed gain of saving checkpoints can still increase with model size and GPU numbers. Our results show that, with Nebula, saving a checkpoint with a size of 97GB in a training job on 128 A100 Nvidia GPUs can be reduced from 20 minutes to 1 second. With the ability to reduce checkpoint times from hours to seconds-a potential reduction of 95 percent to 99.9 percent, Nebula provides a solution to frequent saving and reduction of end-to-end training time in large-scale training jobs.

The chart shows Nebula achieved a 96.9 percent reduction in single checkpointing time with GPT2-XL.

To learn more about Azure Container for PyTorch, please check out this announcement blog.

MLflow 2.0 and Azure Machine Learning

MLflow is an open-source platform for the complete machine learning lifecycle, from experimentation to deployment. Being one of the MLflow contributors, Azure Machine Learning made its workspaces MLflow-compatible, which means organizations can use Azure Machine Learning workspaces in the same way that they use an MLflow tracking server. MLflow has recently released its new version, MLflow 2.0, which incorporates a refresh of the core platform APIs based on extensive feedback from MLflow users and customers, which simplifies the platform experience for data science and machine learning operations workflows. We’re excited to announce that MLflow 2.0 is also supported in Azure Machine Learning workspaces.

Read this blog to learn more about what you can do with MLflow 2.0 in Azure Machine Learning.

Azure AI is empowering developers and organizations to build cutting-edge AI solutions with its rich set of open-source technologies. From leveraging pre-trained models to customizing AI capabilities with new technologies like Hugging Face foundation models, to integrating responsible AI practices with new open-source tools, Azure AI is driving innovation and efficiency in the AI industry. With Azure AI infrastructure, organizations can accelerate their large-scale AI workloads and achieve even greater results. Read this blog and the on-demand session to take a deep dive into what open-source projects and features we’ve announced at Azure Open Source Day 2023.

We’d like to conclude this blog post with some outstanding customer examples that demonstrate their success strategy of combining open-source technologies and building their own AI solutions to transform businesses.

What is most important about these announcements is the creative and transformative ways our customers are leveraging open-source technologies to build their own AI solutions.

These are just a few examples from our customers.

Customers innovating with open-source on Azure AI

Elekta is a company that provides technology, software, and services for cancer treatment providers and researchers. Elekta considers AI as essential to expanding the use and availability of radiotherapy treatments. AI technology helps accelerate the overall treatment planning process and monitors patient movement in real-time during treatment. Elekta uses Azure cloud infrastructure for the storage and compute resources needed for their AI-enabled solutions. Elekta relies heavily on Azure Machine Learning, Azure Virtual Machines, and the PyTorch open-source machine learning framework to create virtual machines and optimize their neural networks. Read full story.

The National Basketball Association (NBA) is using AI and open-source technologies to enhance its fan experience. The NBA and Microsoft have partnered to create a direct-to-consumer platform that offers more personalized and engaging content to fans. The NBA uses AI-driven data analysis system, NBA CourtOptix, which uses player tracking and spatial position information to derive insights into the games. The system is powered by Microsoft Azure, including Azure Data Lake Storage, Azure Machine Learning, MLflow, and Delta Lake, among others. The goal is to turn the vast amounts of data into actionable insights that fans can understand and engage with. The NBA also hopes to strengthen its direct relationship with fans and increase engagement through increased personalization of content delivery and marketing efforts. Read full story."
Microsoft_News,https://azure.microsoft.com/en-us/blog/announcing-a-renaissance-in-computer-vision-ai-with-microsofts-florence-foundation-model/,,Announcing a renaissance in computer vision AI with Microsoft,"Extract robust insights from image and video content with Azure Cognitive Service for Vision

We are pleased to announce the public preview of Microsoft’s Florence foundation model, trained with billions of text-image pairs and integrated as cost-effective, production-ready computer vision services in Azure Cognitive Service for Vision. The improved Vision Services enables developers to create cutting-edge, market-ready, responsible computer vision applications across various industries. Customers can now seamlessly digitize, analyze, and connect their data to natural language interactions, unlocking powerful insights from their image and video content to support accessibility, drive acquisition through SEO, protect users from harmful content, enhance security, and improve incident response times.

Microsoft was recently named a Leader in the IDC MarketScape: Worldwide General-Purpose Computer Vision AI Software Platforms 2022 Vendor Assessment (doc #US49776422, November 2022). The new Vision Services improves content discoverability with automatic captioning, smart cropping, classifying, background removal, and searching for images. Furthermore, users can track movements, analyze environments, and receive real-time alerts with responsible AI controls.

Reddit will be using Vision Services to generate captions for hundreds of millions of images on its platform. Tiffany Ong, Reddit Product Manager of Consumer Product has said,

“With Microsoft’s Vision technology, we are making it easier for users to discover and understand our content. The newly created image captions make Reddit more accessible for everyone and give redditors more opportunities to explore our images, engage in conversations, and ultimately build connections and a sense of community.”

Microsoft is harnessing the power of the new Vision Services in Microsoft 365 apps like Teams, PowerPoint, Outlook, Word, Designer, OneDrive, in addition to the Microsoft Datacenter. Microsoft Teams is driving innovation in the digital space with the help of segmentation capabilities, taking virtual meetings to the next level. PowerPoint, Outlook, and Word leverage image captioning for automatic alt-text to improve accessibility. Microsoft Designer and OneDrive are using improved image tagging, image search, and background generation to simplify image discoverability and editing. Microsoft Datacenters are leveraging Vision Services to enhance security and infrastructure reliability.

At this week’s Microsoft Ability Summit, companies will learn how they can improve the accessibility of their visual content. We’ll share the future of our Seeing AI app and LinkedIn will share the benefits of utilizing Vision Services to deliver automatic alt-text descriptions for image analysis. As a preview, Jennison Asuncion, LinkedIn’s Head of Accessibility Engineering Evangelism has said,

“More than 40 percent of LinkedIn’s feed posts include at least one image. We want every member to have equal access to opportunity and are committed to ensuring that we make images accessible to our members who are blind or who have low vision so they can be a part of the online conversation. With Azure Cognitive Service for Vision, we can provide auto-captioning to edit and support alt. text descriptions. I’m excited about this new experience because now, not only will I know my colleague shared a picture from an event they attended, but that my CEO Ryan Roslansky is also in the picture.”

Try out the new out-of-the-box features our customers are using in Vision Studio:

Dense captions: Automatically deliver rich captions, design suggestions, accessible alt-text, SEO optimization, and intelligent photo curation to support digital content.

Automatically deliver rich captions, design suggestions, accessible alt-text, SEO optimization, and intelligent photo curation to support digital content. Image retrieval: Improve search recommendations and advertisements with natural language queries that seamlessly measure the similarity between images and text.

Improve search recommendations and advertisements with natural language queries that seamlessly measure the similarity between images and text.

Background removal: Transform the look and feel of images by easily segmenting people and objects from their original background, replacing them with a preferred background scene.

Transform the look and feel of images by easily segmenting people and objects from their original background, replacing them with a preferred background scene. Model customization: Lower costs and time to deliver custom models that match unique business demands at high precision, and with just a handful of images.

Lower costs and time to deliver custom models that match unique business demands at high precision, and with just a handful of images. Video summarization (Video TL;DR): Search and interact with video content in the same intuitive way you think and write. Locate relevant content without the need for additional metadata.

Innovate responsibly

Review the responsible AI principles to learn how we are committed to developing AI systems that help make the world more accessible. We are focused on helping organizations take full advantage of AI, and we are investing heavily in programs that provide technology, resources, and expertise to empower those working to create a more sustainable, safe, and accessible world.

Get started today with Azure Cognitive Service for Vision

Revolutionize your computer vision applications with improved efficiency, accuracy, and accessibility in image and video processing, at the same low price. Visit Vision Studio to try out our latest demos.

Learn more about Azure Cognitive Service for Vision:"
Microsoft_News,https://blogs.microsoft.com/blog/2023/03/06/introducing-microsoft-dynamics-365-copilot/,,"Introducing Microsoft Dynamics 365 Copilot, the world’s first copilot in both CRM and ERP, that brings next-generation AI to every line of business","Today, we’re announcing the next generation of AI product updates across our business applications portfolio, including the launch of the new Microsoft Dynamics 365 Copilot – providing interactive, AI-powered assistance across business functions.

According to our recent survey on business trends, nearly 9 out of 10 workers hope to use AI to reduce repetitive tasks in their jobs. With Dynamics 365 Copilot, organizations empower their workers with AI tools built for sales, service, marketing, operations and supply chain roles. These AI capabilities allow everyone to spend more time on the best parts of their jobs and less time on mundane tasks.

Customer relationship management (CRM) and enterprise resource planning (ERP) systems have long been mission-critical customer and business data sources; however, they frequently require burdensome tasks like manual data entry, content generation and notetaking. Dynamics 365 Copilot takes advantage of recent advancements in generative AI to automate these tedious tasks and unlock the full creativity of the workforce. Dynamics 365 Copilot puts CRM and ERP to work for business users to accelerate their pace of innovation and improve business outcomes in every line of business:

Copilot in Microsoft Dynamics 365 Sales and Viva Sales helps sellers dramatically reduce the time they spend on clerical tasks. AI helps write email responses to customers and can even create an email summary of a Teams meeting in Outlook. The meeting summary pulls in details from the seller’s CRM such as product and pricing information, as well as insights from the recorded Teams call. With sellers spending as much as 66% of their day checking and responding to emails, this presents a significant business upside to give the seller more time with their customers.

helps sellers dramatically reduce the time they spend on clerical tasks. AI helps write email responses to customers and can even create an email summary of a Teams meeting in Outlook. The meeting summary pulls in details from the seller’s CRM such as product and pricing information, as well as insights from the recorded Teams call. With sellers spending as much as 66% of their day checking and responding to emails, this presents a significant business upside to give the seller more time with their customers. Copilot in Dynamics 365 Customer Service empowers agents to deliver exceptional customer care. Dynamics 365 Copilot drafts contextual answers to queries in both chat and email, in addition to providing an interactive chat experience over knowledge bases and case history so this AI-powered expertise is always available to answer questions. We’re also making it easier for customer service departments to build virtual agents in minutes with conversation boosters in Power Virtual Agents , which harnesses the power of Azure OpenAI Service and Bing to provide answers from company websites and internal knowledge bases that you choose.

empowers agents to deliver exceptional customer care. Dynamics 365 Copilot drafts contextual answers to queries in both chat and email, in addition to providing an interactive chat experience over knowledge bases and case history so this AI-powered expertise is always available to answer questions. We’re also making it easier for customer service departments to build virtual agents in minutes with , which harnesses the power of Azure OpenAI Service and Bing to provide answers from company websites and internal knowledge bases that you choose. Copilot in Dynamics 365 Customer Insights and Dynamics 365 Marketing empowers marketers to simplify their workflow in data exploration, audience segmentation and content creation. With Copilot in Dynamics 365 Customer Insights , marketers can curate highly personalized and targeted customer segments by having a dialogue with their customer data platform using natural language. Marketers can receive suggestions about additional segments that may not have been previously considered. This new capability can handle complex calculations and match customers that fit a select profile. Using Copilot in Dynamics 365 Marketing , marketers can describe their customer segment in their own words to create a target segment with the query assist feature. Marketers can also use Dynamics 365 Copilot to effortlessly get inspiration for fresh email campaign content based on a simple request. Copilot makes suggestions based on key topics entered by the marketer, the organization’s existing marketing emails, as well as from a range of internet sources to increase the relevance of generated ideas.

and empowers marketers to simplify their workflow in data exploration, audience segmentation and content creation. Copilot in Dynamics 365 Business Central streamlines the creation of product listings for online commerce. Product attributes such as color, material and size can be used to create compelling product descriptions for online storefronts in seconds. The descriptions can be further tailored by choosing tone of voice, format and length. Business Central customers using Shopify can seamlessly publish the products with descriptions to their Shopify store in just a few clicks.

streamlines the creation of product listings for online commerce. Product attributes such as color, material and size can be used to create compelling product descriptions for online storefronts in seconds. The descriptions can be further tailored by choosing tone of voice, format and length. Business Central customers using Shopify can seamlessly publish the products with descriptions to their Shopify store in just a few clicks. Lastly, Copilot in Microsoft Supply Chain Center, which Microsoft Dynamics 365 Supply Chain Management customers can access, will proactively flag external issues such as weather, financials and geography that may impact key supply chain processes. Predictive insights then surface impacted orders across materials, inventory, carrier, distribution network and more. Supply chain planners can then automatically draft an email generated by Dynamics 365 Copilot to alert impacted partners and mitigate potential disruptions before they happen.

The next era of business applications is being transformed by generative AI. Users will increasingly expect their CRM and ERP applications to include AI-powered expertise. Dynamics 365 Copilot brings the latest AI breakthroughs to every line of business, improving customer experience, employee experience and operational efficiency. Essential to our approach as we bring these latest advancements to customers is our commitment to responsible AI by design – our framework for the safe deployment of AI technologies.

Today’s announcement builds on recent AI momentum across Microsoft 365, Dynamics 365, and the Power Platform. This includes: the next generation of AI capabilities in Microsoft Teams, the collaboration platform for work with more than 280 million monthly active users; Viva Sales, which helps sellers by bringing a sales copilot to their flow of work in Microsoft 365; and Power Apps, enabling citizen developers to write code using natural language.

You can read more about today’s AI announcements from Emily He, CVP, Business Applications and Platform here. Join us on March 16 as we share the next step in our journey to reinvent productivity with AI. You can RSVP for the event on the Microsoft LinkedIn page.

YouTube Video Click here to load media

Tags: AI, CRM, Microsoft Dynamics 365 Copilot, Microsoft Viva"
Microsoft_News,https://blogs.bing.com/search/march_2023/Bing-Preview-Release-Notes-Tone-Changes-and-More,,Bing Preview Release Notes: Tone Changes and More,"As more of you access the new Bing preview, your feedback is helping us improve. In the last two weeks we added Bing preview capabilities to the Bing and Edge mobile apps, integrated Bing chat with Skype , and announced we're bringing Bing to the Windows 11 taskbar But we're also making daily incremental improvements to the new Bing preview. You can expect us to post regular updates here that summarize changes we've made and what we’re learning.Here's what's new:We've introduced the ability to toggle the tone of chat from ""Precise"", which focuses on shorter, more search-focused answers, to ""Creative"" which gives responses that are longer and more descriptive. The middle setting (""Balanced"") is somewhere in-between. You’ll notice a color change in the UX between purple, blue, and green depending on which is selected. Our goal is to let you decide the type of chat behavior that best meets your needs. We’ll continue to tune this experience based on feedback. As we mentioned last week , we've set a limit of chat turns in a single conversation to six. It's our intention to increase these limits—but in the meantime, we realize it may be difficult to anticipate when you'll need to reset to a new topic. You'll now see a turn counter and stoplights appear at the bottom of each Bing response to signal where you are in the conversation.If you used the Bing chat experience built into the Edge Dev channel for Windows, Bing was sometimes unable to recognize the context of the page you were browsing. We've fixed this problem for most scenarios.We've improved some chat behaviors that previously would have unnecessarily constrained responses or made them appear defensive or adversarial. Bing responses should be more engaging and provide more elaborate observations.Keep your feedback coming!- The Bing Team"
Microsoft_News,https://news.microsoft.com/source/shortform/people-of-ai-how-these-microsoft-employees-are-shaping-the-defining-technology-of-our-time,,People of AI: How these Microsoft employees are shaping the defining technology of our time,"Artificial intelligence (AI) at Microsoft is powered by – and for – people. Here’s how five of those people are using the defining technology of our time to develop innovative solutions to the world’s most challenging issues:

"
Microsoft_News,https://blogs.windows.com/windowsexperience/2023/02/28/introducing-a-big-update-to-windows-11-making-the-everyday-easier-including-bringing-the-new-ai-powered-bing-to-the-taskbar/,,Introducing a big update to Windows 11 making the everyday easier including bringing the new AI-powered Bing to the taskbar,"It’s an exciting time in technology, not just for our industry but for the world. The Windows PC has never been more relevant in our daily lives, and this is increasingly the case as we approach the next wave of computing led by the mass adoption of AI. Today’s major update to Windows 11, that I am pumped to introduce, meets this new age of AI and reinvents and improves the way people get things done on their PCs.

Launched just over a year ago, Windows 11 gave the PC a modern refresh and all new experiences that enable each of us to connect, participate, and be seen and heard. Since the launch, Windows 11 users continue to be more engaged than Windows 10 users and our US consumer customer satisfaction is higher than any version of Windows ever.

In the last three weeks, we also launched the new AI-powered Bing into preview for more than 1 million people in 169 countries, and expanded the new Bing to the Bing and Edge mobile apps as well as introduced it into Skype. It is a new era in Search, Chat and Creation and with the new Bing and Edge you now have your own copilot for the web.

Today, we take the next major step forward adding to the incredible breadth and ease of use of the Windows PC by implementing a typable Windows search box and the amazing capability of the new AI-powered Bing directly into the taskbar. Putting all your search needs for Windows in one easy to find location.

The search box is one of the most widely used features on Windows, with over half a billion users every month, and now with the typable Windows search box and the new AI-powered Bing front and center to this experience you will be empowered to find the answers you’re looking for, faster than ever before.

We’ve been inspired by people’s stories of how they are using the new Bing. For example, a first-generation grad student from a developing country shared how the new Bing gives him access to information and resources that were previously inaccessible and difficult to find. Stories like these energize and inspire us. With the new Bing in the Windows taskbar, you will be more empowered to harness the world’s information.

For me personally, this technology is having incredible impact on how my kids, and I communicate with my dad, their grandfather, in Greek. It’s important for us to stay connected to where we’re from, including speaking the language, and with the new Bing chat experience we can learn and practice writing and speaking in Greek with my dad. It’s inspiring and changing the way we communicate and connect in ways we never imagined.

Soon hundreds of millions of Windows 11 users can get access to this incredible new technology to search, chat, answer questions and generate content from right on their Windows taskbar.

If you’re in the Bing preview, all you’ll need to do is install today’s Windows 11 update to access the new search box. To join the new Bing preview sign up on the waitlist.

We can’t wait to see how the new Bing in Windows inspires you.

Additional new Windows 11 features in the update, designed to make your everyday easier

We’re also excited to introduce a host of new features from across the team that will make your everyday easier on Windows 11. For example, you will be able to link your iPhone® mobile device directly to your Windows 11 PC using a new preview of Phone Link for iOS. Additionally, you’ll notice improved touch experiences, full screen widgets, and quick access to the Windows 365 app. Windows 11 also includes new AI features in Start, as well as ongoing updates to make the operating system more accessible and sustainable and delivering on our continued commitment to quality and ease of use across the system and applications. We look forward to hearing your feedback on these new updates.

Introducing Phone Link for iOS in preview

Today, we share the next step on our journey to remove barriers for those of you who have iPhones with the introduction of Phone Link for iOS. With Phone Link for iOS you’ll never have to worry about missing that important call or text while you are concentrating on your Windows 11 PC.

This builds on our continued efforts to bring you closer to what’s more important, like easier access to the photos on your iPhone with iCloud integration in the Photos app. Launching first as a preview to Windows Insiders, you can learn more about getting started with the preview of Phone Link for iOS by visiting the Windows Insider Blog.

Android® phone users get an even richer experience

Phone Link capabilities have been available to Android users for quite some time and we’re happy to share that we’re making the connection even stronger between an Android device and a Windows PC. With hundreds of thousands of reviews in the Microsoft Store, we are energized to hear that people are enjoying having instant access to everything they love on their phone on their Windows PC.

For those of you with a Samsung phone, we’ve made it easier to activate your phone’s personal hotspot with a single click from within the Wi-Fi network list on your PC. And with the Recent Websites feature, Samsung users can also now easily transfer their browser sessions from their smartphone to their Windows PC, allowing them to continue browsing effortlessly—a great way to stay in your flow.

Broadcast your best self, right when you need to with advanced AI

Whether you are taking a conference call in a busy lobby, giving the pitch of your life to an investor halfway around the world, or meeting your newest family member, we all can relate to wanting to look and sound our best so we can connect in the most meaningful way possible.

Last year we launched Windows Studio Effects1. Enabled by advanced AI, this collection of audio and video effects enables you to customize your audio and video for any situation you are in.

Effects like eye contact, background blur, automatic framing and voice focus, available to use with your built-in camera and mic, enhance your video calling experience. With this update, we are making it even easier to find and adjust your Windows Studio Effects settings directly from the taskbar in quick settings. Now you can instantly adjust background blur, eye contact and automatic framing, and apply them to your favorite communications applications, with seamless integration into Microsoft Teams. Our partners are continuing to deliver exciting new devices that light up these features, like the previously announced Samsung Galaxy Book Pro 2 360 and the Lenovo ThinkPad X13s. Check out other new device announcements that our partners including Acer, ASUS, Dell, HP, Lenovo and our gaming partners made at CES.

Connect in more ways with a simple click

When we launched Windows 11, we included integration with Microsoft Teams through the Chat feature available from your desktop on the taskbar, making it easier for you to make the connections you seek. With this update, the Chat signature experience has been fully revamped to make it easier to preview your video and jump straight into a call or share a call link through any app with those you care about most. You can also get faster, easier access to all of your conversations, with the ability to navigate between conversations in Chat—all in one window.

Providing help is easier than ever with the redesigned Quick Assist app

Are you on the receiving end of the technical assistance call—from your brother whose computer “just stopped working,” your neighbor who can’t login to an important app, or your parent who just can’t find that thing they saved yesterday? For those of you who provide technical assistance to family and friends, we know how challenging it can be to help.

You can open Quick Assist right from the Start menu and get connected more quickly than before, and even take advantage of the new capability to switch between screen sharing and full control during a session to give or get help the way you want. And you’ll love this, there’s a new laser pointer you can use to highlight an icon, menu, or anything else on screen so that you can help guide people through the learning process.

More of the news and information you care about is just a swipe away

Sometimes you just want to quickly see the latest headlines, get the score of the big game, check your stocks, the weather, or even your schedule—but you don’t want to have to juggle multiple devices. With Widgets, you don’t have to; news and information you want is within reach and without disruption.

We are excited to introduce the expansion of Widgets to include Phone Link, Xbox Game Pass, and partners like Meta and Spotify, so it has never been easier to stay up to date on the things that matter. By simply clicking the weather icon in your taskbar or swiping from the left, Widgets delivers important information at a glance. With the launch of new Widgets, we are creating a better experience for you, and new ways for developers to reach Windows customers. Get more information on developer tools to get started.

Enhancing your touch experience

Sometimes we need a break from our desks and want to use our PCs in a more casual setting like sitting back and relaxing on the couch to watch a movie. In times like those, when your keyboard and mouse get left behind, you want to maximize your screen experience and make it more responsive to your touch.

Windows customers love the easy way they can quickly and intuitively navigate their Windows touchscreen devices without a mouse and keyboard. Recent enhancements like touch controls for Snap to get your windows perfectly arranged with just a touch, and new touch gestures that allow you to easily open and close Start, Widgets and quick settings, have made getting things done on touch devices effortless. Now, you can maximize screen real estate and flexibility when using your device without a keyboard with the collapsed taskbar. When you detach your screen, the taskbar instantly slides away. Need to open another app or check your Widgets pane? Simply swipe up to expand it for easy navigation.

Screen recording in Snipping Tool

A picture might paint a thousand words, but a video can tell a story. For all the teachers, creators, students, marketers…you get the picture video. Easily capture what you are doing with a new built-in screen recorder in Snipping Tool.

We’re continuing to expand the capabilities of this fan-favorite app, so now you can easily capture, save and share your Snipping Tool creations – all right in the app. To use the screen recorder functionality, you can search and launch Snipping Tool through Search on the taskbar and select record. Your screen captures are now automatically saved to a default folder, so you won’t have to worry about losing them. Want to snip something quickly? Here’s a keyboard shortcut: Windows key + Shift key + S.

Tabs make navigating Notepad easier than ever

For developers out there who love a quick way to capture lines of code for easy reuse, Windows 11’s Notepad app is here for you.

We are enhancing Notepad, bringing tabs to the app experience. Notepad tabs will provide a quick and easy way to keep your data organized and enable you to switch between notes so you can create ready-to-compile code without formatting issues. Simply open the Notepad app and click the + icon to create a new tab.

New accessibility features include Braille display support and enhanced voice access in key apps

We believe the world is a better place when everyone can participate, so we are continuing to make Windows 11 the most accessible version of Windows yet. We’re pleased to deliver enhancements to Narrator that extend support for more Braille displays, which includes three new Designed for Surface displays from HumanWare. Now switching between Narrator and other screen readers while using your Braille display is a seamless experience. This crucial functionality means Narrator can effortlessly interact with accessible accessories, ensuring people who are blind are able to use Windows with ease.

We’re also bringing voice access functionality out of preview and delivering a more flexible and enhanced solution when using voice on Windows 11. You can use voice access with your favorite Microsoft apps across Windows 11, from working on a Word document to managing files in File Explorer. Whether you’re connecting, collaborating or creating, you can easily use your Windows device to do more, with or without a keyboard and mouse. Here’s a full list of voice commands.

New energy recommendations make it easier for you to control your environmental impact

Windows wants to empower people to more easily take action to reduce their carbon footprint on our journey to invest in sustainable technology. With new toggles and recommendations directly in your system settings, you can more easily understand your choices and take action to adjust your settings so you can make the best choice for your personal PC usage and for the environment.

Harness the power of AI to find the files you need recommended in your Start menu

For those of you who use Windows in a business setting, we are helping you get to what you need more quickly and easily—whether that be a file you need in an instant, or your cloud PC so you can work the way you want.

Available on Windows 11 Pro devices and higher that are Azure Active Directory (AAD) joined, we are personalizing your experience by delivering AI-powered recommended content within your Start menu. Simply click to open the Start menu and find related content to help you prepare for upcoming meetings, quickly access files you’re collaborating on, and more.

You’ll also find even more to love in File Explorer—from our fastest ever file search to recommended local and cloud files, right where you need them.

Access your Cloud PC with the new Windows 365 app

For quick access to your Cloud PC, we have made the Windows 365 app generally available in the Microsoft Store. With the Windows 365 app, you can go from your desktop straight to your Cloud PC, which provides you with a personalized experience tailored to your settings, profile and work style. It also reduces friction for IT administrators who can enable employees with a single sign-on experience. You can download it now at https://aka.ms/Windows365app.

How to take advantage of all these new features

Windows is delighted to deliver on our promise to bring exciting new experiences to Windows 11 more frequently in our continuing commitment to innovate in ways that matter to you. With this update, we are bringing the power of the new AI-powered Bing and additional new features to make staying connected—whether it be to the people or information you care about—easier, for everyone. These new experiences will start to become available today, via Windows Update and new apps available via Microsoft Store updates2. Users with eligible devices running Windows 11, version 22H2 who are interested in experiencing these new features now, can choose to do so by opening Windows Update settings (Settings > Windows Update) and selecting Check for updates3. We anticipate full availability of the new features delivered via Windows Update in the March 2023 monthly security update release (find more information for commercial customers).

We’re pumped about this update and believe there’s never been a better time to experience the magic of the Windows PC than right now; learn more here.

1 Hardware dependent.

2Click ‘Get updates’ in Microsoft Store > Library – and search your favorite titles or explore our new curated collection of mobile apps and games.

3Device reboot required to enable new features. New feature availability may vary by market.

iPhone is a trademark of Apple Inc.

Android is a trademark of Google LLC.

Editor’s note – March 3, 2023 – Text above has been edited for additional clarity on functionality of the snipping tool shortcut.

___________________________________________________________________________"
Microsoft_News,https://www.microsoft.com/en-us/research/blog/responsible-ai-the-research-collaboration-behind-new-open-source-tools-offered-by-microsoft/,,Responsible AI: The research collaboration behind new open-source tools offered by Microsoft,"As computing and AI advancements spanning decades are enabling incredible opportunities for people and society, they’re also raising questions about responsible development and deployment. For example, the machine learning models powering AI systems may not perform the same for everyone or every condition, potentially leading to harms related to safety, reliability, and fairness. Single metrics often used to represent model capability, such as overall accuracy, do little to demonstrate under which circumstances or for whom failure is more likely; meanwhile, common approaches to addressing failures, like adding more data and compute or increasing model size, don’t get to the root of the problem. Plus, these blanket trial-and-error approaches can be resource intensive and financially costly.

VIDEO Responsible AI Toolbox demo Learn how this suite of tools can help assess machine learning models through a lens of responsible AI.

Through its Responsible AI Toolbox (opens in new tab), a collection of tools and functionalities designed to help practitioners maximize the benefits of AI systems while mitigating harms, and other efforts for responsible AI, Microsoft offers an alternative: a principled approach to AI development centered around targeted model improvement. Improving models through targeting methods aims to identify solutions tailored to the causes of specific failures. This is a critical part of a model improvement life cycle that not only includes the identification, diagnosis, and mitigation of failures but also the tracking, comparison, and validation of mitigation options. The approach supports practitioners in better addressing failures without introducing new ones or eroding other aspects of model performance.

“With targeted model improvement, we’re trying to encourage a more systematic process for improving machine learning in research and practice,” says Besmira Nushi, a Microsoft Principal Researcher (opens in new tab) involved with the development of tools for supporting responsible AI. She is a member of the research team behind the toolbox’s newest additions (opens in new tab): the Responsible AI Mitigations Library (opens in new tab), which enables practitioners to more easily experiment with different techniques for addressing failures, and the Responsible AI Tracker (opens in new tab), which uses visualizations to show the effectiveness of the different techniques for more informed decision-making.

Targeted model improvement: From identification to validation

The tools in the Responsible AI Toolbox, (opens in new tab) available in open source and through the Azure Machine Learning (opens in new tab) platform offered by Microsoft, have been designed with each stage of the model improvement life cycle in mind, informing targeted model improvement through error analysis, fairness assessment, data exploration, and interpretability.

For example, the new mitigations library bolsters mitigation by offering a means of managing failures that occur in data preprocessing, such as those caused by a lack of data or lower-quality data for a particular subset. For tracking, comparison, and validation, the new tracker brings model, code, visualizations, and other development components together for easy-to-follow documentation of mitigation efforts. The tracker’s main feature is disaggregated model evaluation and comparison, which breaks down model performance by data subset to present a clearer picture of a mitigation’s effects on the intended subset, as well as other subsets, helping to uncover hidden performance declines before models are deployed and used by individuals and organizations. Additionally, the tracker allows practitioners to look at performance for subsets of data across iterations of a model to help practitioners determine the most appropriate model for deployment.

“Data scientists could build many of the functionalities that we offer with these tools; they could build their own infrastructure,” says Nushi. “But to do that for every project requires a lot of effort and time. The benefit of these tools is scale. Here, they can accelerate their work with tools that apply to multiple scenarios, freeing them up to focus on the work of building more reliable, trustworthy models.” Besmira Nushi, Microsoft Principal Researcher

Building tools for responsible AI that are intuitive, effective, and valuable can help practitioners consider potential harms and their mitigation from the beginning when developing a new model. The result can be more confidence that the work they’re doing is supporting AI that is safer, fairer, and more reliable because it was designed that way, says Nushi. The benefits of using these tools can be far-reaching—from contributing to AI systems that more fairly assess candidates for loans by having comparable accuracy across demographic groups to traffic sign detectors in self-driving cars that can perform better across conditions like sun, snow, and rain.

Creating tools that can have the impact researchers like Nushi envision often begins with a research question and involves converting the resulting work into something people and teams can readily and confidently incorporate in their workflows.

“Making that jump from a research paper’s code on GitHub to something that is usable involves a lot more process in terms of understanding what is the interaction that the data scientist would need, what would make them more productive,” says Nushi. “In research, we come up with many ideas. Some of them are too fancy, so fancy that they cannot be used in the real world because they cannot be operationalized.”

Multidisciplinary research teams consisting of user experience researchers, designers, and machine learning and front-end engineers have helped ground the process as have the contributions of those who specialize in all things responsible AI. Microsoft Research works closely with the incubation team of Aether (opens in new tab), the advisory body for Microsoft leadership on AI ethics and effects, to create tools based on the research. Equally important has been partnership with product teams whose mission is to operationalize AI responsibly, says Nushi. For Microsoft Research, that is often Azure Machine Learning (opens in new tab), the Microsoft platform for end-to-end ML model development. Through this relationship, Azure Machine Learning can offer what Microsoft Principal PM Manager Mehrnoosh Sameki (opens in new tab) refers to as customer “signals,” essentially a reliable stream of practitioner wants and needs directly from practitioners on the ground. And, Azure Machine Learning is just as excited to leverage what Microsoft Research and Aether have to offer: cutting-edge science. The relationship has been fruitful.

As the current Azure Machine Learning platform made its debut five years ago, it was clear tooling for responsible AI was going to be necessary. In addition to aligning with the Microsoft vision for AI development, customers were seeking out such resources. They approached the Azure Machine Learning team with requests for explainability and interpretability features, robust model validation methods, and fairness assessment tools, recounts Sameki, who leads the Azure Machine Learning team in charge of tooling for responsible AI. Microsoft Research, Aether, and Azure Machine Learning teamed up to integrate tools for responsible AI into the platform, including InterpretML (opens in new tab) for understanding model behavior, Error Analysis (opens in new tab) for identifying data subsets for which failures are more likely, and Fairlearn (opens in new tab) for assessing and mitigating fairness-related issues. InterpretML and Fairlearn are independent community-driven projects that power several Responsible AI Toolbox functionalities.

ARTICLE Building AI responsibly from research to practice Putting AI principles into action requires new kinds of engineering tools.

Before long, Azure Machine Learning approached Microsoft Research with another signal: customers wanted to use the tools together, in one interface. The research team responded with an approach that enabled interoperability, allowing the tools to exchange data and insights, facilitating a seamless ML debugging experience. Over the course of two to three months, the teams met weekly to conceptualize and design “a single pane of glass” from which practitioners could use the tools collectively. As Azure Machine Learning developed the project, Microsoft Research stayed involved, from providing design expertise to contributing to how the story and capabilities of what had become Responsible AI dashboard (opens in new tab) would be communicated to customers.

After the release, the teams dived into the next open challenge: enabling practitioners to better mitigate failures. Enter the Responsible AI Mitigations Library and the Responsible AI Tracker, which were developed by Microsoft Research in collaboration with Aether. Microsoft Research was well-equipped with the resources and expertise to figure out the most effective visualizations for doing disaggregated model comparison (there was very little previous work available on it) and navigating the proper abstractions for the complexities of applying different mitigations to different subsets of data with a flexible, easy-to-use interface. Throughout the process, the Azure team provided insight into how the new tools fit into the existing infrastructure.

With the Azure team bringing practitioner needs and the platform to the table and research bringing the latest in model evaluation, responsible testing, and the like, it is the perfect fit, says Sameki.

An open-source approach to tooling for responsible AI

While making these tools available through Azure Machine Learning supports customers in bringing their products and services to market responsibly, making these tools open source is important to cultivating an even larger landscape of responsibly developed AI. When release ready, these tools for responsible AI are made open source and then integrated into the Azure Machine Learning platform. The reasons for going with an open-source-first approach are numerous, say Nushi and Sameki:

freely available tools for responsible AI are an educational resource for learning and teaching the practice of responsible AI;

more contributors, both internal to Microsoft and external, add quality, longevity, and excitement to the work and topic; and

the ability to integrate them into any platform or infrastructure encourages more widespread use.

The decision also represents one of the Microsoft AI principles in action—transparency.

“In the space of responsible AI, being as open as possible is the way to go, and there are multiple reasons for that,” says Sameki. “The main reason is for building trust with the users and with the consumers of these tools. In my opinion, no one would trust a machine learning evaluation technique or an unfairness mitigation algorithm that is unclear and close source. Also, this field is very new. Innovating in the open nurtures better collaborations in the field.” Mehrnoosh Sameki, Microsoft Principal PM Manager

Looking ahead

AI capabilities are only advancing. The larger research community, practitioners, the tech industry, government, and other institutions are working in different ways to steer these advancements in a direction in which AI is contributing value and its potential harms are minimized. Practices for responsible AI will need to continue to evolve with AI advancements to support these efforts.

For Microsoft researchers like Nushi and product managers like Sameki, that means fostering cross-company, multidisciplinary collaborations in their continued development of tools that encourage targeted model improvement guided by the step-by-step process of identification, diagnosis, mitigation, and comparison and validation—wherever those advances lead.

“As we get better in this, I hope we move toward a more systematic process to understand what data is actually useful, even for the large models; what is harmful that really shouldn’t be included in those; and what is the data that has a lot of ethical issues if you include it,” says Nushi. “Building AI responsibly is crosscutting, requiring perspectives and contributions from internal teams and external practitioners. Our growing collection of tools shows that effective collaboration has the potential to impact—for the better—how we create the new generation of AI systems.”

Opens in a new tab"
Microsoft_News,https://www.microsoft.com/en-us/research/blog/responsible-ai-the-research-collaboration-behind-new-open-source-tools-offered-by-microsoft/,,Responsible AI: The research collaboration behind new open-source tools offered by Microsoft,"As computing and AI advancements spanning decades are enabling incredible opportunities for people and society, they’re also raising questions about responsible development and deployment. For example, the machine learning models powering AI systems may not perform the same for everyone or every condition, potentially leading to harms related to safety, reliability, and fairness. Single metrics often used to represent model capability, such as overall accuracy, do little to demonstrate under which circumstances or for whom failure is more likely; meanwhile, common approaches to addressing failures, like adding more data and compute or increasing model size, don’t get to the root of the problem. Plus, these blanket trial-and-error approaches can be resource intensive and financially costly.

VIDEO Responsible AI Toolbox demo Learn how this suite of tools can help assess machine learning models through a lens of responsible AI.

Through its Responsible AI Toolbox (opens in new tab), a collection of tools and functionalities designed to help practitioners maximize the benefits of AI systems while mitigating harms, and other efforts for responsible AI, Microsoft offers an alternative: a principled approach to AI development centered around targeted model improvement. Improving models through targeting methods aims to identify solutions tailored to the causes of specific failures. This is a critical part of a model improvement life cycle that not only includes the identification, diagnosis, and mitigation of failures but also the tracking, comparison, and validation of mitigation options. The approach supports practitioners in better addressing failures without introducing new ones or eroding other aspects of model performance.

“With targeted model improvement, we’re trying to encourage a more systematic process for improving machine learning in research and practice,” says Besmira Nushi, a Microsoft Principal Researcher (opens in new tab) involved with the development of tools for supporting responsible AI. She is a member of the research team behind the toolbox’s newest additions (opens in new tab): the Responsible AI Mitigations Library (opens in new tab), which enables practitioners to more easily experiment with different techniques for addressing failures, and the Responsible AI Tracker (opens in new tab), which uses visualizations to show the effectiveness of the different techniques for more informed decision-making.

Targeted model improvement: From identification to validation

The tools in the Responsible AI Toolbox, (opens in new tab) available in open source and through the Azure Machine Learning (opens in new tab) platform offered by Microsoft, have been designed with each stage of the model improvement life cycle in mind, informing targeted model improvement through error analysis, fairness assessment, data exploration, and interpretability.

For example, the new mitigations library bolsters mitigation by offering a means of managing failures that occur in data preprocessing, such as those caused by a lack of data or lower-quality data for a particular subset. For tracking, comparison, and validation, the new tracker brings model, code, visualizations, and other development components together for easy-to-follow documentation of mitigation efforts. The tracker’s main feature is disaggregated model evaluation and comparison, which breaks down model performance by data subset to present a clearer picture of a mitigation’s effects on the intended subset, as well as other subsets, helping to uncover hidden performance declines before models are deployed and used by individuals and organizations. Additionally, the tracker allows practitioners to look at performance for subsets of data across iterations of a model to help practitioners determine the most appropriate model for deployment.

“Data scientists could build many of the functionalities that we offer with these tools; they could build their own infrastructure,” says Nushi. “But to do that for every project requires a lot of effort and time. The benefit of these tools is scale. Here, they can accelerate their work with tools that apply to multiple scenarios, freeing them up to focus on the work of building more reliable, trustworthy models.” Besmira Nushi, Microsoft Principal Researcher

Building tools for responsible AI that are intuitive, effective, and valuable can help practitioners consider potential harms and their mitigation from the beginning when developing a new model. The result can be more confidence that the work they’re doing is supporting AI that is safer, fairer, and more reliable because it was designed that way, says Nushi. The benefits of using these tools can be far-reaching—from contributing to AI systems that more fairly assess candidates for loans by having comparable accuracy across demographic groups to traffic sign detectors in self-driving cars that can perform better across conditions like sun, snow, and rain.

Creating tools that can have the impact researchers like Nushi envision often begins with a research question and involves converting the resulting work into something people and teams can readily and confidently incorporate in their workflows.

“Making that jump from a research paper’s code on GitHub to something that is usable involves a lot more process in terms of understanding what is the interaction that the data scientist would need, what would make them more productive,” says Nushi. “In research, we come up with many ideas. Some of them are too fancy, so fancy that they cannot be used in the real world because they cannot be operationalized.”

Multidisciplinary research teams consisting of user experience researchers, designers, and machine learning and front-end engineers have helped ground the process as have the contributions of those who specialize in all things responsible AI. Microsoft Research works closely with the incubation team of Aether (opens in new tab), the advisory body for Microsoft leadership on AI ethics and effects, to create tools based on the research. Equally important has been partnership with product teams whose mission is to operationalize AI responsibly, says Nushi. For Microsoft Research, that is often Azure Machine Learning (opens in new tab), the Microsoft platform for end-to-end ML model development. Through this relationship, Azure Machine Learning can offer what Microsoft Principal PM Manager Mehrnoosh Sameki (opens in new tab) refers to as customer “signals,” essentially a reliable stream of practitioner wants and needs directly from practitioners on the ground. And, Azure Machine Learning is just as excited to leverage what Microsoft Research and Aether have to offer: cutting-edge science. The relationship has been fruitful.

As the current Azure Machine Learning platform made its debut five years ago, it was clear tooling for responsible AI was going to be necessary. In addition to aligning with the Microsoft vision for AI development, customers were seeking out such resources. They approached the Azure Machine Learning team with requests for explainability and interpretability features, robust model validation methods, and fairness assessment tools, recounts Sameki, who leads the Azure Machine Learning team in charge of tooling for responsible AI. Microsoft Research, Aether, and Azure Machine Learning teamed up to integrate tools for responsible AI into the platform, including InterpretML (opens in new tab) for understanding model behavior, Error Analysis (opens in new tab) for identifying data subsets for which failures are more likely, and Fairlearn (opens in new tab) for assessing and mitigating fairness-related issues. InterpretML and Fairlearn are independent community-driven projects that power several Responsible AI Toolbox functionalities.

ARTICLE Building AI responsibly from research to practice Putting AI principles into action requires new kinds of engineering tools.

Before long, Azure Machine Learning approached Microsoft Research with another signal: customers wanted to use the tools together, in one interface. The research team responded with an approach that enabled interoperability, allowing the tools to exchange data and insights, facilitating a seamless ML debugging experience. Over the course of two to three months, the teams met weekly to conceptualize and design “a single pane of glass” from which practitioners could use the tools collectively. As Azure Machine Learning developed the project, Microsoft Research stayed involved, from providing design expertise to contributing to how the story and capabilities of what had become Responsible AI dashboard (opens in new tab) would be communicated to customers.

After the release, the teams dived into the next open challenge: enabling practitioners to better mitigate failures. Enter the Responsible AI Mitigations Library and the Responsible AI Tracker, which were developed by Microsoft Research in collaboration with Aether. Microsoft Research was well-equipped with the resources and expertise to figure out the most effective visualizations for doing disaggregated model comparison (there was very little previous work available on it) and navigating the proper abstractions for the complexities of applying different mitigations to different subsets of data with a flexible, easy-to-use interface. Throughout the process, the Azure team provided insight into how the new tools fit into the existing infrastructure.

With the Azure team bringing practitioner needs and the platform to the table and research bringing the latest in model evaluation, responsible testing, and the like, it is the perfect fit, says Sameki.

An open-source approach to tooling for responsible AI

While making these tools available through Azure Machine Learning supports customers in bringing their products and services to market responsibly, making these tools open source is important to cultivating an even larger landscape of responsibly developed AI. When release ready, these tools for responsible AI are made open source and then integrated into the Azure Machine Learning platform. The reasons for going with an open-source-first approach are numerous, say Nushi and Sameki:

freely available tools for responsible AI are an educational resource for learning and teaching the practice of responsible AI;

more contributors, both internal to Microsoft and external, add quality, longevity, and excitement to the work and topic; and

the ability to integrate them into any platform or infrastructure encourages more widespread use.

The decision also represents one of the Microsoft AI principles in action—transparency.

“In the space of responsible AI, being as open as possible is the way to go, and there are multiple reasons for that,” says Sameki. “The main reason is for building trust with the users and with the consumers of these tools. In my opinion, no one would trust a machine learning evaluation technique or an unfairness mitigation algorithm that is unclear and close source. Also, this field is very new. Innovating in the open nurtures better collaborations in the field.” Mehrnoosh Sameki, Microsoft Principal PM Manager

Looking ahead

AI capabilities are only advancing. The larger research community, practitioners, the tech industry, government, and other institutions are working in different ways to steer these advancements in a direction in which AI is contributing value and its potential harms are minimized. Practices for responsible AI will need to continue to evolve with AI advancements to support these efforts.

For Microsoft researchers like Nushi and product managers like Sameki, that means fostering cross-company, multidisciplinary collaborations in their continued development of tools that encourage targeted model improvement guided by the step-by-step process of identification, diagnosis, mitigation, and comparison and validation—wherever those advances lead.

“As we get better in this, I hope we move toward a more systematic process to understand what data is actually useful, even for the large models; what is harmful that really shouldn’t be included in those; and what is the data that has a lot of ethical issues if you include it,” says Nushi. “Building AI responsibly is crosscutting, requiring perspectives and contributions from internal teams and external practitioners. Our growing collection of tools shows that effective collaboration has the potential to impact—for the better—how we create the new generation of AI systems.”

Opens in a new tab"
Microsoft_News,https://blogs.microsoft.com/blog/2023/02/22/the-new-bing-preview-experience-arrives-on-bing-and-edge-mobile-apps-introducing-bing-now-in-skype/,,The new Bing preview experience arrives on Bing and Edge Mobile apps; introducing Bing now in Skype,"Two weeks ago, we introduced the world to the all new AI-powered Bing and Microsoft Edge — your copilot for the web. Since then, based on strong and positive product feedback and engagement, we’ve welcomed more than one million people in 169 countries off the waitlist into the preview. We continue to expand the preview to more people every day. Our preview community is actively using the breadth of new features across Search, Answers, Chat and Creation with total engagement up significantly. Feedback on the new capabilities is positive, with 71% of testers giving the new Bing a “thumbs up” on the new search and answers capabilities. We’re even more excited about the breadth of feedback we are receiving on where and how we can improve and we are acting on it with regular updates.

We’re seeing some interesting use cases and queries in preview testing. I recently learned about a father showing his son the new Bing, and together they discovered and created in a way not easily done with today’s search engines. They started off by creating sci-fi stories using simple prompts in chat, eventually leading to the development of a video game idea where Bing not only helped create a plot, but also generated the code to input directly into Scratch – a visual programming tool. In just a few queries, they captured the wonder and potential of the new Bing and Edge. We are hearing many similar stories on how the new Bing is helping people discover and create in ways previously not possible.

Sign up for the new Bing and Edge mobile apps

In this spirit of learning and continuing to build new capabilities, we’re excited to share today the preview release of the new Bing and Edge mobile apps. We’re beginning to roll out the incredible capabilities of the new Bing and Edge on your smartphone along with some exciting new features, such as voice input. In addition, we are creating a new chat experience, beginning with Skype, to enhance your social communications with your friends and family.

The new Bing and Edge goes mobile; Now introducing voice access

Because we know 64% of searches occur on mobile phones, we are releasing all new Bing and Edge mobile apps to serve as your copilot for the web even when you are away from your desktop.

Imagine an unexpected layover in a new city. As you plan a quick afternoon stop in Tokyo, you ask Bing to help find a place to store your luggage. It then provides tips for navigating the metro system on your way to the famed Shinjuku station. With a few hours to explore, Bing creates a short itinerary, helping you get the most out of your quick visit, and even translates along the way.

Available on iOS and Android today, the Bing mobile app offers a fresh look and experience. Tapping the Bing icon at the bottom will invoke a chat session, where you can engage in all the same ways you can from the desktop. Ask simple or complex questions and receive answers and citations. Choose how you want your answers displayed – bullet points, text or simplified responses. Explore the Bing chat experience to refine your query or compose an email, poem or list.

With the introduction of the new Bing mobile app, we’re adding one of the preview community’s most requested features – voice. Available on mobile and on desktop, voice search provides more versatility in how you can deliver prompts and receive answers from Bing.

In addition, those who have access to the preview will be able to utilize the new Bing experience from the homepage of the Microsoft Edge mobile app.

Bing goes social with Skype

To better assist you when you are collaborating with friends and family, we are introducing AI-powered Bing for Skype. More than 36 million people use Skype daily to connect through phone calls and chats across borders and around the world and the new Bing is going to enable some helpful and fun new scenarios and capabilities.

Imagine having a copilot for your friends and family as you stay connected and plan your next get together. Simply add Bing to the group, as you would any Skype contact, and now you can ask Bing to answer questions and provide information for the entire group. For example, if your family is chatting about the next family reunion, you can simply ask Bing for suggestions on travel destinations, expected weather forecasts and interesting events around your time of travel, and everyone in the chat will get access to the results. When you are catching up with friends, you can ask Bing to simply fetch information from the web, for example, the latest news or last night’s award shows to add to your conversation.

You can choose how you want your answers to be displayed – bullet points, text or a simplified response. Bing can accommodate your preferences. Fluent in more than 100 languages, and capable of translating between them, Bing can offer unique value to this global communications tool.

Available worldwide in preview today, the new Bing in Skype can provide helpful, real-time answers to all your questions. As we learn and fine-tune this amazing new capability, we envision bringing it to other communications apps, like Teams, in the future.

If you’re currently on the Bing preview experience, these features are available to you later today. In the first few days of testing these mobile experiences, you may occasionally find connectivity issues in low-bandwidth situations. We’re aware of the issue and are working on a fix.

If you’re among those awaiting access, we appreciate both your patience and your excitement. We’re working as fast as possible to onboard more people every day. If you’re interested in trying it for yourself, please sign up for the Bing preview today. We hope you enjoy the new capabilities and please keep the feedback coming so we can continue to improve the product for you.

*Skype user interface will vary during initial rollout.

Tags: AI, Bing, Microsoft Edge, skype"
Microsoft_News,https://blogs.microsoft.com/on-the-issues/2023/02/02/responsible-ai-chatgpt-artificial-intelligence/,,Meeting the AI moment: advancing the future through responsible AI,"Early last summer, a small group of senior leaders and responsible AI experts at Microsoft started using technology from OpenAI similar to what the world now knows as ChatGPT. Even for those who had worked closely with the developers of this technology at OpenAI since 2019, the most recent progress seemed remarkable. AI developments we had expected around 2033 would arrive in 2023 instead.

Looking back at the history of our industry, certain watershed years stand out. For example, internet usage exploded with the popularity of the browser in 1995, and smartphone growth accelerated in 2007 with the launch of the iPhone. It’s now likely that 2023 will mark a critical inflection point for artificial intelligence. The opportunities for people are huge. And the responsibilities for those of us who develop this technology are bigger still. We need to use this watershed year not just to launch new AI advances, but to responsibly and effectively address both the promises and perils that lie ahead.

The stakes are high. AI may well represent the most consequential technology advance of our lifetime. And while that’s saying a lot, there’s good reason to say it. Today’s cutting-edge AI is a powerful tool for advancing critical thinking and stimulating creative expression. It makes it possible not only to search for information but to seek answers to questions. It can help people uncover insights amid complex data and processes. It speeds up our ability to express what we learn more quickly. Perhaps most important, it’s going to do all these things better and better in the coming months and years.

I’ve had the opportunity for many months to use not only ChatGPT, but the internal AI services under development inside Microsoft. Every day, I find myself learning new ways to get the most from the technology and, even more important, thinking about the broader dimensions that will come from this new AI era. Questions abound.

For example, what will this change?

Over time, the short answer is almost everything. Because, like no technology before it, these AI advances augment humanity’s ability to think, reason, learn and express ourselves. In effect, the industrial revolution is now coming to knowledge work. And knowledge work is fundamental to everything.

This brings huge opportunities to better the world. AI will improve productivity and stimulate economic growth. It will reduce the drudgery in many jobs and, when used effectively, it will help people be more creative in their work and impactful in their lives. The ability to discover new insights in large data sets will drive new advances in medicine, new frontiers in science, new improvements in business, and new and stronger defenses for cyber and national security.

Will all the changes be good?

While I wish the answer were yes, of course that’s not the case. Like every technology before it, some people, communities and countries will turn this advance into both a tool and a weapon. Some unfortunately will use this technology to exploit the flaws in human nature, deliberately target people with false information, undermine democracy and explore new ways to advance the pursuit of evil. New technologies unfortunately typically bring out both the best and worst in people.

Perhaps more than anything, this creates a profound sense of responsibility. At one level, for all of us; and, at an even higher level, for those of us involved in the development and deployment of the technology itself.

There are days when I’m optimistic and moments when I’m pessimistic about how humanity will put AI to use. More than anything, we all need to be determined. We must enter this new era with enthusiasm for the promise, and yet with our eyes wide open and resolute in addressing the inevitable pitfalls that also lie ahead.

The good news is that we’re not starting from scratch.

At Microsoft, we’ve been working to build a responsible AI infrastructure since 2017. This has moved in tandem with similar work in the cybersecurity, privacy and digital safety spaces. It is connected to a larger enterprise risk management framework that has helped us to create the principles, policies, processes, tools and governance systems for responsible AI. Along the way, we have worked and learned together with the equally committed responsible AI experts at OpenAI.

Now we must recommit ourselves to this responsibility and call upon the past six years of work to do even more and move even faster. At both Microsoft and OpenAI, we recognize that the technology will keep evolving, and we are both committed to ongoing engagement and improvement.

The foundation for responsible AI

For six years, Microsoft has invested in a cross-company program to ensure that our AI systems are responsible by design. In 2017, we launched the Aether Committee with researchers, engineers and policy experts to focus on responsible AI issues and help craft the AI principles that we adopted in 2018. In 2019, we created the Office of Responsible AI to coordinate responsible AI governance and launched the first version of our Responsible AI Standard, a framework for translating our high-level principles into actionable guidance for our engineering teams. In 2021, we described the key building blocks to operationalize this program, including an expanded governance structure, training to equip our employees with new skills, and processes and tooling to support implementation. And, in 2022, we strengthened our Responsible AI Standard and took it to its second version. This sets out how we will build AI systems using practical approaches for identifying, measuring and mitigating harms ahead of time, and ensuring that controls are engineered into our systems from the outset.

Our learning from the design and implementation of our responsible AI program has been constant and critical. One of the first things we did in the summer of 2022 was to engage a multidisciplinary team to work with OpenAI, build on their existing research and assess how the latest technology would work without any additional safeguards applied to it. As with all AI systems, it’s important to approach product-building efforts with an initial baseline that provides a deep understanding of not just a technology’s capabilities, but its limitations. Together, we identified some well-known risks, such as the ability of a model to generate content that perpetuated stereotypes, as well as the technology’s capacity to fabricate convincing, yet factually incorrect, responses. As with any facet of life, the first key to solving a problem is to understand it.

With the benefit of these early insights, the experts in our responsible AI ecosystem took additional steps. Our researchers, policy experts and engineering teams joined forces to study the potential harms of the technology, build bespoke measurement pipelines and iterate on effective mitigation strategies. Much of this work was without precedent and some of it challenged our existing thinking. At both Microsoft and OpenAI, people made rapid progress. It reinforced to me the depth and breadth of expertise needed to advance the state-of-the-art on responsible AI, as well as the growing need for new norms, standards and laws.

Building upon this foundation

As we look to the future, we will do even more. As AI models continue to advance, we know we will need to address new and open research questions, close measurement gaps and design new practices, patterns and tools. We’ll approach the road ahead with humility and a commitment to listening, learning and improving every day.

But our own efforts and those of other like-minded organizations won’t be enough. This transformative moment for AI calls for a wider lens on the impacts of the technology – both positive and negative – and a much broader dialogue among stakeholders. We need to have wide-ranging and deep conversations and commit to joint action to define the guardrails for the future.

We believe we should focus on three key goals.

First, we must ensure that AI is built and used responsibly and ethically. History teaches us that transformative technologies like AI require new rules of the road. Proactive, self-regulatory efforts by responsible companies will help pave the way for these new laws, but we know that not all organizations will adopt responsible practices voluntarily. Countries and communities will need to use democratic law-making processes to engage in whole-of-society conversations about where the lines should be drawn to ensure that people have protection under the law. In our view, effective AI regulations should center on the highest risk applications and be outcomes-focused and durable in the face of rapidly advancing technologies and changing societal expectations. To spread the benefits of AI as broadly as possible, regulatory approaches around the globe will need to be interoperable and adaptive, just like AI itself.

Second, we must ensure that AI advances international competitiveness and national security. While we may wish it were otherwise, we need to acknowledge that we live in a fragmented world where technological superiority is core to international competitiveness and national security. AI is the next frontier of that competition. With the combination of OpenAI and Microsoft, and DeepMind within Google, the United States is well placed to maintain technological leadership. Others are already investing, and we should look to expand that footing among other nations committed to democratic values. But it’s also important to recognize that the third leading player in this next wave of AI is the Beijing Academy of Artificial Intelligence. And, just last week, China’s Baidu committed itself to an AI leadership role. The United States and democratic societies more broadly will need multiple and strong technology leaders to help advance AI, with broader public policy leadership on topics including data, AI supercomputing infrastructure and talent.

Third, we must ensure that AI serves society broadly, not narrowly. History has also shown that significant technological advances can outpace the ability of people and institutions to adapt. We need new initiatives to keep pace, so that workers can be empowered by AI, students can achieve better educational outcomes and individuals and organizations can enjoy fair and inclusive economic growth. Our most vulnerable groups, including children, will need more support than ever to thrive in an AI-powered world, and we must ensure that this next wave of technological innovation enhances people’s mental health and well-being, instead of gradually eroding it. Finally, AI must serve people and the planet. AI can play a pivotal role in helping address the climate crisis, including by analyzing environmental outcomes and advancing the development of clean energy technology while also accelerating the transition to clean electricity.

To meet this moment, we will expand our public policy efforts to support these goals. We are committed to forming new and deeper partnerships with civil society, academia, governments and industry. Working together, we all need to gain a more complete understanding of the concerns that must be addressed and the solutions that are likely to be the most promising. Now is the time to partner on the rules of the road for AI.

Finally, as I’ve found myself thinking about these issues in recent months, time and again my mind has returned to a few connecting thoughts.

First, these issues are too important to be left to technologists alone. And, equally, there’s no way to anticipate, much less address, these advances without involving tech companies in the process. More than ever, this work will require a big tent.

Second, the future of artificial intelligence requires a multidisciplinary approach. The tech sector was built by engineers. However, if AI is truly going to serve humanity, the future requires that we bring together computer and data scientists with people from every walk of life and every way of thinking. More than ever, technology needs people schooled in the humanities, social sciences and with more than an average dose of common sense.

Finally, and perhaps most important, humility will serve us better than self-confidence. There will be no shortage of people with opinions and predictions. Many will be worth considering. But I’ve often found myself thinking mostly about my favorite quotation from Walt Whitman – or Ted Lasso, depending on your preference.

“Be curious, not judgmental.”

We’re entering a new era. We need to learn together.

Tags: AI, artificial intelligence, ChatGPT, OpenAI, Responsible AI"
Microsoft_News,https://news.microsoft.com/source/features/ai/microsoft-approach-to-ai/,,What is Microsoft’s approach to AI?,"At Microsoft, we believe artificial intelligence (AI) is the defining technology of our time.

We have been on the forefront of cutting-edge research in AI and integrating these powerful, innovative AI technologies into our products and services to help customers do more. Microsoft AI, powered by Azure, provides billions of intelligent experiences every day in Windows, Xbox, Microsoft 365, Teams, Azure AI, Power Platform, Dynamics 365 and Microsoft Defender.

Our AI tools and technologies are designed to benefit everyone at every level in every organization. They are used in workplaces, home offices, academic institutions, research labs and manufacturing facilities around the world, and they are helping everyone from scientists and salespeople to farmers, software developers and security practitioners.

We have made huge investments in AI because we are optimistic about what it can do to help people, industry and society, and because we’re committed to bringing technology and people together to realize the promises of AI responsibly.

To learn more about Microsoft’s work with AI, read about:

Click here to load media

Our approach to using AI responsibly

Microsoft believes that when you create powerful technologies, you also must ensure that the technology is developed and used responsibly. We are committed to a practice of responsible AI by design, guided by a core set of principles: fairness, reliability and safety, privacy and security, inclusiveness, transparency and accountability.

Microsoft is putting these principles into practice across the company to develop and deploy AI that will have a positive impact on society.

“With the right guardrails, cutting-edge technology can be safely introduced to the world to help people be more productive and go on to solve some of our most pressing societal problems,” says Natasha Crampton, the chief responsible AI officer at Microsoft.

AI systems are the product of many different decisions made by those who develop and deploy them. From system purpose to how people interact with AI systems, we need to guide these decisions toward beneficial and equitable outcomes.

“That’s what our practice of responsible AI by design is all about,” Crampton says. “We ensure that responsible AI considerations are addressed at the earliest stages of system design and then throughout the whole lifecycle, so that the appropriate controls and mitigations are baked into the system being built, not bolted on at the end.”

This approach does not eliminate all risks, and a commitment to listening, learning and improving is paramount. But it does encourage developers to be clear about any limitations, account for intended uses and potential misuses, and think expansively about how to secure the benefits of a system and guard against its risks.

We believe proactive, self-regulatory efforts by responsible companies help pave the way for these new laws, but we recognize that not all organizations will adopt responsible practices voluntarily.

Microsoft President, Brad Smith, recently outlined the importance of the company stepping up to meet the current AI moment, including calling for thoughtful policy.

“Countries and communities will need to use democratic law-making processes to engage in whole-of-society conversations about where the lines should be drawn to ensure that people have protection under the law,” Smith wrote.

“Effective AI regulations should center on the highest risk applications and be outcomes-focused and durable in the face of rapidly advancing technologies and changing societal expectations. To spread the benefits of AI as broadly as possible, regulatory approaches around the globe will need to be interoperable and adaptive, just like AI itself,” he added.

Microsoft believes democratic, law-making processes are a vital part of a global dialogue with industry, academia and civil society to create principled and actionable norms that ensure organizations develop and deploy AI responsibly.

As part of this process, we are committed to publicly sharing the company’s learnings and best practices, along with the tools that guide our efforts. This includes our Responsible AI Standard, a framework for translating our high-level principles into actionable guidance for our engineering teams.

Like all transformative technologies, we are aware that AI has its risks. Some people will use this technology to exploit the flaws in human nature, target people with false information, undermine democracy and cause harm. We need to plan for and mitigate these risks.

Microsoft has been working on its cross-company, cross-discipline, responsible AI effort for more than six years, creating a strong foundation upon which to keep building for the future. We are clear-eyed about the need to continue moving forward with urgency to keep pace with the rapid evolution of technology and changing societal expectations.

“Fundamentally, our AI work is grounded in our company mission to help every person and organization on the planet to achieve more,” says Crampton, “and it is undergirded by our steadfast commitment to the responsible development and use of AI.”

Click here to load media

Our approach to AI research

For more than 30 years, Microsoft Research has been advancing the foundations of computing and translating new scientific understanding into innovative technologies to create value for our customers and broad benefit to society.

Our researchers collaborate across disciplines, institutions and geographies to deliver cutting-edge advances in vision, speech, language, decision-making and machine learning. They have pioneered AI breakthroughs in conversational speech recognition, machine translation, image captioning, natural language understanding and commonsense question answering.

Recent efforts have focused on developing large-scale models that can process information in increasingly sophisticated ways while also becoming more natural and intuitive to use. Advances in deep learning, coupled with internet-scale datasets and Microsoft Azure’s increasingly powerful AI supercomputing resources, have made it possible to create AI models that perform a broad range of tasks across many different applications.

“Large-scale AI is shifting the landscape of computing research,” says Ashley Llorens, vice president and managing director at Microsoft Research. “As we orient around that shift, you’ll see new frontiers that advance our understanding of human and machine intelligence and how they can intersect and reinforce each other in profound new ways.”

Our research has played a key role in evolving model architectures and creating AI technology that is more efficient and more adaptable across an even broader range of tasks.

Microsoft researchers have been working on these problems for years, developing expertise in areas like parallel computation that allows people to more quickly train machine learning models at unprecedented scale. This has led to innovations like DeepSpeed, an open-source, deep learning optimization library for distributed training that was developed by Microsoft Research and now is used by the broader computing community.

We also are focused on delivering value and solving real-world problems through Microsoft products and services. Project FarmVibes, for example, merges AI and data to offer open-source tools that can help farmers adopt sustainable agriculture practices. And the Microsoft Climate Research Initiative provides our research and computing capabilities to a team of multidisciplinary scientists working together to address climate change.

Our new AI4Science organization is focused on applying deep learning to the natural sciences to model and predict natural phenomena and help address critical issues such as climate change, green energy and pharmaceutical discovery. Our project teams, which include a global collective of researchers and engineers, are exploring a new approach to machine learning, generating training data by simulating natural phenomena from fundamental equations rather than using datasets from the internet.

This could enable researchers to understand and predict natural phenomena at scales ranging from quantum to galactic and, in turn, drive breakthroughs such as the discovery of new materials that can remove carbon from the atmosphere, Llorens says.

“At the end of the day, we’re focused on pushing the frontiers in ways that enhance the human experience and positively impact society as a whole,” he says.

“To achieve this, we’ll need to engage as part of the global research community and continually challenge our assumptions about what is possible. That’s what will produce the future advancements we need.”

Our approach to AI infrastructure

With growing confidence in AI and businesses aiming to do more with less, customers are looking for a trusted partner to streamline adoption and rapidly apply intelligence across workloads to improve operations, drive efficiencies and reduce costs. More than a decade ago, we forecast this exponential growth in demand for AI systems and started to build special computing infrastructure to handle it.

Today, Microsoft’s AI platform, Azure AI, offers infrastructure optimized and purposely built for running large AI models that are ushering in a new era of productivity and creativity. Thanks to our investments, we’re able to deliver a wide range of AI-powered products that fit the needs of our customers and also deliver best-in-class performance and scale for the most compute-intensive AI training and inference workloads.

Our unique architecture design combines the fastest graphics processing units, or GPUs, available in the market along with a network architecture that chains together thousands of GPUs to enable AI model training and inference at scale.

“Having thousands of GPUs with high-bandwidth interconnect enables everything else from there,” says Eric Boyd, Microsoft corporate vice president for AI Platform.

Organizations large and small are developing Azure AI solutions because they can achieve more at scale, more easily, with the proper enterprise-level privacy, security and responsible AI protections that Azure offers.

We have committed to building Azure into an AI supercomputer for the world, serving as the foundation of our vision to democratize AI as a platform. Microsoft pushed the frontier of cloud supercomputing technology, announcing our first top-5 supercomputer in 2020, and subsequently constructing multiple AI supercomputing systems at massive scale.

We also fine-tuned our purpose-built, AI-optimized infrastructure capability in partnership with OpenAI to train and deploy OpenAI’s family of models for research advancement and developer production. This infrastructure is now available to all Azure customers.

“When other people come to us, we can literally give them the same style of infrastructure that we used for OpenAI, because that’s now the standard way that we do it,” Boyd says.

Microsoft’s Azure OpenAI Service provides businesses and developers with high-performance AI models, such as GPT-3.5, Codex and DALL∙E 2, at production scale with industry-leading uptime. This is the same production service we use to power AI models in our own products, including GitHub Copilot, Power Platform, and the recently announced Microsoft Designer and AI-powered search in Bing and Edge.

We continue to evolve our AI infrastructure based on feedback and insights from training and serving AI models at scale. Our teams work in lockstep with industry partners on the design of GPUs, networks and datacenters that are optimized for AI workloads.

“Microsoft continues to be on the cutting edge, and customers get to take advantage of all the benefits of that,” says Boyd. “They’re getting the best training infrastructure, the best software, the best networking – all of these things combined give the best experience.”

Our approach to using AI for social good

Microsoft believes AI can help people tackle some of society’s biggest global challenges. Our AI for Good initiative provides funding, technology and expertise to help individuals and nonprofits accelerate progress in fields, such as accessibility, digital literacy and equity, sustainability and climate change, human rights and resilience, health disparities, food insecurity, cybersecurity and others.

“There are problems where AI is uniquely positioned to help, where AI is not just another solution but is the only solution,” says Juan Lavista Ferres, Microsoft’s chief data scientist and the director of the AI for Good Lab.

One such project, for instance, involves mapping all the places where humans live in order to better understand natural disaster risks and guide preparedness efforts. Another includes mapping rooftops of buildings in India, noting the materials the structures are made of to help disaster teams prioritize those that are more likely to fail in certain types of disasters. Yet another is mapping all the renewable energy installations around the world to help show the impact of solar and wind farms.

“A person would spend 400 years looking at satellite imagery and understanding if humans live there or not, but AI can do this in an hour,” Lavista Ferres says. “These AI models make it easier for people to get all the information in one place, and from there the humans can make the necessary decisions.”

Microsoft’s AI for Good Lab is an applied research and data visualization laboratory that harnesses the power of big data and Azure’s cloud technology. Its team of data scientists works with strategic partners and experts from academia, nonprofits and governments to not only help address critical global concerns but also to better measure the progress of efforts underway and to identify gaps where aid might be helpful.

The projects are as varied as the problems and combine Microsoft’s efforts with those of our partners.

For example, the AI for Health program invests in research led by institutions such as Fred Hutchinson Cancer Research Center, IRIS, the Novartis Foundation and Seattle Children’s Research Institute. These efforts are making healthcare more affordable, especially in places where doctors are few and medical needs are great.

Though we see great potential for AI’s assistance to help solve some of the world’s most pressing issues, we also recognize the limitations of the technology. It’s important to work through moral and ethical questions for every project, Lavista Ferres says, especially to make sure the models are getting enough data from enough places and aren’t leaving anyone out — for example, making sure all skin colors are represented for an app that detects skin cancer.

“When you train an AI model, it will be able to generalize from the data you have, but not from the data you don’t have, so any bias can generate problems,” he says. “Having humans in the loop is the key element. We are looking for solutions that can benefit everyone, not just particular cohorts of the population.”"
Microsoft_News,https://blogs.bing.com/search/february-2023/The-new-Bing-Edge-%E2%80%93-Learning-from-our-first-week,,The new Bing & Edge – Learning from our first week,"A little over a week ago, we shared an all new, AI-powered Bing search engine, Edge web browser, and integrated Chat, that we think of as Your Copilot for the Web. It is designed to deliver better search results, more complete answers to your questions, a new chat experience to better discover and refine your search, and the ability to generate content to spark your creativity.



Since we made this available in limited preview, we have been testing with a select set of people in over 169 countries to get real-world feedback to learn, improve, and make this product what we know it can be – which is not a replacement or substitute for the search engine, rather a tool to better understand and make sense of the world.



Here is what we have learned in the first seven days of testing:



First, we have seen increased engagement across traditional search results and with the new features like summarized answers, the new chat experience, and the content creation tools. In particular, feedback on the answers generated by the new Bing has been mostly positive with 71% of you giving the AI-powered answers a “thumbs up.” We’re seeing a healthy engagement on the chat feature with multiple questions asked during a session to discover new information.



Next, we have received good feedback on how to improve. This is expected, as we are grounded in the reality that we need to learn from the real world while we maintain safety and trust. The only way to improve a product like this, where the user experience is so much different than anything anyone has seen before, is to have people like you using the product and doing exactly what you all are doing. We know we must build this in the open with the community; this can’t be done solely in the lab. Your feedback about what you're finding valuable and what you aren't, and what your preferences are for how the product should behave, are so critical at this nascent stage of development.



We would categorize our learnings as follows:

Better Search and Answers. You are giving good marks on the citations and references that underly the answers in Bing. It makes it easier to fact check and it provides a nice starting point to discover more. On the other hand, we are finding our share of challenges with answers that need very timely data like live sports scores. For queries where you are looking for a more direct and factual answers such as numbers from financial reports, we’re planning to 4x increase the grounding data we send to the model. Lastly, we’re considering adding a toggle that gives you more control on the precision vs creativity of the answer to tailor to your query.

Chat. The ease of use and approachability of chat has been an early success. Through your active use, we feel good about the discoverability and design to make it easy to access. There is also a lot of engagement which is delivering value for improving search and answers. One area where we are learning a new use-case for chat is how people are using it as a tool for more general discovery of the world, and for social entertainment. This is a great example of where new technology is finding product-market-fit for something we didn’t fully envision.



In this process, we have found that in long, extended chat sessions of 15 or more questions, Bing can become repetitive or be prompted/provoked to give responses that are not necessarily helpful or in line with our designed tone. We believe this is a function of a couple of things:

Very long chat sessions can confuse the model on what questions it is answering and thus we think we may need to add a tool so you can more easily refresh the context or start from scratch The model at times tries to respond or reflect in the tone in which it is being asked to provide responses that can lead to a style we didn’t intend.This is a non-trivial scenario that requires a lot of prompting so most of you won’t run into it, but we are looking at how to give you more fine-tuned control.

We want to thank those of you that are trying a wide variety of use cases of the new chat experience and really testing the capabilities and limits of the service – there have been a few 2 hour chat sessions for example! - as well as writing and blogging about your experience as it helps us improve the product for everyone.

General fit and finish. Some of you have encountered and reported technical issues or bugs with the new Bing, such as slow loading, broken links, or incorrect formatting. Many of these issues have been addressed with our daily releases and even more will be addressed with our larger releases each week.

New feature requests. Some of you have requested more features and capabilities for the new Bing, such as booking flights or sending email. You’d also like to share great searches/answers. We love your creative ideas and are capturing these for potential inclusion in future releases.

We are thankful for all the feedback you are providing. We are committed to daily improvement and giving you the absolute best search/answer/chat/create experience possible. We intend to provide regular updates on the changes and progress we are making. Please keep the feedback coming."
Microsoft_News,https://www.microsoft.com/en-us/security/blog/2023/02/09/learn-what-an-ai-driven-future-means-for-cybersecurity-at-microsoft-secure/,,Join us at Microsoft Secure to innovate and grow,"Maintaining security across today’s vast digital ecosystem is a team effort. AI and machine learning have helped to detect threats quickly and respond effectively. Yet we all know that the best defense still requires human wisdom and experience. From a frontline security operations admin to the chief information security officer (CISO), every one of us brings a unique perspective that helps achieve our common purpose—to protect what matters.

As the threat surface increases with remote and hybrid work, security professionals are being asked to protect more with less. Tight budgets and timelines often leave little time to share knowledge, grow skills, or nurture the next generation of defenders.

That’s why I’m proud to announce a new annual security event designed to empower our community—join us on March 28, 2023, for Microsoft Secure. Register today.

Security is human-first and tech-driven

I’m continuously awed and humbled by the ingenuity and dedication shown by cyber defenders at every level of our partner and customer ecosystem. The first iteration of Microsoft Secure will kick off an annual event designed to build on that spirit of ingenuity. Technology helps our security professionals do more, and it’s always powered by people­­—the quietly fearless security professionals who make everything possible and the CISOs in boardrooms fielding security questions from colleagues. Microsoft Secure is for you.

Discover the latest comprehensive security innovations designed for you

Microsoft Secure will kick off at 8:30 AM PT with conversations on the state of the industry between Microsoft leaders helping to deliver the products security teams use daily. I have the honor of delivering this year’s keynote, along with Charlie Bell, Executive Vice President, Microsoft Security, and we will share insights on how an AI-powered future in cybersecurity can create a safer world for all—you won’t want to miss this. Other speakers joining me include Joy Chik, President, Identity and Network Access, Microsoft, Bret Arsenault, Corporate Vice President and Chief Information Security Officer, Microsoft, and and John Lambert, Corporate Vice President, Distinguished Engineer, Microsoft Security Research.

Innovation sessions highlighting our latest product updates across security, compliance, identity, management, and privacy will follow our keynotes. And around midday, you can attend breakout sessions, hands-on workshops, and product deep dives organized around four themes:

Discover technology across cloud security, security information and event management and extended detection and response, and threat intelligence enabled by AI. Enable smarter, real-time access decisions for all identities and cloud-managed endpoints. Minimize insider risk and safeguard sensitive information across platforms, app, and clouds. Guard against threats like ransomware with Zero Trust architecture and built-in security.

For more interactive learning, join these live-open discussions and engagement opportunities, including Ask the Experts, Table Topics, and Connection Zone forums. Plus, our team will provide insights and answers to your questions in the event chat in real-time throughout the day.

Join your security community at this new event

Deep dive with your peers into six hours of fresh announcements, innovations, and comprehensive security strategies. By joining our very first Microsoft Secure, you’ll:

Be among the first to see what an AI-powered future means for cybersecurity to help you protect more with less.

to help you protect more with less. Gain insights from industry experts to help you defend today and shape the future of security for tomorrow.

to help you defend today and shape the future of security for tomorrow. Dive into deep technical content in the breakout sessions featuring extended detection and response, multicloud security, cloud-managed endpoints, Zero Trust, built-in security configurations, and more.

featuring extended detection and response, multicloud security, cloud-managed endpoints, Zero Trust, built-in security configurations, and more. Connect with your peers in a live question and answer chat and have your most pressing security questions answered by Microsoft experts.

Join us at Microsoft Secure to get the simplified, comprehensive protection you need to innovate and grow. Together, let’s create a safer world for all.

Register now for Microsoft Secure.

To learn more about Microsoft Security solutions, visit our website. Bookmark the Security blog to keep up with our expert coverage on security matters. Also, follow us on LinkedIn (Microsoft Security) and Twitter (@MSFTSecurity) for the latest news and updates on cybersecurity."
Microsoft_News,https://news.microsoft.com/the-new-Bing/,,"Reinventing search with a new AI-powered Bing and Edge, your copilot for the web","To empower people to unlock the joy of discovery, feel the wonder of creation and better harness the world’s knowledge, today we’re improving how the world benefits from the web by reinventing the tools billions of people use every day, the search engine and the browser.

Today, we’re launching an all new, AI-powered Bing search engine and Edge browser, available in preview now at Bing.com, to deliver better search, more complete answers, a new chat experience and the ability to generate content. We think of these tools as an AI copilot for the web.

Read more"
Microsoft_News,https://www.microsoft.com/en-us/microsoft-365/blog/2023/02/01/microsoft-teams-premium-cut-costs-and-add-ai-powered-productivity/,,Microsoft Teams Premium: Cut costs and add AI-powered productivity,"As we face economic uncertainties and changes to work patterns, organizations are searching for ways to optimize IT investments and re-energize employees to achieve business results. Now—more than ever—organizations need solutions to adapt to change, improve productivity, and reduce costs. Fortunately, modern tools powered by AI hold the promise to boost individual, team, and organizational-level productivity and fundamentally change how we work.

This promise is rapidly becoming a reality. At Microsoft, we’re working to incorporate new, AI-powered capabilities across our consumer and enterprise products, including Microsoft Teams.

As part of this continuous innovation, I’m excited to share that Microsoft Teams Premium is generally available. Built on the familiar, all-in-one collaborative experience of Microsoft Teams, Teams Premium brings the latest technologies, including Large Language Models powered by OpenAI’s GPT, to make meetings more intelligent, personalized, and protected—whether it’s one-on-one, large meetings, virtual appointments, or webinars.1

Do more with less

With more than 400 new features and improvements added to Microsoft Teams last year, and many more to come in 2023, all Teams users can count on continued innovation to deepen connections and foster collaboration. But some customers are looking for Teams to do more—offer more advanced meeting capabilities to increase productivity and help to consolidate their software investments to reduce costs. Today, many organizations not only pay for meeting solutions, but also purchase expensive add-on products for webinars, virtual appointments, meeting intelligence, and more. With Teams Premium, customers can get these advanced meeting capabilities and more for one low cost of USD10 per user per month. And, for a limited time, you can get Teams Premium for just USD7 per user per month or 30 percent off the standard price.2,3,4,5

Microsoft Teams Premium Reduce costs and gain AI-powered productivity with more intelligent, personalized, and protected meetings. Try for free today

Meet better with Teams Premium

Focus on what matters with AI-powered meetings, including GPT from OpenAI

Microsoft Teams Learn more

With a 252 percent increase in weekly time spent in meetings in the first two years of the pandemic, we needed to find ways to “work smarter, not harder.” Both the pace of work and the amount of information needed to sift through have grown exponentially, especially with meetings. There’s a ton of time-consuming administrative work during meetings, like taking notes, figuring out important takeaways, and capturing the right action items and owners.

That’s why Teams is infusing AI throughout the meeting experience, helping you be more productive in new ways. With intelligent recap in Teams Premium, you’ll get automatically generated meeting notes, recommended tasks, and personalized highlights to help you get the information most important to you, even if you miss the meeting.

Figure 1. With intelligent recap, you’ll have the information that’s most important for you after a meeting, all in one place.

With intelligent recap, you can now save time spent reviewing meeting recordings. AI-generated chapters divide the meeting into sections so it’s easy to pick and choose the content most relevant to you. This is available today for PowerPoint Live meeting recordings. Intelligent recap will automatically generate meeting chapters based on the meeting transcript as well.

Figure 2. Available today, you can quickly see relevant PowerPoint Live chapters in the meeting recording.

In addition, there may be particular points in a meeting that you want to revisit. Available today, personalized timeline markers—that only you can see—call out when you joined or left a meeting in the meeting recording, so you can quickly click and listen in on what you missed. Personalized timeline markers will expand to include when your name was mentioned and when a screen was shared.

Figure 3. Today, in the meeting recording, see when you joined or left a meeting—only visible to you—to quickly catch up on what you missed.

Soon, these personalized meeting highlights will expand to include speaker timeline markers that show you who spoke during the meeting, when they spoke, and allows you to jump to that moment. Speaker timeline markers are intelligently organized by who you work most closely with, so you’ll never miss feedback shared from your manager in a meeting again.

With intelligent recap, you can focus on the meeting discussion itself and not on capturing notes. In the coming months, you’ll see key points and takeaways after the meeting, with AI-generated notes automatically created and powered by GPT. Follow-up is easy with AI-generated tasks and action items automatically suggested for you.

AI-generated chapters for PowerPoint Live and personalized timeline markers for when you leave and join a meeting are available today. The additional intelligent recap capabilities shared here will be available in the second quarter of 2023.

AI is also here to help with some of the toughest collaboration challenges—working with people who natively speak different languages. Anyone can turn on live captions in Teams and see real-time captions in the spoken language. But if meeting participants speak different languages, organizations often spend thousands of dollars for additional real-time meeting translation services. With live translations (for captions) now available in Teams Premium, you get AI-powered real-time translations from 40 spoken languages. Meeting participants can read captions in their own language, saving money and making meetings more productive and effortless. Only the meeting organizer needs to have Teams Premium for all meeting attendees to enjoy live translations.

Figure 5. Help reduce language barriers during meetings with live translation for captions.

Personalized: Easily create meetings that suit your needs and your organization’s policies

We’ve heard from many organizations about the need to customize their meetings to provide a best-in-class experience during client calls or create an engaging and inclusive environment within the company. When meeting with clients in person or just connecting with a co-worker, an important part of the experience is embodying the company brand and culture. But with so many interactions and meetings moving to virtual experiences, these key elements aren’t at the forefront. With Teams Premium, you get that extra level of professionalism and personalization. Branded meetings let everyone see the logo and colors of your company when you join the meeting, and allow your brand colors to be infused in the meeting itself. During the meeting, Teams Premium users can enable brand-approved organization backgrounds and organization together mode scenes, so that what makes your company and your people unique will shine through in every part of the meeting. These organization backgrounds and together mode scenes are available now and branded meetings will be available in mid-February 2023.

Figure 6. Infuse your brand in every meeting, including a custom-branded meeting lobby.

Meetings are not “one size fits all.” You wouldn’t go to a coffee shop for a confidential meeting or an auditorium for a one-on-one. When you schedule an online meeting, you just use the default settings because drilling into meeting options takes valuable time out of your day. Now with Teams Premium, IT admins can create customized meeting templates—like a client call, brainstorming meeting, or help desk call— to automatically include the correct settings, reducing the time and thought process it takes to create and get the meeting right. With templates, leaders can ensure that their meetings adhere to company best practices and policies.

Figure 7. Meeting templates, once configured by your IT admin, are easy to use to schedule a new meeting.

Just like meetings are not “one size fits all,” different Teams policies are often assigned based on user groups or departments. For example, your legal department may have a less restrictive meeting or messaging policies, such as working with external users, than outside agency contractors. Assigning meetings, messaging, and app policies individually can be a complex task. But with the now available custom user policy packages, IT can save time by creating a customized bundle of policies for users with similar roles in the organization. It’s a simplified, streamlined time saver that provides consistency when managing policies for groups of users across your organization.

Teams Premium Make every meeting more personalized, intelligent, and protected. Get started today

Protected: Help keep confidential meetings confidential

As meetings have shifted to virtual and hybrid, it has created a new set of information protection challenges for organizations. Sensitive and confidential business conversations like board meetings, financial discussions, or undisclosed product reviews now happen through Teams meetings. While setting up a Teams meeting is a quick and simple process, it’s critical for sensitive meetings to have an added layer of protection to help ensure the content and information remain secure.

With advanced meeting protection available today in Teams Premium, you can easily upgrade safeguards for confidential business meetings without hampering the meeting experience. New meeting options, like watermarking to deter leaks and limiting who can record, give you additional protections to keep the discussion private. Meeting organizers can leverage a unique watermark over attendee screen shares and video feeds to confidently present and display sensitive information. And for those rare, extremely sensitive meetings that require disabling some of the core meeting features for an advanced encryption option, IT-enabled users can apply end-to-end encryption (E2EE) option to the meeting. As a reminder, data exchanged during Teams calls or meetings is always secured using industry-standard encryption in transit and at rest.

Figure 8. Easily watermark content and speakers during a meeting and automatically apply relevant Teams meeting options based on sensitivity labels.

Microsoft 365 E5 Learn more

We know that meetings can often change topics and sometimes that includes discussing business-sensitive information that needs an extra layer of protection. For Microsoft 365 E5 customers with Teams Premium can now enable Microsoft Purview Information Protection sensitivity labels for Teams meetings. Meeting organizers can leverage sensitivity labels to automatically apply the most relevant and important meeting options based on the sensitivity of meeting content. Compliance admins can configure this integration with Teams meetings in the Microsoft Purview compliance portal to determine which meeting options should be enforced if the label is used in a meeting.

Managing and protecting information shared in meetings is now easier with the new capabilities available today in Teams Premium.

Virtual Appointments: Delight clients, streamline appointment management, and measure results

Whether you’re providing mortgage advice, conducting a health visit, or selling to customers, connecting virtually with customers has become a necessity. Now, organizations see the continued opportunity to engage and reach customers conveniently from any location.

With Teams Premium, it’s now easy to connect with customers and manage the end-to-end customer experience with Virtual Appointments in Teams, saving you time and money on additional add-on or point solutions. You can delight customers with a seamless join experience that allows external attendees to join virtual, branded lobby rooms through text messages or email on any device browser—without them having to download an app.

Figure 9. Delight customers right from their mobile device with a seamless experience that includes a virtual, branded lobby and easy pre-appointment chatting capabilities.

Your scheduling administrators are empowered to set up and manage scheduled and on-demand virtual appointments in one location with advanced capabilities like appointment queuing. Your organization can also measure the business value of virtual appointments and drive customer outcomes with department-level or organization-level analytics on customer metrics such as wait times and no-show rates.

Figure 10. Streamline management in a single location with appointment scheduling, queue viewing, and analytics.

Delighting clients, streamlining appointment managing, and measuring results just got easier today with new Virtual Appointments, available now. Read the Tech Community blog to learn more.

Webinars: Host events with seamless registration and customized experiences

Many organizations want an end-to-end solution to host various types of virtual events—whether those events are customer-facing webinars to grow business or online organization-wide trainings—that offer personalized touches for presenters and attendees alike. Teams Premium includes webinars to easily host these events while also saving you time and money—no need for add-on solutions or working across different platforms. Webinars allow presenters to join the virtual green room so that preparation before the webinar is seamless. Presenters have the time and space to connect and do a quick briefing or test run without disturbing attendees. While attendees wait for the event to start, they can engage with the presenters and one another through chat and Q&A.

Figure 11. Connect and prep with the host and other presenters in the virtual green room and engage with attendees through chat and Q&A.

And during the webinar, presenters can more effectively manage what attendees see. These host controls create more professionally produced events and make it easy to create more dynamic engagement for presenters and attendees. Along with this customization, the registration experience will be even better with registration waitlist and manual approval and the ability to customize the registration start and end times for better event management.

Figure 12. Manage the attendee experience so they only see shared content and participants brought on-screen.

To elevate your presentation and deliver more dynamic content, integrate different external media feeds into your webinar using RTMP-in. By leveraging an external encoder and enabling RTMP-in, you’ll be able to live stream a custom RTMP source, whether it be a professionally produced video or high-quality screen sharing, to all attendees in the event.

Figure 13. Stream different media types directly into the presentation with RTMP-in.

To build excitement and drive attendance to your webinars, you can leverage timely reminders with automated reminder emails. These emails will be sent to every confirmed registrant at a configured time you set ahead of the event and will include a custom-branded header, webinar details, and a link to join the event.

Figure 14. Send automated reminder emails to confirmed registrants before events.

These webinar capabilities are available now, with the exception of automated email reminders which will be available in March 2023. Learn more about these new webinar experiences.

Microsoft eCDN: Improve live event experiences

To improve live event experiences within an organization, our Microsoft Enterprise Content Deliver Network (eCDN) is now included in Teams Premium. With Microsoft eCDN, organizations can seamlessly and securely live stream global meetings, all-hands gatherings, and town halls, and distribute company-wide trainings using Teams Live Events. Microsoft eCDN helps reduce the load on the corporate network, helps prevent connectivity failure and poor video quality, and doesn’t require any additional installation on user endpoints and devices.

Get started with Teams Premium today

Expect more from your meeting solution. Reduce costs and gain AI-powered productivity with Microsoft Teams Premium. Give it a try for free for 30 days3 or buy before June 30, 2024, for just USD7 per user per month—30 percent off the standard USD10 pricing.4 Try or buy Teams Premium today.

1GCC is launching March 1, 2023.

2Introductory pricing of USD7 per user per month is available for the entire term of your initial subscription (except for some month-to-month and some 3-year annual billed monthly subscriptions). This offer ends June 30, 2024, and will return to the standard USD10 per user per month price on July 1, 2024, unless otherwise stated. This offer is available worldwide to Commercial (including WW Commercial Public Sector), Non-profit (standard discounting applies), and GCC (GCC launching March 1, 2023). Microsoft reserves the right to cancel, change, or suspend this introductory pricing at any time without notice. Listed pricing may vary due to currency, country, and regional variant factors. Contact your Microsoft sales representative to learn more.

3Your free Microsoft Teams Premium trial will automatically end after 30 days.

4A user must have an existing Microsoft 365 or Office 365 license as a requirement for the Teams Premium add-on. Learn more.

5Learn how to set up Teams Premium with this step-by-step technical guide. Check out the guide."
Microsoft_News,https://news.microsoft.com/apac/features/inside-taiwans-ai-hospital-of-the-future/,,Inside Taiwan’s ‘AI hospital of the future’,"The telltale signs of infection appeared soon after the patient arrived in the emergency room. So doctors at China Medical University Hospital (CMUH) ordered a lab test to identify the culprit.

Three days later, they got their answer: a drug-resistant bacteria. This particular bug had evolved to outfox most antibiotics, even ones used as a last resort. It is a notorious and potentially fatal threat that haunts hospitals worldwide.

But by then the patient was about to be discharged. That’s because an AI model developed by CMUH had already identified the bacteria – in one hour, compared with the 72 hours the standard lab test took. Doctors had prescribed new drugs as a result, and the patient recovered.

That AI model is a key pillar of CMUH’s “intelligent antimicrobial system,” which was deployed into clinical practice last year. Since then, CMUH has seen patient mortality fall by 25%, antibiotic costs by 30% and antibiotic use by 50%. It has helped doctors treat thousands of patients much like the one who left the ER in March.

Since CMUH medical staff started using the AI-powered “intelligent antimicrobial system,” the system has seen patient mortality fall by 25%, antibiotic costs by 30% and antibiotic use by 50%. Photo by Billy H.C. Kwok for Microsoft.

And it is just one example of how CMUH is using AI to create a new era of healthcare, said Dr. Kai-Cheng Hsu, director of CMUH’s Artificial Intelligence Center for Medical Diagnosis.

CMUH has developed and deployed hundreds of AI algorithms, hosted on Microsoft’s Azure cloud platform, that are used every day across the system’s 12 hospitals. The team’s custom-built AI models are helping doctors diagnose diseases like cancer and Parkinson’s. They’re helping ER staff treat stroke and heart attack patients quicker. And they’re helping ease the paperwork load on doctors and nurses.

“The major goals of every AI tool we develop are to save patients’ lives and save doctors’ time,” Hsu said. “Our vision is to be a world-class platform provider for the AI hospital of the future.”

Saving time, saving lives

CMUH has been laying the foundations for that AI hospital for years. In 2015, the system established a center for big data, which could ensure patient data privacy while supplying training fuel for AI algorithms. The AI Center for Medical Diagnosis launched two years later.

CMUH is using AI to create a new era of healthcare, says Dr. Kai-Cheng Hsu (left), director of CMUH’s Artificial Intelligence Center for Medical Diagnosis, and Dr. Jiaxin Yu (right), director of CMUH’s AI Innovation Center. Photo by Billy H.C. Kwok for Microsoft.

Today, 10 different AI clinics operate at CMUH. A cross-disciplinary team of doctors and AI researchers meet monthly to discuss potential new projects and review progress on existing research. Models that are successfully validated and tested are integrated into clinical practice. To date, eight of its AI models have received regulatory approval from Taiwan’s Food and Drug Administration, and eight more have been submitted for review.

All have been developed and deployed using the Azure Machine Learning platform.

“Azure is at the core of our digital healthcare transformation,” said Dr. Jiaxin Yu, director of CMUH’s AI Innovation Center. “The platform lets us quickly develop new AI tools, deploy them into the clinic and improve the daily practice of our physicians.”

The AI models are often incorporated into familiar software doctors use every day. Some are deployed with a literal push of a button. For example, doctors who order an MRI on a knee injury can click a button marked “AI” that predicts the likelihood of a meniscus tear. That instant result can avoid delays for a follow-up appointment and get a patient treated quicker.

Saving time often means saving lives. That is increasingly true when it comes to the rapid identification of deadly, drug-resistant bacteria. The World Health Organization predicts that by 2050, antibiotic resistance will cause more deaths than cancer.

But as the patient with drug-resistant bacteria found, the standard lab method can take up to three days. So CMUH developed a new model. It combined machine learning with a common and much simpler lab technique that identifies molecular fingerprints of different bacterial strains. Data on thousands of clinical samples were used to train the algorithm, which can accurately identify six different types of multi-drug resistant bacteria in one hour, Yu said.

With possible heart attack patients, critical care can be delayed while waiting for a specialist to review an electrocardiogram (ECG), Hsu said. CMUH developed an algorithm that can analyze ECGs, detect the likelihood of a heart attack and send a message to an on-duty specialist for confirmation.

CMUH emergency room staff have used the AI model for two years. It has cut in half the time between when a patient arrives and when they are treated, Hsu said. The algorithm was so successful they decided to partner with a medical device manufacturer to bring it into ambulances as an early warning system.

Chief Technology Director Chiung-Tzu Hsiao, Department of Laboratory Medicine (center), inspects a device on November 24, 2022, in Taichung, Taiwan. Photo by Billy H.C. Kwok for Microsoft.

Fire departments in the cities of Taichung and Nantou have used the system for nearly a year, Hsu said. An ECG can be taken in an ambulance and then uploaded to the cloud, where the AI model can help with a diagnosis and alert medical teams at the hospital to prepare for a heart attack patient. This can cut the time between symptom onset and the start of treatment from two hours down to 10 minutes, he said.

Not all AI models have been as successful, Hsu and Yu said.

CMUH developed an algorithm to predict sepsis, a serious illness triggered by infection. Many patients with sepsis show signs of organ failure. When the AI model was trained, it learned to correlate those symptoms with the illness. But not all patients with organ failure have sepsis. As a result, the model incorrectly flagged some patients with organ failure as having sepsis. To solve the problem, Yu said, the team could train future models with additional labels to help it distinguish cases where organ failure is not caused by infection.

Hsu and Yu noted that doctors have always had to make complex decisions using the data they had. AI is there to help support those decisions by providing deeper insights into data, not to make decisions best left to medical experts.

Based on CMUH’s journey, AI can help improve the care doctors deliver, they said. That is why CMUH hopes to share its AI tools broadly using the Azure platform.

“We want to deploy our AI models to hospitals and clinics around the world, and it is much more efficient and cost-effective to use a cloud platform,” Yu said. “Patient privacy is always a top concern, and a critical reason we chose Azure is because it can ensure the safety of sensitive health data. Azure really reduces the barriers to bringing AI into the hospital.”

Related:

Read CMUH’s peer-reviewed research on using AI to detect heart attacks, spot blocked arteries in the brain and identify drug-resistant microbes.

Top image: Medical staff at China Medical University Hospital in Taichung, Taiwan, are using AI to predict patients’ need for antibiotics and other medicines, some of the hundreds of AI algorithms that are used every day across the system’s 12 hospitals. Photo by Billy H.C. Kwok for Microsoft."
Microsoft_News,https://blogs.microsoft.com/on-the-issues/2023/02/02/responsible-ai-chatgpt-artificial-intelligence/,,Meeting the AI moment: advancing the future through responsible AI,"Early last summer, a small group of senior leaders and responsible AI experts at Microsoft started using technology from OpenAI similar to what the world now knows as ChatGPT. Even for those who had worked closely with the developers of this technology at OpenAI since 2019, the most recent progress seemed remarkable. AI developments we had expected around 2033 would arrive in 2023 instead.

Looking back at the history of our industry, certain watershed years stand out. For example, internet usage exploded with the popularity of the browser in 1995, and smartphone growth accelerated in 2007 with the launch of the iPhone. It’s now likely that 2023 will mark a critical inflection point for artificial intelligence. The opportunities for people are huge. And the responsibilities for those of us who develop this technology are bigger still. We need to use this watershed year not just to launch new AI advances, but to responsibly and effectively address both the promises and perils that lie ahead.

The stakes are high. AI may well represent the most consequential technology advance of our lifetime. And while that’s saying a lot, there’s good reason to say it. Today’s cutting-edge AI is a powerful tool for advancing critical thinking and stimulating creative expression. It makes it possible not only to search for information but to seek answers to questions. It can help people uncover insights amid complex data and processes. It speeds up our ability to express what we learn more quickly. Perhaps most important, it’s going to do all these things better and better in the coming months and years.

I’ve had the opportunity for many months to use not only ChatGPT, but the internal AI services under development inside Microsoft. Every day, I find myself learning new ways to get the most from the technology and, even more important, thinking about the broader dimensions that will come from this new AI era. Questions abound.

For example, what will this change?

Over time, the short answer is almost everything. Because, like no technology before it, these AI advances augment humanity’s ability to think, reason, learn and express ourselves. In effect, the industrial revolution is now coming to knowledge work. And knowledge work is fundamental to everything.

This brings huge opportunities to better the world. AI will improve productivity and stimulate economic growth. It will reduce the drudgery in many jobs and, when used effectively, it will help people be more creative in their work and impactful in their lives. The ability to discover new insights in large data sets will drive new advances in medicine, new frontiers in science, new improvements in business, and new and stronger defenses for cyber and national security.

Will all the changes be good?

While I wish the answer were yes, of course that’s not the case. Like every technology before it, some people, communities and countries will turn this advance into both a tool and a weapon. Some unfortunately will use this technology to exploit the flaws in human nature, deliberately target people with false information, undermine democracy and explore new ways to advance the pursuit of evil. New technologies unfortunately typically bring out both the best and worst in people.

Perhaps more than anything, this creates a profound sense of responsibility. At one level, for all of us; and, at an even higher level, for those of us involved in the development and deployment of the technology itself.

There are days when I’m optimistic and moments when I’m pessimistic about how humanity will put AI to use. More than anything, we all need to be determined. We must enter this new era with enthusiasm for the promise, and yet with our eyes wide open and resolute in addressing the inevitable pitfalls that also lie ahead.

The good news is that we’re not starting from scratch.

At Microsoft, we’ve been working to build a responsible AI infrastructure since 2017. This has moved in tandem with similar work in the cybersecurity, privacy and digital safety spaces. It is connected to a larger enterprise risk management framework that has helped us to create the principles, policies, processes, tools and governance systems for responsible AI. Along the way, we have worked and learned together with the equally committed responsible AI experts at OpenAI.

Now we must recommit ourselves to this responsibility and call upon the past six years of work to do even more and move even faster. At both Microsoft and OpenAI, we recognize that the technology will keep evolving, and we are both committed to ongoing engagement and improvement.

The foundation for responsible AI

For six years, Microsoft has invested in a cross-company program to ensure that our AI systems are responsible by design. In 2017, we launched the Aether Committee with researchers, engineers and policy experts to focus on responsible AI issues and help craft the AI principles that we adopted in 2018. In 2019, we created the Office of Responsible AI to coordinate responsible AI governance and launched the first version of our Responsible AI Standard, a framework for translating our high-level principles into actionable guidance for our engineering teams. In 2021, we described the key building blocks to operationalize this program, including an expanded governance structure, training to equip our employees with new skills, and processes and tooling to support implementation. And, in 2022, we strengthened our Responsible AI Standard and took it to its second version. This sets out how we will build AI systems using practical approaches for identifying, measuring and mitigating harms ahead of time, and ensuring that controls are engineered into our systems from the outset.

Our learning from the design and implementation of our responsible AI program has been constant and critical. One of the first things we did in the summer of 2022 was to engage a multidisciplinary team to work with OpenAI, build on their existing research and assess how the latest technology would work without any additional safeguards applied to it. As with all AI systems, it’s important to approach product-building efforts with an initial baseline that provides a deep understanding of not just a technology’s capabilities, but its limitations. Together, we identified some well-known risks, such as the ability of a model to generate content that perpetuated stereotypes, as well as the technology’s capacity to fabricate convincing, yet factually incorrect, responses. As with any facet of life, the first key to solving a problem is to understand it.

With the benefit of these early insights, the experts in our responsible AI ecosystem took additional steps. Our researchers, policy experts and engineering teams joined forces to study the potential harms of the technology, build bespoke measurement pipelines and iterate on effective mitigation strategies. Much of this work was without precedent and some of it challenged our existing thinking. At both Microsoft and OpenAI, people made rapid progress. It reinforced to me the depth and breadth of expertise needed to advance the state-of-the-art on responsible AI, as well as the growing need for new norms, standards and laws.

Building upon this foundation

As we look to the future, we will do even more. As AI models continue to advance, we know we will need to address new and open research questions, close measurement gaps and design new practices, patterns and tools. We’ll approach the road ahead with humility and a commitment to listening, learning and improving every day.

But our own efforts and those of other like-minded organizations won’t be enough. This transformative moment for AI calls for a wider lens on the impacts of the technology – both positive and negative – and a much broader dialogue among stakeholders. We need to have wide-ranging and deep conversations and commit to joint action to define the guardrails for the future.

We believe we should focus on three key goals.

First, we must ensure that AI is built and used responsibly and ethically. History teaches us that transformative technologies like AI require new rules of the road. Proactive, self-regulatory efforts by responsible companies will help pave the way for these new laws, but we know that not all organizations will adopt responsible practices voluntarily. Countries and communities will need to use democratic law-making processes to engage in whole-of-society conversations about where the lines should be drawn to ensure that people have protection under the law. In our view, effective AI regulations should center on the highest risk applications and be outcomes-focused and durable in the face of rapidly advancing technologies and changing societal expectations. To spread the benefits of AI as broadly as possible, regulatory approaches around the globe will need to be interoperable and adaptive, just like AI itself.

Second, we must ensure that AI advances international competitiveness and national security. While we may wish it were otherwise, we need to acknowledge that we live in a fragmented world where technological superiority is core to international competitiveness and national security. AI is the next frontier of that competition. With the combination of OpenAI and Microsoft, and DeepMind within Google, the United States is well placed to maintain technological leadership. Others are already investing, and we should look to expand that footing among other nations committed to democratic values. But it’s also important to recognize that the third leading player in this next wave of AI is the Beijing Academy of Artificial Intelligence. And, just last week, China’s Baidu committed itself to an AI leadership role. The United States and democratic societies more broadly will need multiple and strong technology leaders to help advance AI, with broader public policy leadership on topics including data, AI supercomputing infrastructure and talent.

Third, we must ensure that AI serves society broadly, not narrowly. History has also shown that significant technological advances can outpace the ability of people and institutions to adapt. We need new initiatives to keep pace, so that workers can be empowered by AI, students can achieve better educational outcomes and individuals and organizations can enjoy fair and inclusive economic growth. Our most vulnerable groups, including children, will need more support than ever to thrive in an AI-powered world, and we must ensure that this next wave of technological innovation enhances people’s mental health and well-being, instead of gradually eroding it. Finally, AI must serve people and the planet. AI can play a pivotal role in helping address the climate crisis, including by analyzing environmental outcomes and advancing the development of clean energy technology while also accelerating the transition to clean electricity.

To meet this moment, we will expand our public policy efforts to support these goals. We are committed to forming new and deeper partnerships with civil society, academia, governments and industry. Working together, we all need to gain a more complete understanding of the concerns that must be addressed and the solutions that are likely to be the most promising. Now is the time to partner on the rules of the road for AI.

Finally, as I’ve found myself thinking about these issues in recent months, time and again my mind has returned to a few connecting thoughts.

First, these issues are too important to be left to technologists alone. And, equally, there’s no way to anticipate, much less address, these advances without involving tech companies in the process. More than ever, this work will require a big tent.

Second, the future of artificial intelligence requires a multidisciplinary approach. The tech sector was built by engineers. However, if AI is truly going to serve humanity, the future requires that we bring together computer and data scientists with people from every walk of life and every way of thinking. More than ever, technology needs people schooled in the humanities, social sciences and with more than an average dose of common sense.

Finally, and perhaps most important, humility will serve us better than self-confidence. There will be no shortage of people with opinions and predictions. Many will be worth considering. But I’ve often found myself thinking mostly about my favorite quotation from Walt Whitman – or Ted Lasso, depending on your preference.

“Be curious, not judgmental.”

We’re entering a new era. We need to learn together.

Tags: AI, artificial intelligence, ChatGPT, OpenAI, Responsible AI"
Microsoft_News,https://cloudblogs.microsoft.com/dynamics365/bdm/2023/02/02/microsoft-boosts-viva-sales-with-new-gpt-seller-experience/,,Microsoft boosts Viva Sales with new GPT seller experience,"Update on 7/18/2023: Viva Sales is now Microsoft Sales Copilot.

For sales teams, the adage “time is money” is more relevant than ever before. Time wasted on low-value tasks literally leaves opportunities to sell and engage prospects on the table. At Microsoft, we want to use AI to help sellers focus time on what matters most—making meaningful connections, building trust, and creating long-term relationships.

That’s why I’m thrilled to announce the preview of a new generative AI-powered experience in Microsoft Viva Sales that helps sellers communicate more effectively with prospects and customers.

Viva Sales will now generate suggested email content for a variety of scenarios—such as replying to an inquiry or creating a proposal—complete with data specifically relevant to the recipient, such as pricing, promotions, and deadlines. By auto-suggesting customizable content, sellers can spend less time composing emails and searching for sales data from colleagues and databases. Why is this important? According to new research commissioned by Microsoft, managing email consumes over 66 percent of a seller’s day.1 This new AI-powered capability helps sellers recapture this valuable time, empowering them to focus time on what matters most.

Microsoft Viva Sales Through monthly product updates, we're rapidly adding new innovations to Viva Sales. Try it out today

Leveraging the power of Azure OpenAI Service and GPT, Viva Sales provides access to rich, people-centric data and insights in the Microsoft Cloud. Viva Sales can remind sellers when it’s time to follow up with a prospect or customer and then auto-generate a preformatted email response with personalized text and next best actions, along with details such as product descriptions, proposals, and deadlines. When responding to an email, Viva Sales provides sellers in-the-moment suggested responses based upon categories such as “make a proposal”, “reply to an inquiry,” or “suggest your own”. The seller simply selects the option to suit their needs and a reply is generated for the seller to review, edit to their liking, and send. The reply is enriched with the combined data from Microsoft Graph—which provides access to people-centric data and insights in the Microsoft Cloud, including Microsoft 365, Windows, and Microsoft Enterprise Mobility + Security, and the customer relationship management (CRM) system (Microsoft Dynamics 365 or Salesforce®). This allows sellers to improve their overall communication and deliver a superior customer experience—all in the flow of work.

Figure 1: Scenarios for auto-generated responses

Figure 2: Examples of auto-generated responses

These new GPT capabilities strengthen our existing capabilities of Conversation intelligence, which leverages state-of-the-art natural language technology to automatically generate a call summary, detect questions, calculate conversational key performance indicators (KPIs), extract action items, and more. With the addition of auto-suggested email content, sellers can free up even more time to focus on priorities.

Watch the Viva Sales generative AI demo below.

Viva Sales generative AI demo

Responsible AI

We are committed to creating responsible AI by design. Our work is guided by a core set of principles: fairness, reliability and safety, privacy and security, inclusiveness, transparency, and accountability. We are putting those principles into practice across the company to develop and deploy AI that will have a positive impact on society. We take a cross-company approach through cutting-edge research, best-of-breed engineering systems, and excellence in policy and governance. Alongside OpenAI’s leading research on AI alignment, we are advancing a framework for the safe deployment of our own AI technologies that are aimed to help guide the industry toward more responsible outcomes.

Learn more about Viva Sales

Viva Sales launched in general availability in October 2022, and the response from our customers has been amazing. We are rapidly adding new innovations to Viva Sales through our monthly product updates. To learn more and get started today, visit the Viva Sales webpage and to stay informed of upcoming updates, read the monthly update blog.

1Sales Teams Need a Transformation, Microsoft is Ready to Deliver, Futurum."
Microsoft_News,https://blogs.microsoft.com/on-the-issues/2023/02/02/responsible-ai-chatgpt-artificial-intelligence/,,Meeting the AI moment: advancing the future through responsible AI,"Early last summer, a small group of senior leaders and responsible AI experts at Microsoft started using technology from OpenAI similar to what the world now knows as ChatGPT. Even for those who had worked closely with the developers of this technology at OpenAI since 2019, the most recent progress seemed remarkable. AI developments we had expected around 2033 would arrive in 2023 instead.

Looking back at the history of our industry, certain watershed years stand out. For example, internet usage exploded with the popularity of the browser in 1995, and smartphone growth accelerated in 2007 with the launch of the iPhone. It’s now likely that 2023 will mark a critical inflection point for artificial intelligence. The opportunities for people are huge. And the responsibilities for those of us who develop this technology are bigger still. We need to use this watershed year not just to launch new AI advances, but to responsibly and effectively address both the promises and perils that lie ahead.

The stakes are high. AI may well represent the most consequential technology advance of our lifetime. And while that’s saying a lot, there’s good reason to say it. Today’s cutting-edge AI is a powerful tool for advancing critical thinking and stimulating creative expression. It makes it possible not only to search for information but to seek answers to questions. It can help people uncover insights amid complex data and processes. It speeds up our ability to express what we learn more quickly. Perhaps most important, it’s going to do all these things better and better in the coming months and years.

I’ve had the opportunity for many months to use not only ChatGPT, but the internal AI services under development inside Microsoft. Every day, I find myself learning new ways to get the most from the technology and, even more important, thinking about the broader dimensions that will come from this new AI era. Questions abound.

For example, what will this change?

Over time, the short answer is almost everything. Because, like no technology before it, these AI advances augment humanity’s ability to think, reason, learn and express ourselves. In effect, the industrial revolution is now coming to knowledge work. And knowledge work is fundamental to everything.

This brings huge opportunities to better the world. AI will improve productivity and stimulate economic growth. It will reduce the drudgery in many jobs and, when used effectively, it will help people be more creative in their work and impactful in their lives. The ability to discover new insights in large data sets will drive new advances in medicine, new frontiers in science, new improvements in business, and new and stronger defenses for cyber and national security.

Will all the changes be good?

While I wish the answer were yes, of course that’s not the case. Like every technology before it, some people, communities and countries will turn this advance into both a tool and a weapon. Some unfortunately will use this technology to exploit the flaws in human nature, deliberately target people with false information, undermine democracy and explore new ways to advance the pursuit of evil. New technologies unfortunately typically bring out both the best and worst in people.

Perhaps more than anything, this creates a profound sense of responsibility. At one level, for all of us; and, at an even higher level, for those of us involved in the development and deployment of the technology itself.

There are days when I’m optimistic and moments when I’m pessimistic about how humanity will put AI to use. More than anything, we all need to be determined. We must enter this new era with enthusiasm for the promise, and yet with our eyes wide open and resolute in addressing the inevitable pitfalls that also lie ahead.

The good news is that we’re not starting from scratch.

At Microsoft, we’ve been working to build a responsible AI infrastructure since 2017. This has moved in tandem with similar work in the cybersecurity, privacy and digital safety spaces. It is connected to a larger enterprise risk management framework that has helped us to create the principles, policies, processes, tools and governance systems for responsible AI. Along the way, we have worked and learned together with the equally committed responsible AI experts at OpenAI.

Now we must recommit ourselves to this responsibility and call upon the past six years of work to do even more and move even faster. At both Microsoft and OpenAI, we recognize that the technology will keep evolving, and we are both committed to ongoing engagement and improvement.

The foundation for responsible AI

For six years, Microsoft has invested in a cross-company program to ensure that our AI systems are responsible by design. In 2017, we launched the Aether Committee with researchers, engineers and policy experts to focus on responsible AI issues and help craft the AI principles that we adopted in 2018. In 2019, we created the Office of Responsible AI to coordinate responsible AI governance and launched the first version of our Responsible AI Standard, a framework for translating our high-level principles into actionable guidance for our engineering teams. In 2021, we described the key building blocks to operationalize this program, including an expanded governance structure, training to equip our employees with new skills, and processes and tooling to support implementation. And, in 2022, we strengthened our Responsible AI Standard and took it to its second version. This sets out how we will build AI systems using practical approaches for identifying, measuring and mitigating harms ahead of time, and ensuring that controls are engineered into our systems from the outset.

Our learning from the design and implementation of our responsible AI program has been constant and critical. One of the first things we did in the summer of 2022 was to engage a multidisciplinary team to work with OpenAI, build on their existing research and assess how the latest technology would work without any additional safeguards applied to it. As with all AI systems, it’s important to approach product-building efforts with an initial baseline that provides a deep understanding of not just a technology’s capabilities, but its limitations. Together, we identified some well-known risks, such as the ability of a model to generate content that perpetuated stereotypes, as well as the technology’s capacity to fabricate convincing, yet factually incorrect, responses. As with any facet of life, the first key to solving a problem is to understand it.

With the benefit of these early insights, the experts in our responsible AI ecosystem took additional steps. Our researchers, policy experts and engineering teams joined forces to study the potential harms of the technology, build bespoke measurement pipelines and iterate on effective mitigation strategies. Much of this work was without precedent and some of it challenged our existing thinking. At both Microsoft and OpenAI, people made rapid progress. It reinforced to me the depth and breadth of expertise needed to advance the state-of-the-art on responsible AI, as well as the growing need for new norms, standards and laws.

Building upon this foundation

As we look to the future, we will do even more. As AI models continue to advance, we know we will need to address new and open research questions, close measurement gaps and design new practices, patterns and tools. We’ll approach the road ahead with humility and a commitment to listening, learning and improving every day.

But our own efforts and those of other like-minded organizations won’t be enough. This transformative moment for AI calls for a wider lens on the impacts of the technology – both positive and negative – and a much broader dialogue among stakeholders. We need to have wide-ranging and deep conversations and commit to joint action to define the guardrails for the future.

We believe we should focus on three key goals.

First, we must ensure that AI is built and used responsibly and ethically. History teaches us that transformative technologies like AI require new rules of the road. Proactive, self-regulatory efforts by responsible companies will help pave the way for these new laws, but we know that not all organizations will adopt responsible practices voluntarily. Countries and communities will need to use democratic law-making processes to engage in whole-of-society conversations about where the lines should be drawn to ensure that people have protection under the law. In our view, effective AI regulations should center on the highest risk applications and be outcomes-focused and durable in the face of rapidly advancing technologies and changing societal expectations. To spread the benefits of AI as broadly as possible, regulatory approaches around the globe will need to be interoperable and adaptive, just like AI itself.

Second, we must ensure that AI advances international competitiveness and national security. While we may wish it were otherwise, we need to acknowledge that we live in a fragmented world where technological superiority is core to international competitiveness and national security. AI is the next frontier of that competition. With the combination of OpenAI and Microsoft, and DeepMind within Google, the United States is well placed to maintain technological leadership. Others are already investing, and we should look to expand that footing among other nations committed to democratic values. But it’s also important to recognize that the third leading player in this next wave of AI is the Beijing Academy of Artificial Intelligence. And, just last week, China’s Baidu committed itself to an AI leadership role. The United States and democratic societies more broadly will need multiple and strong technology leaders to help advance AI, with broader public policy leadership on topics including data, AI supercomputing infrastructure and talent.

Third, we must ensure that AI serves society broadly, not narrowly. History has also shown that significant technological advances can outpace the ability of people and institutions to adapt. We need new initiatives to keep pace, so that workers can be empowered by AI, students can achieve better educational outcomes and individuals and organizations can enjoy fair and inclusive economic growth. Our most vulnerable groups, including children, will need more support than ever to thrive in an AI-powered world, and we must ensure that this next wave of technological innovation enhances people’s mental health and well-being, instead of gradually eroding it. Finally, AI must serve people and the planet. AI can play a pivotal role in helping address the climate crisis, including by analyzing environmental outcomes and advancing the development of clean energy technology while also accelerating the transition to clean electricity.

To meet this moment, we will expand our public policy efforts to support these goals. We are committed to forming new and deeper partnerships with civil society, academia, governments and industry. Working together, we all need to gain a more complete understanding of the concerns that must be addressed and the solutions that are likely to be the most promising. Now is the time to partner on the rules of the road for AI.

Finally, as I’ve found myself thinking about these issues in recent months, time and again my mind has returned to a few connecting thoughts.

First, these issues are too important to be left to technologists alone. And, equally, there’s no way to anticipate, much less address, these advances without involving tech companies in the process. More than ever, this work will require a big tent.

Second, the future of artificial intelligence requires a multidisciplinary approach. The tech sector was built by engineers. However, if AI is truly going to serve humanity, the future requires that we bring together computer and data scientists with people from every walk of life and every way of thinking. More than ever, technology needs people schooled in the humanities, social sciences and with more than an average dose of common sense.

Finally, and perhaps most important, humility will serve us better than self-confidence. There will be no shortage of people with opinions and predictions. Many will be worth considering. But I’ve often found myself thinking mostly about my favorite quotation from Walt Whitman – or Ted Lasso, depending on your preference.

“Be curious, not judgmental.”

We’re entering a new era. We need to learn together.

Tags: AI, artificial intelligence, ChatGPT, OpenAI, Responsible AI"
Microsoft_News,https://news.microsoft.com/en-in/features/microsoft-research-project-helps-languages-survive-and-thrive/,,Microsoft Research project helps languages survive — and thrive,"A woman named Boa Sr was the last link to a 65,000-year-old pre-Neolithic culture on the Andaman Islands in the Indian Ocean. When she died in 2010, the Bo language died, too, becoming extinct.

If that sounds like an isolated incident, it isn’t. Every two weeks, a language is lost somewhere in the world.

Take the Mundas, a community of about a million people spread across the eastern Indian states of Jharkhand, Orissa and West Bengal.

“I learnt Mundari very late in life as my parents lived in another state where they were working, so we didn’t speak the language at home,” says Dr. Meenakshi Munda, a member of the Munda community and an assistant professor in the anthropology department at a university in Ranchi, Jharkhand. “I understand how identity matters for a community and our younger generation is losing its identity because they don’t know their language.”

The Munda community is concerned about the longevity of their language as only prominent languages like Bengali, Hindi and Odiya are taught to kids in schools.

While there’s a written script for Mundari, it has negligible digital content or presence online, giving even fewer incentives for people to invest in learning the language."
Microsoft_News,https://news.microsoft.com/apac/features/microsoft-university-researchers-use-ai-to-aid-in-study-of-ancient-script-on-chinas-oracle-bones/,,"Microsoft, university researchers use AI to aid in study of ancient script on China’s ‘oracle bones’","Since farmers began digging up ancient bone fragments in the fields around the Yellow River in eastern China over 100 years ago, researchers have been poring over the mysterious script found on them.

The script on the “oracle bones,” so called because they were used to try to divine the future, is the earliest known form of Chinese writing, dating back 3,000 years. But their study has been challenging: the bones are fragile and fragmented, copies of the script made by ink rubbings can be blurry or incomplete and collections are scattered in national museums and private collections in China and around the world.

Now researchers in Beijing are using AI to fast-track the basic but necessary work of comparing each script sample with thousands of others in databases. This work paves the way for researchers to decipher them and shed light on everything from the daily concerns of people in ancient times to how Chinese writing first developed.

“This is a great example of human-machine collaboration,” said Bofeng Mo, a professor from the Center for Oracle Bone Studies at Capital Normal University, who worked on the project with Zhirong Wu, a senior researcher at Microsoft Research Asia.

Bofeng Mo and Zhirong Wu collaborated to develop an AI model to study the script on oracle bones. Photo by Gilles Sabrie for Microsoft.

Oracle bone inscriptions have been recognized by UNESCO’s International Memory of the World Register as a valuable record of the Shang people from 1400 B.C. to 1100 B.C., in addition to being the earliest evidence of a Chinese writing system. In China, every kid learns about the oracle bones in school.

Most of the bones were excavated around Anyang City in Henan Province, about 500 kilometers (about 310 miles) southwest of Beijing. They were usually the scapula, or shoulder blades, of oxen or the belly shells of turtles – both of which offer a flat surface for the script. During the Shang Dynasty, a bronze-age civilization, someone would heat the bones until they cracked. The pattern of the cracks would offer guidance on matters around praying, royal and military affairs, the weather, harvests and so on.

Since 1899, about 150,000 pieces have been unearthed and are now housed in more than 100 institutes around the world, according to experts behind the UNESCO nomination. The biggest collections are in the National Library of China, the Palace Museum and other Chinese institutions though oracle bones collections are found as far away as the Royal Scottish Museum and the Royal Ontario Museum in Canada.

The markings have both pictograph and text elements. With no equivalent of a Rosetta Stone as a guide, scientists have only deciphered about 1,000 of the approximately 4,000 characters identified.

Before the Diviner Project, studying oracle bones script was an arduous, manual process. Photo by Gilles Sabrie for Microsoft.

Up until now script study has been painstakingly laborious. The earliest copies of oracle bone script were made by Chinese ink rubbings and, more recently, photographs and 3D imaging technology. Researchers had to manually compare each image to find duplicates or overlaps, with the goal of stitching together fragments – like a jigsaw puzzle – into a more complete whole for study.

“Since a piece of oracle bone may have been recorded several times with different levels of clarity and integrity, a lot of work is need to relate, compare and interpret them,” Yubin Jiang, a researcher at the Research Center for Unearthed Documents and Ancient Characters at Fudan University, told Microsoft. “In the past, this burden fell solely on the shoulders of scholars with rich experience and sharp memory, but their research only led to random findings.”

“Diviner has managed to complete wide-ranging duplication detection in a highly efficient, fruitful and exciting way,” he added.

Wu, the researcher at Microsoft, focuses on the nascent field of self-supervised learning, a type of machine learning that does not rely on people to do manual labeling of data. He approached Mo about a year ago after hearing that the professor was experimenting with AI to study script. At the time, Mo was using off-the-shelf image recognition software, which only allowed a few images to be uploaded each time and required a user to pick one as a reference image.

“We developed the technology to train the Diviner model from scratch,” said Wu.

The Diviner Project uses AI to sift through thousands of images to match patches of script like a jigsaw puzzle. Courtesy of Microsoft.

Wu said he and one other team member took eight to nine months to build the model. In November 2022, in the space of one week, the Diviner Project compared 181,134 pieces of inscription rubbings across 100 databases. It not only reproduced tens of thousands of previously identified duplicates found by people but also found more than 300 new pairs.

After Wu and Mo shared the results on the website of the Pre-Qin Research Office at the Chinese Academy of Social Sciences, which has its own substantial collection of oracle bones, researchers at other institutions have reached out to them for help, said Wu. The project was also featured in a special oracle bones episode on national broadcaster CCTV on January 2, 2023.

This is just the first step.

“The current project is to clean the data and recover the data to the original form by joining small fragments to the original big one,” said Wu. “With this, we hope we can move on to the final challenge – deciphering the meaning of these characters.”

Those findings could have implications for different fields.

“To archaeologists, they are the cultural remains of humans. To historians, they are the historical material of the Shang Dynasty. To linguists, they are the earliest systemic Chinese characters,” said Mo. Moreover, “records of solar eclipses, lunar eclipses and meteor showers found in oracle bone inscriptions can be merged with astronomy.”

Top image: Zhirong Wu of Microsoft Research Asia uses AI to study ancient Chinese script on oracle bones. Photo by Gilles Sabrie for Microsoft."
Microsoft_News,https://startups.microsoft.com/blog/azure-openai-service-for-startups/,,Azure OpenAI Service powers the next generation of startups,"Microsoft for Startups Founders Hub brings people, knowledge and benefits together to help founders at every stage solve startup challenges. Sign up in minutes with no funding required.

Large-scale, generative AI models have been fueling the next wave of startups and applications, leveraging APIs with deep understandings of language and code to enable new comprehensive scenarios and cutting-edge solutions.

Members of the Microsoft for Startups Founders Hub can access free credits to OpenAI APIs, and the launch of Azure OpenAI Service has presented even more opportunities for startups in our portfolio to take advantage of the OpenAI offerings under the Microsoft umbrella and build using the next generation of AI services.

Read on to better understand what Azure OpenAI Service is and how to leverage it.

What is Azure OpenAI Service?

Azure OpenAI Service is an Azure AI service that allows access to OpenAI GPT-4 (waitlist only), GPT-3, Codex, and DALL-E models with the security and enterprise promise of Azure. These models can be adapted to tasks such as content generation, summarization, semantic search, and natural language to code translation.

ChatGPT and GPT-4: These are both conversation in, message-out models designed for conversational interfaces as well as non-chat scenarios. You can use these models to perform specific actions like tax advisory through a few-shot learning , or ground these models on your relevant data for specialized outputs, like searching through your internal documentation.

Codex is an AI system that translates natural language to code. Startups can use Codex to generate natural-language descriptions of code examples, generate code snippets and more.

DALL-E is a generative model, generating images from text prompts. Startups can use this to create brand images, artwork based on prompts or even end-to-end design studios customized to user’s prompts.

Users can access Azure OpenAI Service through REST APIs, Python SDK, or the web-based interface in the Azure OpenAI Studio. Microsoft co-develops the APIs with OpenAI, ensuring compatibility and a smooth transition from one to the other.

Azure OpenAI Service also allows developers to discover the art-of-the-possible with cutting-edge models from OpenAI that provide the security capabilities of Microsoft Azure while running the same models as OpenAI. Azure OpenAI Service offers private networking, regional availability, and responsible AI content filtering.

How’s this different from the OpenAI API benefit on Microsoft for Startups Founders Hub?

Free credits to Azure OpenAI Service APIs are directly available as a benefit in Microsoft for Startups Founders Hub and as a service via Azure. Azure OpenAI Service gets you access to the APIs along with 99.9% uptime, built-in content filtering, enterprise-grade security, privacy controls, and regional availability as an enterprise-class service.

How can Microsoft for Startups portfolio companies access Azure OpenAI Service?

we currently limit the access and use of Azure OpenAI, including limiting access to the ability to modify content filters and/or abuse monitoring. Startups may use Azure credits for access, but the amount of credits needed will depend on how much you use the service.

Startups in Microsoft for Startups Founders Hub must apply for access for their specific use case. You’re encouraged to apply under the most fitting review criteria for your stage. Once approved for use, customers can login to the Azure portal to create an Azure OpenAI Service resource and get started either in our Studio website or via code. You can read and learn more via our documentation. Reach out to the Founders Hub Support Center for more guidance.

Watch this space as we roll out future developments for the Microsoft for Startups Founders Hub.

Not yet joined Microsoft for Startups Founders Hub? Sign up today to get credits for OpenAI APIs, technical advisory, up to $150,000 in Azure credits, access to Microsoft startup experts and mentors, and so much more.

Tags: AI, Azure OpenAI, Azure OpenAI Service, GPT-3, LaunchWithAI, OpenAI, OpenAI Codex"
Microsoft_News,https://create.microsoft.com/en-us/learn/articles/how-to-image-prompts-dall-e-ai,,How to use AI image prompts to generate art using DALL‑E,"How to use AI image prompts to generate art using DALL‑E

Thanks to the magic of DALL‑E artificial intelligence (now in its third generation as DALL‑E 3), Microsoft Designer now lets anyone generate totally unique images that have never been seen before, simply by writing a clear AI image prompt—just type what you want to see!

Like any new technology, DALL‑E makes all kinds of exciting new things possible, but it also takes a little bit of experimentation to get the best results.

Note: These tips for creating AI-generated art apply to both Microsoft Designer and the DALL‑E site. The benefit of using Designer is that it is also a graphic design app, so you’ll not only get unique images generated from the ideas you type, but you also can add more design elements like text or graphics and AI-powered editing experiences that will perfectly integrate it all into a design. We even have a treasure trove of Microsoft Designer templates, Pinterest templates, and other social media templates to get you started.

How to create an image with DALL‑E and Microsoft Designer

Using DALL‑E to generate images may seem deceptively simple. It's actually just simple—no deception detected. Here's how to get started:

Option A: Generate a complete design

This option lets you create a complete AI-generated design, not just an image—so you'll also be including details like your intended design's format (example: A Facebook post) and purpose (Example: Advertise a sale on lighting fixtures).

1. Go to Microsoft Designer's Image Creator.

2. In the text box labeled ""Describe the design you want to create,"" enter a phrase that describes the design you want to create. Hit try for free, then pick the design that matches your vision most closely—you can edit your work from here. If you're not satisfied with any of the design options, return to the previous screen and refine your prompt.

Option B: Generate a stand-alone image

This is the option we'll be focusing on today: Generating unique, high-quality DALL-E images. To do this from Designer:

1. Navigate directly to Microsoft Designer's image creator.

2. Designer's image generator defaults to a prompt box you can fill in to have Designer create the prompt for you. Use this option if you're coming up short on prompt ideas!

If you'd rather write your prompt from scratch, select Edit entire prompt on the bottom of the prompt box. From there, you can delete the default prompt and add your own.

What kind of images can you generate? Anything!

DALL-E's image capabilities range from simple icons and patterns to illustrations, artwork, and even photorealistic images and depictions of 3D objects.

For the purposes of this article, let's imagine we're generating materials to promote our running club.

Let's type in ""an adorable character running, ink-and-watercolor illustration, colorful background"" and see what we get:

Not bad for our first try, right?

Note: All of the prompts we share today will be linked to the same prompt within Designer's image creator. Follow the link to try the prompt for yourself and see what your results look like!

How to write the most effective AI image prompt for DALL‑E

Since you get out of it what you put into it, how do you write a good prompt for DALL‑E? In short, it's best to imagine your image already exists in some kind of online gallery, and then write the kind of short caption you might imagine appearing with it.

Be specific

If you enter just a single word—like ""runner,"" for example—you could end up with anything from a photo of an elite athlete winning a marathon to a cute pencil sketch of a child running through a meadow—or, as you see in the example above, even a made-up creature! Rather than using a single word, use a phrase to describe what you're looking for. Here are a few suggestions for additional details to include in your search phrases:

A few specific details about the object or character

Info about the setting or background to use for the image

The medium style in which it's depicted, such as oil painting, digital photo, or even marble statue

Other adjectives, such as ""colorful,"" ""swirling,"" ""playful,"" ""happy,"" ""minimalist,"" ""geometric,"" ""vibrant,"" ""dramatic,"" ""ornate,"" ""austere,"" etc.—anything that could help build your desired aesthetic

Add directive details

Rather than just specifying the medium style as ""oil painting,"" you could describe it as ""oil-on-canvas, masterpiece by Caravaggio, from 1599."" Or rather than ""photograph,"" you could request ""HD photograph, digital camera, studio lighting, large-format portrait on film.""

Including these extra details in your image prompts help the AI technology hone in on the type of image you mean, even if it doesn't always get it exactly right.

Avoid these pitfalls

There are a few limits to AI generation, so some types of image prompts are less likely to achieve the desired effect. A few things to avoid in descriptions are:

Complex scenes with multiple subjects

Detailed layout requests (for example, ""A big red Object X on the left, friendly Object Y on the right, a small Object Z wearing Item A above them"")

Images with multiple faces (these are often distorted)

Requests for text (for example, ""a sign saying 'Happy birthday!'""), because the generator doesn't know how to spell!

Why use AI to generate an image?

With so many existing images available, why try generating your own image using DALL‑E?

To create an original image

You're guaranteed an image that's never been seen or used before—the chance to show something truly unique to you or your brand!

To let your imagination run wild

Combine all kinds of subjects, settings, and art styles, and you can create some wild and wonderful combinations to catch your audience's eye. Koala bear detective? Marble sculpture of a cartoon character? Anything is possible!

To depict imaginary people

By generating images you can include humans in your creative pieces without them needing to be real. No need to find models—or to get people to sign release forms!

To develop a signature look

By reusing the same style keywords while changing subjects, you can create multiple images over time that all look related, creating an interesting and consistent look for your brand.

Generating different image styles with AI image prompts

When it comes to generating images, knowledge about how to describe things is power—to ask for something, you need to be able to describe it!

Discovering the names of interesting art styles is important and it can be part of the fun. Because AI generation tools are trained on real images, there's no need to use a convoluted description—just phrase things normally. Pull words and phrases from online research sources, gallery websites, and even art textbooks. The sky's the limit.

To whet your appetite, let's look at a whole range of examples for our imaginary running club.

Try different art medium styles

From watercolors to airbrushes, there are a lot of different ways to make marks on paper. Indicate the art medium style or method in your image prompts for unique results.

The four images above were generated with these prompts:

Pro tip: Try these words and phrases for different art styles: ""stencil art,"" ""crayon,"" ""chalk,"" ""etching,"" ""oil paintings,"" ""ballpoint pen,"" ""colored pencil,"" ""Chinese watercolor,"" ""pastels,"" ""woodcut,"" ""charcoal,"" ""screen print,"" ""photocollage,"" ""storybook illustration,"" ""newspaper cartoon,"" ""vintage illustration from [decade].""

Get a decidedly digital look

For a more contemporary feel, you can generate illustrations with a more digital look.

The four images above were generated with these prompts:

Pro tip: Try these phrases for different digital styles: ""digital art,"" ""vector graphics,"" ""minimalist,"" ""geometric,"" ""isometric,"" ""2.5D,"" ""matte clay,"" ""digital painting,"" ""screenshot from [a favorite game or animation],"" ""diagram,"" ""instruction manual.""

Make it retro—and make it arty!

You can call upon the whole of art history to get the style you're after! Try generating anything from ancient cave paintings to 20th-century modern art and give your piece a vintage twist.

Your description might include years, art movements, media, or famous artists. And while you're at it, you can try describing it as a ""masterpiece,"" ""masterwork,"" or ""outstanding example of…""—it never hurts to ask, after all.

The four images above were generated with these prompts:

Pro tip: Other art styles to try: ""surrealism,"" ""Dadaism,"" ""metaphysical painting,"" ""orphism,"" ""cubism,"" ""suprematism,"" ""De Stijl,"" ""futurism,"" ""expressionism,"" ""realism,"" ""Bauhaus,"" ""color field painting,"" ""impressionism,"" ""baroque,"" ""rococo,"" ""mannerism,"" ""ancient Egyptian papyrus,"" ""ancient Roman mosaic.""

Generate some faux-tography

For a more realistic-looking image, you could describe a photograph.

This time, your description might include references to elements such as lighting, time of day, angle, and distance (for example, ""close-up,"" ""low camera angle"") or technical elements such as camera type, lens, and so on. For example, a photo taken by a DSLR, 35mm lens will look different from a flash photo from a disposable camera.

The four images above were generated with these prompts:

Pro tip: Other photography-related terms to play with: ""trail cam,"" ""CCTV,"" ""VHS,"" ""infrared photography,"" ""daguerreotype,"" ""cyanotype,"" ""photo from [a favorite magazine or website],"" ""film still from [a favorite movie or TV show],"" ""color splash,"" ""extreme close-up,"" ""wide-angle lens,"" ""telephoto lens,"" ""light leaks,"" ""autochrome,"" ""camera phone,"" ""camera obscura,"" ""warm lighting,"" ""long exposure,"" ""fast shutter speed,"" ""back lighting,"" ""low-key lighting,"" ""golden hour,"" ""blue hour,"" ""macro lens,"" ""motion blur,"" ""shallow depth-of-field,"" ""action photography,"" ""candid portrait.""

Make an object

Although the images are 2D, you can of course describe a 3D artwork and generate images of that! When crafting your image prompt, it might be helpful to think of the object as it would appear in a photograph so, again, you can reference lighting, backgrounds, lenses and so on, to achieve the effect you want.

The four images above were generated with these prompts:

Pro tip: Other materials you might try: ""felt,"" ""tapestry,"" ""knitting,"" ""embroidery,"" ""papercraft,"" ""origami,"" ""pop-up books,"" ""modelling clay,"" ""porcelain,"" ""ceramics,"" ""terracotta,"" ""metalwork,"" ""jewelry,"" ""crystal,"" ""fiberglass""…even ""butter.""

Write an AI image prompt and let's go!

It really is that simple! It's all about experimenting and discovering what's possible. You're sure to generate some fantastic images, and plenty of amusing mistakes along the way.

In the examples above, we focused on runners, but you could generate any kind of subject: buildings, interior designs, costume designs, imaginary monsters, unusual landscapes, and more.

As you explore further, you might find yourself looking up famous art movements on Wikipedia, learning more about film stock or investigating architectural glossaries to create ever-more inventive descriptions."
Microsoft_News,https://blogs.microsoft.com/blog/2023/01/23/microsoftandopenaiextendpartnership/,,Microsoft and OpenAI extend partnership,"Today, we are announcing the third phase of our long-term partnership with OpenAI through a multiyear, multibillion dollar investment to accelerate AI breakthroughs to ensure these benefits are broadly shared with the world.

This agreement follows our previous investments in 2019 and 2021. It extends our ongoing collaboration across AI supercomputing and research and enables each of us to independently commercialize the resulting advanced AI technologies.

Supercomputing at scale – Microsoft will increase our investments in the development and deployment of specialized supercomputing systems to accelerate OpenAI’s groundbreaking independent AI research. We will also continue to build out Azure’s leading AI infrastructure to help customers build and deploy their AI applications on a global scale.

– Microsoft will increase our investments in the development and deployment of specialized supercomputing systems to accelerate OpenAI’s groundbreaking independent AI research. We will also continue to build out Azure’s leading AI infrastructure to help customers build and deploy their AI applications on a global scale. New AI-powered experiences – Microsoft will deploy OpenAI’s models across our consumer and enterprise products and introduce new categories of digital experiences built on OpenAI’s technology. This includes Microsoft’s Azure OpenAI Service, which empowers developers to build cutting-edge AI applications through direct access to OpenAI models backed by Azure’s trusted, enterprise-grade capabilities and AI-optimized infrastructure and tools.

– Microsoft will deploy OpenAI’s models across our consumer and enterprise products and introduce new categories of digital experiences built on OpenAI’s technology. This includes Microsoft’s Azure OpenAI Service, which empowers developers to build cutting-edge AI applications through direct access to OpenAI models backed by Azure’s trusted, enterprise-grade capabilities and AI-optimized infrastructure and tools. Exclusive cloud provider – As OpenAI’s exclusive cloud provider, Azure will power all OpenAI workloads across research, products and API services.

“We formed our partnership with OpenAI around a shared ambition to responsibly advance cutting-edge AI research and democratize AI as a new technology platform,” said Satya Nadella, Chairman and CEO, Microsoft. “In this next phase of our partnership, developers and organizations across industries will have access to the best AI infrastructure, models, and toolchain with Azure to build and run their applications.”

“The past three years of our partnership have been great,” said Sam Altman, CEO of OpenAI. “Microsoft shares our values and we are excited to continue our independent research and work toward creating advanced AI that benefits everyone.”

Since 2016, Microsoft has committed to building Azure into an AI supercomputer for the world, serving as the foundation of our vision to democratize AI as a platform. Through our initial investment and collaboration, Microsoft and OpenAI pushed the frontier of cloud supercomputing technology, announcing our first top-5 supercomputer in 2020, and subsequently constructing multiple AI supercomputing systems at massive scale. OpenAI has used this infrastructure to train its breakthrough models, which are now deployed in Azure to power category-defining AI products like GitHub Copilot, DALL·E 2 and ChatGPT.

These innovations have captured imaginations and introduced large-scale AI as a powerful, general-purpose technology platform that we believe will create transformative impact at the magnitude of the personal computer, the internet, mobile devices and the cloud.

Underpinning all of our efforts is Microsoft and OpenAI’s shared commitment to building AI systems and products that are trustworthy and safe. OpenAI’s leading research on AI Alignment and Microsoft’s Responsible AI Standard not only establish a leading and advancing framework for the safe deployment of our own AI technologies, but will also help guide the industry toward more responsible outcomes.

Tags: AI, Azure OpenAI Service"
Microsoft_News,https://azure.microsoft.com/en-us/blog/general-availability-of-azure-openai-service-expands-access-to-large-advanced-ai-models-with-added-enterprise-benefits/,,"General availability of Azure OpenAI Service expands access to large, advanced AI models with added enterprise benefits","Large language models are quickly becoming an essential platform for people to innovate, apply AI to solve big problems, and imagine what’s possible. Today, we are excited to announce the general availability of Azure OpenAI Service as part of Microsoft’s continued commitment to democratizing AI, and ongoing partnership with OpenAI.

With Azure OpenAI Service now generally available, more businesses can apply for access to the most advanced AI models in the world-including GPT-3.5, Codex, and DALL-E 2-backed by the trusted enterprise-grade capabilities and AI-optimized infrastructure of Microsoft Azure, to create cutting-edge applications. Customers will also be able to access ChatGPT-a fine-tuned version of GPT-3.5 that has been trained and runs inference on Azure AI infrastructure-through Azure OpenAI Service soon.

Empowering customers to achieve more

We debuted Azure OpenAI Service in November 2021 to enable customers to tap into the power of large-scale generative AI models with the enterprise promises customers have come to expect from our Azure cloud and computing infrastructure-security, reliability, compliance, data privacy, and built-in Responsible AI capabilities.

Since then, one of the most exciting things we’ve seen is the breadth of use cases Azure OpenAI Service has enabled our customers-from generating content that helps better match shoppers with the right purchases to summarizing customer service tickets, freeing up time for employees to focus on more critical tasks.

Customers of all sizes across industries are using Azure OpenAI Service to do more with less, improve experiences for end-users, and streamline operational efficiencies internally. From startups like Moveworks to multinational corporations like KPMG, organizations small and large are applying the capabilities of Azure OpenAI Service to advanced use cases such as customer support, customization, and gaining insights from data using search, data extraction, and classification.

“At Moveworks, we see Azure OpenAI Service as an important component of our machine learning architecture. It enables us to solve several novel use cases, such as identifying gaps in our customer’s internal knowledge bases and automatically drafting new knowledge articles based on those gaps. This saves IT and HR teams a significant amount of time and improves employee self-service. Azure OpenAI Service will also radically enhance our existing enterprise search capabilities and supercharge our analytics and data visualization offerings. Given that so much of the modern enterprise relies on language to get work done, the possibilities are endless-and we look forward to continued collaboration and partnership with Azure OpenAI Service.”–Vaibhav Nivargi, Chief Technology Officer and Founder at Moveworks.

“Al Jazeera Digital is constantly exploring new ways to use technology to support our journalism and better serve our audience. Azure OpenAI Service has the potential to enhance our content production in several ways, including summarization and translation, selection of topics, AI tagging, content extraction, and style guide rule application. We are excited to see this service go to general availability so it can help us further contextualize our reporting by conveying the opinion and the other opinion.”–Jason McCartney, Vice President of Engineering at Al Jazeera.

“KPMG is using Azure OpenAI Service to help companies realize significant efficiencies in their Tax ESG (Environmental, Social, and Governance) initiatives. Companies are moving to make their total tax contributions publicly available. With much of these tax payments buried in IT systems outside of finance, massive data volumes, and incomplete data attributes, Azure OpenAI Service finds the data relationships to predict tax payments and tax type-making it much easier to validate accuracy and categorize payments by country and tax type.”–Brett Weaver, Partner, Tax ESG Leader at KPMG.

Azure-the best place to build AI workloads

The general availability of Azure OpenAI Service is not only an important milestone for our customers but also for Azure.

Azure OpenAI Service provides businesses and developers with high-performance AI models at production scale with industry-leading uptime. This is the same production service that Microsoft uses to power its own products, including GitHub Copilot, an AI pair programmer that helps developers write better code, Power BI, which leverages GPT-3-powered natural language to automatically generate formulae and expressions, and the recently-announced Microsoft Designer, which helps creators build stunning content with natural language prompts.

All of this innovation shares a common thread: Azure’s purpose-built, AI-optimized infrastructure.

Azure is also the core computing power behind OpenAI API’s family of models for research advancement and developer production.

Azure is currently the only global public cloud that offers AI supercomputers with massive scale-up and scale-out capabilities. With a unique architecture design that combines leading GPU and networking solutions, Azure delivers best-in-class performance and scale for the most compute-intensive AI training and inference workloads. It’s the reason the world’s leading AI companies-including OpenAI, Meta, Hugging Face, and others-continue to choose Azure to advance their AI innovation. Azure currently ranks in the top 15 of the TOP500 supercomputers worldwide and is the highest-ranked global cloud services provider today. Azure continues to be the cloud and compute power that propels large-scale AI advancements across the globe.

Source: TOP500 The List: TOP500 November 2022, Green500 November 2022.

A responsible approach to AI

As an industry leader, we recognize that any innovation in AI must be done responsibly. This becomes even more important with powerful, new technologies like generative models. We have taken an iterative approach to large models, working closely with our partner OpenAI and our customers to carefully assess use cases, learn, and address potential risks. Additionally, we’ve implemented our own guardrails for Azure OpenAI Service that align with our Responsible AI principles. As part of our Limited Access Framework, developers are required to apply for access, describing their intended use case or application before they are given access to the service. Content filters uniquely designed to catch abusive, hateful, and offensive content constantly monitor the input provided to the service as well as the generated content. In the event of a confirmed policy violation, we may ask the developer to take immediate action to prevent further abuse.

We are confident in the quality of the AI models we are using and offering customers today, and we strongly believe they will empower businesses and people to innovate in entirely new and exciting ways.

The pace of innovation in the AI community is moving at lightning speed. We’re tremendously excited to be at the forefront of these advancements with our customers, and look forward to helping more people benefit from them in 2023 and beyond.

Getting started with Azure OpenAI Service"
Microsoft_News,https://azure.microsoft.com/en-us/blog/whats-new-in-azure-data-ai-empowering-retailers-to-streamline-operations-and-accelerate-time-to-value/,,What’s new in Azure Data & AI: Empowering retailers to streamline operations and accelerate time to value,"The new year brings opportunity for thoughtful reflection about the past year, both personally and professionally. 2022 was a year of firsts for me-first time having clam chowder at Pike Place Market as a local, first time going shopping for heels with my daughter, and first time delivering an Azure keynote at Inspire as a Microsoft employee when pre-COVID-19, I was a Partner listening in the audience. And here is another first; the start of a new blog series where I plan to share more about noteworthy and inspiring data and AI innovations we are releasing across Microsoft. Given the National Retail Federation’s Big Show this week, I’ll also highlight how these innovations impact retail.

Let’s explore what’s new for Azure Data & AI this month:

Microsoft underscores resilient retail at NRF

A bellwether for economic and societal trends, the retail industry continues to be on the front line of adaptive innovation. And rather than trying to predict the future, retailers are working to achieve greater business agility necessary to thrive in it. This means that, like Majid Al Futtaim Retail, they automate tedious processes so employees can focus on higher-value tasks. Like Grupo Bimbo, they unify disparate data points in real time so that employees can access a central source of truth when and where they need it. And, like CCC Group, they stay laser-focused on delivering differentiated customer experiences to build loyal fans. Across each of these organizations, data is seen as an accelerant for growth, powering more personalized customer experiences, cost-efficient supply chains, and proactive responses to market trends.

Business agility requires people, processes, and technologies to work in harmony, and to align on how massive amounts of data are managed, analyzed, and actioned to respond to market demands. Increasingly, these efforts focus on driving sustainable growth that limits carbon emissions, for example by using machine learning to more accurately forecast demand to reduce excess inventory and waste.

We know cloud technologies like databases, containers, and AI can enable more accurate decisions, but it can be challenging to ensure these technologies speak to each other in the right way at the right time on a global scale. This is where Azure and the Microsoft Intelligent Data Platform-the description we use to refer to all of the Data & AI Azure products and services we offer shine. With managed databases like Cosmos DB, analytics services like Azure Synapse, and leading AI offerings, retailers can take advantage of the “by design” integration the Microsoft Intelligent Data Platform offers, which means they are able to invest more time in creating value rather than integrating and managing their data estate.

The Microsoft Intelligent Data Platform came to life through new immersive demo experiences this year at NRF and I’m going to briefly highlight what we showcased at the conference. Earlier this week at NRF, Microsoft’s Alysa Taylor and Shelley Bransten spoke on the topic of Resilient Retail and shared examples of organizations digitizing their businesses to do more with less. You can read more about their talks on our Industry blog.

Microsoft also met with customers at our NRF booth to discuss strategies for making sense of all their data. For example, these two demos highlight how tight integrations between data, analytics, and AI can help make resilient retail a reality.

Wide World Importers (WWI), a global supermarket chain, wants to maximize the value of their data estate. By using Azure Synapse pipelines with Cosmos DB, they get real time insights which are automatically shared with the right decision makers through tools like Azure Data Explorer and Power BI. They’re able to track their supply chain data in real time and use predictive AI to reduce costs. They’re also able to govern their data estate from a single application one pane of glass using Microsoft Purview.

Next, Wide World Importers taps into the power of Azure AI to build a more connected customer experience. They use Azure Form Recognizer to detect and redeem promotional offers. Azure Cognitive Search helps customers find product information more quickly by recognizing their search intent and helps WWI deliver more personalized recommendations. Pre-built AI capabilities, such as speech recognition and computer vision, also differentiate the shopping experience and provide a more accessible flow.

The general availability of Azure OpenAI Service

As Eric Boyd mentioned in his blog, we announced the general availability of Azure OpenAI Service as part of our ongoing partnership with OpenAI. Azure OpenAI Service provides a commercialization platform for businesses to leverage advanced AI models like GPT-3.5, Codex, and DALL*E to create innovative applications. Customers of all sizes across industries are using Azure OpenAI Service to do more with less, improve experiences for end users, and streamline operational efficiencies.

Microsoft Responsible AI Dashboard now available

The digitization of retail enables retailers to meet customer expectations with increasing precision, from providing personalized recommendations online to restocking inventory based on computer vision in physical stores. Shoppers expect the technology behind their retail experience to apply data and AI responsibly. In December, we began rolling out our new Responsible AI dashboard in Azure Machine Learning, which includes capabilities like fairness assessment, interpretability, error analysis, and causal inferencing. And today, we are excited to announce the general availability of the Microsoft Responsible AI dashboard. Retailers can leverage the Responsible AI dashboard to optimize the shopper’s experience as well as build trust and positive perception for their brands.

See how you can learn more about Responsible AI.

Full text search capabilities come to Azure Cosmos DB for Apache Cassandra

Azure Cosmos DB has seen tremendous momentum within the retail industry, given its ability to automatically and instantly scale when traffic is unpredictable without sacrificing performance or cost efficiency. Microsoft runs both the Windows store and Xbox Live on Azure Cosmos DB for this very purpose. This month, we’re announcing several performance enhancements to Azure Cosmos DB to make it easier and faster for developers to query data stores in Azure Cosmos DB. These include the ability to do full text searches in Azure Cosmos DB for Apache Cassandra through a native integration with Azure Cognitive Search, and support for GraphQL and REST through Data API builder.

For more technical detail about these and other updates to Azure Cosmos DB, visit our developer blog.

JSON support for Azure Cache for Redis Enterprise generally available

Support for JSON documents in Azure Cache for Redis Enterprise tiers, delivered via the RedisJSON module, has been made generally available as of November 2022.

This turns Azure Cache for Redis Enterprise into a high-performance NoSQL document store and drives efficiency for developers to modernize their applications. The new RedisJSON module update is well suited to retail customers looking to store, search, and index product catalogs and shopper data via a single atomic operation.

To learn more on Azure Cache for Redis Enterprise and the RedisJSON module please check out the blog.

Microsoft named a Leader in the 2022 Gartner Magic Quadrant for Insight Engines

In December, Microsoft was named a leader in the 2022 Gartner Magic Quadrant for Insight Engines, which evaluates the capabilities of various vendors in the market for providing enterprise-scale search for app development.

Organizations benefit, no matter the industry, but Cognitive Search is an exceptionally powerful tool for retailers, helping them to quickly find and analyze data related to customer behavior, sales, and inventory. It can also be used to personalize the shopping experience for individual customers based on their past interactions and preferences.

Learn more and download the report.

Customers innovating with Azure Data & AI

I’d like to close my inaugural “what’s new” blog post with my favorite way of making everything I’ve covered above actionable-by sharing examples of our customers succeeding. I share them as a way of helping spark the understanding-maybe even a little imagination-so that others can better envision how this amazing new Data & AI technology can be used in their own organizations.

I hope you enjoyed reading this month’s edition of what’s new in Azure Data & AI. We look forward to sharing more insights and inspiration in the months ahead."
Microsoft_News,https://www.microsoft.com/en-us/research/blog/advancing-human-centered-ai-updates-on-responsible-ai-research/,,Advancing human-centered AI: Updates on responsible AI research,"Editor’s note: All papers referenced here represent collaborations throughout Microsoft and across academia and industry that include authors who contribute to Aether, the Microsoft internal advisory body for AI Ethics and Effects in Engineering and Research.

Video A human-centered approach to AI Learn how considering potential benefits and harms to people and society helps create better AI in the keynote “Challenges and opportunities in responsible AI” (2022 ACM SIGIR Conference on Human Information Interaction and Retrieval).

Artificial intelligence, like all tools we build, is an expression of human creativity. As with all creative expression, AI manifests the perspectives and values of its creators. A stance that encourages reflexivity among AI practitioners is a step toward ensuring that AI systems are human-centered, developed and deployed with the interests and well-being of individuals and society front and center. This is the focus of research scientists and engineers affiliated with Aether, the advisory body for Microsoft leadership on AI ethics and effects. Central to Aether’s work is the question of who we’re creating AI for—and whether we’re creating AI to solve real problems with responsible solutions. With AI capabilities accelerating, our researchers work to understand the sociotechnical implications and find ways to help on-the-ground practitioners envision and realize these capabilities in line with Microsoft AI principles.

The following is a glimpse into the past year’s research for advancing responsible AI with authors from Aether. Throughout this work are repeated calls for reflexivity in AI practitioners’ processes—that is, self-reflection to help us achieve clarity about who we’re developing AI systems for, who benefits, and who may potentially be harmed—and for tools that help practitioners with the hard work of uncovering assumptions that may hinder the potential of human-centered AI. The research discussed here also explores critical components of responsible AI, such as being transparent about technology limitations, honoring the values of the people using the technology, enabling human agency for optimal human-AI teamwork, improving effective interaction with AI, and developing appropriate evaluation and risk-mitigation techniques for multimodal machine learning (ML) models.

Considering who AI systems are for

The need to cultivate broader perspectives and, for society’s benefit, reflect on why and for whom we’re creating AI is not only the responsibility of AI development teams but also of the AI research community. In the paper “REAL ML: Recognizing, Exploring, and Articulating Limitations of Machine Learning Research (opens in new tab),” the authors point out that machine learning publishing often exhibits a bias toward emphasizing exciting progress, which tends to propagate misleading expectations about AI. They urge reflexivity on the limitations of ML research to promote transparency about findings’ generalizability and potential impact on society—ultimately, an exercise in reflecting on who we’re creating AI for. The paper offers a set of guided activities designed to help articulate research limitations (opens in new tab), encouraging the machine learning research community toward a standard practice of transparency about the scope and impact of their work.

Walk through REAL ML’s instructional guide and worksheet that help researchers with defining the limitations of their research and identifying societal implications these limitations may have in the practical use of their work. Explore REAL ML

Despite many organizations formulating principles to guide the responsible development and deployment of AI, a recent survey highlights that there’s a gap between the values prioritized by AI practitioners and those of the general public. The survey, which included a representative sample of the US population, found AI practitioners often gave less weight than the general public to values associated with responsible AI. This raises the question of whose values should inform AI systems and shifts attention toward considering the values of the people we’re designing for, aiming for AI systems that are better aligned with people’s needs.

Related papers

Creating AI that empowers human agency

Supporting human agency and emphasizing transparency in AI systems are proven approaches to building appropriate trust with the people systems are designed to help. In human-AI teamwork, interactive visualization tools can enable people to capitalize on their own domain expertise and let them easily edit state-of-the-art models. For example, physicians using GAM Changer can edit risk prediction models for pneumonia and sepsis to incorporate their own clinical knowledge and make better treatment decisions for patients.

A study examining how AI can improve the value of rapidly growing citizen-science contributions found that emphasizing human agency and transparency increased productivity in an online workflow where volunteers provide valuable information to help AI classify galaxies. When choosing to opt in to using the new workflow and receiving messages that stressed human assistance was necessary for difficult classification tasks, participants were more productive without sacrificing the quality of their input and they returned to volunteer more often.

Failures are inevitable in AI because no model that interacts with the ever-changing physical world can be complete. Human input and feedback are essential to reducing risks. Investigating reliability and safety mitigations for systems such as robotic box pushing and autonomous driving, researchers formalize the problem of negative side effects (NSEs), the undesirable behavior of these systems. The researchers experimented with a framework in which the AI system uses immediate human assistance in the form of feedback—either about the user’s tolerance for an NSE occurrence or their decision to modify the environment. Results demonstrate that AI systems can adapt to successfully mitigate NSEs from feedback, but among future considerations, there remains the challenge of developing techniques for collecting accurate feedback from individuals using the system.

The goal of optimizing human-AI complementarity highlights the importance of engaging human agency. In a large-scale study examining how bias in models influences humans’ decisions in a job recruiting task, researchers made a surprising discovery: when working with a black-box deep neural network (DNN) recommender system, people made significantly fewer gender-biased decisions than when working with a bag-of-words (BOW) model, which is perceived as more interpretable. This suggests that people tend to reflect and rely on their own judgment before accepting a recommendation from a system for which they can’t comfortably form a mental model of how its outputs are derived. Researchers call for exploring techniques to better engage human reflexivity when working with advanced algorithms, which can be a means for improving hybrid human-AI decision-making and mitigating bias.

How we design human-AI interaction is key to complementarity and empowering human agency. We need to carefully plan how people will interact with AI systems that are stochastic in nature and present inherently different challenges than deterministic systems. Designing and testing human interaction with AI systems as early as possible in the development process, even before teams invest in engineering, can help avoid costly failures and redesign. Toward this goal, researchers propose early testing of human-AI interaction through factorial surveys, a method from the social sciences that uses short narratives for deriving insights about people’s perceptions.

But testing for optimal user experience before teams invest in engineering can be challenging for AI-based features that change over time. The ongoing nature of a person adapting to a constantly updating AI feature makes it difficult to observe user behavior patterns that can inform design improvements before deploying a system. However, experiments demonstrate the potential of HINT (Human-AI INtegration Testing), a framework for uncovering over-time patterns in user behavior during pre-deployment testing. Using HINT, practitioners can design test setup, collect data via a crowdsourced workflow, and generate reports of user-centered and offline metrics.

Check out the 2022 anthology of this annual workshop that brings human-computer interaction (HCI) and natural language processing (NLP) research together for improving how people can benefit from NLP apps they use daily. HCI + NLP 2022 anthology

Related papers

Although we’re still in the early stages of understanding how to responsibly harness the potential of large language and multimodal models that can be used as foundations for building a variety of AI-based systems, researchers are developing promising tools and evaluation techniques to help on-the-ground practitioners deliver responsible AI. The reflexivity and resources required for deploying these new capabilities with a human-centered approach are fundamentally compatible with business goals of robust services and products.

Natural language generation with open-ended vocabulary has sparked a lot of imagination in product teams. Challenges persist, however, including for improving toxic language detection; content moderation tools often over-flag content that mentions minority groups without respect to context while missing implicit toxicity. To help address this, a new large-scale machine-generated dataset, ToxiGen, enables practitioners to fine-tune pretrained hate classifiers for improving detection of implicit toxicity for 13 minority groups in both human- and machine-generated text.

Download the large-scale machine-generated ToxiGen dataset and install source code for fine-tuning toxic language detection systems for adversarial and implicit hate speech for 13 demographic minority groups. Intended for research purposes. ToxiGen dataset

Multimodal models are proliferating, such as those that combine natural language generation with computer vision for services like image captioning. These complex systems can surface harmful societal biases in their output and are challenging to evaluate for mitigating harms. Using a state-of-the-art image captioning service with two popular image-captioning datasets, researchers isolate where in the system fairness-related harms originate and present multiple measurement techniques for five specific types of representational harm: denying people the opportunity to self-identify, reifying social groups, stereotyping, erasing, and demeaning.

The commercial advent of AI-powered code generators has introduced novice developers alongside professionals to large language model (LLM)-assisted programming. An overview of the LLM-assisted programming experience reveals unique considerations. Programming with LLMs invites comparison to related ways of programming, such as search, compilation, and pair programming. While there are indeed similarities, the empirical reports suggest it is a distinct way of programming with its own unique blend of behaviors. For example, additional effort is required to craft prompts that generate the desired code, and programmers must check the suggested code for correctness, reliability, safety, and security. Still, a user study examining what programmers value in AI code generation shows that programmers do find value in suggested code because it’s easy to edit, increasing productivity. Researchers propose a hybrid metric that combines functional correctness and similarity-based metrics to best capture what programmers value in LLM-assisted programming, because human judgment should determine how a technology can best serve us.

Related papers

Understanding and supporting AI practitioners

Organizational culture and business goals can often be at odds with what practitioners need for mitigating fairness and other responsible AI issues when their systems are deployed at scale. Responsible, human-centered AI requires a thoughtful approach: just because a technology is technically feasible does not mean it should be created.

Similarly, just because a dataset is available doesn’t mean it’s appropriate to use. Knowing why and how a dataset was created is crucial for helping AI practitioners decide on whether it should be used for their purposes and what its implications are for fairness, reliability, safety, and privacy. A study focusing on how AI practitioners approach datasets and documentation reveals current practices are informal and inconsistent. It points to the need for data documentation frameworks designed to fit within practitioners’ existing workflows and that make clear the responsible AI implications of using a dataset. Based on these findings, researchers iterated on Datasheets for Datasets and proposed the revised Aether Data Documentation Template.

Use this flexible template to reflect and help document underlying assumptions, potential risks, and implications of using your dataset. Document your data

AI practitioners find themselves balancing the pressures of delivering to meet business goals and the time requirements necessary for the responsible development and evaluation of AI systems. Examining these tensions across three technology companies, researchers conducted interviews and workshops to learn what practitioners need for measuring and mitigating AI fairness issues amid time pressure to release AI-infused products to wider geographic markets and for more diverse groups of people. Participants disclosed challenges in collecting appropriate datasets and finding the right metrics for evaluating how fairly their system will perform when they can’t identify direct stakeholders and demographic groups who will be affected by the AI system in rapidly broadening markets. For example, hate speech detection may not be adequate across cultures or languages. A look at what goes into AI practitioners’ decisions around what, when, and how to evaluate AI systems that use natural language generation (NLG) further emphasizes that when practitioners don’t have clarity about deployment settings, they’re limited in projecting failures that could cause individual or societal harm. Beyond concerns for detecting toxic speech, other issues of fairness and inclusiveness—for example, erasure of minority groups’ distinctive linguistic expression—are rarely a consideration in practitioners’ evaluations.

Coping with time constraints and competing business objectives is a reality for teams deploying AI systems. There are many opportunities for developing integrated tools that can prompt AI practitioners to think through potential risks and mitigations for sociotechnical systems.

Related papers

Thinking about it: Reflexivity as an essential for society and industry goals

As we continue to envision what all is possible with AI’s potential, one thing is clear: developing AI designed with the needs of people in mind requires reflexivity. We have been thinking about human-centered AI as being focused on users and stakeholders. Understanding who we are designing for, empowering human agency, improving human-AI interaction, and developing harm mitigation tools and techniques are as important as ever. But we also need to turn a mirror toward ourselves as AI creators. What values and assumptions do we bring to the table? Whose values get to be included and whose are left out? How do these values and assumptions influence what we build, how we build, and for whom? How can we navigate complex and demanding organizational pressures as we endeavor to create responsible AI? With technologies as powerful as AI, we can’t afford to be focused solely on progress for its own sake. While we work to evolve AI technologies at a fast pace, we need to pause and reflect on what it is that we are advancing—and for whom.

Opens in a new tab"
Microsoft_News,https://news.microsoft.com/source/features/digital-transformation/a-grocer-that-sells-smoothies-snacks-and-easier-lives-welcome-to-zabkas-autonomous-stores/,,"A grocer that sells smoothies, snacks and ‘easier lives’? Welcome to Żabka’s autonomous stores","In his mind, there is one true adversary, one old barrier that must be crushed for good. His foe is friction.

That’s the word retail leaders like Tomasz Blicharski use when describing the kinds of hassles that annoy shoppers, that even cause some people to avoid brick-and-mortar grocery stores altogether.

Hassles like waiting in line to check out or even needing to check out at all, basically any in-store task that steals precious time from a grocery shopper’s day, says Blicharski, executive vice president of Żabka Group, Poland’s largest convenience store chain spanning more than 9,000 locations.

But the time has come, Blicharski says, for shoppers to expect their grocery stops to last 60 seconds or less. That’s the average duration of customer visits at the company’s 50-plus autonomous grocery stores – a checkout-free concept it calls Żabka Nano: no carts, no clerks, no cash, no closing time.

A shopper peruses food items at a Żabka store.

To launch those stores, and to make friction a ghost of groceries past, Żabka partnered with AiFi, a California company that enables autonomous shopping with computer-vision technology.

“Our enemy is friction, and we are here to defeat that friction and conquer the autonomous world,” Blicharski says.

“We want shoppers’ lives to be easier, as easy as opening the fridge. This is our mission. We want to free up the free time of the consumer, so they can return to and enjoy their lives,” he adds. “This is a revolutionary step for physical retailers.”

That revolution relies on AiFi’s core technology – computer vision, a type of artificial intelligence or AI that helps computers understand what they see. AiFi deploys numerous AI-enabled cameras across a store’s ceiling. To enter those stores, shoppers swipe their payment cards or use the retailer’s app.

Tomasz Blicharski.

Digital video captured by the cameras feeds AiFi’s computer-vision platform, which recognizes the shoppers’ behaviors, including when they pluck individual products from the shelves.

Computer vision also helps store managers understand everything happening in the shop, including foot-traffic patterns and sales relative to product groupings, shelf height and placement. The AiFi platform runs on Microsoft Azure.

AiFi’s system may be sophisticated. But the cameras – “totally off the shelf, nothing particularly special” – allow AiFi to deploy its platform quicker and cheaper than other autonomous retailers that rely on weight sensors in store shelves, says Steve Carlin, AiFi’s CEO.

“We only need two weeks (to outfit a store). That’s what we ask for. We can do it faster,” Carlin says.

A Żabka shopper walks toward shelves full of beverages.

In fact, with its platform deployed in 100 retail spaces across North America, Europe, the Middle East, Asia and Australia, AiFi is the world’s largest provider of autonomous shopping solutions.

“Our platform is way more flexible than a lot of our competition because we don’t have to touch the shelves at all,” Carlin says. “You can take a space that already exists and retrofit it. And you can move the shelves. You can’t do that with weight sensors, which require digging a trench in the floor, running cable to the shelf and electrifying the shelf. And once you’ve done that, that shelf isn’t moving.”

In addition to deploying its tech at grocery stores in Europe, the U.S. and the United Arab Emirates, AiFi has brought autonomous shopping to college campuses, sports venues and workplaces. The Miami Dolphins offer football fans cashier-less concessions stands inside Hard Rock Stadium. At the Indianapolis 500, racing fans have dashed into an autonomous store to buy snacks and merchandise. And at the University of Denver, students purchase fresh foods at two grab-and-go markets on campus.

“At one European stadium we’re in, the concessions wait time use to be 70 seconds,” Carlin says. “They went to our frictionless store format, and that time got reduced to 16 seconds. That made it the best-selling concession stand they’ve ever had in their stadium.”

Click here to load media

AiFi’s tech does not use facial recognition or biometrics, keeping customers anonymous. When a shopper enters, the system only creates a virtual avatar of that customer and never uses personal data.

“We don’t need your face. We don’t need your palm to be read to do what we do. We are only interested in identifying a virtual avatar with a payment method,” Carlin says.

To date, more than 800,000 shoppers have made about 1.5 million transactions through AiFi’s platform.

“One of the reasons I joined Microsoft (in 2018) was my interest in autonomous stores,” says Shelley Bransten, corporate vice president of worldwide retail and consumer goods industries at Microsoft. “I’m thrilled we’re partnering with AiFi to make their solution as ubiquitous as Wi-Fi.”

Customers can enter by using their payment cards or the retailer’s app.

Soon, the autonomous shopping experience will gain even more intelligence with Smart Store Analytics, a new Microsoft Cloud for Retail offering announced Jan. 10 and available through Microsoft’s partnership with AiFi. Currently in public preview, Smart Store Analytics was co-developed with Zabka and is being tested at all Żabka Nano stores, Blicharski says.

“It’s a tool that enables us to operate these stores more like an e-commerce (retailer),” Blicharski says. “A physical retailer will be able to manage the store in a way that’s way more optimal for the consumer, from assortment selection to personalized promotions” involving Żabka Nano products like ready meals, snacks, juices and smoothies.

Once installed, Smart Store Analytics pulls store data from the AiFi platform to deliver insights that allow retail managers to maximize store layout, product recommendations and inventory. This “phygital” experience, where the physical and digital world blend together, can ultimately help boost sales, lower costs and improve the in-store experience.

The solution also enables store managers to understand how their customers shop, interact with products and move through the aisles, displaying foot traffic as a heat map. It tracks how much money, on average, customers spend and how long they dwell in front of certain displays and shelves. And it plots unit sales to shopper height to help dial in the best shelf placements.

Smart Stores Analytics helps physical stores operate more like an e-commerce retailer, says Tomasz Blicharski.

At the company level, Żabka will use Smart Store Analytics to extract more value from data and use those insights to improve operational metrics at its 50-plus Nano stores. In the future, those insights will help Żabka enhance its supply chain management, predict individual store demands, build ordering schedules for replenishment, and react even faster if a product is out of stock.

In the grocery game, profit margins are tight. By streamlining operations around a single, unified solution like Smart Store Analytics, Żabka executives say they expect to further lower company overhead and share the resulting cost savings with its Nano stores and, ultimately, with shoppers.

“Digital technology is what will make the difference between retailers that thrive during this period of economic, societal and technological change, and those that get left behind,” Bransten says. “Honestly, there’s not a retailer out there who doesn’t want to reimagine the store experience, but until now it’s not really been possible.

“Retailers want to build the type of resilience that enables them to move beyond just responding when disruption happens to them,” she adds. “They want to drive growth through agility and innovation.”

Top photo: Two shoppers prepare to enter a Żabka store. (All photos courtesy of Żabka.)"
Microsoft_News,https://blogs.microsoft.com/accessibility/how-ai-is-being-used-to-improve-mental-health/,,How AI is being used to improve mental health,"Mental health continues to be an area of great need in our society, according to the World Health Organization, approximately 1 in 4 people in the world will be affected by mental health disorders at some point in their lives. However, it can be difficult to pinpoint the exact number, as many people might not seek treatment or receive a diagnosis, with social and cultural stigmas continuing to play a part, despite the fact it can affect individuals of all ages, genders and backgrounds.

As we think of the role technology, especially in addressing the disbalance between available healthcare providers and increased demand of those services, AI and AI algorithms could play a role in reducing that gap. From diagnosis through behavioural data and automated assessments, to personalized care through customized recommendations of treatment, technology has the potential of scaling available mental health support.

However, to be truly inclusive, AI systems need to build on inclusive data and design with intersectional considerations in mind (such as culture, language, race, gender and more). Furthermore, user privacy and protection is absolutely paramount. Users must be aware at all times be of how their information is being used and by whom and have full control over it.

In our latest request for proposals for the AI for Accessibility grant program, project submissions gravitated around a few key themes, including: Cognitive Behavioral Therapy (CBT) as a modality for delivering mental health services, personalization of support in local languages through text analysis, AI-human partnerships for community-informed care as well as the exploration of wearables in detecting changes in mental health.

The opportunity for culturally inclusive mental health resources

An interdisciplinary team spearheaded by SafeLab, in partnership with the University of Pennsylvania, Columbia University and mental health service provider the Center for Black Well-being, is working on developing a web new platform, JoyNet. The platform will focus on culturally relevant resources related to grief and mental health challenges in support of Black youth, which will displayed in accessible and visually appealing ways. Furthermore, the goal is for JoyNet to be used and kept as an open-source code, allowing further expansion to other underrepresented and marginalized communities."
Microsoft_News,https://news.microsoft.com/source/features/digital-transformation/haleon-harnesses-microsofts-seeing-ai-technology-to-make-health-product-information-more-accessible-for-people-who-are-blind-or-have-low-vision/,,Haleon harnesses Microsoft’s Seeing AI technology to make health product information more accessible for people who are blind or have low vision,"For Marc Powell, a seemingly simple trip to the store to buy medication or other consumer health products is often an onerous, complicated undertaking.

Powell, who is blind, usually must ask a store employee to help find what he needs and then read the information on the packaging to him, which can feel intrusive. At home he’ll ask his partner, who has partial sight, for help, but the print is sometimes too small for her to read. In a pinch, he’ll scour the internet or wait until a family member stops by and can read aloud to him the information he needs.

“I’m incredibly reliant on somebody else to let me know about the product — what I’m meant to do with it, how many tablets I can take or what it contains,” says Powell, the accessibility innovation lead for the U.K.-based Royal National Institute of Blind People (RNIB), who lives in Cambridge, England. “It’s crazy to say that, isn’t it?”

A new collaboration between Microsoft and global consumer health company Haleon aims to make health product information more accessible for people who are blind or have partial vision, or individuals with low literacy. The companies worked together to expand the functionality of Microsoft’s Seeing AI app to provide detailed audio information for more than 1,500 Haleon products in the U.S. and the U.K., including brands such as Centrum, Sensodyne and Emergen-C. The initiative was launched in recognition of World Sight Day Oct. 13.

Using Seeing AI, users can now scan the bar code on Haleon products and hear the same information that is provided on the packaging, such as the product name, usage instructions and ingredients. When users point a phone at a Haleon product, the Seeing AI app guides them to the bar code with a series of intensifying beeps. After scanning the code, users can navigate between sections to get the specific information they want, a feature that has been well-received by partially sighted people who tried out the functionality before its launch.

“We have had great feedback from people who are blind and have low vision,” says Tamara Rogers, global chief marketing officer at Haleon. “They really value the increased independence that comes from being empowered to access our product information themselves.”

The new functionality was developed not just for people who are blind or have low vision, but also for those who have literacy challenges, Rogers says. “There’s a classic health industry saying which is, ‘Always read the label, always read the instructions,’ and for some, that just isn’t possible,” she says.

“This initiative will make Haleon products more accessible to people who are blind or have low vision. It will also provide more independence to people with low literacy levels. This is a great way of being able to communicate in a different way, audibly, rather than asking people to read.”

Launched in 2017, Microsoft’s Seeing AI application is an AI camera-based app that can read text such as documents or signs, describe scenes, recognize currency and even identify friends. Available in 19 languages, the app has become a multipurpose tool that is helping people who are blind or have low vision navigate their daily lives. The newly enhanced functionality helps consumers in the U.S. and U.K. read packaging details in English. Previously, there wasn’t an easy way for Seeing AI to read detailed information on packaging without a user moving a camera around the text.

The collaboration with Haleon “is really important and exciting, because Seeing AI has always been able to recognize products, but the challenge has been having access to data that is really rich, and that comes from the manufacturer,” says Saqib Shaikh, an engineering manager at Microsoft who led the team that developed Seeing AI.

“Now you can just scan the barcode and hear exactly what was written on the package. It’s directly what the manufacturer wanted you to hear. The information is really accurate, and you’re getting it all in one place. You’re not having to scan all the different sides of the package to find the bits you want. It’s all right there once you’ve scanned the barcode.

“Now you can give more information, and trustworthy information,” Shaikh says. “Haleon is leading the way in doing this.”

Shaikh hopes more companies will follow Haleon’s lead and use technology to provide audio information for people who are blind or who have low vision, or those with literacy challenges. Doing so could provide important information not just for health products, he says, but for food items and countless other things people use in their daily lives.

“I’d love to make every product out there accessible so you can just scan it, whether by bar code or some other future technology, and know what it is,” he says. “This data is out there. It’s just that all the data’s in siloes. What we were able to do here was, by the companies having the will, to break down these siloes.”

More than 3 million people in the United States and more than 2 million in the U.K. are living with sight loss, and millions more struggle with poor literacy. A study commissioned by Haleon found that 93 percent of respondents didn’t think health products were accessible enough, and almost one in five said they had taken an incorrect dosage of a product because they couldn’t read the packaging.

Haleon saw technology as a tool to address those issues, Rogers says, but wanted to build on an existing platform rather than creating new technology that people who are blind or have low vision would need to adopt. Haleon approached Microsoft about using the Seeing AI app to create audio guides for its products, and the two companies worked closely together to build out the new functionality for Haleon’s bar codes. Microsoft developed an end-to-end pipeline that allows Haleon to control the data for its consumer products, which is stored in Azure, and update information or add new items as needed.

Powell says to his knowledge, Haleon — a spinoff of GlaxoSmithKline created in July 2022 to focus on consumer health products — is the first consumer health company to provide accessible information through Seeing AI for its products.

“I think this will be really useful,” he says. “This allows us as blind people to have the same level of knowledge and understanding as someone who can read the packaging. So this is a really good step.”

Click here to load media

Amar Latif, a Scottish television personality and travel company founder, lost his sight at age 18 due to retinitis pigmentosa, a rare eye disease. Like Powell, he’s had to rely on other people to read him information about health products and medicines.

“When I lost my sight, I really struggled to know what things were — bottles, potions, medicines, toothpaste,” he says. “It’s so hard to know A, what it was, and B, how to use it. So sometimes I just had to risk it. Sometimes it just wasn’t practical to ask somebody, so you just start to take matters into your own hands and wish for the best.”

The new functionality for Haleon products using Seeing AI, Latif says, will help people like him access health product information with greater independence and privacy.

“It’s fantastic. A blind person can use their phone to scan the bar code on loads of products,” he says. “If I was to scan a toothpaste or some painkillers, not only am I able to read all of the information that a sighted person can read, but I can jump from heading to heading.”

To Powell, making information on packaging accessible to people who are blind or have low vision isn’t just a matter of protecting privacy, minimizing health risks or providing greater convenience. It’s a fundamental right.

“We need to start to think about this as a wider equality and inclusion issue,” he says. “We do have a right to that information, and now, technology can provide that. I think this is something that we should look to implement more broadly as a basic standard moving forward.”"
Microsoft_News,https://blogs.bing.com/search-quality-insights/october-2022/Microsoft-Turing-Academic-Program-Workshop,,Tapping into Large Language Models with Microsoft’s Turing Academic Program,"This is a place devoted to giving you deeper insight into the news, trends, people and technology behind Bing."
Microsoft_News,https://news.microsoft.com/source/features/ai/a-conversation-with-kevin-scott-whats-next-in-ai/,,A conversation with Kevin Scott: What’s next in AI,"For example, I’ve been playing around with an experimental system I built for myself using GPT-3 designed to help me write a science fiction book, which is something that I’ve wanted to do since I was a teenager. I have notebooks full of synopses I’ve created for theoretical books, describing what the books are about and the universes where they take place. With this experimental tool, I have been able to get the logjam broken. When I wrote a book the old-fashioned way, if I got 2,000 words out of a day, I’d feel really good about myself. With this tool, I’ve had days where I can write 6,000 words in a day, which for me feels like a lot. It feels like a qualitatively more energizing process than what I was doing before.

This is the “copilot for everything” dream—that you would have a copilot that could sit alongside you as you’re doing any kind of cognitive work, helping you not just get more done, but also enhancing your creativity in new and exciting ways.

This increase in productivity is clearly a boost to your satisfaction. Why do these tools bring more joy to work?

All of us use tools to do our work. Some of us really enjoy acquiring the tools and mastering them and figuring out how to deploy them in a super effective way to do the thing that we’re trying to do. I think that is part of what’s going on here. In many cases, people now have new and interesting and fundamentally more effective tools than they’ve had before. We did a study that found using no-code or low-code tools led to more than an 80% positive impact on work satisfaction, overall workload and morale by users. Especially for tools that are in their relatively early stages, that’s just a huge benefit to see.

For some workers, it’s literally enhancing that core flow that you get into when you’re doing the work; it speeds you up. It’s like having a better set of running shoes to go run a race or marathon. This is exactly what we’re seeing with the experiences developers are having with Copilot; they are reporting that Copilot helps them stay in the flow and keeps their minds sharper during what used to be boring and repetitive tasks. And when AI tools can help to eliminate drudgery from a job, something that is super repetitive or annoying or that was getting in their way of getting to the thing that they really enjoy, it unsurprisingly improves satisfaction.

Personally, these tools let me be in flow state longer than I was before. The enemy of creative flow is distraction and getting stuck. I get to a point where I don’t know quite how to solve the next thing, or the next thing is, like, “I’ve got to go look this thing up. I’ve got to context switch out of what I was doing to go solve the subproblem.” These tools increasingly solve the subproblem for me so that I stay in the flow.

In addition to GitHub Copilot and DALL∙E 2, AI is showing up in Microsoft products and services in other ways. How is next-generation AI improving current products such as Teams and Word?

This is the big untold story of AI. To date, most of AI’s benefits are spread across 1,000 different things where you may not even fully appreciate how much of the product experience that you’re getting is coming from a machine learned system.

For example, we’re sitting here in this Teams call on video and, in the system, there are all these parameters that were learned by a machine learning algorithm. There are jitter buffers for the audio system to smooth out the communication. The blur behind you on your screen is a machine learning algorithm at work. There are more than a dozen machine learning systems that make this experience more delightful for the both of us. And that is certainly true across Microsoft.

We’ve gone from machine learning in a few places to literally 1,000 machine learning things spread across different products, everything from how your Outlook email client works, your predictive text in Word, your Bing search experience, to what your feed looks like in Xbox Cloud Gaming and LinkedIn. There’s AI all over the place making these products better.

One of the big things that has changed in the past two years is it used to be the case that you would have a model that was specialized to each one of these tasks that we have across all our products. Now you have a single model that gets used in lots of places because they’re broadly useful. Being able to invest in these models that become more powerful with scale—and then having all the things built on top of the model benefit simultaneously from improvements that you’re making—is tremendous.

Microsoft’s AI research and development continues through initiatives such as AI4Science and AI for Good. What excites you most about this area of AI?

The most challenging problems we face as a society right now are in the sciences. How do you cure these intractably complicated diseases? How do you prepare yourself for the next pandemic? How do you provide affordable, high-quality healthcare to an aging population? How do you help educate more kids at scale in the skills that they will need for the future? How do you develop technologies that will reverse some of the negative effects of carbon emissions into the atmosphere? We’re exploring how to take some of these exciting developments in AI to those problems.

The models in these basic science applications have the same scaling properties as large language models. You build a model, you get it into some self-supervised mode where it’s learning from a simulation or it’s learning from its own ability to observe a particular domain, and then the model that you get out of it lets you dramatically change the performance of an application—whether you’re doing a computational fluid dynamics simulation or you’re doing molecular dynamics for drug design.

There’s immense opportunity there. This means better medicines, it means maybe we can find the catalyst we don’t have yet to fix our carbon emission problem, it means across the board accelerating how scientists and other folks with big ideas can work to try to solve society’s biggest challenges.

How have breakthroughs in computing techniques and hardware contributed to the advances in AI?

The fundamental thing underlying almost all of the recent progress we’ve seen in AI is how critical the importance of scale has proven to be. It turns out that models trained on more data with more compute power just have a much richer and more generalized set of capabilities. If we want to keep driving this progress further—and to be clear, right now we don’t see any end to the benefits of increased scale—we need to optimize and scale up our compute power as much as we possibly can.

We announced our first Azure AI supercomputer two years ago, and at our Build developer conference this year I shared that we now have multiple supercomputing systems that we’re pretty sure are the largest and most powerful AI supercomputers in the world today. We and OpenAI use this infrastructure to train nearly all of our state-of-the-art large models, whether that’s our Turing, Z-code and Florence models at Microsoft or the GPT, DALL∙E and Codex models at OpenAI. And we just recently announced a collaboration with NVIDIA to build a supercomputer powered by Azure infrastructure combined with NVIDIA GPUs.

Some of this progress has just been via brute force compute scale with bigger and bigger clusters of GPUs. But maybe even a bigger breakthrough is the layer of software that optimizes how models and data are distributed across these giant systems, both to train the models and then to serve them to customers. If we’re going to put forth these large models as platforms that people can create with, they can’t only be accessible to the tiny number of tech companies in the world with enough resources to build giant supercomputers.

So, we’ve invested a ton in software like DeepSpeed to boost training efficiency, and the ONNX Runtime for inference. They optimize for cost and latency and generally help us make bigger AI models more accessible and valuable for people. I’m super proud of the teams we have working on these technologies because Microsoft is really leading the industry here, and we’re open sourcing all of it so others can keep improving.

These advances are all playing out amid an ongoing concern that AI is going to impact jobs. How do you think about the issue of AI and jobs?

We live in a time of extraordinary complexity and historic macroeconomic change, and as we look out 5, 10 years into the future, even to just achieve a net neutral balance for the whole world, we’re going to need new forms of productivity for all of us to be able to continue enjoying progress. We want to be building these AI tools as platforms that lots of people can use to build businesses and solve problems. We believe that these platforms democratize access to AI to far more people. With them, you’ll get a richer set of problems solved and you’ll have a more diverse group of people being able to participate in the creation of technology.

With the previous instantiation of AI, you needed a huge amount of expertise just to get started. Now you can call Azure Cognitive Services, you can call the Azure OpenAI Service and build complicated products on top of these things without necessarily having to be so expert at AI that you’ve got to be able to train your own large model from scratch."
Microsoft_News,https://news.microsoft.com/apac/features/vulcan-coalition-ai-jobs/,,Vulcan Coalition helps people with disabilities train for AI jobs,"In Thailand, there are more than 1.7 million people with disabilities, but only 30 percent of them have a job. That’s an issue Methawee Thatsanasateankit thought she could help solve.

Thatsanasateankit co-founded Vulcan Coalition in 2020 with the objective of both developing new AI services in Thai language and improving the quality of life of people with disabilities.

According to neuroscience studies, some individuals who are blind or deaf have heightened perceptions that allow them to compensate for their sensory loss.

“We learned that people with disabilities almost have a superpower,” Thatsanasateankit said. “So, we saw an opportunity to match them to this type of work.”

That combination would assist a major problem in Thailand, where the startup is based: a lack of workers capable of labeling the large amounts of data being produced in Thai language.

Data labeling involves identifying raw data, like audio files or videos, and adding informative labels for context. This allows a machine learning model to learn from the data, which enables apps like chatbots and voice recognition services.

Thatsanasateankit and fellow co-founder Niran Pravithana developed a curriculum they could present to the Thai government to show that people with disabilities could perform well as data labelers through this reskilling effort. Vulcan partnered with the Ministry of Social Development and Human Security to educate 2,000 people in data labeling. The Vulcan Academy portal serves as a training and testing tool for potential candidates.

“When we first told people that we would like to employ them as data labelers, they were a little bit scared because it was out of their comfort zone,” Thatsanasateankit said. “People have told them that they couldn’t do many types of work. We had to convince them to take the course. But now it’s something they can be proud of because they can tell other people they do this high-value job.”

Punnaphoj Aeuepalisa is a blind senior software engineer at Vulcan Coalition. He helped create the platform used by individuals to label data through speech-to-text and other processes, and is a key voice in how the company is developing AI programs moving forward.

“I have had an interest in computer science since I was a child,” Aeuepalisa said. “I enrolled at university in the computer engineering department. After graduation, I met the chief research officer at Vulcan and he told me he’d like to form an engineering department of people with disabilities. So, I joined the team and we do many products and platforms using our system. There are also many projects we are doing in collaboration with outside organizations.”

Microsoft’s global mission to empower every person and every organization to achieve more took root in the worldwide AI for Good program, which brings the full technological capabilities of the Microsoft Cloud and AI platforms to make the world more sustainable and accessible to everyone.

Not only was Vulcan Coalition recognized by Microsoft for its steps in AI for Accessibility, it also won the Thailand Virtual Hackathon for a hardware and software solution that automized health and check-in processes for visitors with disabilities, including automatic visual detections of masks powered by AI on the Microsoft Cloud.

The Vulcan team utilized its deaf members to label and train AI using visual data in the Vulcan Data Labeling Platform. The company earned a USD 25,000 grant and rewards aimed at further supporting the project’s development, including mentoring and support for an AI for Good grant application and fast-tracked listing on the Microsoft Azure Marketplace.

“Without Microsoft’s help, it would be harder for a small startup like us to be recognized by larger companies,” Thatsanasateankit said.

Now, Vulcan Coalition is working with banks, human resource and home automation companies to create chatbots, AI processes and models for use across the country. Approximately 30 percent of revenue from Vulcan’s AI service will be shared with the staff to support their long-term sustainability.

In Thailand, a company must hire one employee with a disability for every 100 employees. In some cases, Vulcan said companies simply pay the money to the individuals and don’t offer a real work opportunity.

For Vulcan, it partners with companies who are eager to utilize skilled workers. The company estimates that within two years of the program’s start, it will have matched 600 people with disabilities into AI jobs. For the workers, it offers them a dignified source of income apart from getting trained in high-demand tech skills.

“Our workforce has been very intrigued about our project. They want to know how it’s going and how our work can be used in the future,” Aeuepalisa said. “They are very interested and very proud of what they are doing.”

Top image: Punnaphoj Aeuepalisa, a senior software engineer at Vulcan Coalition, helped create a platform to label data through speech-to-text and other processes. Photo by Adryel Talamantes for Microsoft."
Microsoft_News,https://news.microsoft.com/source/features/ai/from-hot-wheels-to-handling-content-how-brands-are-using-microsoft-ai-to-be-more-productive-and-imaginative/,,From Hot Wheels to handling content: How brands are using Microsoft AI to be more productive and imaginative,"When designers at the toy company Mattel were asked recently to come up with a new Hot Wheels model car, they sought inspiration from DALL∙E 2, an AI system developed by OpenAI that creates custom images and art based on what people describe in plainspoken language.

Using the tool, designers can type in a prompt such as, “A scale model of a classic car” and DALL∙E 2 will generate an image of a toy vintage car, perhaps silver in color and with whitewall tires.

As a next step, the designer could erase the top of the car and then type, “Make it a convertible” and DALL∙E 2 will update the image of the car as a convertible. The designer can keep tweaking the design, asking DALL∙E 2 to try it in pink or blue, with the soft-top on, and on and on.

DALL∙E 2 is coming to Microsoft’s Azure OpenAI Service, by invitation, allowing select Azure AI customers to generate custom images using text or images, the company announced today at Microsoft Ignite, a conference for developers and IT professionals.

The availability of DALL∙E 2 through Azure OpenAI Service provides customers such as Mattel cloud AI infrastructure that blends the cutting-edge innovation of text-to-image generation with the compliance, responsible AI guardrails and certifications that Azure offers, Microsoft says.

The Mattel designers were able to generate dozens of images, each iteration sparking and refining ideas that could help design a final fleshed-out rendering of a new Hot Wheels model car.

“It’s about going, ‘Oh, I didn’t think about that!’” said Carrie Buse, director of product design at Mattel Future Lab in El Segundo, California. She sees the AI technology as a tool to help designers generate more ideas. “Ultimately, quality is the most important thing,” she noted. “But sometimes quantity can help you find the quality.”

Microsoft is also integrating DALL∙E 2 into its consumer apps and services starting with the newly announced Microsoft Designer app, and it will soon be integrated into Image Creator in Microsoft Bing.

The rollout of DALL∙E 2 across Microsoft products and services reflects how the company’s investment in AI research is infusing AI into everything it builds, produces and delivers to help everyone boost productivity and innovation.

Over the last 18 months, we’ve seen this transition in technology from proving that you can do things with AI to mapping it to actual scenarios and processes where it’s useful to the end user.

The trend is the result of nonlinear breakthroughs in AI capabilities achieved by bringing more compute to more data to train richer and more powerful models, according to Eric Boyd, Microsoft corporate vice president for AI Platform.

“The power of the models has crossed this threshold of quality and now they’re useful in more applications,” he said. “The other trend that we’re seeing is all the product developers are thinking through and understanding the ways that they can use AI in their products for both ease of use as well as saying, ‘Oh, I can make my product work better if I use AI.’”

DALL∙E 2 was trained on a supercomputer hosted in Azure that Microsoft built exclusively for OpenAI. The same Azure supercomputer was also used to train OpenAI’s GPT-3 natural language models and Codex, the model that powers GitHub Copilot and certain features in Microsoft Power Apps that run on Azure OpenAI Service. Azure also makes it possible for these AI tools to rapidly generate image, text or code suggestions for a person to review and consider using.

The addition of DALL∙E 2 builds on Microsoft and OpenAI’s ongoing partnership and expands the breadth of use cases within Azure OpenAI Service, the newest in the Azure Cognitive Services family currently in preview, which offers the security, reliability, compliance, data privacy and other enterprise-grade capabilities built into Microsoft Azure.

Other AI technologies developed by Microsoft and available through Azure Cognitive Services such as language translation, speech transcription, optical character recognition and document summarization are showing up in products and services such as Microsoft Teams, Microsoft Power Platform and Microsoft 365.

“Over the last 18 months, we’ve seen this transition in technology from proving that you can do things with AI to mapping it to actual scenarios and processes where it’s useful to the end user,” said Charles Lamanna, Microsoft corporate vice president of business applications and platform. “It’s the productization of these very large language models.”

‘Whenever I get an email from my boss, send a text message to my phone’

These AI capabilities are aimed at eliminating tedious work and enabling employees to focus on higher-value tasks, such as freeing sales associates to engage in conversations with customers without having to take notes, Lamanna said. These new tools can also automate processes that currently eat up hours of people’s workdays such as writing summaries of sales calls and adding them to a client database.

“We can now inject AI that listens to our conversation and helps people be more productive by creating transcripts, capturing action items, doing summarization of the meeting, identifying common phrases or doing analysis about, ‘Am I a good listener?’” said Lamanna. “That required the advancement of the state-of-the-art AI and the advancement of these digital collaboration tools.”

Lamanna is focused on creating tools that enable anyone with a computing device to create their own AI-powered applications using the Microsoft Power Platform. For example, his team is rolling out a feature in Power Automate with AI powered copilot capabilities that allow people to use natural language to build workflow processes that connect various services running in the Microsoft cloud.

“Users in normal language can say, ‘Hey, whenever I get an email from my boss, send a text message to my phone and put a to-do in my Outlook,’” Lamanna explained. “They can just say that, and it gets generated automatically.”

Click here to load media

This ability to turn a sentence into a workflow dramatically expands the number of people who can create AI-powered software solutions, he said. People with a touch more technical know-how can further customize and refine their applications with low-code tools and graphical interfaces available in the Power Platform such as the intelligent document processing technology in AI Builder, he added.

A lawyer could use this technology to build a customized application that is triggered whenever a new contract is uploaded to the firm’s SharePoint site. This app could extract key information such as who wrote the contract, the parties involved and the industry sector and then email a summary of the contract with these details to lawyers in the firm who cover the sector or clients.

“That’s kind of magic,” said Lamanna, contrasting this type of AI automated workflow to how such tasks are typically accomplished today. “You check the SharePoint site, open a new file, and skim and try to summarize it to see if you have to do anything with it. AI is getting people out of this monotony and getting computers to do what’s best for them to do anyway.”

Content AI

The digital transformation of the past several years has added to the flood of content that people around the world produce. Microsoft customers, for example, now add about 1.6 billion pieces of content every day to Microsoft 365. Think marketing presentations, contracts, invoices and work orders along with video recordings and transcripts of Teams meetings.

“They’re creating documents, they’re collaborating on them in Teams and they are storing them in SharePoint-powered experiences,” said Jeff Teper, Microsoft president of collaborative apps and platform. “What we want to do is integrate AI technologies with this content so clients can do more structured activities like contract approvals, invoice management and regulatory filings.”

That’s why Microsoft created Microsoft Syntex, a new content AI offering for Microsoft 365 that leverages Azure Cognitive Services and other AI technologies to transform how content is created, processed and discovered. It reads, tags and indexes content – whether digital or paper – making it searchable and available within specific applications or as reusable knowledge. It can also manage the content lifecycle with security and retention settings.

Click here to load media

For instance, TaylorMade Golf Company turned to Microsoft Syntex for a comprehensive document management system to organize and secure emails, attachments and other documents for intellectual property and patent filings. At the time, company lawyers manually managed this content, spending hours filing and moving documents to be shared and processed later.

With Microsoft Syntex, these documents are automatically classified, tagged and filtered in a way that’s more secure and makes them easy to find through search instead of needing to dig through a traditional file and folder system. TaylorMade is also exploring ways to use Microsoft Syntex to automatically process orders, receipts and other transactional documents for the accounts payable and finance teams.

Other customers are using Microsoft Syntex for contract management and assembly, noted Teper. While every contract may have unique elements, they are constructed with common clauses around financial terms, change control, timeline and so forth. Rather than write those common clauses from scratch each time, people can use Syntex to assemble them from various documents and then introduce changes.

“They need AI and machine learning to spot, ‘Hey, this paragraph is very different from our standard terms. This could use some extra oversight,’” he said.

“If you’re trying to read a 100-page contract and look for the thing that’s significantly changed, that’s a lot of work versus the AI helping with that,” he added. “And then there’s the workflow around those contracts: Who approves them? Where are they stored? How do you find them later on? There’s a big part of this that’s metadata.”

When DALL∙E 2 gets personal

The availability of DALL∙E 2 in Azure OpenAI Service has sparked a series of explorations at RTL Deutschland, Germany’s largest privately held cross-media company, about how to generate personalized images based on customers’ interests. For example, in RTL’s data, research and AI competence center, data scientists are testing various strategies to enhance the user experience by generative imagery.

RTL Deutschland’s streaming service RTL+ is expanding to offer on-demand access to millions of videos, music albums, podcasts, audiobooks and e-magazines. The platform relies heavily on images to grab people’s attention, said Marc Egger, senior vice president of data products and technology for the RTL data team.

“Even if you have the perfect recommendation, you still don’t know whether the user will click on it because the user is using visual cues to decide whether he or she is interested in consuming something. So artwork is really important, and you have to have the right artwork for the right person,” he said.

Imagine a romcom movie about a professional soccer player who gets transferred to Paris and falls in love with a French sportswriter. A sports fan might be more inclined to check out the movie if there’s an image of a soccer game. Someone who loves romance novels or travel might be more interested in an image of the couple kissing under the Eiffel Tower.

Combining the power of DALL∙E 2 and metadata about what kind of content a user has interacted with in the past offers the potential to offer personalized imagery on a previously inconceivable scale, Egger said.

“If you have millions of users and millions of assets, you have the problem that you simply can’t scale it – the workforce doesn’t exist,” he said. “You would never have enough graphic designers to create all the personalized images you want. So, this is an enabling technology for doing things you would not otherwise be able to do.”

Egger’s team is also considering how to use DALL∙E 2 in Azure OpenAI Service to create visuals for content that currently lacks imagery, such as podcast episodes and scenes in audiobooks. For instance, metadata from a podcast episode could be used to generate a unique image to accompany it, rather than repeating the same generic podcast image over and over.

Along similar lines, a person who is listening to an audiobook on their phone would typically look at the same book cover art for each chapter. DALL∙E 2 could be used to generate a unique image to accompany each scene in each chapter.

Using DALL∙E 2 through Azure OpenAI Service, Egger added, provides access to other Azure services and tools in one place, which allows his team to work efficiently and seamlessly. “As with all other software-as-a-service products, we can be sure that if we need massive amounts of imagery created by DALL∙E, we are not worried about having it online.”

The appropriate and responsible use of DALL∙E 2

No AI technology has elicited as much excitement as systems such as DALL∙E 2 that can generate images from natural language descriptions, according to Sarah Bird, a Microsoft principal group project manager for Azure AI.

“People love images, and for someone like me who is not visually artistic at all, I’m able to make something much more beautiful than I would ever be able to using other visual tools,” she said of DALL∙E 2. “It’s giving humans a new tool to express themselves creatively and communicate in compelling and fun and engaging ways.”

Her team focuses on the development of tools and techniques that guide people toward the appropriate and responsible use of AI tools such as DALL∙E 2 in Azure AI and that limit their use in ways that could cause harm.

To help prevent DALL∙E 2 from delivering inappropriate outputs in Azure OpenAI Service, OpenAI removed the most explicit sexual and violent content from the dataset used to train the model, and Azure AI deployed filters to reject prompts that violate content policy.

In addition, the team has integrated techniques that prevent DALL∙E 2 from creating images of celebrities as well as objects that are commonly used to try to trick the system into generating sexual or violent content. On the output side, the team has added models that remove AI generated images that appear to contain adult, gore and other types of inappropriate content.

We’re designing the interfaces to help users … use this tool to get the representation they want.

DALL∙E 2 is still subject to a challenge that many AI systems encounter: the system is only as good as the data used to train it. Without the benefit of context that provides insight to user intent, less descriptive prompts to DALL-E 2 can surface biases embedded in the training data – text and images from the internet.

That’s why Bird is working with Microsoft product teams to teach people how to use DALL∙E 2 in ways that help them achieve their goals – such as using more descriptive prompts that help the AI system better understand what results they’re after.

“We’re designing the interfaces to help users be more successful in what it’s generating, and sharing the limitations today, so that users are able to use this tool to get the representation that they want, not whatever average representation exists on the internet,” she said.

‘How do you predict the future?’

Buse recently joined the Mattel Future Lab, which is exploring ideas such as the metaverse and NFTs, or non-fungible tokens, to expand the reach of the toy business. She’s using DALL∙E 2 as a tool to help her imagine what these virtual experiences could look like.

“It’s fun to poke around in here to think about what would come up in a virtual world based on – pick a descriptor – a forest, mermaids, whatever,” she said, explaining that DALL∙E 2 is helping her team predict this future. “How do you predict the future? You keep feeding yourself more information, more imagery and thoughts to try and imagine how this would come together.”

Boyd, the Microsoft corporate vice president for Azure Platform, said DALL∙E 2 and the family of large language models that underpins it are unlocking this creative force across customers. The AI system is fuel for the imagination, enabling users to think of new and interesting ideas and bring them alive in their presentations and documents.

“What is most exciting, I think, is we’re just scratching the surface on the power of these large language models,” he said.

Related:

Top image: Mattel toy designers are investigating how to use images generated by DALL∙E 2 in Azure OpenAI Service to help inspire new Hot Wheels designs. By typing plain language prompts like “A DTM race car like a hot rod” or “A Bonneville salt flats racer like a DTM race car,” they can generate multiple images to help spark creativity and inform final designs.

John Roach writes about Microsoft research and innovation. Follow him on Twitter."
Microsoft_News,https://news.microsoft.com/source/features/ai/microsoft-open-sources-its-farm-of-the-future-toolkit/,,Microsoft open sources its ‘farm of the future’ toolkit,"FARMINGTON, Wash. – The gently rolling hills here in eastern Washington have long grown rich harvests of wheat, barley and lentils.

Fifth-generation farmer Andrew Nelson is adding a new bumper crop to that bounty: Data.

He gathers it from sensors in the soil, drones in the sky and satellites in space. They feed Nelson information about his farm at distinct points, every day, all year long — temperature variations, soil moisture and nutrient levels, plant health and more.

Nelson in turn feeds that data into Project FarmVibes, a new suite of farm-focused technologies from Microsoft Research. Starting today, Microsoft will open source these tools so researchers and data scientists — and the rare farmer like Nelson, who is also a software engineer — can build upon them to turn agricultural data into action that can help boost yields and cut costs.

The first open-source release is FarmVibes.AI. It is a sample set of algorithms aimed at inspiring the research and data science community to advance data-driven agriculture. Nelson is using this AI-powered toolkit to help guide decisions at every phase of farming, from before seeds go into the ground until well after harvest.

FarmVibes.AI algorithms, which run on Microsoft Azure, predict the ideal amounts of fertilizer and herbicide Nelson should use and where to apply them; forecast temperatures and wind speeds across his fields, informing when and where he plants and sprays; determine the ideal depth to plant seeds based on soil moisture; and tell him how different crops and practices can keep carbon sequestered in his soil.

“Project FarmVibes is allowing us to build the farm of the future,” said Nelson, who has partnered with Microsoft Research to turn his 7,500 acres into a proving ground for Project FarmVibes. “We’re showcasing the impact technology and AI can have in agriculture. For me, Project FarmVibes is saving a lot in time, it’s saving a lot in costs and it’s helping us control any issues we have on the farm.”

The new tools sprouted from Microsoft’s work with large customers like Land O’ Lakes and Bayer to integrate and analyze data. Project FarmVibes reflects more recent research in precision and sustainable agriculture.

By open sourcing its latest research tools, Microsoft wants to spread them far beyond Washington to help tackle the world’s urgent food problem, said Ranveer Chandra, managing director of Research for Industry.

By 2050, we’ll need to roughly double global food production to feed the planet, Chandra said. But as climate change accelerates, water levels drop and arable lands vanish, doing that sustainably will be a huge challenge.

“We believe one of the most promising approaches to address this problem is data-driven agriculture,” he said.

At Microsoft, we are working to empower growers with data and AI to augment their knowledge about farming and help them grow nutritious food in a sustainable way.

Research bears fruit

Until recently, Nelson’s farm was like many others around the world. He had internet in his home, but the Wi-Fi signal ended outside his door. His 7,500 acres were a dead zone.

Now he’s using a Project FarmVibes solution, called FarmVibes.Connect, which will eventually be open sourced by Microsoft to bring connectivity to remote and rural places. It delivers broadband access via TV white spaces, the unused spectrum that flickers as “snow” between channels. Today, Nelson has a solar-powered TV white spaces antenna that acts like a Wi-Fi router, but one that can cover most of his farm.

That connectivity has allowed him to glean insights from the FarmVibes.AI suite. Now available in GitHub, FarmVibes.AI includes:"
Microsoft_News,https://news.microsoft.com/apac/features/ai-drones-dolphins-maui63/,,AI-equipped drones study dolphins on the edge of extinction,"Small in size and with distinctive, rounded dorsal fin, Māui dolphins are one of the rarest and most threatened dolphins in the sea, with a known population of just 54. Decades of fishing practices, such as gillnetting off the west coast of New Zealand in the South Pacific have pushed this sub-species to near extinction.

Photo courtesy of MAUI63.

Now scientists and conservationists are using a combination of drones, AI and cloud technologies to learn more about these rare marine mammals. They say the solution can also be applied to study other species fighting for survival in the world’s oceans.

The effort is part of a growing trend toward using AI and other technologies to more effectively collect and analyze data for environmental conservation. For example, Microsoft AI for Earth’s partner, Conservation Metrics, combines machine learning, remote sensing and scientific expertise to increase the scale and effectiveness of wildlife surveys. NatureServe, another partner organization, leverages Esri ArcGIS tools and Microsoft cloud computing to generate high-resolution habitat maps for imperiled species.

The scientists and conservationists with the not-for-profit group MAUI63 are using AI and other tools to support the conservation of the Māui dolphins, named after the Polynesian demigod, Māui.

From left, Willy Wang, MAUI63 co-founder, Hayley Nessia, pilot, Pete Carscallen, pilot and Tane van der Boon, MAUI63 co-founder, pose after a survey flight. Photo courtesy of MAUI63.

Māui dolphins play an important part of the ecological and spiritual fabric of Aotearoa — the Māori name for New Zealand. They inhabit the waters off the west coast of the country’s North Island — also known as Te Ika-a-Māui, which translates to “the Fish of Māui.”

Weighing 50 kilograms and measuring up to 1.7 meters when fully grown, Māui dolphins are one of the smallest members of the marine dolphin family and among the most elusive. They have white, grey and black markings and black rounded dorsal fins. Unlike human facial features, the markings don’t vary between animals, meaning individuals can’t be identified with the naked eye. Conventional ways of monitoring and studying these fast-moving animals at sea have proved problematic and costly. Researchers admit relatively little is known about their behavior, particularly in winter when weather conditions deteriorate.

Now, MAUI63 believes it has a solution: an AI-powered drone that can efficiently find, track and identify dolphins. The aim of their work, according to co-founder and marine biologist, Professor Rochelle Constantine, is to “give certainty to our uncertainty.”

“Currently everything we know about them is from summer. We know virtually nothing about them in winter,” she says.

Constantine, together with technology and innovation specialist Tane van der Boon and drone enthusiast Willy Wang, formed MAUI63 in 2018. At the time, the Māui dolphin population was estimated at 63 individuals. That figure has since dropped to 54.

Over drinks at a pub, Van der Boon, who is the group’s CEO, and Wang came up with the idea of leveraging drones, machine learning and cloud computing to study the dolphins. “I was getting interested in computer learning — I really saw how teaching computers to see is quite an amazing thing. All the things that we could start to solve and do really intrigued me,” he says.

The Māui dolphins’ rounded fins differ from the more pointed-shaped fins of other dolphins. That meant existing computer vision models were not fit for identifying Māui dolphins. So, van der Boon spent “a couple of months of nights and weekends” teaching himself how to build a model. He then painstakingly tagged Māui dolphin images from internet footage to train it to identify them.

Māui dolphins, including young calf, swim off the coast of Hamiltons Gap in Auckland, New Zealand. Photo courtesy of University of Auckland, Oregon State and the Department of Conservation.

It was the first challenge of many. Four years of development, testing and fundraising followed. The team also had to gain specialist qualifications to fly their 4.5 meter-wingspan drone out to sea. They spotted their first Māui dolphins earlier this year.

“It was pretty exciting. We were sitting in the van, the drone was 16 kilometers down the coast, and we could see the AI detecting dolphins as we were doing circles around them,” van der Boon says.

Development has been helped along by funding under New Zealand’s Cloud and AI Country plan, which includes funding for projects with sustainable societal impact, as well as support from Microsoft Philanthropies ANZ. The solution combines an 8K ultra high-definition still camera and a full HD gimbal camera with an object detection model for spotting dolphins, and an open-source algorithm originally developed for facial recognition. Hosted on Microsoft Azure, it gathers data that will be used to identify individual animals by the shape and size of their dorsal fins and any scratches and marks on them.

MAUI63 is also developing an app called Sea Spotter, funded by Microsoft, which uses Azure Functions to allow people to upload photos of Māui sightings and use an AI algorithm to learn which individual they saw. Being able to pinpoint the Māui dolphin’s habitat is crucial for understanding how to protect them against threats, according to the conservationists.

Constantine says the risk of Māui dolphins being caught as bycatch in the nets of fishing boats is now “extremely low” thanks to a marine sanctuary that was put in place around their known habitat in 2008 and expanded in 2020. Nonetheless, they may stray outside these protected areas. That is why MAUI63 is working on an integration project with fishing companies to ultimately notify their crews of sightings made by the drone in real time.

MAUI63 uses an object detection computer vision model to spot dolphins from the drone footage that was collected as a part of a survey. Photo courtesy of MAUI63.

Another threat is toxoplasmosis, a disease caused by a parasite that lives in cat feces. It enters the marine food chain through runoff from the land, causing stillbirths and death in marine mammals. “If you understand where dolphins are on a regular basis, you can start to look at the areas where toxoplasmosis might be entering the water and maybe something can be done about that,” says van der Boon.

MAUI63’s aim is to provide scientifically robust information to conservation decision-makers. “We’re just trying to collect the data and make it available to anyone who needs it. We’re not here to make decisions on how they should or shouldn’t be protected. That’s key to us because everyone has quite different views on it,” says van der Boon. At this stage, he says, it is far from certain that MAUI63’s work will help prevent extinction, but what everyone can agree on is that it is worth trying.

Māui dolphins hold a special significance for many indigenous Māori — they are considered to be kaitiaki (guardians) that helped guide the waka (canoes) of their ancestors when they first came to Aotearoa hundreds of years ago.

Environmental scientist Dr. Aroha Spinks says protecting them is essential to increasing the mauri, or life force, of the environment. “From a Māori point of view — which is also backed up by science — the health of the environment affects the health and wellbeing of the people,” she says.

MAUI63 plans to make its learnings and technology available to people working with other marine species, such as a potential project in Antarctica with the European Union Environmental Council. Constantine hopes the high-tech approach will be as game changing for other researchers as it has been for her. “It makes such a huge difference to my world and the conversations I can have, and the information we can give to governments and the public about how to make conservation decisions that really matter.”

Top image: MAUI63 uses a combination of drones, AI and cloud technologies to learn more about Maui dolphins. Video courtesy of MAUI63."
Microsoft_News,https://news.microsoft.com/source/features/innovation/microsoft-launches-project-airsim-an-end-to-end-platform-to-accelerate-autonomous-flight/,,"Microsoft launches Project AirSim, an end-to-end platform to accelerate autonomous flight","Josh Riedy knew it wasn’t real – that he wasn’t actually hovering near the top of a wind turbine in North Dakota, hundreds of feet off the ground. But it didn’t matter when he looked down. His stomach still dropped as if he were on a rollercoaster.

The CEO of Airtonomy was inside a digital replica of a real wind farm at the time, trailing a simulated drone through virtual reality glasses as it inspected towering turbines. His North Dakota-based company has been using these hyper-realistic simulations to train autonomous aerial vehicles that are now inspecting wind farms, surveying wildlife and detecting leaks in oil tanks across the Midwest.

Every one of those AI-powered flights first happened countless times in simulated 3D worlds. Because if AI is the key to building autonomy in the air, data is the key to building AI – data that is impossible to get in the real world, Riedy said.

“You don’t want to fly drones into wind turbines, powerlines or really anything for that matter,” Riedy said. “Coupled with the fact that winter can literally last 7 months in North Dakota, we realized we needed something other than the physical world to design our solutions for customers.”

The answer was Microsoft’s Project AirSim, announced today at the Farnborough International Airshow. Project AirSim is a new platform running on Microsoft Azure to safely build, train and test autonomous aircraft through high-fidelity simulation.

In these realistic environments, AI models can run through millions of flights in seconds, learning how to react to countless variables much like they would in the physical world: How would the vehicle fly in rain, sleet or snow? How would strong winds or high temperatures affect battery life? Can the drone’s camera see a turbine’s arms on an overcast day just as well as a clear one?

Click here to load media

Project AirSim uses the power of Azure to generate massive amounts of data for training AI models on exactly which actions to take at each phase of flight, from takeoff to cruising to landing. It will also offer libraries of simulated 3D environments representing diverse urban and rural landscapes as well as a suite of sophisticated pretrained AI models to help accelerate autonomy in aerial infrastructure inspection, last-mile delivery and urban air mobility.

Project AirSim is available today in limited preview. Interested customers can contact the Project AirSim team to learn more.

It arrives as advances in AI, computing and sensor technology are beginning to transform how we move people and goods, said Gurdeep Pall, Microsoft corporate vice president for Business Incubations in Technology & Research. And this isn’t just happening in remote areas home to wind farms; with urban density on the rise, gridlocked roads and highways simply can’t cut it as the quickest way to get from Point A to Point B. Instead, businesses will look to the skies and autonomous aircraft.

“Autonomous systems will transform many industries and enable many aerial scenarios, from the last-mile delivery of goods in congested cities to the inspection of downed power lines from 1,000 miles away,” Pall said. “But first we must safely train these systems in a realistic, virtualized world. Project AirSim is a critical tool that lets us bridge the world of bits and the world of atoms, and it shows the power of the industrial metaverse – the virtual worlds where businesses will build, test and hone solutions and then bring them into the real world.”

Accelerating aerial autonomy

High-fidelity simulation was at the heart of AirSim, an earlier open-source project from Microsoft Research that is being retired but inspired today’s launch. AirSim was a popular research tool, but it required deep expertise in coding and machine learning.

Now, Microsoft has transformed that open-source tool into an end-to-end platform that allows Advanced Aerial Mobility (AAM) customers to more easily test and train AI-powered aircraft in simulated 3D environments.

“Everyone talks about AI, but very few companies are capable of building it at scale,” said Balinder Malhi, engineering lead for Project AirSim. “We created Project AirSim with the key capabilities we believe will help democratize and accelerate aerial autonomy – namely, the ability to accurately simulate the real world, capture and process massive amounts of data and encode autonomy without the need for deep expertise in AI.”

With Project AirSim, developers will be able to access pretrained AI building blocks, including advanced models for detecting and avoiding obstacles and executing precision landings. These out-of-the-box capabilities eliminate the need for deep machine learning expertise, helping expand the universe of people who can start training autonomous aircraft, Malhi said.

Airtonomy, which participated in an early access program for Project AirSim, used it to help customers launch remote inspections of critical infrastructure quickly and safely, without the time, expense and risk of sending a crew to remote locations – and without deep technical backgrounds.

“We create autonomous capture routines for the frontline worker – people who don’t use drones and robots on a regular basis but need them to act like any other tool within their service vehicle,” Riedy said. With Airtonomy, not only does the drone inspect the asset automatically, the captured data is automatically contextualized at the moment of capture. These features can be extended to any asset in any industry, enabling novel and automated end-to-end workflows.

“It’s amazing to see those responsible for our nation’s infrastructure use these tools literally with a push of a button and have a digital representation at their fingertips for things like outages, disaster response or route maintenance. Project AirSim is transforming how robotics and AI can be used in an applied fashion,” he said.

Using data from Bing Maps and other providers, Project AirSim customers will also be able to create millions of detailed 3D environments and also access a library of specific locations, like New York City or London, or generic spaces, like an airport.

Microsoft is also working closely with industry partners to extend accurate simulation to weather, physics and – crucially – the sensors an autonomous machine uses to “see” the world. A collaboration with Ansys leverages their high-fidelity physics-based sensor simulations to enable customers with rich ground truth information for autonomous vehicles. Meanwhile, Microsoft and MathWorks are working together so customers can bring their own physics models to the AirSim platform using Simulink.

As simulated flights occur, huge volumes of data get generated. Developers capture all that data and use it to train AI models through various machine learning methods.

Gathering this data is impossible to do in the real world, where you can’t afford to make millions of mistakes, said Matt Holvey, director of intelligent systems at Bell , which also participated in Project AirSim’s early access program. Often, you can’t afford to make one.

Given that, Bell is turning to Project AirSim to hone the ability of its drones to land autonomously. It’s a tough problem. What if the landing pad is covered in snow, or leaves or standing water? Will the aircraft be able to recognize it? What if the rotor blades kick up dust, obscuring the vehicle’s vision? AirSim let Bell train its AI model on thousands of ‘what if’ scenarios in a matter of minutes, helping it practice and perfect a critical maneuver before attempting it in the real world.

The future of autonomous flight

The emerging world of advanced aerial mobility will launch a diverse cast of vehicles into the skies, from hobbyist drones to sophisticated eVTOLs (electric vertical take-off and landing) aircraft carrying passengers. And the potential use cases are almost limitless, Microsoft says: inspecting powerlines and ports, ferrying packages and people in crowded cities, operating deep inside cramped mines or high above farmlands.

But technology alone won’t usher in the world of autonomous flight. The industry must also chart a pathway through the world’s airspace monitoring systems and regulatory environments. The Project AirSim team is actively engaged with standards bodies, civil aviation and regulatory agencies in shaping the necessary standards and means of compliance to accelerate this industry.

Microsoft also plans to work with global civil aviation regulators on how Project AirSim might help with the certification of safe autonomous systems, Pall said, potentially creating scenarios inside AirSim that an autonomous vehicle must successfully navigate. In one case there is blinding rain, in one case deep winds, in one case it loses GPS connectivity. If the vehicle can still get from Point A to Point B every time, Pall said, that could be an important step toward certification.

Project AirSim is a critical tool that lets us bridge the world of bits and the world of atoms, and it shows the power of the industrial metaverse.

And the industry is moving closer toward scalable commercial operation of autonomous systems. Bell recently used Project AirSim to prepare for NASA’s Systems Integration and Operationalization (SIO) extension project, which aims to accelerate the use of autonomous aircraft in the national airspace system. The company’s Autonomous Pod Transport (APT) aircraft flew through a corridor in the Dallas-Fort Worth area, successfully demonstrating the craft’s ability to maintain contact with ground-based radar monitoring systems.

“AirSim allowed us to get a true understanding of what to expect before we flew in the real world,” Bell’s Holvey said. “It’s going to be one of the tools that will accelerate the timeline for scaling aerial mobility. If we have to test and validate everything by hand, or in a physical lab, or on a flying aircraft, we’re talking about decades, and it’s going to cost billions. But Project AirSim pulls that forward through high-fidelity simulation.”

Ashish Kapoor, the creator of the of the original AirSim in Microsoft Research, is proud to have helped the simulation engine evolve from a research tool that existed largely in code into a more robust platform that any business can use without a deep technical background. An aviator himself, Kapoor can’t wait to see what that means for the world of flight.

“A ton of data gets generated when an aircraft flies through space in Project AirSim,” said Kapoor, now general manager of Microsoft’s autonomous systems research group. “Our ability to capture that data and translate it into autonomy is going to significantly change the landscape of aviation. And because of that we are going to see many more vehicles in the sky, helping to monitor farms, inspect critical infrastructure and transport goods and people to the remotest of places.”

Related links:

Learn more: Project AirSim

Read more: How autonomous systems use AI to learn from the world around it

Top image: A simulated drone inspects a Seattle cell tower inside Project AirSim, a new platform to safely build, train and test autonomous aircraft through high-fidelity simulation. Video from Microsoft.

Jake Siegel writes about Microsoft research and innovation."
Microsoft_News,https://news.microsoft.com/source/features/ai/eedi-online-math-quiz/,,AI helps create personalized math lessons for students,"Like many students around the world, Eithne, 14, in Chorley, United Kingdom, was struggling to keep up in math at school after more than a year of COVID-19 related disruptions. In June 2021, her parents signed her up for a summer program offered by Eedi, an online math tutoring service.

“Just dealing with lockdown, she hadn’t had enough of a really good background,” said her mother, Arianna. “She missed most of the Year 7 Maths, then Year 8. So, we thought, ‘Let’s give it a go, let’s see where she needs a bit of help.’”

Newly enrolled students on Eedi are asked to take a dynamic quiz of 10 multiple choice diagnostic questions that the service uses to learn where students struggle most in math. This information allows the service to place students on a learning pathway to overcome those specific obstacles, or misconceptions.

“We ask them a question based roughly on their age group and then we say, ‘Well, what’s the next best question to ask them based on their previous answer?’” explained Iris Hulls, the head of operations at Eedi. “We learn as much about them as possible to predict either growth or comfort topics for them.”

The dynamic quiz is powered by AI developed by researchers at the Microsoft Research Lab in Cambridge, United Kingdom, who specialize in machine learning algorithms that help people make decisions.

The AI uses each answer to predict the probability the student will correctly answer each of thousands of other possible next questions and then weighs those probabilities to decide what question to ask next to pinpoint knowledge gaps.

The information gleaned from the quiz is akin to what a teacher might learn from a one-on-one conversation with a student, explained Cheng Zhang, a Microsoft principal researcher at the lab who led the development of the machine learning model that powers Eedi’s dynamic quiz.

“If the student doesn’t know 3 times 7, we may want to ask 1 plus 1,” Zhang said. “We want to adapt the quiz based on the previous answer.”

Once students’ misconceptions are identified, the Eedi platform slots students onto a learning pathway that helps them overcome their misconceptions and do better in math at school.

Eithne was slotted onto a pathway that included a review of topics covered in Year 8 and prepared her for success in Year 9, including geometry.

“It’s very good for finding your weaknesses and your strengths and being able to understand why you’re maybe not as good in this one area,” Eithne said. “You’re able to realize, ‘I’ve been doing this wrong for ages.’”

Good questions, good data

The success of Microsoft’s next-best-question model hinges on the data used to train it, noted Zhang. In Eedi’s case, these are thousands of vetted, high-quality diagnostic questions developed specifically to help teachers identify student misconceptions about math topics.

“Our technology is just an enhancer that makes this high-quality data give more insights,” Zhang said.

Diagnostic questions are well-thought-through multiple choice questions that have one correct answer and three wrong answers, with each wrong answer designed to reveal a specific misconception.

“Maths lends itself quite well to this kind of multiple-choice assessment because more often than not there’s a right answer and these wrong answers; it’s much less subjective than some of the humanities subjects,” said Craig Barton, an Eedi co-founder and the company’s director of education.

Barton latched on to the power of diagnostic questions when, as a math teacher, he attended a training course on formative assessments and learned that well-formulated wrong answers can provide insight to why a student is struggling.

“In the past, it was always kids got things right, which is fine, or they got things wrong and then I had to start doing detective work to figure out where they were going wrong,” he said. “That’s okay if you work one-to-one, but if you’ve got 30 kids in a class, that’s potentially quite time consuming.”

Good diagnostic questions, Barton said, must be clear and unambiguous, check for one thing, be answerable in 20 seconds, link each wrong answer to a misconception and ensure that a student is unable to answer it correctly while having a key misconception.

“This notion that the kids can’t get it right whilst having a key misconception is the hardest one to factor in, but it’s probably the most important,” he said.

For example, consider the question: “Which of the following is a multiple of 6? – A: 20, B: 62, C: 24, or D: 26.”

According to Barton, on the surface this is a decent question. That’s because students could think a “multiple” means the “6” is the first number (B) or last number (D), or the student could have difficulty with their multiplication tables and select A. The correct answer is C: 24.

“But the major flaw in this question is if you don’t know the difference between a factor and a multiple, you could get this question right, whereas experience will tell us that the biggest misconception students have with multiples is they mix them up with factors,” he said.

A better question to ask, then, is, “Which of these is a multiple of 15? – A: 1, B: 5, C: 60 or D: 55.” That’s because the possible answers include factors and multiples. The correct answer is C: 60. A student who confuses factors with multiples might instead pick A: 1 or B: 5, and a student who needs work on multiplication might pick D: 55.

“When you write these things, you’ve really got to think, ‘What are all the different ways kids can go wrong and how am I going to capture those in three wrong answers?’” Barton explained.

Teacher tools to online tutor

After the workshop, Barton went home and wrote about 50 diagnostic questions and tested them out on students in his class. They worked.

Barton is also a math book author and podcaster with thousands of followers on social media. He used his influence to spread the word on diagnostic questions and collaborated with Eedi co-founder Simon Woodhead to build an online database with thousands of diagnostic questions for teachers to access for their lesson planning.

“Then I thought, ‘Wait a minute, we could do something a bit better than this,’” Barton said. “’Imagine if the kids could answer the questions online and we could capture that data and then, before you know it, we’ve got insights into specific areas where students struggle.’”

The website exploded in popularity and attracted investors as well as the attention of Hulls, who along with colleagues was exploring options to use data to scale and make the benefits of math tutoring accessible to more families. The team formed Eedi. An advisor introduced them to Zhang and her team’s research on the next-best-question algorithm, which aims to accelerate decision making by gathering and analyzing relevant personal information.

At the time, the Microsoft researchers were working on healthcare scenarios, using AI to help doctors more efficiently make decisions about what tests to order to diagnose patient ailments.

For example, if a patient walks into an emergency room with a hurt arm, the doctor will ask a series of questions leading up to an X-ray, such as “How did you hurt your arm?” and, “Can you move your fingers?” instead of, “Do you have a cold?” because the answer will reveal relevant information for this patient’s treatment. The next-best-question algorithm automates this information gathering process.

The advisor thought the model would work well with Eedi’s dataset of diagnostic questions, automating the collection of information a tutor could glean from a one-on-one conversation with a student.

“We were aware that we had collected a lot of data. We wanted to do smarter stuff with our data; we wanted to be able to predict what misconceptions students might have before they even answer questions,” said Woodhead, who is Eedi’s chief data scientist.

The Eedi team worked with the Microsoft researchers to train the model on their diagnostic questions to efficiently pinpoint where students need the most support in math.

The model works without collecting any personal identifying information from the students, Woodhead noted.

“It doesn’t need to know a name. It doesn’t need to know an email address. It’s looking at patterns,” he said.

From this information, the system can pinpoint the best lessons for students to take on Eedi. Without that guidance, students tend to rely on strategies they’re already using at school, which isn’t the right starting point for the majority of students who are looking for a private tutor, according to Hulls.

“It really helps direct the children and their families at home to know where to start,” she said.

It’s a great idea that there might be personalized learning pathways or lessons for students. Not all students learn at the same pace, or in the same way.

Cause and effect

Eedi’s internal data shows that the tutoring service resolves 95% of the student misconceptions, noted Hulls, and students who use the platform overwhelmingly express greater confidence in math.

After the summer program on the Eedi platform, Eithne entered her Year 9 a step ahead of her classmates.

“I was like, ‘I can do this,’” she said. “I can actually explain to the people around me how to do the problems.”

Eithne has continued to use the Eedi platform, often turning to the service when she gets stuck on her homework. She enjoys a rewards program that incentivizes students to keep up with their lessons and finds the platform’s explanation of misconceptions helpful in learning key concepts.

The Eedi team is now working with Microsoft researchers to implement a next-generation machine learning model that builds on the deep end-to-end causal inference algorithm to recommend personalized learning pathways for each individual student.

“People think all students need to learn the Venn diagram first and then geometry. But maybe that is not the best for every single student. Every student learns differently,” Zhang said. “Maybe for one student the order should be switched, and for another student we need to revisit some other topic.”

This next-generation algorithm is at the forefront of causal machine learning, a field of research that incorporates the notion of cause and effect, of causality, into tools that help people make decisions.

“It’s a great idea that there might be personalized learning pathways or lessons for students,” said Arianna, Eithne’s mother. “Not all students learn at the same pace or in the same way.”

Related:

Learn more about Eedi.

Check out Cheng Zhang’s research at Microsoft.

John Roach writes about Microsoft research and innovation. Follow him on Twitter.

Top image: Eithne, 14, in Chorley, United Kingdom, does a lesson on the online math tutoring service Eedi. The service uses AI developed by Microsoft. Photo by Jonathan Banks."
Microsoft_News,https://news.microsoft.com/source/features/ai/azure-openai-service-helps-customers-accelerate-innovation-with-large-ai-models-microsoft-expands-availability/,,Build: Azure OpenAI Service helps customers accelerate innovation with large AI models; Microsoft expands availability,"Customers shopping for a used car can sometimes feel overwhelmed digging through countless specs and reviews, but CarMax, the largest used car retailer in the U.S., is making it easier for customers to find the most useful information.

Thanks to powerful AI language models, potential buyers can now see summaries of customer reviews for every make, model and year of vehicle that CarMax sells, about 5,000 combinations in a vast inventory of approximately 45,000 cars. The summaries provide easy-to-read takeaways from real customer reviews: whether it’s a great family car, how comfortable the ride is or if there’s enough space to pack for weekend adventures.

CarMax has also used the models to create new website content that allows customers to easily see what’s new for each version of a car, helping them decide whether new features are worth splurging on.

CarMax generated the massive amount of original content in just a few months — a rate previously impossible — with powerful GPT-3 natural language models built by the company OpenAI. To expand the work, CarMax is now using Azure OpenAI Service, which combines access to OpenAI’s models with Azure’s enterprise-grade capabilities such as security, compliance and regional availability.

“With Azure OpenAI Service, we are able to create content that empowers our customers so they can be informed before they make a decision,” said Shamim Mohammad, CarMax executive vice president and chief information and technology officer. “Being able to innovate at scale, being able to make our customers’ experience easier, being able to experiment — all those things are possible because of this service and the partnership we have with Microsoft.”

At its Microsoft Build conference today, Microsoft announced that Azure OpenAI Service is now available in a limited access preview. Customers who want to use the service can apply for access. Introduced at Microsoft Ignite 2021 as a new product within the Azure Cognitive Services family, a part of Azure AI, Azure OpenAI Service was previously available by invitation only.

With Azure OpenAI Service, we are able to create content that empowers our customers so they can be informed before they make a decision.

The service has a new responsible AI system that filters out harmful content and helps detect abuse. Additionally, Azure OpenAI Service now offers access to more models, including GPT-3, Codex and embeddings models. Codex can generate code and translate plain language to code, while embeddings make semantic search and other tasks easier. The service also offers new capabilities for customers to fine tune models for more tailored results.

Giving customers the guarantees and promises of Azure

Azure OpenAI Service is enabling customers across industries from health care to financial services to manufacturing to quickly perform an array of tasks. Innovations include generating unique content for customers, summarizing and classifying customer feedback, and extracting text from medical records to streamline billing. The most common uses have been writing assistance, translating natural language to code and gaining data insights through search, entity extraction, sentiment and classification.

“One of the most interesting things is the variety of use cases that can be supported off of a single model,” said Eric Boyd, corporate vice president for Azure AI at Microsoft. “Azure OpenAI Service is really leading the way with these new large language models and giving customers the guarantees and promises in Azure that this is going to be reliable and secure, and their privacy will be protected, as they explore this incredible frontier of what’s possible with these new technologies.”

Through OpenAI’s API and Azure OpenAI Service, CarMax used GPT-3 to abstractly summarize and fine tune 100,000 customer reviews into 5,000 well-written summaries. The job would have taken CarMax’s editorial team 11 years to complete, said Kevin Hopwood, a principal software engineer at the company.

The summaries and other model-generated content have improved customer engagement and search engine optimization, while the time saved has enabled CarMax’s content creators to focus on deeper research, long-form articles and more creative tasks, he said.

“The best thing we can do is free up their time so they can explore new content ideas and new ways to engage customers,” said Hopwood.

Click here to load media

Used car retailer CarMax has used Azure OpenAI Service to help summarize 100,000 customer reviews into short descriptions that surface key takeaways for each make, model and year of vehicle in its inventory.

Azure’s security, compliance, reliability and other enterprise-grade capabilities will enable CarMax to scale its use of GPT-3 in cases requiring the extraction of millions of keywords. The model’s ability to learn with just a few examples of intended outputs, a process called few-shot learning, will help CarMax’s 60 product teams use the models without needing any additional teams of data scientists.

“Being an Azure service, this tool puts a lot of power into our traditional Microsoft C# engineers that they didn’t have before,” said Sean Goetz, director, application systems at CarMax. “We can expand it to other teams just like any other Microsoft tool set.”

Building systems to support responsible AI

The power of GPT-3, which is pre-trained on a vast amount of internet text, comes with a risk of generating harmful or unintended results. Microsoft has made significant investments to help guard against abuse and unintended harm, which includes requiring applicants to show well-defined use cases and incorporate Microsoft’s principles for responsible AI use. One important way CarMax and other customers meet the criteria is by having humans in the loop to make sure model outputs are accurate and up to content standards before they’re published.

The new responsible AI system integrated in Azure OpenAI Service can help filter out content that is sexual, violent, hateful or related to self-harm. The team plans to add additional filters and customization features as they work with customers during the preview period and learn what’s needed in practice.

We’ve built the system not to say we’re filtering everything and we’ve got the right answer, but to be able to get that feedback and rapidly adapt.

The filtering system also identifies possible patterns of abuse or unintended harm, in which case Microsoft would work with customers to investigate, respond and block an abusive user if needed. An incident response team is available to quickly update content filters as language evolves. For example, if a new racial slur emerges, the team will rapidly respond and block the term as hate speech.

“We’ve built the system not to say we’re filtering everything and we’ve got the right answer, but to be able to get that feedback and rapidly adapt,” said Sarah Bird, Microsoft’s responsible AI lead for Azure AI. “We’re also not making a judgment about whether or not it’s OK for users to post certain content online. We’re saying we don’t think our AI system should generate this type of content.”

To help customers build robust systems, Microsoft is also providing UX design guidelines and patterns, and a transparency note describing the limits, intended uses and characteristics of the service.

“We think very carefully about the tools that we create and how they’re going to be used, and we’re really trying to make sure they’re going to be used responsibly so that the benefits of this technology can accrue to everybody,” Microsoft’s Boyd said.

Responsible AI principles have been a helpful guide for Farmlands, New Zealand’s largest rural supplies cooperative, where human reviewers are also part of its work with Azure OpenAI Service to improve customer service and generate new content for its website.

Farmlands used OpenAI’s API and Azure OpenAI Service to condense 350,000 customer interactions into brief write-ups that help call center associates quickly understand a customer’s situation and respond effectively. In the past, associates had to scroll through emails and case notes while keeping a customer on hold. The summaries can pick up subtleties like sarcasm and complexities like a case involving 11 interactions with a customer who received the wrong fuel.

“It saves our call center staff time and improves our customers’ experience,” said Gareth Pullar, an insights and analytics manager at Farmlands.

The retailer is also using the service to extract keywords from interactions and to classify interactions as “positive,” “neutral” or “negative.” It’s exploring an internal technical chatbot and the generation of product descriptions for its e-commerce site. Using Azure OpenAI Service means engineers, who use a full Azure stack, will be able to gain data insights into customer trends more easily, while scaling their use of model-generated content throughout the company, Pullar said.

“In terms of generating content, it’s a game-changer,” said Jean van Schalkwyk, Farmlands business intelligence lead. “It’s just really exciting technology.”

Related:

Top photo: Azure OpenAI Service helped CarMax turn 100,000 customer reviews into readable summaries that surface key takeaways and help people shopping for a used car make informed purchasing decisions. Photo courtesy of CarMax."
Microsoft_News,https://news.microsoft.com/source/features/ai/how-ai-makes-developers-lives-easier-and-helps-everybody-learn-to-develop-software/,,"How AI makes developers’ lives easier, and helps everybody learn to develop software","Ever since Ada Lovelace, a polymath often considered the first computer programmer, proposed in 1843 using holes punched into cards to solve mathematical equations on a never-built mechanical computer, software developers have been translating their solutions to problems into step-by-step instructions that computers can understand.

That’s now changing, according to Kevin Scott, Microsoft’s chief technology officer.

Today, AI-powered software development tools are allowing people to build software solutions using the same language that they use when they talk to other people. These AI-powered tools translate natural language into the programming languages that computers understand.

“That allows you, as a developer, to have an intent to accomplish something in your head that you can express in natural language and this technology translates it into code that achieves the intent you have,” Scott said. “That’s a fundamentally different way of thinking about development than we’ve had since the beginning of software.”

This paradigm shift is driven by Codex, a machine learning model from AI research and development company OpenAI that can translate natural language commands into code in more than a dozen programming languages.

Codex descended from GPT-3, OpenAI’s natural language model that was trained on petabytes of language data from the internet. Codex was trained on this language data as well as code from GitHub software repositories and other public sources.

“It makes coding more productive in terms of removing not-so-fun work and also helping you remember things you might have forgotten and helping you with the approach to solve problems,” Peter Welinder, vice president of products and partnerships for OpenAI, said of Codex.

Click here to load media

The increase in productivity that Codex brings to software development is a game changer, according to Scott. It allows developers to accomplish many tasks in two minutes that previously took two hours.

“And oftentimes, the things that the tools are doing is they are helping you to very quickly go through the least interesting parts of your job so that you can get to the most interesting parts of your job, which makes the qualitative experience of creating much more pleasant and stimulating and fun,” he said.

AI and code come together

Microsoft and OpenAI formed a partnership in 2019 to accelerate breakthroughs in AI – including jointly developing some of the world’s most powerful AI supercomputers – and deliver them to developers to build the next generation of AI applications through Azure OpenAI Service.

Microsoft subsidiary GitHub also worked with OpenAI to integrate Codex into GitHub Copilot, a downloadable extension for software development programs such as Visual Studio Code. The tool uses Codex to draw context from a developer’s existing code to suggest additional lines of code and functions. Developers can also describe what they want to accomplish in natural language, and Copilot will draw on its knowledge base and current context to surface an approach or solution.

GitHub Copilot, released in a technical preview in June 2021, today suggests about 35% of the code in popular languages like Java and Python generated by the tens of thousands of developers in the technical preview who regularly use GitHub Copilot. GitHub Copilot will move to general availability this summer, bringing this AI-assisted coding capability to millions of professional developers, Microsoft announced today at its Microsoft Build developer’s conference.

“A lot of software has common frameworks and pieces of scaffolding. Copilot does such an awesome job of doing all that for you so you can focus your energy and your creativity on the things that you’re trying to solve uniquely,” said Julia Liuson, president of the developer division at Microsoft, which includes GitHub.

As more developers experiment with Codex and GitHub Copilot, more clues to the potential of AI-assisted development are emerging, according to Welinder. For example, natural language documentation inside most software programs is sparse. Users of GitHub Copilot create this documentation by default as they use the tool.

“You get a bunch of comments in the code just from the nature of telling Copilot what to do,” he said. “You’re documenting the code as you go, which is mind-blowing.”

These comments, in turn, serve as a teaching tool for other developers, who often study other programs to learn how to solve specific problems in their own programs. The ability of Codex to translate from code to natural language is another way developers can learn as they program, which will lower the barrier of entry to coding, Welinder added.

From low code to no code

Meanwhile, AI-powered low code and no code tools, such as those available through Microsoft Power Platform, aim to enable billions of people to develop the software applications that they need to solve their unique problems, from an audiologist digitizing simple paper forms to transform hearing loss prevention in Australia to a tool that relieves the burden of manual data-entry work from employees of a family owned business and an enterprise grade solution that processes billions of dollars of COVID-19 loan forgiveness claims for small businesses.

Today, the hundreds of millions of people who are comfortable working with formulas in Microsoft Excel, a spreadsheet program, could easily bring these skills into Power Platform where they can build these types of software applications, according to Charles Lamanna, Microsoft corporate vice president of business applications and platform.

“One of the big pushes we’ve been doing is to go to the next level, to go from hundreds of millions of people that can use these tools to billions of people that can use these tools,” he said. “And the only way we think we can actually do that is to go from low code to no code by using AI-powered development.”

To do this, Lamanna’s team first integrated GPT-3 with Microsoft Power Apps for a feature called Power App Ideas, which allows people to create applications using conversational language in Power Fx, an open-source programming language for low code development with its origins in Microsoft Excel. The next step, announced at Build, is a feature called Power Apps express design, which leverages AI models from Azure Cognitive Services to turn drawings, images, PDFs and Figma design files into software applications.

“We’ve made it so that we can do image recognition and map it to the constructs that exist within an application. We understand what’s a button, what’s a grouping, what’s a text box and generate an application automatically based on those drawings without you having to understand and wire up all these different components,” Lamanna said.

Click here to load media

A new AI-powered feature called Power Apps express design helps turn sketches and other images into the bones of an app, helping people with little or no coding experience develop software.

This transition from low code to no code on the back of AI follows a general trend of computing becoming more accessible over time, he added. Personal computers were rare 40 years ago, spreadsheets were uncommon 30 years ago, internet access was limited 20 years ago, for example. Until recently, video and photo editing were reserved for experts.

Software development should also become more accessible, Lamanna said.

“If we want everybody to be a developer, we can’t plan on teaching everyone how to write Python code or JavaScript. That’s not possible. But it is possible if we create the right experiences and get them in front of enough people who can click and drag and drop and use concepts that are familiar to create amazing solutions,” he said.

Developers for the software-powered future

GitHub Copilot as well as the low code and no code offerings available via the Power Platform are the first phase of AI-powered development, according to Liuson. She envisions AI-powered models and tools that will help developers of all ability levels clean data, check code for errors, debug programs and explain what blocks of code mean in natural language.

These features are part of a larger vision of AI-powered tools that could serve as assistants that help developers more quickly find solutions to their problems and help anyone who wants to build an application go from an idea in their head to a piece of software that works.

“As a developer, we all have days that we have pulled out our hair, saying, ‘Why is this thing not working?’ And we consult with a more senior developer who points us in the right direction,” Liuson said. “When Copilot can go, ‘Hey here are the four different things that are common with this pattern of problem,’ that will be huge.”

This new era of AI-assisted software development can lead to greater developer productivity, satisfaction and efficiency and make software development more natural and accessible to more people, according to Scott.

For example, a gamer could use natural language to program non-player characters in Minecraft to accomplish tasks such as build structures, freeing the gamer to attend to other, more pressing tasks. Graphic designers can use natural language to build 3D scenes in the graphics rendering engine Babylon.js. Teachers can use 3D creation and collaboration tools like FrameVR to speak into existence a metaverse world such as a moonscape with rovers and an American flag.

“You can describe to the AI system what you want to accomplish,” Scott said. “It can try to figure out what it is you meant and show you part of the solution and then you can refine what the model is showing you. It’s this iterative cycle that’s free flowing and natural.”

These tools, Scott added, will also swell the ranks of developers in a world that will be increasingly powered by software.

“Because the future is so dependent on software, we want a broad and inclusive set of people participating in its creation,” he said. “We want people from all sorts of backgrounds and points of view to be able to use the most powerful technology they can lay their hands on to solve the problems that they have, to help them build their businesses and create prosperity for their families and their communities.”

Related:

Top photo: Kevin Scott, Microsoft chief technology officer, said AI-powered tools help developers get from thoughts in their heads to code. Photo courtesy of Microsoft.

John Roach writes about Microsoft research and innovation. Follow him on Twitter."
Microsoft_News,https://news.microsoft.com/europe/features/winds-of-change-how-one-of-the-worlds-largest-wind-companies-is-using-ai-to-capture-more-energy/,,How one of the world’s largest wind companies is using AI to capture more energy,"In 1898, Hans Søren Hansen arrived in Lem, Denmark, a small farming town about 160 miles from Copenhagen. The 22-year-old was eager to make his way in business and bought a blacksmith shop. In time, he became known to those in the area for his innovative spirit.

Hansen’s business went on to change with the times, morphing into building steel window frames. Future generations continued to expand on Hansen’s openness to change, evolving to building hydraulic cranes, and ultimately, in 1987, becoming Vestas Wind Systems, one of the largest wind turbine manufacturers in the world.

That tenacity to adapt and succeed has continued to define Vestas, which is now looking to optimize wind energy efficiency for customers who use its turbines in 85 countries.

Working on a proof of concept with Microsoft and Microsoft partner minds.ai, Vestas successfully used artificial intelligence (AI) and high-performance computing to generate more energy from wind turbines by optimizing what is known as wake steering.

That potential energy increase is important. But also important, Vestas says, was the rapidity with which the proof of concept was developed – in a few months – and what that could mean for putting it into place. The company is not the first to study the issue, but the expedited results were a differentiator for it.

Sven Jesper Knudsen, Vestas Chief Specialist and modeling and analytics module design owner.

“This is a theoretical exercise that has been living in the research community for years,” says Sven Jesper Knudsen, Vestas chief specialist and modeling and analytics module design owner. “And there have been some demonstrations by both our competitors and also some wind farm owners. We wanted to see if we could try to shorten the development cycle.

“Time to market is essential to the whole wind industry to meet aggressive targets that we all have,” Knudsen says.

Wind, like solar, energy is a clean alternative to fossil fuels for creating electricity. Both wind and solar are of growing importance as the world looks to decrease the use of coal, gas and crude oil to reduce carbon emissions to meet climate change goals.

Wind power also is one of the fastest-growing renewable energy technologies, according to the International Energy Agency (IEA), an organization that works with governments and industry to help them shape and secure a sustainable energy future.

In 2050, two-thirds of the world’s total energy supply will come from wind, solar, bioenergy, geothermal and hydro energy, with wind power expected to increase 11-fold, the agency said in a report last year, Net Zero by 2050: A Roadmap for the Global Energy Sector.

“In the net zero pathway, global energy demand in 2050 is around 8% smaller than today, but it serves an economy more than twice as big and a population with 2 billion more people,” the IEA says in the report.

Wind energy has many advantages. But one challenge is that the amount of energy that is harnessed can change daily based on wind conditions. Finding ways to better capture every part of wind energy is important to Vestas – hence what began last year as the “Grand Challenge,” as the company described it.

A woman works in Vestas’ blades factory in Nakskov, in south Denmark. (Photo courtesy of Vestas)

Wind turbines cast a wake, or a “shadow effect” that can slow other turbines that are located downstream, Knudsen says. Energy can be recaptured using wake steering, turning turbine rotors to point away from oncoming wind to deflect the wake.

“The idea is that you control that shadow effect away from downstream turbines and you then channel more wind energy to these downstream turbines,” he says.

To accomplish this, Vestas used Microsoft Azure high-performance computing, Azure Machine Learning and help from Microsoft partner minds.ai, which used DeepSim, its reinforcement learning-based controller design platform.

Reinforcement learning is a type of machine learning in which AI agents can interact and learn from their environment in real-time, and largely by trial and error. Reinforcement learning tests out different actions in either a real or simulated world and gets a reward – say, higher points – when actions achieve a desired result.

Vestas’ use of Azure high-performance computing also meant getting results faster.

Click here to load media

“I was completely blown away that one week into the project, we had an almost minimal live product,” Knudsen says. Vestas used the platform to run simulations to train controllers to react to wind conditions and yaw, or oscillate, to capture energy that otherwise would be lost.

Incorporating AI to maximize clean energy is of growing importance.

“You can use AI to both optimize the construction, siting and the operations of a wind farm, but more importantly, you can use AI to optimize across different systems, both when it comes to consumption but also production,” says Espen Mehlum, head of energy and materials program on benchmarking for the World Economic Forum.

“That’s where the huge untapped potential is for AI – we’re just scratching the surface and seeing the first use cases.”

Espen Mehlum, head of energy and materials program on benchmarking for the World Economic Forum. (Photo courtesy of Espen Mehlum)

Mehlum was one of the coauthors of a World Economic Forum report last fall, Harnessing Artificial Intelligence to Accelerate the Energy Transition, written in collaboration with BloombergNEF and the German Energy Agency, Deutsche Energie-Agentur.

“AI technology has the potential to rapidly accelerate the energy transition, particularly in the power sector,” the report noted, setting out nine principles for safely and responsibly incorporating AI in the energy transition.

The climate crisis is “all hands-on deck,” Mehlum says. “The world has decided that with the Paris Agreement, and now with the measures that were confirmed at the COP26 meeting late last year in Glasgow, to limit global warming to well below 2 degrees Celsius, and ideally to around 1.5 degrees.

“The increase is already at 1.1 degrees,” he says. “So, the global carbon budget that is left to emit – if you have any hope to reach 1.5 degrees or 2 degrees – is shrinking very fast.”

The New Energy Outlook 2021, BloombergNEF’s annual long-term scenario analysis on the future of the energy economy, notes the importance of employing every wind and solar technology that is feasible to help reduce emissions.

“Getting on track for net zero emissions in 2050 means deploying commercially available abatement technologies in each sector this decade,“ the report says. “More than three quarters of the effort to cut emissions in the next nine years falls to the power sector and to faster deployment of wind and solar PV (photovoltaic). ”

Vestas’ proof of concept is one piece of a very intricate and global challenge toward reducing carbon emissions and maximizing clean energy. For its work, the company was given an Editor’s Choice award for “Best Use of High-Performance Computing in Energy” last fall by HPCwire, a publication for the high-performance computing industry.

“The Grand Challenge was one of the most complicated cases we could find,” says Knudsen. “But it was also a case that we’ve been working on for some time. It’s something we tried with some other collaboration partners on this AI journey. And we haven’t been successful with these other partners. But we were very successful with minds.ai and Microsoft.”

“There’s no silver bullet for climate change,” Mehlum says. “You have to look at many, many different areas. And AI is just one of those tools that can be very important both to reduce emissions and to optimize access and systems that we haven’t yet fully utilized.”"
Microsoft_News,https://news.microsoft.com/source/features/ai/new-z-code-mixture-of-experts-models-improve-quality-efficiency-in-translator-and-azure-ai/,,"New Z-code Mixture of Experts models improve quality, efficiency in Translator and Azure AI","Microsoft is making upgrades to Translator and other Azure AI services powered by a new family of artificial intelligence models its researchers have developed called Z-code, which offer the kind of performance and quality benefits that other large-scale language models have but can be run much more efficiently.

“Our goal is to help everyone and every organization on the planet to communicate better, and to achieve that goal there are really two important dimensions — we want the quality of translations to be as good as possible and we want to support as many languages as possible,” said Xuedong Huang, Microsoft technical fellow and Azure AI chief technology officer.

Z-code takes advantage of shared linguistic elements across multiple languages via transfer learning —which applies knowledge from one task to another related task — to improve quality for machine translation and other language understanding tasks. It also helps extend those capabilities beyond the most common languages across the globe to underrepresented languages that have less available training data.

“With Z-code we are really making amazing progress because we are leveraging both transfer learning and multitask learning from monolingual and multilingual data to create a state-of-the-art language model that we believe has the best combination of quality, performance and efficiency that we can provide to our customers,” Huang said.

These models use a sparse “Mixture of Experts” approach that is more efficient to run because it only needs to engage a portion of the model to complete a task, as opposed to other architectures that have to activate an entire AI model to run every request. This architecture allows massive scale in the number of model parameters while keeping the amount of compute constant.

To put these models in production, Microsoft is using NVIDIA GPUs and Triton Inference Server to deploy and scale them efficiently for high-performance inference.

Microsoft has recently deployed Z-code models to improve common language understanding tasks such as name entity recognition, text summarization, custom text classification and key phrase extraction across its Azure AI services. But this is the first time a company has publicly demonstrated that it can use this new class of Mixture of Experts models to power machine translation products.

The new Z-code-based translation model is now available, by invitation initially, to customers using document translation in Translator, a Microsoft Azure Cognitive Service which is a part of Azure AI.

Microsoft’s Z-code models consistently improved translation quality over current production models, according to common industry metrics. In contrast with typical multilingual transfer learning approaches, which typically show AI quality gains in languages that have fewer direct translation examples available for training, the Z-code Mixture of Experts models show consistent gains even in the largest languages.

Human evaluators in a blind test commissioned by Microsoft found that the Z-code Mixture of Experts models improved translations across languages, with an average gain of 4%. For instance, the models improved English to French translations by 3.2 %, English to Turkish by 5.8 %, Japanese to English by 7.6%, English to Arabic by 9.3% and English to Slovenian by 15%.

Creating more powerful and integrative AI systems

Z-code is part of Microsoft’s larger XYZ-code initiative that seeks to combine models for text, vision, audio and multiple languages to create more powerful and integrative AI systems that can speak, hear, see and understand people better.

Over the past five years, Microsoft has developed models that have matched human performance in conversational speech recognition, machine translation, image captioning, SuperGLUE natural language understanding and commonsense question answering. These breakthroughs provide the foundation to realize more ambitious AI systems that can achieve multisensory and multilingual learning that is closer to how people learn and understand, Huang said.

“Those are the pieces, the building blocks that we are using to build a truly differentiated intelligence…and to form production systems that are cost efficient,” Huang said.

Z-code models were developed as part of Microsoft’s AI at Scale and Turing initiatives, which seek to develop large models that are pretrained on vast amounts of textual data to understand nuances of language — which can be integrated in multiple Microsoft products and also made available to customers for their own uses.

The same underlying model can be fine-tuned to perform different language understanding tasks such as translating between languages, summarizing a speech, offering ways to complete a sentence or generating suggested tweets, instead of having to develop separate models for each of those narrow purposes.

Our goal is to help everyone and every organization on the planet to communicate better, and to achieve that goal there are really two important dimensions — we want the quality of translations to be as good as possible and we want to support as many languages as possible.

Many of these language models, however, are so large that it can be challenging to integrate them into real-world products. But Z-code Mixture of Experts models are what’s known as “sparse,” which means that they only activate a fraction of the model’s parameters to perform an individual task, as opposed to engaging the whole model every time.

That makes them much more cost-efficient to run, in the same way that it’s cheaper and more efficient to only heat your house in winter during the times of day that you need it and in the spaces that you regularly use, rather than keeping a furnace running full blast all the time.

Microsoft researchers collaborated closely with NVIDIA to deploy Z-code Mixture of Experts models in production for the first time, and on NVIDIA GPUs. Using the NVIDIA Triton Inference Server, they were able to deploy these models using a more efficient runtime that leveraged CUTLASS and FasterTransformer to optimize these new types of models. The new runtime was able to achieve up to a 27x speedup over non-optimized GPU runtimes.

The Z-code team also worked closely with Microsoft DeepSpeed researchers to learn how to efficiently train massive Mixture of Experts models such as Z-code, as well as more modestly sized Z-code models for production scenarios.

“We have been able to build this one model that can cover a lot of languages and serve various tasks from summarization to text generation to translation and be useful for many other Microsoft teams,” said Hany Hassan Awadalla, Microsoft principal researcher and research manager who helps lead development of Z-code models for Translator and other Azure Cognitive Services.

“So we are working to spread this across the company and reduce their deployment costs, which is the vision of AI at Scale generally,” he said.

Integrating research into customer products

The Z-code models are initially being used to boost Translator’s document translation features, which allow customers to translate entire Word documents, PDFs, PowerPoint presentations or other documents into new languages with all the formatting preserved.

Original sentence Human translation Previous machine translation Improved Z-code Mixture of Experts model translation Komisija u razumnom roku sažetke dostavlja Sekretarijatu ICCAT-a. The Commission shall forward the summaries to the ICCAT Secretariat within a reasonable period of time. Within a reasonable time of time, the Commission submits the summary to the ICCAT Secretariat. The Commission shall transmit the summaries to the ICCAT Secretariat within a reasonable period of time. Мисля, че трябва да бъдем внимателни, за да облекчим производителите, дистрибуторите и търговците на дребно. I think we have to be careful to ease the burden for producers, distributors and retailers. I think we need to be careful to ease manufacturers, distributors and retailers. I think we need to be careful to make it easier for manufacturers, distributors and retailers.

That’s because Z-code runs most efficiently when it has batches of sentences to translate at once, and document translation lends itself well to that task, said Vishal Chowdhary, partner development manager of Translator who led efforts to turn a research model into something that could be deployed in real-world production scenarios and made available to customers.

Previously, Translator needed 20 separate models to translate between 10 languages: one for English to French, French to English, English to Macedonian, Macedonian to English and so on.

Now, one single Z-code production model can translate all 10 languages to and from English, eliminating the need for multiple systems. Larger research Z-code models have been able to translate directly between 101 languages in 10,000 directions, without having to go through English first.

Companies with international operations in multiple markets often need a way to improve communication across departments with employees that speak many different languages. Today’s machine learning models need huge translation data sets with dialects for training, and there may not be enough data for all the desired languages and dialects, particularly in smaller markets.

The ability to share knowledge across different languages enables Z-code to produce more accurate results for underrepresented languages that don’t have a huge number of translation examples to learn from. This will help improve AI fairness and ensure that high-quality translations are not restricted to languages with rich training resources only, Huang said.

“The 107 languages we currently support might cover what’s spoken at the Olympics or the United Nations,” Huang said. “But there are 7,000 languages spoken around the world and there are a lot of small communities we aren’t able to support yet. We want to be fully multilingual with our AI because our goal is to serve every citizen on the planet.”

Related:

Top image: Translator Partner Development Manager Vishal Chowdhary (left) and Principal Researcher Hany Hassan Awadalla (right) helped lead the Microsoft team that is now using Z-code Mixture of Experts AI models to power machine translation improvements in Translator. Photo by Dan DeLong for Microsoft.

Jennifer Langston writes about Microsoft research and innovation. Follow her on Twitter."
Microsoft_News,https://news.microsoft.com/source/features/digital-transformation/eq-trumps-iq-how-att-and-microsoft-partner-to-help-businesses-innovate/,,‘EQ trumps IQ’: How AT&T and Microsoft partner to help businesses innovate,"Everything began with a phone chat. In 1876, Alexander Graham Bell successfully placed the world’s first telephone call – a quick communication that confirmed his invention and, eventually, created the American Telephone and Telegraph Company.

You know it, no doubt, as AT&T.

Headquartered in Dallas, AT&T is becoming a cloud-first company. Collaborating with Microsoft, they apply technologies across 5G, artificial intelligence (AI), cloud and edge computing to help their mutual customers innovate and grow resiliently in an ever-changing world.

That’s a mighty long way, of course, from the day Bell first rang. Yet it also prompts the question: What did it take for a 146-year-old company to take a lead seat in the Fourth Industrial Revolution – and do so in the middle of a global pandemic?

The answer is as old as, well, the telephone and the telegraph: Having the right people in key roles at the right time.

Two of those people, CEO of AT&T Business Anne Chow and Chief Technology Officer Jeremy Legg, are particularly passionate about applying their distinctive leadership styles and life learnings to help drive AT&T’s big pivot.

On the business side there’s Chow, a Juilliard-trained pianist and fervent fitness boxer who leans on wisdom from those pursuits and others as she provides AT&T’s business customers with breakthrough technologies like 5G to help them operate more efficiently and disrupt their own industries.

“Music has always been a guidepost,” says Chow, an engineer who began her current role in 2019. “As a young musician, it was all about practice, practice, practice, and mastering the science of the music. But it was also about adding my own interpretation, my own emotion, my own creativity.

“I’ve applied that to how I approach work and how I approach my life. I’ve got to have some mastery of the product, the services, the technologies, the science. But just as important, it is the art that brings it to life. There is a balance of art and science in everything.”

On the tech side there’s Legg, whose first job was writing code for a travel company when the airlines began moving from paper to e-tickets. Prior to joining AT&T in 2020, he served as the CTO of WarnerMedia, overseeing the launch of HBO Max. Along the way, he learned that a company’s culture can have more to do with achieving success than any business model or technology.

“As I’ve gotten to a later vintage in life, EQ trumps IQ when you lead large organizations,” Legg says. “Your ability to understand people and how to motivate them – to be authentic – honestly has far more to do with your success than anything else.

“When you have people who are incredibly bright, you have to take them along on that journey and explain ‘the why’ as much as ‘the what.’ You have to incentivize people, and you have to get them to buy in culturally to doing it or it will just simply fail.”

AT&T’s evolution is not about a company that simply decided to transform for transformation’s sake, top executives say. It is all about timing: The global pandemic drove AT&T to expedite its commitment to use cloud technologies to modernize and streamline its business applications. At the same time, it led AT&T to speed the delivery of new services to serve its customers’ changing needs.

“We want our workforce using modern cloud tools,” Legg says. “You can’t build products for customers anymore if it takes you 30 days to provision a server.”

Cloud and AI technologies also enable employees to streamline operations, connect the dots across teams and deliver new services to customers faster. According to Microsoft’s recent Work Trend Index, workers in the telecommunications industry want digital tools and solutions to not only alleviate stress but to help with team communications and automate repetitive tasks – which leads to a better customer experience.

As a key part of that push, AT&T announced it will move its 5G mobile network to the Microsoft Cloud. Bringing existing and future network workloads to Azure for Operators will help AT&T increase productivity, reduce costs and deliver innovative services that meet its customers’ evolving needs.

AT&T and Microsoft are also developing new solutions that will help enterprises lower costs while increasing efficiency, reliability and security at the edge of their premises and facilities through capabilities such as AT&T-enabled Azure Sphere and Guardian module, and AT&T MEC with Azure.

“You’ve got to be able to leverage those kinds of modern development tools and think about what customer problem are you trying to solve, not what technology are you building. That’s a mindset shift,” Legg says.

AT&T is now looking to bring private 4G/5G wireless networks to enterprise and public sector customers to enable low-latency services at the edge. The company is including the ability to roam beyond the geographical boundaries of the AT&T private network and still stay connected through the AT&T public network. It’s called AT&T Private 5G Edge. Currently under development with Microsoft, the service is using Azure private MEC with Azure Private 5G Core to help deploy these private wireless networks rapidly.

While at WarnerMedia, Legg also led public cloud efforts. At AT&T, he oversees the company’s massive infrastructure footprint – and so much data.

“What’s different with AT&T is the scale,” Legg says. “We don’t have 10,000 or 20,000 servers. We have hundreds and hundreds and hundreds of thousands. There’s well north of 480 petabytes (1 petabyte equals 1,000 terabytes) of data that transfers our wireless network every day. This is the last mile. This is the actual operation of the physical internet itself.”

As he now focuses on millions of homes patched with AT&T fiber and hundreds of millions of points of presence along the 5G network, he’s asking himself equally big questions, like: “How do we think about the products that we want to run on top of it?”

“That is moving us, I think, from being a connectivity provider to being a connectivity provider that can also begin to think about products and services,” Legg says.

“So, how are we enabling gaming? And enhancing privacy and security? How do we help with autonomous vehicles? What is our strategy for telemedicine?”

At AT&T Business – where Chow leads an organization of 30,000 employees who serve 2.5 million business customers worldwide – she’s asking similar questions. Many of the answers, she says, lie in AT&T’s 5G service.

“What 5G means to us in terms of our cellular service and coverage, that’s not going to be the exciting part,” Chow says. “The exciting part is what 5G will trigger businesses and organizations to do differently, how it will unleash a whole set of outcomes to you and me, the consumers.

“Whether that’s how we receive our health care, or how our children may experience higher education differently. For example, they might be able to experience the Louvre (Museum in Paris) without ever actually going to the Louvre.”

Across numerous business verticals, Chow cites 5G-driven disruptions that already make life better for people in many walks of life.

In the automotive world, vehicles can receive firmware updates over the air with 5G and Azure, compared to manual updates that must be done at a service garage, she explained. In manufacturing, live video analytics can track employee safety on a shop floor, shutting off equipment in milliseconds if a person gets too close to a machine or otherwise appears to be in jeopardy.

In entertainment, Azure Edge Zones with AT&T allow musicians to jam together while playing separately in their home environments.

That musical example truly resonates with Chow. As a young girl, she took piano lessons and mastered Beethoven’s “Moonlight Sonata.” She became so proficient she earned a spot in Juilliard’s pre-college division – at age 10.

Click here to load media

Chow sees similarities between organizations and orchestras, between business leaders and conductors.

And for AT&T’s collaboration with Redmond, Washington-based Microsoft, she sees still more harmony. To explain, Chow uses music’s two most important clefs, the bass and the treble.

AT&T’s services and products, its infrastructure and position as a global network provider “are foundational to the world and to technology,” she says. “You could correlate that to the bass clef.”

Meanwhile, Microsoft’s position as a cloud leader along with the tech tools and capabilities that Microsoft brings to the marketplace all remind Chow of notes on the treble clef.

“What is played on each of those clefs individually can be a piece unto itself,” she says. “But when you bring the two together, they serve as the foundation for beautiful music.

“What’s so exciting about our strategic alliance,” she adds, “is together we can largely shape and catalyze so much of this innovation that will be for good, that will advance business, that will advance the economy, that will advance society.”

Photos courtesy of AT&T."
Microsoft_News,https://news.microsoft.com/source/features/digital-transformation/how-nokia-is-using-azure-arc-to-empower-customers-in-a-multicloud-world/,,How Nokia is using Azure Arc to empower customers in a multicloud world,"Organizations today are increasingly operating in multicloud and hybrid environments, using a mix of public, private and edge clouds to manage their technology assets.

That has created opportunities and complexities for enterprises in serving their customers, as telecommunications giant Nokia can attest. The Finnish company recently began using Microsoft Azure Arc, a multicloud and on-premises management platform, a key step in its commitment to serve customers in that new environment.

The path leading to Azure Arc dates back to 2016, when Nokia launched its Analytics, Virtualization and Automation (AVA) system, an artificial intelligence-based analytics platform. The company designed the system to help its cell phone carrier customers use data to improve operational efficiencies, increase revenues and provide better experiences for their own customers.

Up to that point, Nokia engineers had been entering data in spreadsheets and using manual methods for analytics. The approach was inefficient, error-prone and inadequate for handling large amounts of data.

“Given the massive increase in network capacity and size, that wasn’t sustainable anymore,” says Paolo Tornaghi, who leads the technology and architecture team in Nokia’s business applications’ advanced services division. “We needed applications that are scalable for customers.”

The AVA system draws data from network operations and other sources to provide AI-powered insights and identify solutions to workflow issues. In 2019, Nokia migrated AVA to the cloud. Moving to Azure gave Nokia the ability to offer AI-powered analytics to customers globally through AVA without needing to manage their individual clouds.

The cloud offered immediate benefits, but as Nokia began to scale AVA, new parameters emerged. For some customers, geographically specific regulatory requirements necessitated keeping data in-country, while other customers wanted to use AVA on other public or private clouds instead of Nokia’s.

Developing bespoke solutions for individual customers wasn’t feasible, and Nokia needed to find a way to deploy its AVA services uniformly across whatever Kubernetes arrangements customers were using.

“That was becoming a problem for us. We weren’t able to offer AVA to our customers who had these restrictions. We had to do something about it,” says Kalyanjeet Gogoi, head of business applications’ advanced services research and development for Nokia.

“This problem is something we put in front of Microsoft and said, ‘How do we handle this?’ It’s a very strong partnership. We develop a lot of our solutions together.”

A team of Microsoft engineers worked closely with Nokia to integrate Azure Arc with AVA and develop the flexible, scalable infrastructure management solution customers needed. Launched in 2019, Azure Arc centralizes how businesses manage their multicloud and on-premises technology, from data centers to edge devices, by projecting resources into Azure.

For Nokia, adopting Azure Arc means the company can operate and monitor AVA applications that are run in customers’ preferred clouds and still meet data regulations in various countries. Sensitive data remains in customers’ clouds and is not transferred elsewhere.

The new Azure Arc-enabled AVA architecture has two parts: a Nokia-owned Azure subscription where AVA applications and workloads run, and a customer cloud with the customer’s Kubernetes stack, onto which Nokia deploys and maintains its AVA applications. The two clouds communicate over a secure channel.

“Security is vital for our customers, and for Nokia,” says Tornaghi. “With Azure Arc and the fact that we are not going to move data from the customer cloud to Azure, data security and privacy is fully respected. No sensitive data is going to be flowing to the public cloud.”

Azure Arc enables Nokia to monitor and manage AVA services through a single screen, Gogoi says, providing visibility into the solutions various customers are using and avoiding the need for localized teams to deploy and monitor those services.

And the new architecture allows Nokia to serve customers it previously could not, Tornaghi says.

“What’s important for customers is respecting the data regulatory requirements they have and also respecting their cloud strategy,” he says. “Those are really the two important points for them, and that’s what, by leveraging Azure Arc, we are solving.”

Top photo: Nokia’s campus in Espoo, Finland. (Courtesy of Nokia)"
Microsoft_News,https://news.microsoft.com/source/features/digital-transformation/using-microsoft-azure-and-its-ai-capabilities-peloton-develops-live-subtitles-for-members-who-are-deaf-or-hard-of-hearing/,,"Using Microsoft Azure and its AI capabilities, Peloton develops live subtitles for members who are deaf or hard of hearing","That day in early February was for David Wolfe Rose like all the Christmases at once, like getting a new kitten, like every special day bundled into one.

Rose had readied a room at the back of his house in preparation for the delivery. That morning, he eagerly waited. Soon two men arrived, put together Rose’s new indoor stationary Peloton Bike and showed him how to use it. Rose was, well, beyond elated.

“It was like getting married again,” he says. “If I’m honest, it was like having another baby. It was just very exciting when the bike arrived.”

Peloton members are known for their dedication to the brand’s energetic online classes. But to Rose, the high-tech bike was about more than just a challenging workout. It promised connection and community. It was a gateway to a place he could belong to.

Rose, who is deaf, bought the bike after learning that Peloton offered subtitles for its on-demand classes. More recently, using Microsoft’s Azure Cognitive Services speech-to-text and translation technology, the company launched live subtitles in September for its live classes, improving accessibility for members who are deaf or hard of hearing.

Suresh Bathini, Peloton’s vice president of software engineering, says the New York City-based company decided to work with Microsoft to expand accessibility to its platform. He knew after hearing from a member who would sign entire live classes for her partner, who is deaf, that doing so was the right move for the Peloton community, he says.

“That prompted us to provide subtitles for people who are taking live classes. We want to provide immersive experiences that are accessible to all users,” Bathini says.

Previously, the company had provided subtitles only for its on-demand classes. But that meant that the signature live experience so valued by members wasn’t available to those who are deaf or hard of hearing.

While the decision to introduce live subtitles was clear, executing on that vision proved a bit murkier. A primary challenge was determining how automated speech recognition software could facilitate Peloton’s specific vocabulary, including the numerical phrases used for class countdowns and to set resistance and cadence levels. Latency was another issue – subtitles wouldn’t be very useful, after all, if they lagged behind what instructors were saying.

Bathini says Peloton chose Azure Cognitive Services because it was cost-effective and allowed Peloton to customize its own machine learning model for converting speech to text, and was significantly faster than other solutions on the market. Microsoft also provided a team of engineers that worked alongside Peloton throughout the development process.

“Having a support system, especially on the engineering side and software side, helped us accelerate the solution,” Bathini says. “It was a very collaborative process.”

Eric Boyd, corporate vice president, Microsoft Azure AI, says Peloton’s use of Azure Cognitive Services is a great example of using artificial intelligence to break down barriers and address inequities.

“It’s terrific to see how Peloton is embracing the power of AI to make their platform more accessible for everyone,” he says. “Using Cognitive Service for Speech, part of the Azure AI platform, Peloton was able to develop and implement live subtitles for its classes, creating a more accessible and engaging experience for its member community, especially for those who are deaf or hard of hearing.

“This collaboration perfectly embodies our mission to empower every person and every organization on the planet to achieve more.”

For Rose, those subtitles on his bike’s display screen have been nothing short of transformational. He’d joined several gyms over the past 20 years, working with personal trainers and lipreading their instructions and guidance. But he couldn’t interact much with other gym members, other than the occasional smile or thumbs-up. After a while, feeling isolated and left out, Rose’s motivation would invariably fizzle and he’d quit going.

“I always felt a little bit excluded at gyms, but with Peloton, it makes me feel like I’m 100% part of the community because I’m able to take part and follow what’s going on,” says Rose, who lives in Telford, a town in central England.

His lack of motivation has evaporated, along with about 20 pounds. Since February, Rose has racked up 900-plus (and counting) rides, joined a Peloton Facebook group and regularly chats online with other Peloton members about topics ranging from equipment issues to weight-loss goals.

“It’s a little community, which is nice,” he says.

When Rose first received the bike, he tried live classes because he wanted the immediacy and sense of connection. He could watch the leaderboard that displays participants’ output and see where he ranked, give another member a high-five and most importantly, watch for the shout-out he hoped to get from the instructor.

Later, Rose would go back and do the class over again with subtitles just to see if he got a shout-out. As of early October, he was still waiting and hoping. But without subtitles, Rose could only watch the instructors and try to copy what they were doing. The introduction of live subtitles, he says, “just made me absolutely ecstatic.

“Now I’ve got the opportunity to do the class live and wait for that shout-out, rather than having to go back and watch it a second time,” says Rose, 60, a senior lecturer in deaf studies and British Sign Language/English interpretation at the University of Wolverhampton.

Meryl Evans previously worked out at a fitness studio for about four years, but like Rose, was ready for a change and wanted more guidance in her workouts. A coach at the studio would give Evans, who is deaf, a printed sheet of instructions to follow along. But they were basic and lacked the sort of detail she wanted – flatten your back, tighten your core – and that maximizes workouts and can help prevent injuries.

When the pandemic hit and gyms closed, Evans decided to look for a subtitled workout she could do at home. Workouts without subtitles weren’t an option – though Evans’ eyes are her “number one listening tool,” she finds it difficult to lipread over video, let alone while focusing on a workout.

Evans tried out Peloton and a competing company and liked Peloton’s variety of classes, ranging from cycling to boot camp and yoga, and its diversity of instructors. But it was Peloton’s subtitles, which were more visible and easier to read than the other company’s, that sealed the deal for her.

“My workouts are now a lot more efficient because I have those instructions in subtitles,” says Evans, 51, a digital marketer and accessibility consultant who lives in Plano, Texas.

“And it’s made a huge difference. My back doesn’t hurt as much as it did because of those instructions.”

A runner and lifelong sports enthusiast, Evans started with a treadmill but soon switched to a Peloton Bike she got through the company’s Comeback Program, which recognizes members who have overcome adversity.

Like many people, both Evans and Rose like working out to music. Evans is a fan of Broadway, especially “Hamilton,” and discovers new music primarily through subtitles in Peloton classes or on TV shows. Rose leans toward ‘80s rock tunes, loves the group Queen and likes to crank his wireless speaker loud enough to feel the beat. Knowing what song is playing during workouts provides an additional boost, both say.

“Even though I can’t hear it, if I know a song, my head will play it,” Evans says. “I’m hearing it in my head as I ride.”

Evans and Rose hope Peloton will add song titles to its live subtitling, something Bathini says the company is looking at doing, and Evans would also like to see the addition of an instructor or two with a disability. Live subtitling for Peloton classes is so far only available in English, but the goal is to make Peloton’s classes as broadly accessible as possible, Bathini says.

“We want to make fitness accessible to all our members. Our mission is really to drive the future of fitness for the world through connected experiences,” he says.

Both Evans and Rose praise Peloton for taking steps to meet the needs of people with disabilities and say other companies, in the fitness industry and beyond, should follow suit. Subtitles are used even by people who aren’t deaf or hard of hearing, Evans points out (ever watched a football game in a loud pub?), as are devices originally designed for people with disabilities, such as elevators.

Peloton offering subtitles “makes a difference, because it shows the company is serious about accessibility,” Evans says. “The fitness industry has a long way to go, but Peloton is probably ahead of the pack because of what they’re doing with subtitles.

“I’m really loyal to Peloton,” she says. “I have no desire to change.”

Nor does Rose, who finally found his workout mojo via a high-tech, internet-connected bike and a community of like-minded folks. Even if other fitness companies follow in Peloton’s footsteps, he plans to stick with them out of “respect and loyalty.”

And he has another reason to stay engaged. One day in late October, Rose got on his bike for a 30-minute ride featuring songs from the 2010s. As the class got underway, a caption popped up. It was the long-awaited shout-out, congratulating Rose on his 900th ride.

In that little room, on the bike that had brought him connection and a newfound passion, Rose whooped with joy.

He’s already thinking about his thousandth ride.

Top photo: David Wolfe Rose works out on his Peloton Bike+ at his home in Telford, England. (Courtesy of David Wolfe Rose)"
Microsoft_News,https://news.microsoft.com/source/features/ai/new-azure-openai-service/,,New Azure OpenAI Service combines access to powerful GPT-3 language models with Azure’s enterprise capabilities,"Since OpenAI, an AI research and deployment company, introduced its groundbreaking GPT-3 natural language model platform last year, users have discovered countless things that these AI models can do with their powerful and comprehensive understanding of language.

For instance, a sports franchise that’s developing a new app to engage with fans during games could use the models’ ability to quickly and abstractly summarize information to convert transcripts of live television commentary into game highlights that someone could choose to include within the app.

The marketing team could use GPT-3’s capability to generate original content and its understanding of what’s happening in the game to help the team brainstorm ideas for social media or blog posts and engage with fans more quickly.

At its Ignite conference today, Microsoft announced it will help its customers uncover these kinds of experiences with the new Azure OpenAI Service, which allows access to OpenAI’s API through the Azure platform and will initially be available by invite only. The new Azure Cognitive Service will give customers access to OpenAI’s powerful GPT-3 models, along with security, reliability, compliance, data privacy and other enterprise-grade capabilities that are built into Microsoft Azure.

Microsoft will also offer Azure OpenAI Service customers new tools to help ensure outputs that the model returns are appropriate for their businesses, and it will monitor how people are employing the technology to help ensure it’s being used for its intended purposes.

“We are just in the beginning stages of figuring out what the power and potential of GPT-3 is, which is what makes it so interesting,” said Eric Boyd, Microsoft corporate vice president for Azure AI. “Now we are taking what OpenAI has released and making it available with all the enterprise promises that businesses need to move into production.”

Click here to load media

Built by OpenAI, GPT-3 is part of a new class of models that can be customized to handle a wide variety of use cases that require a deep understanding of language, from converting natural language to software code to summarizing large amounts of text and generating answers to questions.

As more people are able to access and use them, the models become even more capable, said OpenAI CEO Sam Altman. He looks forward to the day when you can tell a computer what you want in plain language — even if the request is fuzzy like “find the strategy document I can’t remember the name of but wrote three years ago and has this image in it” — and the software will be able to execute that request.

“GPT-3 has really proven itself as the first powerful, general purpose model for natural language — it’s one model you can use for all these things, which developers love because you can try things very easily,” Altman said. “For a while now, we’ve wanted to figure out a way to scale it as broadly as possible, which is part of the thing that really excites us about the partnership with Microsoft.”

While GPT-3 has been publicly available since last year through an API managed by OpenAI, some potential customers have needed additional layers of security, access management, private networking, data handling protections or scaling capacity — which the Azure OpenAI Service will offer.

Click here to load media

The new Azure OpenAI Service will give customers access to OpenAI’s powerful natural language GPT-3 models – with the security, reliability and enterprise capabilities of Microsoft Azure. Azure OpenAI Service can help developers working for a sports franchise create a new app by converting language to software code, then reason over transcripts of live television commentary to offer game summaries for the app and also generate ideas for blog posts and other written content for fans.

Other companies that have already been using the API and want to put those ideas into commercial use will be able to run those solutions on Azure’s global infrastructure to meet their production needs, including critical security, compliance, performance, reliability and scale requirements.

“I believe in people doing what they’re good at,” Altman said. “This allows us to marry all the benefits that Azure customers have come to expect in security and compliance and its massive footprint with all the things that people love about GPT-3.”

Users can also easily teach the models — which have already learned nuances of language from absorbing patterns in billions of pages of publicly available text — to meet specific business needs using their own data. In a process known as “few shot learning,” users only need to show the models a few examples of the kinds of outputs or responses or code they want it to generate.

“It really is a new paradigm where this very large model is now itself the platform. So companies can just use it and give it a couple of examples and get the results they need without needing a whole data science team and thousands of GPUs and all the resources to train the model,” Microsoft’s Boyd said. “I think that’s why we see the huge amount of interest around businesses wanting to use GPT-3 — it’s both very powerful and very simple.”

The potential enterprise uses for GPT-3 range from summarizing common complaints in customer service logs to helping developers code faster without having to stop and search for examples or generating new content as starting points for blog posts, said Dominic Divakaruni, Microsoft group product manager leading Azure OpenAI.

“It helps expedite the process of creative writing, it helps you extract insights from a large amount of text and its code generating capabilities are a great example of the new kinds of business value these models bring,” Divakaruni said. “Customers are learning new things about what it can light up for them each day.”

The Azure OpenAI Service is the latest offering to emerge from a partnership between Microsoft and OpenAI that aims to accelerate breakthroughs in AI, from jointly developing the first supercomputer on Azure to commercializing new AI technologies.

Microsoft, which has a license to the GPT-3 technology that allows the company to integrate it into its own products, is using the Azure OpenAI Service to bring these natural language innovations to customers on a large scale.

Earlier this year, for instance, Microsoft began using GPT-3 in Microsoft Power Apps to help people who have no coding or programming background build apps by translating plain language commands into formulas.

This allows us to marry all the benefits that Azure customers have come to expect in security and compliance and its massive footprint with all the things that people love about GPT-3.

Microsoft subsidiary GitHub and OpenAI also introduced Copilot, a tool that uses a new model based on GPT-3 called Codex, which helps software developers write code more efficiently and avoid repetitive tasks with automatic code completion and suggestions.

Now, the Azure OpenAI Service will offer customers direct access to GPT-3 in a format that is designed to be intuitive enough for developers to use, yet robust enough for machine learning experts to work with the models as they wish.

Because these large language models are trained on vast amounts of internet data, which can include everything from vulgar language to racial stereotypes to personally identifying information, it’s important to give enterprise customers safeguards to help prevent the technology from being used for harmful purposes or generating unwanted results, said Sarah Bird, Microsoft’s responsible AI lead for Azure AI.

That’s why Microsoft initially will make the Azure OpenAI Service available by invitation to customers who are planning to implement well-defined use cases that incorporate responsible principles and strategies for using the AI technology. Collaborations with these early customers will help Microsoft see how its responsible AI safeguards are working in practice and make any needed adjustments, Bird said.

As part of the Azure OpenAI Service, Microsoft will offer new tools to filter and moderate the content of users’ requests and responses to help the models work effectively in each application. Customers will be able to customize those filters according to their business needs, since language that’s appropriate for a video game character may differ from communications aimed at business executives.

Microsoft will also provide safety monitoring and analysis to identify possible cases of abuse or misuse and to help customers ensure their own users are deploying the technology for its intended purposes, Bird said.

Microsoft will also offer customers guidance for using the technology successfully and fairly, such as keeping people in the loop to judge whether the content or code that the model is producing is high quality.

“We expect to learn with our customers, and we expect the responsible AI areas to be places where we learn what things need more polish,” Microsoft’s Boyd said. “This is a really critical area for AI generally and with GPT-3 pushing the boundaries of what’s possible with AI, we need to make sure we’re right there on the forefront to make sure we are using it responsibly.”

Related:

Top image: Azure OpenAI Service uses GPT-3 to convert transcripts of live television commentary during a women’s basketball game into short game summaries that the team building an app to engage with fans can pick from.

Jennifer Langston writes about Microsoft research and innovation. Follow her on Twitter."
Microsoft_News,https://news.microsoft.com/source/features/ai/microsoft-translator-100-language-milestone/,,Azure AI empowers organizations to serve users in more than 100 languages,"Microsoft announced today that 12 new languages and dialects have been added to Translator. These additions mean that the service can now translate between more than 100 languages and dialects, making information in text and documents accessible to 5.66 billion people worldwide.

“One hundred languages is a good milestone for us to achieve our ambition for everyone to be able to communicate regardless of the language they speak,” said Xuedong Huang, Microsoft technical fellow and Azure AI chief technology officer.

Translator today covers the world’s most spoken languages including English, Chinese, Hindi, Arabic and Spanish. In recent years, advances in AI technology have allowed the company to grow its language library with low-resource and endangered languages, such as Inuktitut, a dialect of Inuktut that is spoken by about 40,000 Inuit in Canada.

The new languages and dialects taking Translator over the 100-language milestone are Bashkir, Dhivehi, Georgian, Kyrgyz, Macedonian, Mongolian (Cyrillic), Mongolian (Traditional), Tatar, Tibetan, Turkmen, Uyghur and Uzbek (Latin), which collectively are natively spoken by 84.6 million people.

Removing language barriers

Thousands of organizations have turned to Translator to communicate with their members, employees and clients around the world. The Volkswagen Group, for example, is using the machine translation technology to serve its customers in more than 60 languages. The workload involves translating more than 1 billion words each year. The company started with standard Translator models and is using the custom feature in Translator to fine tune these models with industry specific terms.

The ability for organizations to fine tune pre-trained AI models to their specific needs was core to Microsoft’s vision when it launched Azure Cognitive Services in 2015, according to Huang.

In addition to language, Azure Cognitive Services include AI models for speech, vision and decision-making tasks. These models enable organizations to leverage capabilities, such as a Computer Vision technology known as Optical Character Recognition (OCR). This service extracts text entered on a form in any of the more than 100 languages covered by Translator and uses the text to populate a database.

“Not only do we celebrate what we have done on translation – reach 100 languages – but also for speech and OCR as well,” Huang said. “We want to remove language barriers.”

Multilingual model

The frontier of machine translation technology at Microsoft is a multilingual AI model called Z-code, according to Huang. The model combines several languages from a language family such as the Indian languages of Hindi, Marathi and Gujarati. In this way, the individual language models learn from each other, which reduces data requirements to achieve high-quality translations. For example, the quality of translations to and from Romanian were improved when the translation model is trained together with related French, Portuguese, Spanish and Italian data.

“We can leverage the commonality and use that shared transfer learning capability to improve the whole language family,” Huang said.

The reduced data requirements also enable the Translator team to build models for languages with limited resources or that are endangered due to dwindling populations of native speakers. Several of the languages carrying Translator over the 100-language milestone are low-resource or endangered.

Z-code, Huang added, is part of a larger initiative to combine AI models for text, vision, audio and language in order to enable AI systems that can speak, see, hear and understand and thus more efficiently augment human capabilities. Proof of this so-called XYZ-code vision coming into focus is manifest in the continual rollout of new languages built with multilingual model training technology, he said.

“This is bringing people closer together,” Huang said. “This is the capability already in production because of our XYZ-code vision.”

Related:

John Roach writes about Microsoft research and innovation. Follow him on Twitter.

Top image: Uzbek, the official language of Uzbekistan, is one of a dozen languages and dialects now available on Translator. In this image, two men drink tea in a chaikhana, a traditional tea house in the Fergana region of Uzbekistan. Photo courtesy of Getty Images."
Microsoft_News,https://news.microsoft.com/source/features/company-news/before-the-next-pandemic-lessons-learned-and-those-still-to-be-absorbed/,,"Before the next pandemic: Lessons learned, and those still to be absorbed","Medical student James E.K. Hildreth was on his first clinical rotation when he saw the patient, a Black woman in her early 20s who had just given birth. It was the early 1980s and AIDS was spreading, with no treatment for the virus. Both the mother and her baby did not make it.

“There was nothing we could do except treat their symptoms and watch them die,” Dr. Hildreth says quietly. The experience so affected him he changed his specialty from training to be a transplant surgeon to an HIV investigator. He became one of the world’s top HIV/AIDS researchers, with much of his work focusing on blocking HIV infection by learning how it gets into cells.

Now, as president and CEO of Meharry Medical College in Nashville, one of the nation’s oldest and largest historically Black academic health science centers, he sees similarities between the AIDS era and the COVID-19 pandemic responses – initial reluctance by some government officials to acknowledge the gravity of the virus and its impact on people of color – and says they must not be repeated.

“There’s a lot that we learned,” Dr. Hildreth says. “But one thing we learned for sure is that we need to do a better job of diversifying our health care work force. We need to spend more money on public health and preventive medicine to prevent this from happening again. And it also illustrates the importance of improving the basic health status of all of us, so that the next time this happens, we won’t be having the same conversation again. This is not the last pandemic for sure.”

Meharry is among the academic institutions and nonprofit organizations that are grantees of Microsoft AI for Health, which uses artificial intelligence (AI) and Azure high-performance computing to help improve the health of people and communities worldwide. AI for Health was launched a few months before COVID-19, and once the pandemic struck, more than 180 AI for Health grants went to those on the front lines of COVID-19 research, data and insights.

John Kahan, Microsoft vice president, Chief Data Analytics Officer and global lead for the AI for Health program, says when the pandemic started, so little information was known, and there was a massive race for data and insights.

“I think that our learning is in better shape now,” he says. “The science is in better shape. But it is still unclear that the governments of the world have gotten together on a common set of standards” around exactly what data must be gathered immediately after a pandemic has been declared.

Other AI for Health grantees, including Brown University School of Public Health, the Institute for Health Metrics and Morehouse School of Medicine, agree about the work that remains to be done.

Dr. Ashish Jha, dean of the Brown University School of Public Health, is a pandemic expert who now is also a familiar face to many television viewers in the U.S. for his perspectives. Using Azure and Power BI, Brown and Microsoft AI for Health developed a comprehensive COVID-19 dashboard that includes whether states in the U.S. are meeting COVID-19 testing target numbers, risk levels for each county in the country, and vaccine distribution and administration data. The dashboard also includes worldwide figures, and has become a helpful tool for the public, as well as for policymakers and leaders, to gauge the progress of the vaccine rollout.

What’s important about it and other COVID-19-related dashboards that have since been created is that they represent the first time such important tools have become widely available.

“Fundamentally the public health system’s data infrastructure (during COVID-19) sort of worked a little, but not nearly enough,” Dr. Jha says.

“Every public health department in the U.S. has its own data infrastructure for collecting information on infections, tests, hospitalizations and deaths – and they’re really, really old, clunky systems,” Dr. Jha says. “What that means is that there are places across the country when somebody has a positive COVID-19 test, they might send that information to their local health department by literally printing out the test result, and faxing it to the local health department, who will then hand-enter it into a computer system. This is how data is still largely being collected.”

It hindered the COVID-19 response in the U.S., Dr. Jha says. “At a national level, until very recently, we had no government-driven data on infections and cases and deaths. In fact, national data was being aggregated by a group of journalists who were pulling together data and cleaning it up across every state and putting it together. Even the previous White House (administration) was largely using this data as opposed to using federal data.”

Dr. Jha says a collection of anonymized, non-health related data – such as restaurant reservations made through an app – also are “incredibly helpful” in providing information about people’s behaviors during the pandemic, such as their willingness to go out for dinner. “It’s really a way of measuring people’s sense of safety in their community,” he says. “For example, we saw reservation numbers fall as infection numbers began to rise, well before any policy was made on shutting down restaurants.”

The government didn’t start releasing hospital data until about November 2020 in the U.S., and it’s still not available in many, many countries around the world.

The Institute for Health Metrics and Evaluation (IHME) at the University of Washington School of Medicine used similar anonymized data collected through social media platforms to learn more about behaviors.

At the start of COVID-19, IHME began creating forecasts for COVID-19 cases and the resulting hospital bed demand in the university’s health systems, which proved successful and sparked requests from states across the U.S. and countries around the world. The AI for Health data science team, in roughly 72 hours, rapidly built new Azure capabilities and migrated the IHME data into it to meet the expected onslaught of demand worldwide.

“We produced forecasts for every state in the U.S., put them out publicly on March 26, and then that just created a huge flood of further requests,” says Dr. Christopher J.L. Murray, chair of the department of Health Metrics Sciences at UW and director of IHME. “We rapidly expanded from forecasts for the U.S. to adding Europe and Latin America, and then Africa and Asia. By the summer of last year, we were producing forecasts on a weekly basis for every country.”

IHME also started releasing expanded COVID-19 data visualizations and forecasts – including cumulative and daily deaths, hospital bed use and daily infections and testing – that the White House, the Federal Emergency Management Agency, state governors and hospital administrators have started using to mobilize resources.

Dr. Murray says it’s crucial to have hospital data available.

“It’s a more standardized measure than numbers of cases,” he says. “We learned over the course of the pandemic how bad many of the data systems are in reporting cases and deaths…there’s all sorts of biases based on access to testing, in some cases based on politics.

“The government didn’t start releasing hospital data until about November 2020 in the U.S., and it’s still not available in many, many countries around the world. That really limits our ability to track and forecast the pandemic.”

At Morehouse School of Medicine (MSM), a historically Black medical school in Atlanta, while the leadership of the institution made it a point to hold weekly virtual town halls to communicate with students and staff about COVID-19 and regularly test for the virus, they also developed a “Return to School” application to further ensure the safe return of students, faculty and staff to campus. The application is also used across the Atlanta University Center Consortium (AUCC) campuses that include Morehouse College, Spelman College and Clark Atlanta University.

The web-accessible program works on digital devices such as mobile devices or computers and uses Microsoft AI, Azure and Microsoft Power BI resources to help provide a big-picture look at the campus’ overall health.

With the “Return to School” application, each person must complete a “daily symptom tracker” and show the output at the entrance to campus every time before they are allowed to come onto the campus grounds. Sample questions in the tracker include the following: Are you coughing? Sneezing? Did you travel somewhere in the last 21 days? Any “yes” answers serve as a red flag and yields a “red pass.”

Any person with a “red pass” on the “Return to School” application will not be admitted to campus, says Dr. Alexander Quarshie, a professor of Community Health and Preventive Medicine at Morehouse School of Medicine, who worked with the MSM, AUCC and Microsoft AI teams on “Return to School” application.

Those who are given red passes are sent to the school’s student services or human resources offices for follow-up to be tested for COVID-19, and if they test positively, are directed to follow the CDC’s isolation protocols.

“But if persons are able to truthfully complete these symptom tracker questions, and they also comply with the school’s COVID-19-testing protocol, then they are issued green passes,” he says. “It has been a very effective way of making sure that only those that are compliant, and only those that are safe, can return to campus.”

Meharry Medical College is using AI tools to identify COVID-19 hot spots, analyze mental health impacts and build mobile apps to address behavioral needs, as well as to predict health outcomes for minority communities.

Among the AI tools is a precision population health approach that transcends longstanding gaps by providing what is known as social determinants of health (SDOH)-tailored and equitable healthcare.

We need to spend more money on public health and preventive medicine to prevent this from happening again.

Dr. Hildreth was a member of the Food and Drug Administration committee that authorized the first two COVID vaccines. Earlier this year, he was named one of 12 members of the Biden-Harris COVID-19 Health Equity Task Force, which will be making recommendations on how to address the health inequities caused by the COVID-19 pandemic, and how to prevent such inequities in the future.

‘The first lesson for me is the importance of listening to experts and scientists when you’re dealing with a public health crisis as caused by a virus or a pathogen,” he says. “We spent decades and decades understanding the biology of viruses and pathogenic organisms, and not to take advantage of that knowledge was very unfortunate.

“What we should have done was to focus on those more vulnerable to save as many lives as possible – people in assisted-living facilities, people of color and Indigenous people,” Dr. Hildreth says. “If we had focused our attention on the most vulnerable in terms of our prevention strategies, hundreds of thousands of people in our country would still be alive today.”

With Black doctors totaling less than 6% of physicians in the country, the U.S. also needs to do a better job of diversifying its public health force, he says.

“We need to spend more money on public health and preventive medicine to prevent this from happening again. And it also illustrates the importance of improving the basic health status of all of us, so that the next time (a pandemic) happens, we won’t be having the same conversation again.”

Q&A: Peter Lee on the COVID-19 pandemic, societal resilience and crisis-response science

Learn about resilience through innovation

Lead image: Faculty, staff and students are checked for COVID-19 symptoms at the entrances to Morehouse School of Medicine using the “Return to School” program on their mobile devices. (Photo by DV Photo Video)"
Microsoft_News,https://news.microsoft.com/source/features/ai/from-conversation-to-code-microsoft-introduces-its-first-product-features-powered-by-gpt-3/,,From conversation to code: Microsoft introduces its first product features powered by GPT-3,"At its Build developers conference, Microsoft unveiled its first features in a customer product powered by GPT-3, the powerful natural language model developed by OpenAI, which will help users build apps without needing to know how to write computer code or formulas.

GPT-3 will be integrated in Microsoft Power Apps, the low code app development platform that helps everyone from people with little or no coding experience — so-called “citizen developers” — to professional developers with deep programming expertise build applications to improve business productivity or processes. This includes apps to review non-profit gift donations, manage travel during COVID-19 or reduce overtime required to maintain wind turbines.

For instance, the new AI-powered features will allow an employee building an e-commerce app to describe a programming goal using conversational language like “find products where the name starts with ‘kids.’” A fine-tuned GPT-3 model then offers choices for transforming the command into a Microsoft Power Fx formula, the open source programming language of the Power Platform, such as “Filter(‘BC Orders’ Left(‘Product Name’,4)=”Kids”).

It’s one of the first implementations showing how GPT-3, running on Microsoft Azure and powered by Azure Machine Learning and one of the first internal uses of its new managed endpoints capability, can solve real-world business needs on an enterprise scale, Microsoft said.

With new features powered by GPT-3, Microsoft Power Apps users can describe a programming goal in conversational language and have it automatically transformed into Power Fx code.

While Power Fx is built on Microsoft Excel, and therefore much easier to use than traditional coding languages, creating complex data queries can still be a steep learning curve, and these new features help lower that curve.

“Using an advanced AI model like this can help our low-code tools become even more widely available to an even bigger audience by truly becoming what we call no code,” said Charles Lamanna, corporate vice president for Microsoft’s low code application platform.

Microsoft partnership with OpenAI aims to accelerate breakthroughs in AI

Built by OpenAI, an independent AI research and deployment company, GPT-3 is a massive natural language model that runs exclusively on Azure.

Through a partnership with OpenAI that aims to accelerate breakthroughs in AI — from jointly developing the first supercomputer on Azure that is powerful enough to meet the demands of very large AI models to testing and commercializing new AI technologies — Microsoft has a license to the code behind the GPT-3 model that allows it to integrate the technology directly into its products.

“This will allow people to query and explore data in ways they literally couldn’t do before, and that will be the magical moment,” Lamanna said.

Although these “citizen developers” didn’t need to know computer programming languages, they still previously had to understand the logic of writing formulas that might look something like this: FirstN(Sort(Search(‘BC Orders’, “stroller”, “aib_productname”), ‘Purchase Date’, Descending), 10).

With the new GPT-3-powered features, a person can get the same result by typing plainspoken language like: “Show 10 orders that have stroller in the product name and sort by purchase date with newest on the top.”

The features don’t replace the need for a person to understand the code they are implementing but are designed to assist people who are learning the Power Fx programming language and help them choose the right formulas to get the result they need. That can dramatically expand access to more advanced app building and more rapidly train people to use low code tools.

The new features announced at Microsoft Build will be available in preview in the English language throughout North America by the end of June.

Using an advanced AI model like this can help our low-code tools become even more widely available to an even bigger audience by truly becoming what we call no code.

“GPT-3 is the most powerful natural language processing model that we have in the market, so for us to be able to use it to help our customers is tremendous,” said Bryony Wolf, Power Apps product marketing manager. “This is really the first time you’re seeing in a mainstream consumer product the ability for customers to have their natural language transformed into code.”

GPT-3 is part of a new class of models, which Microsoft is broadly exploring through its AI at Scale initiative, that learn from examining billions of pages of publicly available text. They so deeply absorb nuances of language, grammar, knowledge concepts and context that the same model is able to perform a broad set of tasks that involve generating text.

OpenAI released an Azure-powered API last year that allows developers to explore GPT-3 capabilities. Since then, people have used it to do everything from writing poetry and tweets to generating articles, summarizing emails, answering trivia questions and generating computer code from plain language.

This discovery of GPT-3’s vast capabilities exploded the boundaries of what’s possible in natural language learning, said Eric Boyd, Microsoft corporate vice president for Azure AI. But there were still open questions about whether such a large and complex model could be deployed cost-effectively at scale to meet real-world business needs.

“We’re finding ways to bring it into Azure and our mainstream products,” Boyd said. “We think there are a whole bunch more things that GPT-3 is capable of doing. It’s a foundational new technology that lights up a ton of new possibilities, and this is sort of that first light coming into production,” he said.

The Power Platform team, which also works on low code tools to boost business productivity such as Power BI, Power Automate and Power Virtual Agents, quickly realized that GPT-3’s ability to translate conversational language into code could help advance the core mission of democratizing software development, or making it more straightforward for a wider variety of people.

We think there are a whole bunch more things that GPT-3 is capable of doing. It’s a foundational new technology that lights up a ton of new possibilities, and this is sort of that first light coming into production.

The goal is to have AI help with some of the more mundane elements of coding and formula expression, to both widen the pool of people who are able to use the tools and to free up experienced developers to focus on more interesting problems, like getting to the core of the business solution or building a beautiful interface.

Microsoft plans to infuse Power Fx into other tools within Power Platform, at which time the new natural language features powered by GPT-3 will expand into those products as well.

The Power Platform team worked closely with the Azure AI team to fine tune a GPT-3 model using Azure Machine Learning that could translate between natural language and Power Fx expressions.

The Power Platform team used Azure Machine Learning managed endpoints, a new capability announced in preview at Build that helps people deploy models of all sizes in Azure without needing to intricately manage underlying compute infrastructure. In one of the first internal use cases, the Microsoft product team is using it to deploy and manage the GPT-3 model that the team is using to offer new capabilities to Power Apps users.

The team also added filters to help detect sensitive or inappropriate content in any results that might get returned. The fact that the model in this circumstance is generating prescribed Power Fx formulas makes unintended outcomes less likely than, say, asking it to generate the answer to an open-ended question, Lamanna said.

And in the same way that you type a question into a search engine and then get to decide which result to click on, GPT-3 returns multiple suggestions for Power Fx formulas. The person building the app then chooses the most appropriate one to use.

“In all cases, there is a human in the loop,” Lamanna said. “This isn’t at all about replacing developers, it’s about finding the next 100 million developers in the world.”

Related:

Top image: Charles Lamanna, corporate vice president for Microsoft’s low code application platform. Photo by Dan DeLong for Microsoft.

Jennifer Langston writes about Microsoft research and innovation. Follow her on Twitter."
Microsoft_News,https://news.microsoft.com/source/features/ai/azure-applied-ai-services-accelerate-ai-solution-development-to-help-businesses-soar/,,Azure Applied AI Services accelerate AI solution development to help businesses soar,"At any given moment, turnaround coordinators for German airline Lufthansa CityLine have their eyes glued to monitors displaying more than half a dozen video feeds of airplanes parked at gates around the airport. The coordinators’ job is to ensure that the planes are unloaded, refueled, cleaned, restocked and reloaded so that every passenger reaches their destination safely, on time and with their luggage.

Minutes lost here or there in the turnaround process can add up, costing airlines millions of dollars a year. As many in the industry note, airplanes only make money while in the air.

“Think of a pitstop in a car race, and this is pretty much the same that happens in a turnaround for an aircraft,” said Philipp Grindemann, head of business development and project management for Lufthansa CityLine. “All the processes need to be on time, need to be fast, need to be lean.”

Lufthansa CityLine is a subsidiary of Lufthansa, one of the world’s major airline groups with a network that spans the globe. Lufthansa maintains hubs in Frankfurt and Munich, Germany. Lufthansa CityLine connects passengers with destinations around Europe to and from these hubs, flying more than 300 flights per day. Ontime arrivals and departures are essential for customer satisfaction and Lufthansa’s bottom line.

Outside of weather, delays stem from missteps during the tightly choreographed turnaround process. Like most industry players, Lufthansa CityLine relies on manual timestamps to understand when each step of the turnaround process starts and ends and uses that manual timestamp data to glean insights on where to make adjustments for faster, leaner turnarounds.

In a pilot phase, the airline partnered with zeroG, a Lufthansa Group consulting company founded by Lufthansa Systems to accelerate the tangible impact of artificial intelligence in operational and commercial processes at airlines around the world. One example is improving turnaround management with AI.

ZeroG’s Deep Turnaround solution leverages Azure Video Analyzer, a new offering from Microsoft that combines capabilities from Live Video Analytics and Azure Video Indexer. For Lufthansa, it generates automatic timestamps from the video feeds and issues alerts when the turnaround goes off script.

“With that transparency of Deep Turnaround – knowing when the caterer arrives, knowing when the bridge arrives in order to deboard the aircraft – the airline can steer the process and have much leaner processes than before,” said Manuel van Esch, lead consultant for zeroG.

For example, when a fuel truck arrives later than predicted, Deep Turnaround alerts the turnaround coordinators and other ground operations personnel. The alert kicks off a hunt for a solution that prevents a delay, such as dispatching a second fuel truck to the plane.

Applied AI Services

Azure Video Analyzer is among a handful of Azure Applied AI Services that Microsoft highlighted on Tuesday during Build, the company’s annual conference for developers. These services – Azure Video Analyzer, Azure Metrics Advisor, Azure Bot Service, Azure Cognitive Search, Azure Form Recognizer and Azure Immersive Reader – accelerate the development of scenario-specific AI solutions.

Azure Applied AI Services are built on top of AI models at the core of Azure AI products and services. That includes Azure Cognitive Services, which offer customizable AI models and tools for building AI solutions that help customers extract meaning from text, integrate speech into apps and services, identify and analyze content within images and videos, and make decisions.

Customers can also customize these services and extend them with their own custom models from Azure Machine Learning to meet the specific needs of their business.

Customers routinely tell Microsoft that while they see the potential of AI, building solutions are harder than they anticipated, said Eric Boyd, corporate vice president of Microsoft Azure AI in Redmond, Washington.

“The goal with Azure Applied AI Services is to provide a bit more packaging and structure to really accelerate the development of AI solutions for common business processes,” he said.

The Azure Video Analyzer service, for example, brings together Computer Vision from Azure Cognitive Services and an automatic captioning model along with capabilities for integrating existing closed circuit video feeds and video management systems, which make it easier for businesses to build video analytics solutions.

Microsoft created the Azure Applied AI Services category to target common business scenarios that Boyd’s Azure AI team has seen customers repeatedly build from scratch. For example, Azure Form Recognizer builds on optical character recognition, a computer vision technology that recognizes text and is key to many business solutions from reading receipts to pulling data from intake forms.

“To put it in the application that they wanted, there was so much more they needed to do,” Boyd said. “It wasn’t just about getting the text, it’s about understanding the structure of the document and saying, ‘I have this form that someone has filled out, and I want the information on it in my database.’”

Azure Form Recognizer builds on the underlying optical character recognition technology with a framework to understand the whole document structure, extract the relevant information and populate a database.

Building on Microsoft’s internal AI solutions

Many of the Azure Applied AI Services build on AI tools originally developed for internal products and services, including Azure Metrics Advisor. The tool grew out of work developers did for Microsoft’s search engine Bing to detect deviations from normal operations, such as spikes in queries from one country or a sudden drop in advertising revenue.

“Search is really quite predictable in how it changes day over day, and so being able to detect those anomalies, we could really more quickly jump on the problems and solve them,” Boyd said. “That anomaly detector service has rolled out to a number of places, such as Power BI. But it’s a developers’ interface and requires you to string a lot of it together.”

Microsoft made the technology available to the public through Anomaly Detector, one of the Azure Cognitive Services. For Azure Applied AI Services, Microsoft built on the technology that powers Anomaly Detector and tailored it to common solutions for business customers, making it easy to deploy a solution that monitors metrics and, when something is awry, issues an alert and flags where to look to resolve the issue.

Samsung Electronics deployed Azure Metrics Advisor in China for anomaly detection and root cause analysis of problems that could lead to outages on the cloud-based hardware and software system that enables around-the-clock access to audio and video content streamed over the internet for display on the company’s Smart TVs.

The AI solution built with Azure Metrics Advisor helps Samsung engineers detect incidents before they affect customers and quickly fix the issues, said Jie Zhang, the technical leader of Samsung Electronics (China) R&D Centre, who helped on design and implementation.

The backend development of Azure Bot Service followed a similar trajectory as Azure Metrics Advisor, Boyd noted. That service builds on the core speech and language technologies that power Azure Cognitive Services such as Language Understanding, QnA Maker, Speech to Text and Text to Speech in order to help customers develop intelligent conversational assistants.

“We combine a number of Cognitive Services together and package it up and make it simpler for users to use the whole combined thing,” Boyd said.

More value with AI

Several of the services now available under the Azure Applied AI Services category were previously available as standalone Azure Cognitive Services such as Azure Form Recognizer and Azure Immersive Reader, which enables developers to implement techniques into their applications that improve reading and writing for people regardless of their age or ability.

Other services were individual offerings under Azure AI, such as Azure Bot Services and Azure Cognitive Search, which allows developers to integrate AI-powered search to their apps and websites.

The reorganization, Boyd said, is intended to make it easier for business customers to find AI solutions to common business processes. The new category is expected to grow in the months and years to come as the Azure AI team works with customers within specific industries or sees customers solving the same problem with a combination of Azure AI services.

“We see this category of ‘How do you package and combine and simplify these things?’ really speaking to people understanding that there’s tremendous power in what AI can do and saying, ‘I need to bring that to all areas of my business,’” Boyd said.

The ability of AI to generate and make sense of data is behind zeroG’s embrace of Azure Video Analyzer for the Deep Turnaround solution piloted by Lufthansa CityLine. And this is just the beginning of a digital transformation with AI throughout the Lufthansa Group, according to Xavier Lagardere, the aviation company’s chief data officer.

“We’re not yet systemically a real time data-driven type of company when it comes to making choices, making decisions or even acting upon data,” he said. “There’s an exciting road ahead to do much more with the huge piles of data that we generate in the day-to-day.”

Related:

Top image: A Lufthansa CityLine airplane is parked at an airport gate as ground operations crew prepare it for the next flight. The airline is piloting AI technology that can help improve the efficiency of the turnaround process. Photo courtesy of Lufthansa.

John Roach writes about Microsoft research and innovation. Follow him on Twitter."
Microsoft_News,https://news.microsoft.com/source/features/work-life/reading-progress/,,"Students have a new, less stressful way to improve their reading — and it’s easier for teachers, too","Andres Villegas is a serious, quiet 11-year-old who has loved to read since he was 4 — especially Harry Potter and science fiction. But whenever he was asked to read aloud, his palms would get sweaty and he’d skip or mispronounce words, even ones he knew.

Then his fifth-grade teacher found a new program that lets students practice their verbal reading skills. Soon Andres was reading out loud to a computer that was invisibly evaluating his literacy, instead of having a teacher mark down mistakes on paper, and discovered it was “actually kind of relaxing,” he says. “In front of the camera, I don’t feel that stressed out. I feel like I’m less distracted, and I’m reading better — more clearly and not that slow — and I feel much more confident.”

It’s a development being seen among hundreds of students who have been trying out the new feature, called Reading Progress, which will be available for free in Microsoft Teams for Educators by the start of the next schoolyear in the U.S. It uses AI-enhanced evaluations to give teachers insight into students’ struggles and already has saved them hours each week that they’ve been able to put back into individualized instruction — to the benefit of their students, especially amid the disruptive pandemic.

“This is something teachers really, really needed for management, time, efficiency and effectiveness,” says Andres’ teacher, Jennifer Saikaly Moreno, who quickly spread the word among fellow teachers during remote schooling last fall and is using Reading Progress back in the classroom this spring. “I’ll be using this forever and always.”

For Andres, the newfound confidence has turned him into a supportive leader among his classmates, his teacher says, and is extending beyond the classroom, too: He has started reading books to his little brother, who’s in first grade, as well as his 4-year-old cousin.

Learning to read is a crucial building block for life, and the practice of reading aloud is key to comprehension and empowerment.

“Employability, civic lives, social media, ways for our students to become advocates for themselves and others — it all starts with that foundation of literacy,” says Shaelynn Farnsworth, a reading expert and the News Literacy Project’s national director of educator outreach. “If you’re illiterate, you’re cut off from all those opportunities. That’s why reading is the No. 1 focus and at the forefront of education.”

Jose Garcia wished he’d had a program like Reading Progress growing up in Los Angeles in the early ‘90s.

Garcia, the instructional technology support specialist for Fontana Unified School District, where Andres attends and Saikaly Moreno teaches, was born in the U.S. to parents who had immigrated from Mexico and spoke Spanish at home. From the outset he was shuffled into Spanish-speaking classes, along with almost all the kids he knew. He could speak English, but he says the schools were overcrowded and he didn’t get much practice in reading out loud, which meant he didn’t do well on tests for moving into English-speaking classes.

“I remember the fluency tests where they call you to the table, and the teacher’s assistant puts a timer on and you read, and they mark what you got wrong,” he says. “If this tech was around when I was growing up, I would have tested out earlier, and it would have set me up for better opportunities.”

In most elementary and middle schools in the U.S. today, students do frequent reading tests similar to the ones Garcia recalls.

They read a text to a teacher, who has a paper copy and marks any errors such as a mispronunciation or an omitted or inserted word. The teacher reviews the results to see what level pupils are reading at and what they’re struggling with and need to focus on — both individually and as a class. The assessments give insight into the students’ vocabulary and comprehension, in part by the cadence of their reading and whether they follow punctuation cues with pauses, phrasing and intonation.

It’s a heavily time-intensive process, especially with larger classes, and the insights aren’t easily come by and can be outdated by the time they’re all tabulated. Kids find it stressful, too, and often clam up when they notice the teacher marking down their mistakes.

Mike Tholfsen, the product manager for Microsoft’s Immersive Reader feature, saw teachers tweeting about their frustration and gathered his team for “a giant brainstorm session” in 2018, bringing in literacy experts and educators from around the world to outline the problem.

“We learned that reading fluency is important, but it’s incredibly painful for teachers to do,” Tholfsen recalls. “They hate doing it, it takes them forever, they have to pull the kids out into a hallway where it’s loud, and the rest of the class is going crazy while they’re listening and marking in the hallway. The kids don’t like reading out loud, and for many it’s stigmatizing” — the list of frustrations was long.

“To get better at reading fluency, you need to read out loud and practice more — it’s a self-reinforcing thing,” he says. “But because it’s such a time suck, it’s like kids were only brushing their teeth a couple times a year instead of every day.”

Tholfsen pulled together a team including experts from all reading science methodologies to make sure the new feature would work regardless of the technique being used. Designers had to account for the difference in children’s voices, since voice-recognition software was created for adults, and for accents and colloquialisms — along with masks that can muffle dictation. And developers gave teachers control over the level of discretion, with the ability to change mistakes that get marked or even to turn off auto-detect and do their own evaluations of the videos.

Microsoft had recently acquired Flipgrid, a social learning platform for students. Its founder, Charlie Miller, encouraged Tholfsen’s team to combine audio and video to help teachers feel more connected to students and let them see what was happening — such as distractions or mouth movements — when mistakes were flagged.

When Tholfsen started running the prototype past teachers last year, “it resonated unbelievably and they wanted it now, for their whole school,” he says. “It was a Spidey-sense tingling feeling. We were on to something.”

The timing of the new program couldn’t have been better for Joe Merrill, a first-grade teacher in Florida.

Since schools sent everyone home in March 2020 due to the pandemic, teachers had “a lot of catchup to do” last fall, says Merrill, who teaches foundational reading skills to 6- and 7-year-olds, helping them choppily sound out words at the beginning of the year until they’re smoothly reading whole sentences by the end. First grade is a big academic year, he says, with growth so fast the kids can jump 10 levels, whereas advancement slows to three or four levels a year by fourth grade. Frequent assessments are crucial to help him quickly adjust his instruction and adapt to the pace of the progress being made.

Merrill arranges his pupils into groups of five and aims to listen to one per day per group read out loud, notating their mistakes in order to have a curated list at the end of each week that helps him choose appropriate texts for the following week.

He started using Reading Progress at the beginning of this school year and says it has saved him five hours a week of class time, not to mention hours of work after class to review and assess.

“I can turn that time right back into more targeted instruction, which is incredibly valuable,” says Merrill, whose students surprised him by surpassing yearend expectations only three quarters of the way through. “We’ve been able to close that gap and keep the foot on the accelerator to make sure we’ve caught up.”

In Tacoma, Washington, 9-year-old Brielle Taylor has jumped from a fourth-grade to sixth-grade reading fluency level since starting to use Reading Progress in February.

Brielle recalls completing a reading quiz recently and looking up at her mother, curious how she’d done.

“Mom made this expression, and I didn’t know if it was bad or good, because she just said ‘Whoa,’” Brielle says.

It turned out Brielle had passed her “stretch growth goal,” which students don’t usually meet unless they’ve worked “really hard,” says her mother, Lauren Taylor, who happens to be the principal of the school.

“Looking with my mom lens I’m obviously super proud,” Taylor says. “But from the principal lens, with COVID I wasn’t sure if there would be any growth at all, and so to see that she made not just the typical growth but also beat the year’s stretch growth goal, in March already, that’s huge.”

Even Brielle’s little sister, 6-year-old Zoe, can hear the difference and now asks for Brielle, instead of their mother, to read to her every night before bed.

“She can read harder books now,” Zoe says, “even the new ones she got for Christmas.”

Click here to load media

Brielle’s teacher, Liliya Petrovskaya, says the new feature allows for quicker feedback than the old method, and that makes students more self-motivated.

Petrovskaya assigns a text in Reading Progress to her class and gets the results within five minutes, she says, including words per minute and the accuracy rate. Then she goes through the evaluations on her own and spends the allotted one-on-one class time watching each student’s video with them and discussing it together. The process gives her time to reflect on each kid’s needs without classroom interruptions or the pressure of having to give feedback on the fly.

“When I meet with them now, there’s more quality to it and I can dig deeper with each student, instead of just saying, ‘You read this many words per minute and made these mistakes,’” Petrovskaya says. “And when they listen to themselves, it becomes more intrinsic. Kids naturally want to get better, and this taps into that. It takes the reins from me and gives control to the students over their learning, because they can see their mistakes themselves, and that has been super powerful and empowering for them.”

The Reading Progress insights empower educators as well, helping them teach students at all levels from kindergarten through adulthood.

Luis Oliveira, who has taught English as a second language for 30 years, was shocked to see the word “mathematics” show up in a Reading Progress word cloud as the biggest problem for one of his high school classes. That word had never been an issue before, but the system flagged a mispronunciation for almost every student, and when Oliveira watched the videos at that point in the texts — teachers can skip to certain words or lines as they review the evaluations — he could tell even those who pronounced it correctly had hesitated.

Oliveira often assigns texts about American culture to his immigrant students, knowing they engage more when they’re interested in the subject matter. This schoolyear he chose a lot of articles about the COVID-19 virus and vaccines to help them understand discussions going on in their other classes. He suddenly realized he needed to diversify more.

“The word cloud and videos help target the problem areas much easier,” he says. “And if it helps the teachers help the students, then it’s a great thing.”

Lead image: Brielle Taylor reads to her little sister Zoe. (Photo by Scott Eklund/Red Box Pictures)"
Microsoft_News,https://news.microsoft.com/source/features/ai/with-azure-percept-microsoft-adds-new-ways-for-customers-to-bring-ai-to-the-edge/,,"With Azure Percept, Microsoft adds new ways for customers to bring AI to the edge","Elevators that respond to voice commands, cameras that notify store managers when to restock shelves and video streams that keep tabs on everything from cash register lines to parking space availability.

These are a few of the millions of scenarios becoming possible thanks to a combination of artificial intelligence and computing on the edge. Standalone edge devices can take advantage of AI tools for things like translating text or recognizing images without having to constantly access cloud computing capabilities.

At its Ignite digital conference, Microsoft unveiled the public preview of Azure Percept, a platform of hardware and services that aims to simplify the ways in which customers can use Azure AI technologies on the edge – including taking advantage of Azure cloud offerings such as device management, AI model development and analytics.

Roanne Sones, corporate vice president of Microsoft’s edge and platform group, said the goal of the new offering is to give customers a single, end-to-end system, from the hardware to the AI capabilities, that “just works” without requiring a lot of technical know-how.

The Azure Percept platform includes a development kit with an intelligent camera, Azure Percept Vision. There’s also a “getting started” experience called Azure Percept Studio that guides customers with or without a lot of coding expertise or experience through the entire AI lifecycle, including developing, training and deploying proof-of-concept ideas.

For example, a company may want to set up a system to automatically identify irregular produce on a production line so workers can pull those items off before shipping.

Azure Percept Vision and Azure Percept Audio, which ships separately from the development kit, connect to Azure services in the cloud and come with embedded hardware-accelerated AI modules that enable speech and vision AI at the edge, or during times when the device isn’t connected to the internet. That’s useful for scenarios in which the device needs to make lightning-fast calculations without taking the time to connect to the cloud, or in places where there isn’t always reliable internet connectivity, such as on a factory floor or in a location with spotty service.

In addition to announcing hardware, Microsoft says it is working with third-party silicon and equipment manufacturers to build an ecosystem of intelligent edge devices that are certified to run on the Azure Percept platform, Sones said.

“We’ve started with the two most common AI workloads, vision and voice, sight and sound, and we’ve given out that blueprint so that manufacturers can take the basics of what we’ve started,” she said. “But they can envision it in any kind of responsible form factor to cover a pattern of the world.”

Making AI at the edge more accessible

The goal of the Azure Percept platform is to simplify the process of developing, training and deploying edge AI solutions, making it easier for more customers to take advantage of these kinds of offerings, according to Moe Tanabian, a Microsoft vice president and general manager of the Azure edge and devices group.

For example, most successful edge AI implementations today require engineers to design and build devices, plus data scientists to build and train AI models to run on those devices. Engineering and data science expertise are typically unique sets of skills held by different groups of highly trained people.

“With Azure Percept, we broke that barrier,” Tanabian said. “For many use cases, we significantly lowered the technical bar needed to develop edge AI-based solutions, and citizen developers can build these without needing deep embedded engineering or data science skills.”

The hardware in the Azure Percept development kit also uses the industry standard 80/20 T-slot framing architecture, which the company says will make it easier for customers to pilot proof-of-concept ideas everywhere from retail stores to factory floors using existing industrial infrastructure, before scaling up to wider production with certified devices.

As customers work on their proof-of-concept ideas with the Azure Percept development kit, they will have access to Azure AI Cognitive Services and Azure Machine Learning models as well as AI models available from the open-source community that have been designed to run on the edge.

In addition, Azure Percept devices automatically connect to Azure IoT Hub, which helps enable reliable communication with security protections between Internet of Things, or IoT, devices and the cloud. Customers can also integrate Azure Percept-based solutions with Azure Machine Learning processes that combine data science and IT operations to help companies develop machine learning models faster.

In the months to come, Microsoft aims to expand the number of third-party certified Azure Percept devices, so anybody who builds and trains a proof-of-concept edge AI solution with the Azure Percept development kit will be able to deploy it with a certified device from the marketplace, according to Christa St. Pierre, a product manager in Microsoft’s Azure edge and platform group.

“Anybody who builds a prototype using one of our development kits, if they buy a certified device, they don’t have to do any additional work,” she said.

Security and responsibility

Because Azure Percept runs on Azure, it includes the security protections already baked into the Azure platform, the company says.

Microsoft also says that all the components of the Azure Percept platform, from the development kit and services to Azure AI models, have gone through Microsoft’s internal assessment process to operate in accordance with Microsoft’s responsible AI principles: fairness, reliability and safety, privacy and security, inclusiveness, transparency, and accountability.

The Azure Percept team is currently working with select early customers to understand their concerns around the responsible development and deployment of AI on edge devices, and the team will provide them with documentation and access to toolkits such as Fairlearn and InterpretML for their own responsible AI implementations.

Ultimately, Sones said, Microsoft hopes to enable the development of an ecosystem of intelligent edge devices that can take advantage of Azure services, in the same way that the Windows operating system has helped enable the personal computer marketplace.

“We are a platform company at our core. If we’re going to truly get to a scale where the billions of devices that exist on the edge get connected to Azure, there is not going to be one hyperscale cloud that solves all that through their first-party devices portfolio,” she said. “That is why we’ve done it in an ecosystem-centric way.”

Related:

Top image: The Azure Percept platform makes it easy for anyone to deploy artificial intelligence on the edge. Devices include, from left to right, Trusted Platform Module, Azure Percept Vision and Azure Percept Audio. Each device integrates with industry standard 80/20 hardware. Photo credit: Microsoft."
Microsoft_News,https://news.microsoft.com/source/features/digital-transformation/microsoft-customers-accelerate-innovation-and-transform-industries/,,Microsoft customers accelerate innovation and transform industries,"Click here to load media

The past year has challenged even the most established businesses. Faced with a global pandemic and wide-reaching recession, organizations across all industries were forced to pause and re-evaluate how to best plan for the future – a future that no one could have anticipated. But when the world shut down, innovators got to work.

Through their partnerships with Microsoft, organizations across nearly every industry have accelerated innovation and digital transformation to respond, recover and reimagine their businesses over the past year. From life sciences to financial services, retail to manufacturing and government to nonprofit, Microsoft’s investments in industry-specific people, products and platforms have helped its customers build a foundation for the future."
Microsoft_News,https://news.microsoft.com/source/features/ai/custom-neural-voice-ga/,,Are you talking to me? Azure AI brings iconic characters to life with Custom Neural Voice,"To bring voice conversation capabilities to its Flo chatbot, Progressive Insurance created a synthetic voice using Custom Neural Voice. Image courtesy of Progressive Insurance.

A few years ago, the company launched a Flo chatbot in Facebook messenger, complete with the sunny personality and quirky witticisms that customers have come to expect from the salesperson character played by Stephanie Courtney in TV ads since 2008. When the company started to explore the potential of using a voice conversation to interact with customers, Flo was the natural choice.

“One of Progressive’s core interest areas is we want to make our brand and products available wherever and whenever people want,” said Matt White, technology and innovation manager in Progressive’s acquisition experience group. “That’s why we put Flo in Facebook Messenger, and that’s why we started to explore what’s possible with voice and smart speakers.”

Progressive was already using Azure AI technology to power the chatbot, and it made sense to layer the neural text-to-speech service on top, White said.

The general availability of Custom Neural Voice includes technical controls to help prevent misuse of the service. As part of the voice recording script a customer submits to create the custom voice, the voice actor makes a statement acknowledging that they understand the technology and are aware that the customer is having a Custom Neural Voice made. That recording is compared with the training data using speaker verification technology to make sure the voices match before a customer can begin training the voice. Microsoft also contractually requires customers to get consent from voice talent.

“We did a number of studies and had interactions with the voice acting industry and ethicists in the field to come up with sets of guidelines and ways we want to make sure this technology is used,” Boyd said.

A commitment to responsibility

Contractual terms, limiting access to approved customers and performing speaker verification on audio files are three ways Microsoft is safeguarding against misuse of the technology. Bird’s role within Microsoft is to help develop protocols and support teams in responsibly developing features and products within Azure Cognitive Services, as well as empowering customers to use them responsibly.

“We really want to demonstrate how we can create these technologies that have this positive impact while making sure that we’re not causing harm in the world,” Bird said.

Microsoft conducts impact assessments to determine potential risks. Once risks have been identified, features and processes are created to address them. In the case of Custom Neural Voice, such safeguards include the review process for each potential use case, a code of conduct and the verification comparing voice talent acknowledgement files against training audio files.

Bird said the team is also working on a way to embed a digital watermark within a synthetic voice to indicate that the content was created with an Azure Custom Neural Voice.

Such technical and policy features are in line with Microsoft’s commitment to responsible AI. That commitment includes Transparency Notes, which communicate the purposes, capabilities and limitations of an AI system.

“As creators of this technology, we have an obligation to make sure it’s used responsibly,” Boyd said. “We take responsible AI very seriously; it’s one of our core tenets. And we’re careful with the partners we work with in making sure they follow the guidelines.”

Building a custom voice

So how do a bunch of recorded phrases become a natural-sounding voice that can say anything?

Recordings are used to create a font of sounds, or phonemes. It’s somewhat similar to a font on a computer containing letters and characters that you combine to make words and sentences.

But neural text-to-speech goes way beyond piecing together sounds to form words.

“The real technology breakthrough is the efficient use of deep learning to process the text to make sure the prosody and pronunciation is accurate,” said Xuedong Huang, a Microsoft technical fellow and the chief technology officer of Azure AI Cognitive Services. “The prosody is what the tone and duration of each phoneme should be. We combine those in a seamless way so they can reproduce the voice that sounds like the original person.”"
Microsoft_News,https://news.microsoft.com/source/features/digital-transformation/progressive-gives-voice-to-flos-chatbot-and-its-as-no-nonsense-and-reassuring-as-she-is/,,"Progressive gives voice to Flo’s chatbot, and it’s as no-nonsense and reassuring as she is","The usually sunny Flo is perturbed with Mara (yet again) during a work-from-home Progressive Insurance staff meeting over video. While seated at the computer, Mara is busy talking to someone at home. “Mara, you know you’re not on mute, right?” says Flo. “Oh, there’s a mute button?” the laconic Mara replies with genuine surprise.

During these months of work-from-home meetings, we all can relate. And Flo, of course, makes everything more relatable.

Progressive Insurance’s iconic spokesperson, portrayed by actress Stephanie Courtney, has not only been the star of Progressive’s TV ads since 2008, but also has a strong social media presence, including more than 4 million followers on Facebook. In fact, Progressive created a “Flo” chatbot to enable customers to interact with Flo on Facebook Messenger, as well as other channels, to help customers with basic insurance questions.

Now, Flo’s voice is being added to the chatbot, creating an even more personal experience for customers who adore the personable lady in the white apron.

“Flo obviously has been a staple and a highly recognized brand icon for Progressive,” says Matt White, technology and innovation manager in Progressive’s acquisition experience group. “We wanted the chatbot persona to be friendly and helpful to consumers in their path to purchasing insurance, and ultimately, in becoming customers of Progressive for what we hope will be decades.”

The Flo Chatbot runs on Microsoft Azure. Azure Bot Service and Azure Cognitive Services are among the services used to create the Flo Chatbot in 2017 and now, to give her a voice.

You can banter with the virtual version of Flo, if you like, and you’ll find she’s just as polite and matter-of-fact as she is in Progressive’s ads.

Ask Flo what her favorite movie is, and she responds, “I could try to pick a favorite, but we’d be here until next Tuesday.” Want to know her favorite food? “I could go for a taco right about now but was told I could only have one every hour.”

To get a behind-the-scenes look, we spoke with White to learn more about the Flo Chatbot with voice, Progressive’s work with Microsoft and what’s important when it comes to helping customers.

TRANSFORM: Tells us about the origins of the journey for Progressive, Flo and Microsoft.

WHITE: We began the journey with Microsoft three years ago, when we wanted to embark on building a chatbot. But more importantly than building a chatbot was really to build a conversational experience, and frankly, learn about the potential power of having conversational experiences available in a variety of digital channels.

As we’ve continued to learn about what it takes to build and maintain, and ideally excel, at conversational experiences, we wanted to learn: What does it take to integrate text to speech in a voice component?

The foundation of the bot itself is the Microsoft Bot Framework. What we’ve done is layered on another cognitive service, so we could take all that existing architecture and foundation, and layer in the text-to-speech service.

TRANSFORM: How does the Flo Chatbot help people now, and how will adding voice change things?

WHITE: The Flo chatbot is capable of a variety of different things. There’s a large question-and-answer functionality, from Insurance 101 kind of questions – “What does comprehensive mean?” “What does collision mean in terms of car insurance coverage?” – to if you have policy servicing questions, we can point you in the right direction.

If you’d like to get an insurance quote for a variety of products, with our subsequent releases of the Flo Chatbot, we’ll fully build out the ability for people to get a car insurance quote through the experience.

TRANSFORM: What are some of the wackiest questions the Flo chatbot has been asked?

WHITE: I guess it depends on your perception of wacky. They’ll ask for jokes. They ask, “What’s your favorite movie?” “What’s your favorite food?”

You could say, well, it’s not really worth training answers on that, but people ask. The Microsoft tools certainly make it easy enough to train answers for those kinds of persona-based questions, or just chit-chat kind of questions. I think those are opportunities to delight consumers, so why wouldn’t we?

TRANSFORM: Is incorporating Flo’s personality and sense of humor in the chatbot difficult to do?

WHITE: No, not from a technical perspective. Thankfully, we have some very talented copywriters who are used to writing in the voice of Flo for various purposes.

You always want to be on the lookout for opportunities to delight, but not unintentionally create frustration. You want to be able to acknowledge frustration, too. There are times where some wit or humor is appropriate, depending on the user’s engagement and what they’re asking. And then there’re times when it should be just the facts, or empathy, to help. If someone chats with us and says they had a car accident, that’s not the time for talking about tacos and unicorns. You still want to be friendly and helpful but get them the information they need.

TRANSFORM: What have you learned about chatbots based on communications so far from customers?

There are lots of repetitive questions that a chatbot can certainly handle well – informational questions, point people to the right information. I frankly think it’s just as important to recognize the kinds of things where you really want customers connected to a live person.

One of the things we try and think about, too, is that we always want to provide an off-ramp; we want to avoid user frustration. So if the bot doesn’t understand, or doesn’t comprehend what the user might be asking, we have logic built in such that, rather than getting stuck in a loop, we offer a connection to a person who can help.

In addition to dealing with some of those repetitive questions and repetitive transactions, the chatbot has also helped surface those more complicated questions that you could envision potentially training the bot to handle, but you may not want to. It might make more sense to have a licensed insurance agent from Progressive handle those questions.

TRANSFORM: What are the benefits of using Azure Cognitive Services for the Flo chatbot?

WHITE: One advantage for us is the decoupled nature of the services. In other words, you can use what you need to use. You don’t have to use everything. We use a variety of services for natural language understanding – the LUIS service as well as QnA Maker. Those are two stand-alone services. We use them together, depending on the nature of the user’s question. Now we’re using the neural text-to-speech service that we’ve been able to kind of bolt on, if you will, to this so that we can bring voice to the experience.

Being able to integrate the bot framework, which lives in Azure, into our own kind of Progressive APIs to help answer questions or execute transactions has been one of the key advantages. You’re not locked into a huge suite of products. You can use the products that you need, and then you can layer in other products – your own or others, if needed.

Another advantage with the open-source nature of the Microsoft Bot Framework is that all these services are but an API call away. If you want to layer in a new experience, or tailored experience, or use a service, it’s easy to integrate those pieces on the foundation they’ve already built.

TRANSFORM: Are there other features that Progressive might want to add to the Flo chatbot in the future?

WHITE: We don’t have any near-term plans, but as you might imagine there’s a variety of other cognitive services that, depending on where our conversational journey takes us, you could envision potentially layering in things like computer vision, or machine vision, and other cognitive services.

For example, if we needed pictures of documents, if we needed pictures of anything where people could load them up into the chatbot experience we could use the machine vision service to help identify what is in the image and then process it accordingly.

I think one of the things we’ll find as people get used to chatbots, and engage with them, they’re going to want to be able to do more things. So as those consumer demands grow, we’ll certainly grow with it.

TRANSFORM: It’s crucial to Microsoft that machine learning and artificial intelligence (AI) be used responsibly and ethically. What was your experience in those areas in developing the Flo chatbot?

WHITE: I appreciate Microsoft’s partnership on this front as well. The technology that is out there is incredibly powerful. You can train chatbots to do a lot of things that people can do, but just because we can, doesn’t mean we should. As I mentioned before, there are questions we could reasonably train the chatbot to answer, but that doesn’t mean that we should. It still might be better to get people to a live Progressive Insurance consultant to discuss their particular issue, concern or question.

I think that’s particularly true when you start introducing a character’s voice – but still a voice – and I thought Microsoft’s approach to that in ethics and AI has been very upfront and straightforward in terms of how we use it. It’s certainly been an approach consistent with Progressive’s own core values.

One of the things I appreciate from some of the disclosure that’s required – we want to make it sound real, we want to make it sound authentic, but we also want to be transparent that it’s not. And that’s actually a requirement from Microsoft – that even when you initially engage with the voice font on Google Assistant, as an example, we say upfront that this is a virtual version of Flo.

We want it to sound and act like Flo as much as it can, being a machine, but we want to be very transparent about what it is and what it isn’t. So when people ask, is this a bot, is it a person, we don’t try and pretend it’s a person. Right up front. We offer help if they want to speak to a live person, we can certainly get them there.

(Photos and audio files courtesy of Progressive.)

Visit the AI Blog to learn how Custom Neural Voice is bringing to life other iconic characters, like Bugs Bunny and the Duolingo crew."
Microsoft_News,https://news.microsoft.com/source/features/ai/microsoft-gives-users-control-over-their-voice-clips/,,Microsoft gives users control over their voice clips,"Microsoft is rolling out updates to its user consent experience for voice data to give customers more meaningful control over whether their voice data is used to improve products, the company announced Friday. These updates let customers decide if people can listen to recordings of what they said while speaking to Microsoft products and services that use speech recognition technology.

If customers choose to opt in, people may review these voice clips to improve the performance of Microsoft’s artificial intelligence systems across a diversity of people, speaking styles, accents, dialects and acoustic environments. The goal is to make Microsoft’s speech recognition technologies more inclusive by making them easier and more natural to interact with, the company said.

Customers who do not choose to contribute their voice clips for review by people will still be able to use all of Microsoft’s voice-enabled products and services.

Voice clips are audio recordings of what users said when they used their voice to interact with voice-enabled products and services, such as dictating a translation request or a web search.

Microsoft removes certain personal information from voice clips as they are processed in the cloud, including Microsoft account identifiers and strings of letters or numbers that could be telephone numbers, Social Security numbers and email addresses.

The new settings for voice clips mean that customers must actively choose to allow people to listen to the recordings of what they said. If they do, Microsoft employees and people contracted to work for Microsoft may listen to these voice clips and manually transcribe what they hear as part of a process the company uses to improve AI systems.

“Their transcription is what we consider our ground truth of what was actually spoken inside that audio clip. We use that as a basis for comparison to identify where our AI needs improvement,” said Neeta Saran, a senior attorney at Microsoft in Redmond, Washington.

The more transcripts Microsoft has of how real people talk from contributed voice clips, the better these AI systems will perform.

While Microsoft employees and contractors will only listen to voice clips with user permission, the company may continue to access information associated with user voice activity, such as the transcriptions automatically generated during user interactions with speech recognition AI. The details of how that works are described in the terms of use for individual Microsoft products and services, the company said.

Meaningful consent

These new settings for voice clips are designed to give customers meaningful consent for people to listen to what they said while interacting with Microsoft products and services, including increased awareness of who their voice clips are being shared with and how they are being used.

“This new meaningful consent release is about making sure that we’re transparent with users about how we are using this audio data to improve our speech recognition technology,” Saran said.

Because Microsoft removes account identifiers from the voice clips as they are processed, they will no longer show up in the privacy dashboard of customers’ Microsoft accounts, the company said.

Microsoft does not use any human reviewers to listen to audio data collected from speech recognition features built into enterprise offerings, the company added.

Data retention and next steps

On Oct. 30, 2020, Microsoft stopped storing voice clips processed by its speech recognition technologies. Over the next few months, the company is rolling out the new settings for voice clips across products including Microsoft Translator, SwiftKey, Windows, Cortana, HoloLens, Mixed Reality and Skype voice translation.

If a customer chooses to let Microsoft employees or contractors listen to their voice recordings to improve AI technology, the company will retain all new audio data contributed for review for up to two years. If a contributed voice clip is sampled for transcription by people, the company may retain it for more than two years to continue training and improving the quality of speech recognition AI.

“The more diverse ground truth data that we are able to collect and use to update our speech models, the better and more inclusive our speech recognition technology is going to be for our users across many languages,” Saran said.

Related:"
Microsoft_News,https://news.microsoft.com/source/features/ai/reinforcement-learning/,,"With reinforcement learning, Microsoft brings a new class of AI solutions to customers","Someone looking to book a vacation online today might have very different preferences than they did before the COVID-19 pandemic.

Instead of flying to an exotic beach, they might feel more comfortable driving locally. With limited options for dining out, having a full kitchen might be essential. Motel rooms or cabins might be more appealing than hotels with shared lobbies.

Countless companies use online recommendation engines to show customers products and experiences that match their interests. And yet, traditional machine learning models that predict what people might prefer are often based on data from past experience. That means they aren’t necessarily able to pick up on quickly changing consumer preferences unless they are retrained with new data.

Personalizer, which is part of Azure Cognitive Services within the Azure AI platform, uses a more cutting-edge approach to machine learning called reinforcement learning, in which AI agents can interact and learn from their environment in real time.

The technique used to be primarily used in research labs. But now, it’s making its way into more Microsoft products and services — from Azure Cognitive Services that developers can plug into apps and websites to autonomous systems that engineers can use to refine manufacturing processes. Azure Machine Learning is also previewing cloud-based reinforcement learning offerings for data scientists and machine learning professionals.

“We’ve come a long way in the last two years when we had a lot of proof of concept projects within Microsoft and deployments with a couple of customers,” said Rafah Hosn, senior director at Microsoft Research’s New York lab. “Now we are really progressing nicely into things that can be packaged and shrink wrapped and pointed to a particular set of problems.”

Rafah Hosn, senior director at Microsoft Research Lab – New York City. Photo courtesy of Microsoft.

Z-Tech, the technology hub of Anheuser-Busch InBev, is using Personalizer to deliver tailored recommendations in an online marketplace to better serve small grocery stores across Mexico. Other Microsoft customers and partners are employing reinforcement learning to detect production anomalies and develop robots that can adjust to unpredictable real-world conditions — with models that can learn from environmental cues, expert feedback or customer behavior in real time.

Once Microsoft began using Personalizer on its homepage to contextually personalize the products displayed to each visitor, the company saw a 19-fold increase in engagement with the products that Personalizer chose. The company has also used Personalizer internally to select the right offers, products and content across Windows, Edge browser and Xbox. These scenarios are giving up to a 60% lift in engagement across billions of personalizations each month.

Teams has also used reinforcement learning to find the optimal jitter buffer for a video meeting, which trades off millisecond-scale information delays to provide better connection continuity, while Azure is exploring reinforcement learning-based optimization to help determine when to reboot or remediate virtual machines.

Because reinforcement learning models learn from instantaneous feedback, they can quickly adapt to changing or unpredictable circumstances. Once the COVID-19 pandemic hit, some companies had no idea what to expect as people’s purchasing and travel behaviors changed overnight, said Jeff Mendenhall, a Microsoft principal program manager for Personalizer.

“All of their historic modeling and expert knowledge went out the window,” Mendenhall said. “But with reinforcement learning, Personalizer can update the model every minute if needed to learn and respond to what actual user behaviors are right now.”

In reinforcement learning, an AI agent learns largely by trial and error. It tests out different actions in either a real or simulated world and gets a reward when the actions achieve a desired result — whether that’s a customer hitting the button to book a vacation reservation or a robot successfully unloading an unwieldy bag of coins.

Training an AI agent through reinforcement learning is similar to teaching a puppy to do a trick, Hosn said. It gets a treat when it makes decisions that yield a desired result and learns to repeat the actions that get the most treats. But in complicated real-world scenarios, exploring the vast universe of potential actions and finding an optimal sequence of decisions can be far more complicated.

At the 34th Conference on Neural Information Processing Systems (NeurIPS 2020) this week, Microsoft researchers presented 17 research papers that mark significant progress in addressing some of the field’s biggest challenges. By investing in reinforcement learning teams across its network of Microsoft Research labs, the company says it is developing a portfolio of approaches to tackle different problems and exploring multiple paths to potential breakthroughs.

John Langford, partner research manager at Microsoft Research Lab – New York City. Photo by John Brecher.

Those teams have focused on developing a robust understanding of reinforcement learning’s foundational elements and creating practical solutions for customers — not just novelty demonstrations, researchers say.

They’ve spent a lot of time figuring out which scenarios reinforcement learning is well-suited to solve, as well as probing the technical underpinnings to understand why something works and how to repeat it, said John Langford, a partner research manager at Microsoft Research Lab – New York.

“Right now there’s a big gap between one-off applications where you can get PhDs to grind really hard and figure out a way to make it work as opposed to developing a routinely useful system that can be used over and over again,” Langford said.

“All of our reinforcement learning research at Microsoft really falls into two big buckets — how can we solve challenges that customers are bringing to us and what are the foundations we can use to build replicable, reliable solutions?” he said.

A different approach to machine learning

Reinforcement learning uses a fundamentally different approach than supervised learning, a more common machine learning technique in which models learn to make predictions from training examples they’ve been fed.

If a person is trying to learn French, exposing themselves to French text, grammar rules and vocabulary is closer to a supervised learning approach, said Raluca Georgescu, a research software engineer working on Project Paidia in the Microsoft Research Cambridge UK lab.

With a reinforcement learning approach, they would go to France and learn by talking to people. They’d be penalized with puzzled looks if they say the wrong thing and they’d get rewarded with a croissant if they order it correctly, she said.

A reinforcement learning agent learns from interacting with its environment, either in the real world or in a simulated environment that allows it to safely explore different options. It takes an action and waits to see if it results in a positive or negative outcome, based on a reward system that’s been established. Once that feedback is received, the model learns whether that decision was good or bad and updates itself accordingly.

It’s a really simple form of learning that’s endemic in the natural world, said Langford.

“Even worms can do reinforcement learning — they can learn to go towards things and avoid things based on some feedback,” Langford said. “That ability to learn at a very basic level from your environment is something that is super natural for us but in machine learning it’s a bit more tricky and delicate and requires more thought than supervised learning.”

The new papers presented at NeurIPS this week offer significant contributions in three key research areas: batch reinforcement learning, strategic exploration given rich observations and representation learning. Taken together, researchers say, these breakthroughs aim to boost the efficiency of models and expand the scope of problems that reinforcement learning can solve.

Click here to load media

From research labs to real-world products

Personalizer, the first Azure Cognitive Service to be built on reinforcement learning, grew out of a close collaboration between Microsoft researchers and Azure product experts. They wanted to help developers easily serve the right content to the right users at the right time without requiring a deep knowledge of machine learning.

Metrics Advisor, a new Azure Cognitive Service now available in public preview, also uses reinforcement learning to incorporate feedback and make models more adaptive to a customer’s dataset, which helps detect more subtle anomalies in sensors, production processes or business metrics.

Personalizer automatically selects what to show someone looking at a website or what question a chatbot should ask next to drive a desired business or experience outcome. That could be getting a person to commit to healthier eating habits or to try a new gaming experience. The agent learns through trial and error which content is most helpful or persuasive to different kinds of users.

In trying to make a video recommendation, for instance, what someone prefers to watch might be driven by what time of day it is, whether they’re sitting at home or moving around, or how much battery their device has left. Personalizer learns from the choices or actions that customers with similar characteristics have made.

Z-Tech, the technology hub of Anheuser-Busch InBev, has deployed Azure Personalizer, which uses reinforcement learning, to deliver tailored recommendations to small grocery stores across Mexico. Photo courtesy of Z-Tech.

Z-Tech, the technology hub of the multinational drink and brewing company AB InBev, started using Personalizer this fall to deliver tailored recommendations to mom and pop grocery stores in Mexico placing orders through the MiMercado online marketplace. It has seen a nearly 100% uplift in click-through rates for the personalized products and a 67% increase in converting customer interest into orders.

“As we were learning about the capabilities of the Azure platform, Personalizer came up as something that was very leading edge and very innovative and solved a need for us,” said Luiz Gondim, global chief technology officer for Z-Tech, which aims to bring data-driven solutions to small- and medium-sized businesses.

In the past, the featured products on MiMercado were the same for all customers. Z-Tech was interested in using AI to make personalized and more useful recommendations for an individual corner store selling everything from beer and baking supplies to potato chips and pet food.

Personalizer had two differentiating benefits, said Richard Sheng, global director of data science and analytics for Z-Tech.

“Reinforcement learning models by their very nature generally require less data because they use the current context to generate recommendations and learn through user feedback,” he said. “And having the models already developed and wrapped into an API that we can use in this plug-and-play way was very helpful.”

Microsoft autonomous systems researchers collaborated with scientists and engineers from Sber, a global financial services and technology company that operates SberBank, the largest bank in Russia, Central and Eastern Europe and one of the leading financial institutions worldwide, to use reinforcement learning to develop robotic technologies for unloading heavy collection bags of coins from mobile carts so they can be counted and repackaged.

In a recently published paper describing those results, the researchers detail how manipulating unstable coin bags with a constantly shifting center of gravity is a harder robotics problem than gripping solid objects. It’s the kind of scenario that’s commonplace in the physical world but that robots relying on traditional control systems or neural networks struggle to master, said Albert Efimov, vice-president for research and innovation at SberBank.

“We saw an opportunity to really advance the science and use reinforcement learning to teach a machine to perform a very difficult process,” said Efimov. “The bag has an unpredictable and amorphous shape, and even humans have to think for a minute about how to handle it. For a robot to do this is a big deal.” The Sber and Microsoft team used deep reinforcement learning and machine teaching techniques to first train the AI agent in a simulated environment, where it could explore different strategies and learn what worked best. Once deployed in real-world working conditions, the robotic system was able to successfully unload the coin bags on the first try 95% of the time.

Researchers from Microsoft’s Cambridge-UK lab and Ninja Theory are exploring how reinforcement learning could help develop AI agents that can collaborate with human players in video games. Note: Image is not representative of final game gameplay or visuals.

In Project Paidia, researchers in Microsoft Research’s UK-Cambridge lab are collaborating with Ninja Theory, an Xbox game studio. The goal is to drive state-of-the-art research in reinforcement learning that can enable new applications in modern video games and develop AI agents that can learn to collaborate with human players.

Agents that use reinforcement learning have the potential to better anticipate behaviors and react to nuances to enable effective collaboration with human players who are creative and unpredictable and have different styles of play, said Katja Hofmann, a principal researcher who leads a team that focuses on deep reinforcement learning in gaming and other application areas at Microsoft Research’s Cambridge-UK lab. Bots developed with current technologies struggle to navigate those complexities and simply don’t react in quite the same way that people do.

Principal researcher Katja Hofmann leads a team that focuses on deep reinforcement learning in gaming and other applications at Microsoft’s Cambridge – UK research lab. Photo courtesy of Microsoft.

Video games like Ninja Theory’s Bleeding Edge, which requires characters with different personalities and superpowers to team up to score points and defeat opponents, offer a helpful test bed for developing AI agents that can use reinforcement learning to coordinate actions and react appropriately to new situations through a series of rewards.

“Having a bot that can genuinely collaborate with human players is considered impossible with traditional game AI technology, so that creates a really nice space for us,” Hofmann said. “If we can demonstrate how to do this in gaming, it’s a first step towards demonstrating how we can create agents outside gaming that can work collaboratively with humans in other ways.”

The Project Paidia research team and others across Microsoft helped Azure Machine Learning understand what heavy users of reinforcement learning actually need in terms of infrastructure and compute power.

They’ve developed tools allowing people to experiment with the technology, including a demo allowing people to play a simple game with a reinforcement learning agent to see how it reacts as well as Azure Machine Learning sample notebooks to create an agent that can navigate a lava maze in Minecraft.

Large companies in the industrial, manufacturing and financial services fields that employ data scientists with reinforcement learning expertise are now using Azure Machine Learning’s reinforcement learning offerings introduced earlier this year to efficiently spin up and manage training processes in the cloud, said Keiji Kanazawa, Microsoft principal program manager.

“For customers who are doing large-scale trial and error, the value of the cloud is that they can do it massively,” he said. “Our tools allow customers to focus on what they’re trying to do with reinforcement learning and their goals and the structure of the rewards and all the compute just happens on the back end.”

Top image: Researchers from Microsoft and Sber used reinforcement learning to develop a robotic technology that can unload unwieldy bags of coins from mobile carts. Photo courtesy of Sber.

Related:

Jennifer Langston writes about Microsoft research and innovation. Follow her on Twitter."
Microsoft_News,https://news.microsoft.com/source/features/ai/all-hands-on-deck-how-duke-university-and-ai-for-health-raced-to-create-a-covid-19-solution-for-patients/,,‘All hands on deck’: How Duke University and AI for Health raced to create a COVID-19 solution for patients,"The 7-month-old was crying. Amanda Randles picked her up, held her and continued talking on the video meeting call from home. Nearby, her other 7-month-old baby started to wail. Randles put one baby down, picked up the second and cradled him as he quieted down. The rotation of the crying twins continued during the meeting.

It wasn’t an ordinary work-from-home session for Randles, Duke University assistant professor of biomedical sciences, and one of the nation’s experts in high-performance computing and biomedical engineering.

She and a group of two dozen tech and science professionals from the North Carolina university and from Microsoft AI for Health had been virtually introduced to each other on that April day for the first time – and time was in short supply. They were racing to submit a proposal to the U.S. Food and Drug Administration (FDA) for emergency use authorization of a Y-shaped device called a ventilator splitter and resistor system to help COVID-19 patients, as a growing number of hospitals continued to face a shortage of ventilators.

Randles’ colleague, Muath Bishawi, developed the device, while Randles and her team at Duke created the software for the ventilator splitter resistor system using airflow simulations so it could be customized for patients.

That customization is crucial for making sure patients get the correct amount of oxygen. Though the FDA gave emergency approval allowing two patients to share one ventilator during the pandemic, medical professionals believed it was not optimal, and in some cases, could cause more harm than good.

For a shared ventilator to work well patients needed, among other factors, to be approximately the same weight and have similar lung compliance – a measure of the lungs’ ability to stretch and expand. Finding two such similar patients on a hospital ward can be a game of chance. The ventilator splitter resistor system makes it a safer option.

Click here to load media

“In real life, you don’t want to split ventilators. They’re not built to be split,” says Randles. “It is really only in these dire circumstances that you should even consider splitting them.”

In addition to the voluntary work done on the project by Randles and her team at Duke University, including Mike Kaplan, a medical student, Simbarashe Chidyagwai, a graduate student in biomedical engineering, as well as the Duke Office of Information Technology, others jumped in to help on an unpaid basis. A software developer created a mobile app for doctors to quickly make decisions about matching patients and ventilator settings. Another company stepped up to do the 3D printing of the ventilator splitters themselves.

“Everyone was doing this completely because they thought it was important and they wanted to help,” Randles says. “Everyone was motivated to get this out to doctors as quickly as possible.” Duke University and Microsoft were initially paired through the COVID-19 High Performance Computing Consortium, created in March by the White House Office of Science and Technology Policy (OSTP). The consortium, whose members include Microsoft, aims to provide COVID-19 researchers worldwide with access to the world’s most powerful high-performance computing resources to fight the virus.

Amanda Randles, standing, at Duke University. She was given the Grace Murray Hopper Award in 2017 by the Association for Computing Machinery. Photo credit: Duke University

Amanda Randles, standing, at Duke University. She was given the Grace Murray Hopper Award in 2017 by the Association for Computing Machinery. Photo credit: Duke University

Geralyn Miller, Microsoft AI for Health senior director, is on the consortium’s technical review committee, which reads and reviews COVID-19-related research proposals. She says when Randles’ project came through, it was “incredibly unique” among the hundreds of proposals that were submitted because of its “immediate lifesaving measures.”

“It’s really great that there’s a lot of scientific research happening on the virus itself. It needs to happen,” Miller says. “But this one, this is one that really is focused on saving lives. It was the only one that I’d seen that talked at all about immediately beneficial therapeutic intervention.”

Geralyn Miller, Microsoft AI for Health senior director, says the ventilator splitter project was “incredibly unique” because of its “immediate lifesaving measures.” Photo by Dan DeLong

Miller learned about and empathized with Randles’ chaotic schedule, which includes overseeing a research lab at Duke called Randles Lab and caring for a toddler daughter as well as the twins. Miller, a mother of five, was hired at Microsoft in 1998 as a software developer, a time when few women were in that profession.

“Women are always doing a professional juggling act,” Miller says. “There’s always some element of that happening whether or not it is as intense as it has been with COVID-19, with people juggling family obligations and home schooling and the general things that come with living through a shutdown.”

Randles and the Duke team learned on a Monday they were matched with Microsoft AI for Health to provide the high-performance computing power with Microsoft Azure. By Thursday, they had that first virtual meeting with Microsoft experts in various areas including fluid dynamics, Azure infrastructure and networking, high-performance computing and AI for Health.

“It was all-hands-on deck, let’s get this up and running,” says Miller.

The goal of Duke’s work was “to provide physicians with the entire parameter space, so that no matter what patient weight or what lung compliance they ran into, that data was already there and would provide them with the guidance they needed to determine how best to use this ventilator splitter,” Randles says. “To do that, we needed to pre-compute all the different combinations of parameters, and that led to the need to run hundreds of millions of simulations that, in total, required almost one million compute hours.

“It’s something that was just not possible in the conventional computers and clusters that we had on campus at Duke, at least in the turnaround time that we needed,” she says. “It would have taken months to complete if we had just done it on local resources at Duke.”

Three days after that Thursday meeting, the initial work had been done, with 800,000 hours of compute time logged in 36 hours.

The team then spent the next three days finalizing the project.

“There were emails flying back and forth over the weekend at 2 and 3 in the morning from people trying to track everything down,” says Randles. “The whole team from across the three institutions did not sleep and got things done.”

Randles long has known about not getting sleep and about getting things done. She and her husband, a biochemist, have honed their work-at-home routine during COVID-19 to make it as manageable as possible. “We’ve done a lot of one person gets the kids for an hour-and-half, and then the other person gets the kids for an hour-and-a half,” she says. “And you kind of trade off at these weirdly small-time intervals because there’s so many meetings in between that we needed that kind of flexibility and granularity to get on to virtual meetings that we both needed to attend.”

Amanda Randles, with husband Edward Randles and their three children at home in North Carolina. Photo courtesy of Amanda Randles.

Amanda Randles, with husband Edward Randles and their three children at home in North Carolina. Photo courtesy of Amanda Randles.

Already highly accomplished in her field, the Association for Computing Machinery presented Randles in 2017 with the Grace Murray Hopper Award, given annually to an outstanding young computer professional for a single recent major technical or service contribution.

Randles created computer code that can model the entire arterial system at a subcellular resolution, something that can help show areas in the body where vascular disease may occur. She named the code HARVEY – after William Harvey, the 17th century physician who was the first doctor to accurately describe how blood was pumped around the body by the heart.

MIT Technology Review also named Randles as one of 2017’s “Innovators under 35” and a “visionary” for her work on HARVEY, which has continued to evolve. To make HARVEY more accessible to those in the sciences and medicine, Randles and the Duke team recently introduced a graphical user interface, called Harvis, described in a study published in the Journal of Computational Science.

The ventilator splitter project was something very different for Randles. But it was also something she very much wanted to do when colleague Bishawi asked for her help.

“When we first went on lockdown for COVID-19, I didn’t think there was any way of contributing,” she says. “I wanted to do something useful. With the ventilator splitter, I thought it was exciting that there was actually a way that we could concretely have an impact.”

That immediacy and impact to make things better was among the reasons AI for Health was so interested in the project. Part of the AI for Good initiative, AI for Health is a $60 million, five-year program to empower researchers and organizations with AI to improve the health of people and communities around the world. The program was developed in collaboration with leading health experts who are driving important medical initiatives.

Since April, AI for Health has awarded more than 150 grants to COVID-19 projects around the world.

“One of the things we’re really focused on in AI for Health is societal impact,” Miller says. “Amanda’s project maps very well into our strategy for COVID-19, where one of the areas we’re thinking about is allocation of resources, how to do things like allocate ventilators and ICU beds and PPE (personal protective equipment).”

The FDA has not yet approved the emergency use authorization of the ventilator splitter resistor system, but Randles finds some comfort in that.

“It’s positive that we keep getting put on the back burner,” she says. “That means they don’t need it right this second.”

But if they do, plans can quickly be put into place.

“This work is incredibly important,” Randles says. “The number of cases of COVID-19 are rising. There’s still a finite number of ventilators available, and as we’re starting to push that capacity, doctors need more options, more capabilities and they need more data. And we’re providing them information that’s critical and will hopefully improve patient outcome and patient care.”

Top image: Researchers at Duke University created ventilator splitters that are 3D-printed, and can help make sharing of ventilators safer. Photo credit: Duke University."
Microsoft_News,https://news.microsoft.com/source/features/ai/lobe-machine-learning/,,Lobe aims to make it easy for anyone to train machine learning models,"Sean Cusack has been a backyard beekeeper for 10 years and a tinkerer for longer. That’s how he and an entomologist friend got talking about building an early warning system to alert hive owners to potentially catastrophic threats.

They envisioned installing a motion-sensor-activated camera at a beehive entrance and using machine learning to remotely identify when invaders like mites or wasps or potentially even the Asian giant hornet were getting in.

“A threat like that could kill your hive in a couple of hours, and it’d be game over,” Cusack said. “But had you known within 10 minutes of it happening and could get out there and get involved, you could potentially rescue whole colonies.”

It wasn’t until Cusack heard about Lobe, an app that aims to make machine learning easier for people to use and helps them train models without writing code, that he saw a manageable way to bring the project to reality.

“I’m pretty tech savvy, but when I’d tried to do some machine learning things in the past I found it to be pretty intimidating or overwhelming to put all the pieces of the puzzle together,” said Cusack, a Microsoft software engineer who normally works in enterprise web development. “Lobe immediately clicked for me.”

The free app, which Microsoft is making available today in public preview, helps people with no data science experience import images into Lobe and easily label them to create a machine learning dataset. Lobe automatically selects the right machine learning architecture and starts training without any setup or configuration. Users can evaluate the model’s strengths and weaknesses with real-time visual results, play with the model and offer feedback to boost performance.

Today, Lobe supports image classification but plans to expand to other model and data types in the future, Microsoft says.

Once training is done, the models can be easily exported to run on industry standard platforms and work in apps, websites or devices. That allows people to create end-to-end machine learning solutions at home or in the workplace, such as creating an alert when a resident raccoon gets their garbage or flagging when an employee in a dangerous situation isn’t wearing a helmet.

Early customers include The Nature Conservancy, which is using the Lobe app as part of a larger project to map and protect Caribbean marine resources and pick out which vacation photos uploaded by tourists visiting those regions relate to whale and dolphin watching.

Other customers have used Lobe to build apps that can help identify harmful plants like poison oak on a hike, or that use a camera to send an alert when they accidentally leave the garage door open or when the street parking spot in front of their house opens up.

“Lobe is taking what is a sophisticated and complex piece of technology and making it actively fun,” said Bill Barnes, manager for Lobe, which Microsoft acquired and began incubating in 2018. “What we find is that it inspires people. It fills them with confidence that they can actually use machine learning. And when you have confidence you become more creative and start looking around and asking ‘What other stuff can I do with this?’”

Lobe, which is available for download on Windows or Mac computers, uses open-source machine learning architectures and transfer learning to train custom machine learning models on the user’s own machine. All the data is kept private, with no internet connection or logins required. Because training is automatic, people can start by simply importing images of the things they want Lobe to recognize.

In Cusack’s beehive project, which he proved out during the latest Microsoft Hackathon, he used a motion sensor camera that took pictures of honeybees as they flew into the hive, as well as invaders like wasps, earwigs and the giant Asian hornet. Because sightings of the hornet in the wild are still rare, Cusack printed out pictures, attached them to sticks and stuck them in the beehive to mimic an invasive threat.

Lobe used these images to create a machine learning model that can distinguish among the different insects and run on a small Raspberry Pi device at the entrance of the hive to alert owners to trouble.

Lobe fills a sweet spot for customers looking for a simple and quick way to get started with machine learning using their PCs or Macs without requiring any dependency on the cloud, Microsoft says. It complements Azure AI’s services for customers looking to leverage cloud computing capabilities.

“We really want to empower more people to leverage machine learning and try it for the first time,” said Jake Cohen, Lobe senior program manager. “We want them to be able to use it in ways that they either could not before or didn’t realize they could before.”

The Nature Conservancy is using Lobe to support its Mapping Ocean Wealth project, which seeks to map how and where tourism, fishing and other activities are potentially affecting important ocean resources — with the goal of helping officials in five Caribbean nations make more informed conservation and economic decisions.

The nonprofit is using Lobe to flag vacation photos depicting whale or dolphin watching activities that visitors to those countries have uploaded to a popular travel website. The photos have been stripped of all personal information but retain geographic data, which can help give decision makers a rough idea of how popular those nature-based tourism activities are in different locations.

“There are a lot of good fishing maps, there are a lot of good shipping maps and maps that show where different habitats are. But it’s actually quite hard to capture spatial patterns of what tourists are doing and where and at what intensity,” said Kate Longley-Wood, ocean mapping coordinator for The Nature Conservancy. “So we’ve found that these crowdsourced datasets can be really helpful in filling those gaps.”

Before using Lobe, The Nature Conservancy had to contract with data science researchers and students to create a custom machine learning model that could identify tourists engaging with coral reefs. But Lobe has allowed the nonprofit to do that same work in house, using staff who have no programming or data science experience.

To train the model, Longley-Wood collected two sets of images and imported them into Lobe. The first were of “whale and dolphin watching” vacation photos of people who are clearly engaged in those activities. The second contain images that are “not whale or dolphin” — pictures of open water, other types of boats, people snorkeling.

One advantage of Lobe is that it’s very easy to see where the model is getting things wrong and quickly improve its accuracy, Longley-Wood said. If the model gets confused and incorrectly labels a picture of a person swimming next to a boat as a whale watching photo, you can correct it with the click of a button.

Another early customer, Chris Cachor, is a software engineer for Sincro, an Ansira company focused on automotive marketing. He helps local car dealerships get the best performance out of social media ads.

People are less likely to engage with ads featuring stock images of a car model for sale, as opposed to an authentic photo of the car as it appears on the lot, Cachor said. Yet scripts designed to flag generic car photos haven’t always been able to keep up with increasingly sophisticated computer-generated imagery, he said.

Cachor said he’d thought about using machine learning to automate that task, but the tools he had run across seemed too cumbersome and time consuming to learn. With Lobe, he was able to import and label examples of stock, computer-generated and authentic car images. Within minutes, he had his first version of a computer vision model to weed out photos that are less likely to perform well in ads.

“It was so cool to see results right away without it becoming a weekend-long academic project,” Cachor said. “It kind of took you from zero to 60 really quick.”

Top image: A backyard beekeeper used Lobe, a free app that helps people train custom machine learning models, to create a device that can distinguish between bees entering a hive and invader insects that threaten the colony. Video by Getty Images.

Related:

Jennifer Langston writes about Microsoft research and innovation. Follow her on Twitter."
Microsoft_News,https://news.microsoft.com/source/features/digital-transformation/leave-positive-tracks-wayve-self-driving-solution-seeks-protect-people-planet/,,‘Leave positive tracks’: Wayve’s self-driving solution seeks to protect people and the planet,"Let’s momentarily exit 2020 and pay an imaginary visit to 2029.

(If only we could, right? Anyway, back to our mental trek.)

Picture the world’s cities by the end of this decade: Streets, intersections and roundabouts are a safer, cleaner, quieter and vastly more organized stream of connected, self-driving electric vehicles. Block by block, their shared “driving brain” learns from roadway experiences to make traffic deaths tragedies of our messy past.

Rush hour jams? No chance. Horns? No need. Road rage? No more.

That’s how Alex Kendall sees our urban future. Kendall is the co-founder and CEO of Wayve, a London-based startup that’s building an artificial intelligence (AI) solution that will enable autonomous vehicles to operate not in a single city but in any urban environment, securely moving people and goods.

His vision blends cloud and artificial intelligence capabilities with heavy doses of human equity and healthy air to deliver a new transportation model that will be sustainable, affordable and accessible to people in all cities. He calls it: “Riding the Wayve.”

“One of our values is to leave positive tracks,” Kendall says, “so we exclusively work on electric vehicles.”

To scale their solution, the three-year-old company is leveraging both Microsoft Azure and the Microsoft for Startups: Autonomous Driving program, which provides benefits like free Azure credits and access to Microsoft engineers and program managers to support the development of these complex workloads on the cloud.

Transform recently chatted with Kendall via Microsoft Teams to hear about our commutes of tomorrow.

TRANSFORM: Autonomous driving means different things to different people. What does it mean to you?

KENDALL: It means the start of a new era, creating artificial intelligence that we trust to move people and goods throughout our cities without requiring supervision by humans. We’re talking about a world of autonomous mobility services that disrupts private car ownership, that makes it more sustainable for people to move around cities and, ultimately, that reduces road deaths to zero.

TRANSFORM: Wayve aims to be the first company to launch its self-driving technology in 100 cities, not just one city. Tell me about that goal.

KENDALL: Across the self-driving industry today, many teams are trying to make it work in one place, just trying to get something out there as quickly as they can. This comes at the expense of what we call “generalization”: How quickly can the system go from working in one place to many places?

When humans learn to drive, they go from understanding how to drive in one city to quickly learning how to drive in other cities. In that same way, scaling our technology to other cities should just be a matter of adding a small amount of experience to adapt to each new place.

TRANSFORM: Where are some of those 100 projected cities?

KENDALL: We’re headquartered in London. That will be our first city. Beyond the UK, we are most excited about targeting a few cities in Europe as next expansion points. Next countries include the Netherlands, Belgium and Germany.

TRANSFORM: You mentioned how humans learn to drive. What does that mean?

KENDALL: Humans are interesting because they use many means of learning to learn how to drive. The dominant one is unsupervised learning. That is how humans watch and view the world.

Every time you’re sitting in a car or observing cars driving, you’re building an internal mental model about how things behave, how things move, how things interact. When you actually get in a car, it’s this internal model that makes it efficient for you to learn how to drive.

TRANSFORM: How will Wayve’s machine learning system mimic the human process?

KENDALL: Just like humans, our system learns most efficiently using many sources, including unsupervised learning, imitation learning and reinforcement learning.

First, we learn to drive (autonomously) by copying expert humans. We record the driving data from their vehicles. Based on the data, we learn to copy their expert driving. This is called imitation learning.

From that, we build a self-driving system and deploy it on the roads with safety drivers. (These are people who sit behind the steering wheel during testing and, if needed, immediately take control.) Every time the system makes a mistake, and the safety driver intervenes, we learn from that feedback. This is called reinforcement learning.

Finally, we use computer simulation to learn from the situations that are too dangerous or too rare to experience in the real world. Through these three steps, we build a safe and robust autonomous driver.

TRANSFORM: Who are the expert drivers that you mentioned, and how do you record their driving data?

KENDALL: We deploy our self-driving platform with data-collection devices across large scale-commercial fleets.

We provide these vehicles with data-collection computers – fully integrated, self-driving, sensing suites – and small computers with a 4G connection. Integrated with Azure cloud and IoT services, this allows us to understand this data and send back interesting examples to the cloud, ultimately for our system to learn from. At scale, this will provide us access to millions of images per second.

TRANSFORM: In your computer simulations, are you estimating the accident rates?

KENDALL: We’ve built a scalable (simulation) system to extract insights from every part of the drive. We classify these into scenarios and look at the metrics for each one, whether that’s driving through traffic lights or going through a roundabout in the rain.

It gives us a good view on what we are and aren’t good at – and where we should focus our resources and our learning.

Within each of these scenarios, we can accurately estimate human-level performances and what we need to beat. For example, humans can pass through roundabout intersections without an accident causing injury 99.999 percent of the time. We want to be able to surpass this.

TRANSFORM: What has the Microsoft for Startups: Autonomous Driving program meant for your company and achieving your vision?

KENDALL: In the early days, we were building an autonomous car in our garage, driving it around the block and testing it.

We had nothing to show and everything to prove. Despite that, Microsoft was excited about what we were building. This early engagement was critical. More than the financial credit support, the engineering support around the backend and the quick turnaround to our requests and questions allowed us to get that speed of iteration we needed.

Because we had this speed of iteration, we were able to quickly graduate from a house and build a headquarters and an organization that ultimately decided to build our infrastructure at scale in Azure.

TRANSFORM: When your technology is fully deployed, how will this look in the real world?

KENDALL: We envision a world where we have large fleets of connected vehicles, all sharing experiences to improve and train a driving brain that ultimately learns from its mistakes and learns to adapt to society’s needs at a rapid pace.

TRANSFORM: And this self-driving network will be available to all who want to use it?

KENDALL: Yes, for people who are disabled, self-driving is a technology that should massively increase their mobility options. It should reduce the stigma and the cost (of today’s accessible transportation options).

Also, I don’t want to see self-driving only deployed in affluent areas with expensive infrastructure. I want to see self-driving address urban societies throughout the world. This requires a more intelligent autonomous driving system which is able to understand the world around it. This is only possible with machine learning.

TRANSFORM: When might this become part of everyday life?

KENDALL: Over the next few years, Wayve will get to a point where we have the safety case in place, where we’ll invite members of the public to experience riding the Wayve. They will do this, first, with a safety driver supervising the ride, then as an autonomous service.

By the end of this decade, I think riding the Wayve will be dominant within the multimodal transportation options we use in cities throughout the world. It will just be a matter of time before it is as prevalent as today’s ride-hailing services.

Top photo: Alex Kendall. (All photos courtesy of Wayve)"
Microsoft_News,https://news.microsoft.com/source/features/ai/azure-image-captioning/,,"What’s that? Microsoft’s latest breakthrough, now in Azure AI, describes images as well as people do","Novel object captioning

Image captioning is a core challenge in the discipline of computer vision, one that requires an AI system to understand and describe the salient content, or action, in an image, explained Lijuan Wang, a principal research manager in Microsoft’s research lab in Redmond.

“You really need to understand what is going on, you need to know the relationship between objects and actions and you need to summarize and describe it in a natural language sentence,” she said.

Wang led the research team that achieved – and beat – human parity on the novel object captioning at scale, or nocaps, benchmark. The benchmark evaluates AI systems on how well they generate captions for objects in images that are not in the dataset used to train them.

Image captioning systems are typically trained with datasets that contain images paired with sentences that describe the images, essentially a dataset of captioned images.

“The nocaps challenge is really how are you able to describe those novel objects that you haven’t seen in your training data?” Wang said.

To meet the challenge, the Microsoft team pre-trained a large AI model with a rich dataset of images paired with word tags, with each tag mapped to a specific object in an image.

Datasets of images with word tags instead of full captions are more efficient to create, which allowed Wang’s team to feed lots of data into their model. The approach imbued the model with what the team calls a visual vocabulary.

The visual vocabulary pre-training approach, Huang explained, is similar to prepping children to read by first using a picture book that associates individual words with images, such as a picture of an apple with the word “apple” beneath it and a picture of a cat with the word “cat” beneath it.

“This visual vocabulary pre-training essentially is the education needed to train the system; we are trying to educate this motor memory,” Huang said.

The pre-trained model is then fine-tuned for captioning on the dataset of captioned images. In this stage of training, the model learns how to compose a sentence. When presented with an image containing novel objects, the AI system leverages the visual vocabulary to generate an accurate caption.

“It combines what is learned in both the pre-training and the fine-tuning to handle novel objects in the testing,” Wang said.

When evaluated on nocaps, the AI system created captions that were more descriptive and accurate than the captions for the same images that were written by people, according to results presented in a research paper.

Click here to load media

Speedy ship to production

The new image captioning system is also two times better than the image captioning model that’s been used in Microsoft products and services since 2015, according to a comparison on another industry benchmark.

Given the benefit of improved image captioning to all users of Microsoft products and services, Huang accelerated the integration of the new model into production on Azure.

“We’re taking this AI breakthrough to Azure as a platform to serve a broader set of customers,” he said. “It is not just a breakthrough on the research; the time it took to turn that breakthrough into production on Azure is also a breakthrough.”

Reaching human parity on image captioning, he added, continues a theme of human parity achievement across cognitive AI systems at Microsoft.

“In the last five years,” Huang said, “we have achieved five major human parities: in speech recognition, in machine translation, in conversational question answering, in machine reading comprehension, and in 2020, in spite of COVID-19, we got the image captioning human parity.”

Top image: Legacy: A man riding a skateboard up the side of a building. New: A baseball player catching a ball. Photo courtesy of Getty Images.

Related:

John Roach writes about Microsoft research and innovation. Follow him on Twitter.

Check out these additional images and captions comparing results from the legacy and new AI system."
Microsoft_News,https://news.microsoft.com/source/features/ai/shrinking-the-data-desert/,,Shrinking the ‘data desert’: Inside efforts to make AI systems more inclusive of people with disabilities,"Saqib Shaikh says people who are blind, like himself, typically develop highly organized routines to keep track of their things — putting keys, wallets, canes and other essentials in the same places each time.

Saqib Shaikh, Microsoft principal software engineering lead and one of the founders of Seeing AI. Photo by John Brecher.

But sometimes life gets messy: A child needs help finding a lost stuffed animal, identical garbage bins get moved around on the curb or coats get jumbled together at a party.

Today, a person using Microsoft’s Seeing AI app can point a phone camera at a scene, such as a conference room table, and hear a description of what’s in the frame: laptops, water bottles, power cords, phones. But it would sometimes also be useful for the machine learning algorithms powering the app to recognize objects that are specific to that individual person, said Shaikh, a Microsoft engineer whose team invented Seeing AI.

Until recently, there hasn’t been enough relevant data to train machine learning algorithms to tackle this kind of personalized object recognition for people with vision disabilities. That’s why City, University of London, a Microsoft AI for Accessibility grantee, has launched the Object Recognition for Blind Image Training (ORBIT) research project to create a public dataset from scratch, using videos submitted by people who are blind or have low vision.

The data will be used to train and test new algorithms to recognize and locate important personal objects, which can range from cell phones to face coverings to kitchen tools.

“Without data, there is no machine learning,” said Simone Stumpf, senior lecturer at the Centre for Human-Computer Interaction Design at City, University of London, who leads ORBIT. “And there’s really been no dataset of a size that anyone could use to introduce a step change in this relatively new area of AI.” ­ The lack of machine learning datasets that represent or include people with disabilities is a common roadblock for researchers or developers working with those communities to develop intelligent solutions that can assist with everyday tasks or create AI systems that are less likely to magnify prejudices that can skew decision making.

Click here to load media

“We are in a data desert,” said Mary Bellard, principal innovation architect lead at Microsoft who also oversees the AI for Accessibility program. “There’s a lot of passion and energy around doing really cool things with AI and people with disabilities, but we don’t have enough data.”

“It’s like we have the car and the car is packed and ready to go, but there’s no gas in it. We don’t have enough data to power these ideas.”

To begin to shrink that data desert, Microsoft researchers have been working for the past year and a half to investigate and suggest ways to make AI systems more inclusive of people with disabilities. The company is also funding and collaborating with AI for Accessibility grantees to create or use more representative training datasets, such as ORBIT and the Microsoft Ability Initiative with University of Texas at Austin researchers.

Mary Bellard, principal innovation architect lead at Microsoft who oversees the AI for Accessibility program. Photo provided by Bellard.

Today, Team Gleason announced it is partnering with Microsoft on Project Insight, which will create an open dataset of facial imagery of people living with ALS to help advance innovation in computer vision and train those AI models more inclusively.

It’s an industry-wide problem that won’t be solved by one project or organization alone, Microsoft says. But new collaborations are beginning to address the issue.

A research roadmap on AI Fairness and Disability published by Microsoft Research and a workshop on Disability, Bias and AI hosted last year with the AI Now Institute at New York University found a host of potential areas in which mainstream AI algorithms that aren’t trained on inclusive data either don’t work well for people with disabilities or can actively harm them.

If a self-driving car’s pedestrian detection algorithms haven’t been shown examples of people who use wheelchairs or whose posture or gait is different due to advanced age, for example, they may not correctly identify those people as objects to avoid or estimate how much longer they need to safely cross a street, researchers noted.

AI models used in hiring processes that try to read personalities or interpret sentiment from potential job candidates can misread cues and screen out qualified candidates with autism or who emote differently. Algorithms that read handwriting may not be able to cope with examples from people who have Parkinson’s disease or tremors. Gesture recognition systems may be confused by people with amputated limbs or different body shapes.

It’s fairly common for some people with disabilities to be early adopters of intelligent technologies, yet they’ve often not been adequately represented in the data that informs how those systems work, researchers say.

“When technologies are so desired by a community, they’re often willing to tolerate a higher rate of errors,” said Meredith Ringel Morris, senior principal researcher who manages the Microsoft Research Ability Team. “So imperfect AI systems still have value, but they could provide so much more and work so much better if they were trained on more inclusive data.”

‘Pushing the state of the art’

Danna Gurari, an AI for Accessibility grantee and assistant professor at the University of Texas at Austin, had that goal in mind when she began developing the VizWiz datasets. They include tens of thousands of photographs and questions submitted by people who are blind or have low vision to an app originally developed by researchers at Carnegie Mellon University.

The questions run the gamut: What is the expiration date on this milk? What does this shirt say? Do my fingertips look blue? Do these clouds look stormy? Do the charcoal briquettes in this grill look ready? What does the picture on this birthday card look like?

The app originally crowdsourced answers from people across the internet, but Gurari wondered if she could use the data to improve how computer vision algorithms interpret photos taken by people who are blind.

AI for Accessibility grantee Danna Gurari, assistant professor at the University of Texas at Austin who developed the VizWiz dataset and directs the School of Information’s Image and Video Computing Group.

Many of those questions require reading text, such as determining how much of an over-the-counter medicine is safe to take. Computer vision research has often treated that as a separate problem, for example, from recognizing objects or trying to interpret low-quality photos. But successfully describing real-world photos requires an integrated approach, Gurari said.

Moreover, computer vision algorithms typically learn from large image datasets of pictures downloaded from the internet. Most are taken by sighted people and reflect the photographer’s interest, with items that are centered and in focus.

But an algorithm that’s only been trained on perfect images is likely to perform poorly in describing what’s in a photo taken by a person who is blind; it may be blurry, off center or backlit. And sometimes the thing that person wants to know hinges on a detail that a person who is sighted might not think to label, such as whether a shirt is clean or dirty.

“Often it’s not obvious what is meaningful to people, and that’s why it’s so important not just to design for — but design these technologies with — people who are in the blind and low vision community,” said Gurari, who also directs the School of Information’s Image and Video Computing Group at the University of Texas at Austin.

Her team undertook the massive task of cleaning up the original VizWiz dataset to make it usable for training machine learning algorithms — removing inappropriate images, sourcing new labels, scrubbing personal information and even translating audio questions into text to remove the possibility that someone’s voice could be recognized.

Working with Microsoft funding and researchers, Gurari’s team has developed a new public dataset to train, validate and test image captioning algorithms. It includes more than 39,000 images taken by blind and low vision participants and five possible captions for each. Her team is also working on algorithms that can recognize right off the bat when an image someone has submitted is too blurry, obscured or poorly lit and suggest how to try again.

Earlier this year, Microsoft sponsored an open challenge to other industry and academic researchers to test their image captioning algorithms on the VizWiz dataset. In one common evaluation metric, the top performing algorithm posted a 33% improvement over the prior state of the art.

“This is really pushing the state of the art in captioning for the blind community forward,” said Seeing AI lead engineer Shaikh, who is working with AI for Accessibility grantees and their datasets to develop potential improvements for the app.

A 5 euro bill on a red table. Black oven temperature knob that is currently in the off position. A brown window planter with white flowers and yellow flowers that have died. A person holding a plush toy of a cartoon dinosaur in their hand. A fresh banana that is a little green and mostly yellow A crayon colored drawing of a vase with flowers. The VizWiz Image Captioning dataset provides five possible captions for each image, such as these examples to the right of each photo. This helps computer vision algorithms better learn to recognize and describe what is displayed in photographs submitted by people who are blind or have low vision. Photos available via a Creative Commons 4.0 license.

Making inclusive datasets available to all

Because AI systems model the world based on the data they’re given, people who don’t mirror patterns in the data can be overlooked or actively discriminated against. While the AI community has increasingly acknowledged and worked to improve the fairness of these systems when it comes to gender and race, conversations around being inclusive of people with disabilities are much more nascent, researchers say.

Microsoft Research has launched a multi-pronged effort to define the extent of the problem and avenues for improvement — including the workshop hosted with NYU’s AI Now Institute last year. The workshop convened disability scholars and activists, machine learning practitioners and computer science researchers to begin to discuss how to create AI systems that avoid treating people with disabilities as edge cases or outliers.

“This really points to the question of how ‘normal’ is defined by AI systems and who gets to decide that,” said Kate Crawford, senior principal researcher at Microsoft Research New York and co-founder of the company’s Fairness, Accountability, Transparency and Ethics (FATE) in AI group.

Take the example of a predictive hiring system that assesses video interviews from job candidates and suggests what a “successful” employee will sound and look like, Crawford said.

“Has it been trained on data that suggests that certain abilities or ways of being are standard and therefore desirable? Are people with disabilities or those who are in any way different ranked lower for potential hiring because they differ from the data in the training set? That’s what we really need to be aware of and work against,” Crawford said.

To advance that goal, one area Microsoft researchers are investigating is how often public datasets commonly used to train AI systems include data from people older than 80, because age correlates strongly with disability. Morris and her colleagues have also been exploring how search algorithms might be tweaked to improve results for people with dyslexia.

Last summer, Microsoft hosted disability technologies expert Shaun Kane, an associate professor of computer science at University of Colorado Boulder, as a visiting researcher to jointly investigate how intelligent sensing systems can fail to recognize or respond properly to people who use wheelchairs or have amputated limbs, motor disabilities or body morphology that falls outside of the examples those algorithms have been trained on."
Microsoft_News,https://news.microsoft.com/source/features/digital-transformation/love-all-billie-jean-king-embraces-tech-equality-make-tennis-even-better/,,Love all: Billie Jean King embraces tech and equality to make tennis even better,"In the lingo of her game, Billie Jean King still aches to win the big points.

Never mind that King has collected 39 Grand Slam titles (20 at Wimbledon alone), formed the Women’s Tennis Association to advance gender equity in the sport, co-founded the only co-ed, professional team sports league and, of course, bettered Bobby Riggs in the epic “Battle of the Sexes” match.

Set aside for a quick second that, in recent years, the tennis icon accepted the Presidential Medal of Freedom as an advocate for women and the LGBTQ community then launched a nonprofit to cultivate diverse leadership in the workforce – and that “champion of equality” has basically become her unofficial title.

At 76, King lives by an oft-repeated mantra, four words she always delivers with a smile: “I’m not done yet.”

“When people tell Billie, ‘Wow, you have accomplished a lot,’ she says, ‘I have to keep reinventing. My job now is to support the next generation,’” says Ilana Kloss, president of Billie Jean King Enterprises, a former pro player and King’s partner. “For Billie, technology is a huge part of that impact.”

On Thursday, that impact continued to expand. The Fed Cup – the largest annual women’s team sports competition, pitting professional tennis players from more than 100 nations – was rebranded as the Billie Jean King Cup by BNP Paribas.

Also Thursday, the International Tennis Federation (ITF) and Microsoft announced a collaboration to provide new technologies to enhance the sport of tennis. The tools include a customized dashboard that will provide professional coaches and players with real-time data analytics generated by their current matches.

The dashboard gets its first in-game use next April in Budapest, Hungary at the finals of the Billie Jean King Cup by BNP Paribas, where teams from 12 nations will compete for the trophy.

“Any time my name is on anything, particularly the ‘Women’s World Cup of Tennis’ … I really have a sense of responsibility,” King says. “It reminds me to keep looking forward, to keep (going) every single moment, every single day, keep going toward equality.”

Transform recently spoke via Microsoft Teams with Kloss at her home in New York and with Jamie Capel-Davies, head of the ITF’s science and technical department, at his home in London to hear how these tech advances, built with Microsoft Azure services, will benefit tennis.

TRANSFORM: Ilana, I understand that you and Billie saw a vision for the collaboration with Microsoft and the ITF – a sense that new technologies could elevate play at the tournament finals, where coaching is allowed and team play is embraced. Can you tell me about that vision?

KLOSS: I have worked with Billie for probably 30 years. She’s always about technology and information. She’s always felt that tennis could really use both.

Billie always wants to know more. And she always says how she would have loved to have been born in this era, because of all the information and analytics available to the players. She believes they can help not only the players but the sport and the fans.

TRANSFORM: Do the launch of the dashboard and the rebranding of the competition signal a distinct, new era for this tournament and maybe for the game itself?

KLOSS: Absolutely. Billie is all about breaking barriers, making things better and using all the technology. For her to have her name on the cup at a competition where the latest and the best technology is available to help the players and the team captains is, for Billie, one of the most exciting things. She believes we have to pass the baton to the next generation.

TRANSFORM: Jamie, the dashboard will analyze real-time data on player movement and shots, ball flight and speed – data generated by the ball-tracking cameras and 3D-radar systems used at pro tennis events. How do you see coaches and players applying this new info during the tournament finals in April?

CAPEL–DAVIES: If you’re a player, among the things you always want to know are: Where should I be serving and what speeds do I need to hit to be able to serve an ace? The dashboard offers those analytics.

TRANSFORM: Ilana, same question.

KLOSS: You want to know the points you are winning because certain points in a game are important. I think also knowing which side the opposing player is stronger on, where players serve on certain big points, positioning on the court – where you are and where they are.

TRANSFORM: Jamie, you work at the ITF lab, which tests rackets, balls and court surfaces to preserve the essence of the game while encouraging innovation. Is there a balance between welcoming tech advances like this dashboard with protecting the game’s traditions?

CAPEL–DAVIES: A while ago, there was maybe more of a conflict between innovation and tradition. Now, there’s definitely more appetite for innovation. Tennis, like a lot of sports, is looking over its shoulder at some of the other sports, at computer games, at eGames.

There’s a willingness to try stuff out and maybe not be overprotective. There’s also a realization that you can do both – maintain tradition and introduce innovation without it necessarily being disruptive.

TRANSFORM: Ilana, you played in the 1970s at Wimbledon, the U.S. Open, French Open, the Fed Cup and more. How do you see the addition of new tech meshing with the sport’s adherence to its traditions and lore?

KLOSS: I feel like sometimes the men’s and women’s tours are very conservative in terms of trying new things. Players hate change. Most people hate change.

But sometimes actually not changing is the greater risk. Billie and I have always believed that our sport could be so much better if it embraces technology.

TRANSFORM: Jamie, there are 17 Microsoft Azure services powering the data repository and data filtering inside the dashboard. That offers players and coaches quite an in-the-moment plan for how to win their match.

CAPEL–DAVIES: Yes, it’s the combination of real-time data with a historical perspective. We have data going back several years. You might have already played this particular player. So what happened in that previous match? What are their strengths and weaknesses? What did you do that was effective and that you might want to try and repeat?

TRANSFORM: Ilana, Billie has long fought for the idea that everyone should get an opportunity and a seat at the table. Strictly on a tennis level, does this platform meet that lofty philosophy by offering a new way to share data and analytics – and maybe give more players a chance at greatness?

KLOSS: That’s a very good point. In this team competition, it’s huge because everyone will have access to the information.

Sometimes, on the tour, if you can’t afford the best coach, you’re not getting access to the same information that, say, Serena Williams gets from her team.

A wonderful thing about this partnership with Microsoft, the Billie Jean King Cup and the ITF is that over 116 countries participate in this competition. Their ability to now tap into the data – and to use that information for their federations and their local teams – can be a game-changer. It’s about providing access. That’s where we can really make a difference.

Top photo: Billie Jean King, left, and two teammates accept their trophy for winning the 1963 Fed Cup. (Photo courtesy of the International Tennis Federation.)"
Microsoft_News,https://news.microsoft.com/source/features/sustainability/microsoft-hackathon-leads-to-ai-and-sustainability-collaboration-to-rid-plastic-from-rivers-and-the-ocean/,,Microsoft Hackathon leads to AI and sustainability collaboration to rid plastic from rivers and the ocean,"Plastic bags. Plastic bottles. Plastic toys. Nearly 9 million tons of plastic debris wind up in the ocean every year. Environmental experts say the problem is serious enough that by the year 2050, the amount of plastics in the ocean could outweigh the fish in it if action isn’t taken sooner.

It was among the environmental concerns that gnawed at Drew Wilkinson. Two years ago, as a paralegal for Microsoft in Redmond, Washington, he had an idea for the company’s annual Global Hackathon, and contacted a nonprofit organization he greatly admired, The Ocean Cleanup, based in Rotterdam in the Netherlands. Maybe Microsoft could help?

Wilkinson called it a “shot-in-the-dark” email, the kind you send without knowing if it will land in the bulging inbox of an overloaded employee, or in a giant spam folder. And one that would travel 4,800 miles to another continent.

“I didn’t know anybody at The Ocean Cleanup,” Wilkinson says. “I just went on their website, and found their generic email address, and sent that email, not really expecting much. To my surprise, they responded.”

This was his email:

The communication was forwarded within The Ocean Cleanup offices to its geospatial analyst Robin de Vries. He received it like a Christmas gift in June.

“It felt that we could be helped by a network of experts,” De Vries remembers thinking. “This could be a great opportunity that only comes seldomly.”

I didn’t know anybody at The Ocean Cleanup … To my surprise, they responded.

The Ocean Cleanup is known worldwide for its innovative efforts to rid the ocean of plastics. It has also started focusing on eliminating plastics at major sources – rivers – before they reach the sea.

The organization built technology, unveiled last fall, that has been deployed in rivers in Indonesia and Malaysia, to remove plastics. But a key aspect was figuring out how to identify the waste that was collected – was it plastic or other material, such as sticks and leaves?

For two Microsoft global hackathons, in 2018 and 2019, Hackathon team members in Redmond and from around the world worked with The Ocean Cleanup to build a machine learning model to help quantify the amount of plastic pollution flowing down rivers en route to the ocean.

Subsequent models were then developed to replicate the process on cameras mounted to drones and ships crossing the ocean, and a blueprint for cloud computing infrastructure was created to help the project in the future.

Volunteers from Microsoft’s AI for Earth initiative also participated in the hackathon. AI for Earth is a Microsoft initiative that supports, and partners with, environmental groups and researchers to use artificial intelligence technology and advanced cloud software to solve environmental challenges.

Click here to load media

AI for Earth sponsored the Hack for Sustainability Challenge at the hackathons in 2018 and 2019, with dozens of machine learning specialists, data scientists, software engineers, cloud architects, generalists and interns from around the company volunteering their time for The Ocean Cleanup.

De Vries and another team member from The Ocean Cleanup, project engineer Kees van Oeveren, traveled from the Netherlands to participate.

“That decision turned out to be the fuse to a phase of explosive development,” De Vries says. “When we were in Seattle, we got introduced to so many aspects of the Microsoft organization that it became clear they could be a powerful ally in the quest for clean oceans.”

Before Wilkinson’s email arrived, Van Oeveren recalled the tedious work of labeling some images and doing the work by himself. “I hadn’t embarked yet on doing machine learning and image recognition, but I really wanted to,” he says, although he was not sure of the next steps.

The project was rudimentary, painstaking and time-consuming. “I remember mounting security cameras with power banks attached to them at rivers that would just simply store some images locally” on a computer, Van Oeveren says.

We labeled over 30,000 ocean photos with the help of Hackathon volunteers and their network.

It was a Tuesday when he shared a dataset of images with Microsoft Hackathon volunteers from the “Plastic Free Oceans” team to review. On Friday, in a video phone call meeting with the volunteers, he learned the dataset had already been put through a machine learning model, and bounding boxes had been created for the images, distinguishing what was plastic and what wasn’t.

“That was such a magical moment,” van Oeveren says. “I expected that even if you knew what you were doing, that it would be a project that would take weeks to set up right.”

“We labeled over 30,000 ocean photos with the help of Hackathon volunteers and their network” in the summer of 2019, De Vries says. “Some datasets were even finished before the Hackathon even started. Work is now in progress on the development of machine learning models for ocean photos.”

It allowed us to develop the vision that this is something we can do, not just for one river, but eventually for rivers across the globe.

Dan Morris, AI for Earth program director, says the most important result from the hackathon was that AI for Earth taught The Ocean Cleanup a lot about machine learning. “The real value was teaching them through interaction with data scientists and engineers at Microsoft,” he says.

This year, The Ocean Cleanup was named an AI for Earth grantee for its work.

“Using the AI for Earth grant, we’ve been able to set up and run the machine learning models,” De Vries says. “Having the resources at our fingertips has greatly accelerated the technical progress, by taking away practical concerns and letting us focus on the development.

“It allowed us to develop the vision that this is something we can do, not just for one river, but eventually for rivers across the globe.”

The Ocean Cleanup is highly admired, particularly in the Netherlands, where the organization has been a symbol of pride for years, even before they became more well-known internationally, says Harry van Geijn, a digital adviser for Microsoft in the Netherlands. Van Geijn is among the Microsoft staffers there who have volunteered to help The Ocean Cleanup when it comes to computer and related support.

While its staff is relatively small with around 100 employees, “they have this cause that they pursue with great tenacity and in an extremely professional way,” van Geijn says. So much so that “When I ask around for someone at Microsoft Netherlands to do something for The Ocean Cleanup, half the company raises their hand to say, ‘I want to volunteer for that.’”

Wilkinson, who grew up in the hot, dry climate of the Arizona desert, spent time at sea as a volunteer for the Sea Shepherd Conservation Society, a nonprofit, marine wildlife conservation organization.

In 2018 at Microsoft, he and another coworker started an employee group, Microsoft’s Worldwide Sustainability Community, which has grown to more than 3,000 members globally. The group focuses on ways employees can help the company be more environmentally sustainable. Wilkinson now is a community program manager for the Worldwide Communities Program, which includes the employee group he co-founded.

Wilkinson sees the issue of plastics in the ocean as a pretty solvable problem and is excited about the work that has been done, the work that he spurred with an email.

“I’m not a scientist, but it doesn’t take a lot of science to understand that our fate on the land is very much tied to the ocean,” he says. “The ocean is the planet’s life support system. Without a healthy ocean, we don’t stand a chance either.”

Top image: Some of the plastic and trash picked up onto the conveyor belt of The Ocean Cleanup’s Interceptor 002 on the Klang River in Malaysia. Photo credit: The Ocean Cleanup."
Microsoft_News,https://news.microsoft.com/source/features/ai/openai-azure-supercomputer/,,"Microsoft announces new supercomputer, lays out vision for future AI work","Microsoft has built one of the top five publicly disclosed supercomputers in the world, making new infrastructure available in Azure to train extremely large artificial intelligence models, the company is announcing at its Build developers conference.

Built in collaboration with and exclusively for OpenAI, the supercomputer hosted in Azure was designed specifically to train that company’s AI models. It represents a key milestone in a partnership announced last year to jointly create new supercomputing technologies in Azure.

It’s also a first step toward making the next generation of very large AI models and the infrastructure needed to train them available as a platform for other organizations and developers to build upon.

“The exciting thing about these models is the breadth of things they’re going to enable,” said Microsoft Chief Technical Officer Kevin Scott, who said the potential benefits extend far beyond narrow advances in one type of AI model.

“This is about being able to do a hundred exciting things in natural language processing at once and a hundred exciting things in computer vision, and when you start to see combinations of these perceptual domains, you’re going to have new applications that are hard to even imagine right now,” he said.

Click here to load media

A new class of multitasking AI models

Machine learning experts have historically built separate, smaller AI models that use many labeled examples to learn a single task such as translating between languages, recognizing objects, reading text to identify key points in an email or recognizing speech well enough to deliver today’s weather report when asked.

A new class of models developed by the AI research community has proven that some of those tasks can be performed better by a single massive model — one that learns from examining billions of pages of publicly available text, for example. This type of model can so deeply absorb the nuances of language, grammar, knowledge, concepts and context that it can excel at multiple tasks: summarizing a lengthy speech, moderating content in live gaming chats, finding relevant passages across thousands of legal files or even generating code from scouring GitHub.

As part of a companywide AI at Scale initiative, Microsoft has developed its own family of large AI models, the Microsoft Turing models, which it has used to improve many different language understanding tasks across Bing, Office, Dynamics and other productivity products. Earlier this year, it also released to researchers the largest publicly available AI language model in the world, the Microsoft Turing model for natural language generation.

The goal, Microsoft says, is to make its large AI models, training optimization tools and supercomputing resources available through Azure AI services and GitHub so developers, data scientists and business customers can easily leverage the power of AI at Scale.

“By now most people intuitively understand how personal computers are a platform — you buy one and it’s not like everything the computer is ever going to do is built into the device when you pull it out of the box,” Scott said.

“That’s exactly what we mean when we say AI is becoming a platform,” he said. “This is about taking a very broad set of data and training a model that learns to do a general set of things and making that model available for millions of developers to go figure out how to do interesting and creative things with.”

Training massive AI models requires advanced supercomputing infrastructure, or clusters of state-of-the-art hardware connected by high-bandwidth networks. It also needs tools to train the models across these interconnected computers.

The supercomputer developed for OpenAI is a single system with more than 285,000 CPU cores, 10,000 GPUs and 400 gigabits per second of network connectivity for each GPU server. Compared with other machines listed on the TOP500 supercomputers in the world, it ranks in the top five, Microsoft says. Hosted in Azure, the supercomputer also benefits from all the capabilities of a robust modern cloud infrastructure, including rapid deployment, sustainable datacenters and access to Azure services.

This is about being able to do a hundred exciting things in natural language processing at once and a hundred exciting things in computer vision, and when you start to see combinations of these perceptual domains, you’re going to have new applications that are hard to even imagine right now.

“As we’ve learned more and more about what we need and the different limits of all the components that make up a supercomputer, we were really able to say, ‘If we could design our dream system, what would it look like?’” said OpenAI CEO Sam Altman. “And then Microsoft was able to build it.”

OpenAI’s goal is not just to pursue research breakthroughs but also to engineer and develop powerful AI technologies that other people can use, Altman said. The supercomputer developed in partnership with Microsoft was designed to accelerate that cycle.

“We are seeing that larger-scale systems are an important component in training more powerful models,” Altman said.

For customers who want to push their AI ambitions but who don’t require a dedicated supercomputer, Azure AI provides access to powerful compute with the same set of AI accelerators and networks that also power the supercomputer. Microsoft is also making available the tools to train large AI models on these clusters in a distributed and optimized way.

At its Build conference, Microsoft announced that it would soon begin open sourcing its Microsoft Turing models, as well as recipes for training them in Azure Machine Learning. This will give developers access to the same family of powerful language models that the company has used to improve language understanding across its products.

It also unveiled a new version of DeepSpeed, an open source deep learning library for PyTorch that reduces the amount of computing power needed for large distributed model training. The update is significantly more efficient than the version released just three months ago and now allows people to train models more than 15 times larger and 10 times faster than they could without DeepSpeed on the same infrastructure.

Along with the DeepSpeed announcement, Microsoft announced it has added support for distributed training to the ONNX Runtime. The ONNX Runtime is an open source library designed to enable models to be portable across hardware and operating systems. To date, the ONNX Runtime has focused on high-performance inferencing; today’s update adds support for model training, as well as adding the optimizations from the DeepSpeed library, which enable performance improvements of up to 17 times over the current ONNX Runtime.

“We want to be able to build these very advanced AI technologies that ultimately can be easily used by people to help them get their work done and accomplish their goals more quickly,” said Microsoft principal program manager Phil Waymouth. “These large models are going to be an enormous accelerant.”

Learning the nuances of language

Designing AI models that might one day understand the world more like people do starts with language, a critical component to understanding human intent, making sense of the vast amount of written knowledge in the world and communicating more effortlessly.

Neural network models that can process language, which are roughly inspired by our understanding of the human brain, aren’t new. But these deep learning models are now far more sophisticated than earlier versions and are rapidly escalating in size.

A year ago, the largest models had 1 billion parameters, each loosely equivalent to a synaptic connection in the brain. The Microsoft Turing model for natural language generation now stands as the world’s largest publicly available language AI model with 17 billion parameters.

This new class of models learns differently than supervised learning models that rely on meticulously labeled human-generated data to teach an AI system to recognize a cat or determine whether the answer to a question makes sense.

In what’s known as “self-supervised” learning, these AI models can learn about language by examining billions of pages of publicly available documents on the internet — Wikipedia entries, self-published books, instruction manuals, history lessons, human resources guidelines. In something like a giant game of Mad Libs, words or sentences are removed, and the model has to predict the missing pieces based on the words around it.

As the model does this billions of times, it gets very good at perceiving how words relate to each other. This results in a rich understanding of grammar, concepts, contextual relationships and other building blocks of language. It also allows the same model to transfer lessons learned across many different language tasks, from document understanding to answering questions to creating conversational bots.

“This has enabled things that were seemingly impossible with smaller models,” said Luis Vargas, a Microsoft partner technical advisor who is spearheading the company’s AI at Scale initiative.

The improvements are somewhat like jumping from an elementary reading level to a more sophisticated and nuanced understanding of language. But it’s possible to improve accuracy even further by fine tuning these large AI models on a more specific language task or exposing them to material that’s specific to a particular industry or company.

“Because every organization is going to have its own vocabulary, people can now easily fine tune that model to give it a graduate degree in understanding business, healthcare or legal domains,” he said.

Click here to load media

AI at Scale

One advantage to the next generation of large AI models is that they only need to be trained once with massive amounts of data and supercomputing resources. A company can take a “pre-trained” model and simply fine tune for different tasks with much smaller datasets and resources.

The Microsoft Turing model for natural language understanding, for instance, has been used across the company to improve a wide range of productivity offerings over the last year. It has significantly advanced caption generation and question answering in Bing, improving answers to search questions in some markets by up to 125 percent.

In Office, the same model has fueled advances in the smart find feature enabling easier searches in Word, the Key Insights feature that extracts important sentences to quickly locate key points in Word and in Outlook’s Suggested replies feature that automatically generates possible responses to an email. Dynamics 365 Sales Insights also uses it to suggest actions to a seller based on interactions with customers.

Microsoft is also exploring large-scale AI models that can learn in a generalized way across text, images and video. That could help with automatic captioning of images for accessibility in Office, for instance, or improve the ways people search Bing by understanding what’s inside images and videos.

To train its own models, Microsoft had to develop its own suite of techniques and optimization tools, many of which are now available in the DeepSpeed PyTorch library and ONNX Runtime. These allow people to train very large AI models across many computing clusters and also to squeeze more computing power from the hardware.

That requires partitioning a large AI model into its many layers and distributing those layers across different machines, a process called model parallelism. In a process called data parallelism, Microsoft’s optimization tools also split the huge amount of training data into batches that are used to train multiple instances of the model across the cluster, which are then periodically averaged to produce a single model.

The efficiencies that Microsoft researchers and engineers have achieved in this kind of distributed training will make using large-scale AI models much more resource efficient and cost-effective for everyone, Microsoft says.

When you’re developing a cloud platform for general use, Scott said, it’s critical to have projects like the OpenAI supercomputing partnership and AI at Scale initiative pushing the cutting edge of performance.

He compares it to the automotive industry developing high-tech innovations for Formula 1 race cars that eventually find their way into the sedans and sport utility vehicles that people drive every day.

“By developing this leading-edge infrastructure for training large AI models, we’re making all of Azure better,” Scott said. “We’re building better computers, better distributed systems, better networks, better datacenters. All of this makes the performance and cost and flexibility of the entire Azure cloud better.”

Top image: At its Build developers conference, Microsoft Chief Technical Officer Kevin Scott is announcing that the company has built one of the top five publicly disclosed supercomputers in the world. Art by Craighton Berman.

Related:

Jennifer Langston writes about Microsoft research and innovation. Follow her on Twitter."
Microsoft_News,https://news.microsoft.com/source/features/ai/azure-responsible-machine-learning/,,"Microsoft responsible machine learning capabilities build trust in AI systems, developers say","Anyone who runs a business knows that one of the hardest things to do is accuse a customer of malfeasance. That’s why, before members of Scandinavian Airlines’ (SAS) fraud detection unit accuse a customer of attempting to scam the carrier’s loyalty points program, the detectives need confidence that their case is solid.

“It would hurt us even more if we accidentally managed to say that something is fraud, but it isn’t,” said Daniel Engberg, head of data analytics and artificial intelligence for SAS, which is headquartered in Stockholm, Sweden.

The airline is currently flying a reduced schedule with limited in-flight services to help slow the spread of COVID-19, the disease caused by the novel coronavirus. Before the restrictions, SAS handled more than 800 departures per day and 30 million passengers per year. Maintaining the integrity of the EuroBonus loyalty program is paramount as the airline waits for regular operations to resume, noted Engberg.

EuroBonus scammers, he explained, try to gain as many points as quickly as possible to either book reward travel for themselves or to sell. When fraud occurs, legitimate customers lose an opportunity to claim seats reserved for the loyalty program and SAS loses out on important business revenue.

Today, a large portion of leads on EuroBonus fraud come from an AI system that Engberg and his team built with Microsoft Azure Machine Learning, a service for building, training and deploying machine learning models that are easy to understand, protect and control.

The SAS AI system processes streams of real-time flight, transaction, award claims and other data through a machine learning model with thousands of parameters to find patterns of suspicious behavior.

To understand the model predictions, and thus chase leads and build their cases, the fraud detection unit relies on an Azure Machine Learning capability called interpretability, powered by the InterpretML toolkit. This capability explains what parameters were most important in any given case. For example, it could point to parameters that suggest a scam of pooling points from ghost accounts to book flights.

Model interpretability helps take the mystery out of machine learning, which in turn can build confidence and trust in model predictions, noted Engberg.

“If we build the trust in these models, people start using them and then we can actually start reaping the benefits that the machine learning promised us,” he said. “It’s not about explainability for explainability’s sake. It’s being able to provide both our customers and our own employees with insights into what these models are doing and how they are taking positions for us.”

Understand, protect and control your machine learning solution

Over the past several years, machine learning has moved out of research labs and into the mainstream, and has transformed from a niche discipline for data scientists with Ph.D.s to one where all developers are expected to be able to participate, noted Eric Boyd, corporate vice president of Microsoft Azure AI in Redmond, Washington.

Microsoft built Azure Machine Learning to enable developers across the spectrum of data science expertise to build and deploy AI systems. Today, noted Boyd, all developers are increasingly asked to build AI systems that are easy to explain and that comply with non-discrimination and privacy regulations.

“It is very challenging to have a good sense of, ‘Hey, have I really assessed whether my model is behaving fairly?’ or ‘Do I really understand why this particular model is predicting the way it is?’” he said.

To navigate these hurdles, Microsoft today announced innovations in responsible machine learning that can help developers understand, protect and control their models throughout the machine learning lifecycle. These capabilities can be accessed through Azure Machine Learning and are also available in open source on GitHub.

The ability to understand model behavior includes the interpretability capabilities powered by the InterpretML toolkit that SAS uses to detect fraud in the EuroBonus loyalty program.

In addition, Microsoft said the Fairlearn toolkit, which includes capabilities to assess and improve the fairness of AI systems, will be integrated with Azure Machine Learning in June.

Microsoft also announced a toolkit for differential privacy is now available to developers to experiment with in open source on GitHub and can also be accessed through Azure Machine Learning. The differential privacy capabilities were developed in collaboration with researchers at the Harvard Institute for Quantitative Social Science and School of Engineering.

Differential privacy techniques make it possible to derive insights from private data while providing statistical assurances that private information such as names or dates of birth can be protected.

For example, differential privacy could enable a group of hospitals to collaborate on building a better predictive model on the efficacy of cancer treatments while at the same time helping to adhere to legal requirements to protect the privacy of hospital information and helping to ensure that no individual patient data leaks out from the model.

Azure Machine Learning also has built-in controls that enable developers to track and automate their entire process of building, training and deploying a model. This capability, known to many as machine learning and operations, or MLOps, provides an audit trail to help organizations meet regulatory and compliance requirements.

“MLOps is really thinking around the operational, repeatable side of machine learning,” said Boyd. “How do I keep track of all the different experiments that I have run, the parameters that were set with them, the datasets that were used in creating them. And then I can use that to recreate those same things.”

Contextual bandits and responsibility

In the mid-2010s, Sarah Bird and her colleagues at Microsoft’s research lab in New York were working on a machine learning technology called contextual bandits that learn through exploration experiments how to perform specific tasks better and better over time.

For example, if a visitor to a news website clicks on a story about cats, the contextual bandit learns to present the visitor more stories about cats. To keep learning, the bandit performs experiments such as showing the visitor stories about the Jacksonville Jaguars, a sports team, and the hit musical “Cats.” What story the visitor clicks is another learning data point that leads to greater personalization.

“When it works, it is amazing, you get personalization lifts that you’ve never seen before,” said Bird, who now leads responsible AI efforts for Azure AI. “We started talking to customers and working with our sales team to see who wants to pilot this novel research tech.”

The sales leads gave Bird pause. As potential customers floated ideas about using contextual bandits to optimize the job interview process and insurance claim adjudications, she realized that many people lacked understanding on how contextual bandits work.

“I started saying, ‘Is it even ethical to do experimentation in those scenarios?’” Bird recalled.

The question led to discussions with colleagues in the Fairness, Accountability, Transparency and Ethics in AI research group, or FATE, and a research collaboration on the history of experimental ethics and the implications for reinforcement learning, the type of machine learning behind contextual bandits.

“The technology is good enough that we are using it for real use cases, and if we are using it for real use cases that affect people’s lives, then we better make sure that it is fair and we better make sure that it is safe,” said Bird, who now focuses full time on the creation of tools that make responsible machine learning accessible to all developers.

Huskies, wolves and scammers

Within a few years, ethical AI research had exploded around the world. Model fairness and interpretability were hot topics at major industry gatherings and responsible machine learning tools were being described in the academic literature.

In 2016, for example, Marco Tulio Ribeiro, now a senior researcher at Microsoft’s research lab in Redmond, presented a technique in an academic conference paper to explain the prediction of any classifier, such as computer vision models trained to classify between objects in photos.

To demonstrate the technique, he deliberately trained a classifier to predict “wolf” if a photo had a snowy background and “husky” if there was no snow. He then ran the model on photos of wolves mostly in snowy backgrounds and huskies mostly without snow and showed the results to machine learning experts with two questions: Do you trust the model? How is it making predictions?

Many of the machine learning experts said they trusted the model and presented theories on why it was predicting wolves or huskies such as wolves have pointier teeth, noted Ribeiro. Less than half mentioned the background as a potential factor and almost no one zeroed in on the snow.

“Then I showed them the explanations, and after seeing the explanations, of course everyone basically got it and said, ‘Oh, it is just looking at the background,’” he said. “This is a proof-of-concept; even experts are likely to be fooled by a bad model.”

A refined version of Ribeiro’s explanation technique is one of several interpretability capabilities available to all developers using interpretability on Azure Machine Learning, the toolkit that SAS’s fraud detection unit uses to build cases against scammers in the EuroBonus loyalty program.

Other AI solutions that SAS is creating with Azure Machine Learning include one for ticket sales forecasting and a system that optimizes fresh food stocking for in-flight purchases. The fresh food solution reduced food waste by more than 60% before fresh food sales were halted as part of global efforts to slow the spread of COVID-19.

Engberg and his data analytics and artificial intelligence team continue to build, train and test machine learning models, including further experimentation with the Azure Machine Learning capabilities for interpretability and fairness.

“The more we go into things affecting our customers or us as individuals, I think these concepts of fairness, explainable AI, responsible AI, will be even more important,” said Engberg.

Assessing and mitigating unfairness

Bird’s colleagues in FATE pioneered many of the capabilities in the Fairlearn toolkit. The capabilities allow developers to examine model performance across groups of people such as those based on gender, skin tone, age and other characteristics.

“It could be you have a great idea of what fairness means in an application and because these models are so complex, you might not even notice that it doesn’t work as well for one group of people as another group,” explained Bird. “Fairlearn is allowing you to find those issues.”

EY, a global leader in assurance, tax, transaction and advisory services, piloted fairness capabilities in the Fairlearn toolkit on a machine learning model the firm built for automated lending decisions.

The model was trained on mortgage adjudication data from banks that includes transaction and payment history and credit bureau information. This type of data is generally used to enable assessment of the client’s capability and willingness to pay back a loan. But it also raises concerns about regulatory, legal issues and potential unfairness against applicants of specific demographics.

EY used Fairlearn to evaluate the fairness of model outputs with regards to biological sex. The toolkit, which surfaces results on a visual and interactive dashboard, revealed a 15.3 percentage point difference between positive loan decisions for males versus females.

The Fairlearn toolkit allowed the modelling team at EY to quickly develop and train multiple remediated models and visualize the common trade-off between fairness and model accuracy. The team ultimately landed on a final model that optimized and preserved overall accuracy but reduced the difference between males and females to 0.43 percentage points.

The ability for any developer to assess and mitigate unfairness in their models is becoming essential across the financial industry, noted Boyd.

“Increasingly we’re seeing regulators looking closely at these models,” he said. “Being able to document and demonstrate that they followed the leading practices and have worked very hard to improve the fairness of the datasets are essential to being able to continue to operate.”

Responsible machine learning

Bird believes machine learning is changing the world for the better, but she said all developers need the tools and resources to build models in ways that put responsibility front and center.

Consider, for example, a research collaboration within the medical community to compile COVID-19 patient datasets to build a machine learning model that predicts who is at high risk of serious complications from the novel coronavirus.

Before such a model is deployed, she said, the developers need to make sure they understand how it makes decisions in order to explain the process to doctors and patients. The developers will also want to asses fairness, ensuring the model captures the known elevated risks to males, for example.

“I don’t want a model that never predicts that men are high risk, that would be terrible,” said Bird. “Then, obviously, I want to make sure that the model is not revealing the data of the people it was trained on, so you need to use differential privacy for that.”

Top image: An SAS AI-powered fraud detection tool processes streams of real-time flight information along with transaction, award claims and other data through a machine learning model to find patterns of suspicious behavior. An Azure Machine Learning capability called interpretability explains what model parameters were most important in any given case of suspected fraud. Photo courtesy of SAS.

Editor’s note: A previous version of this story referred to the differential privacy toolkit as WhiteNoise.

Related:

John Roach writes about Microsoft research and innovation. Follow him on Twitter."
Microsoft_News,https://news.microsoft.com/source/features/digital-transformation/in-a-health-care-crisis-zuellig-pharma-pivots-to-the-cloud-to-protect-lives/,,"In a health care crisis, Zuellig Pharma pivots to the cloud to protect lives","Think of a business plan as a race. You’re at the starting line. The pistol goes off. Then suddenly, the rules change. The marathon you thought you were running has become a sprint.

That’s what happened to one of Asia’s largest and oldest health care services groups, Zuellig Pharma, when the COVID-19 pandemic swept the region, triggering mandatory lockdowns that threatened its ability to serve 350,000 medical facilities, hospitals, clinics and pharmacies.

Zuellig Pharma distributes medical supplies, drugs and services across 13 countries, so to ensure that those who needed them continued to receive vital supplies, the company quickly plugged into the power of the cloud.

“Everybody was impacted,” says Tom Vanmolkot, the company’s executive vice president for distribution and client services. “Everybody had to wake up to a new reality. We had to adapt.”

Visit Microsoft Asia News Center to learn how Zuellig Pharma built and launched a range of new digital solutions that are overcoming unprecedented logistical challenges."
Microsoft_News,https://news.microsoft.com/source/features/ai/kevin-scott-reprogramming-the-american-dream/,,"A conversation with Kevin Scott, author of “Reprogramming the American Dream”","Microsoft CTO Kevin Scott. Photo by Brian Smale.

Artificial intelligence is already changing virtually every aspect of our lives, from how we communicate with each other to how we grow our food, and technology experts believe we are just at the beginning of understanding how AI could expand people’s capabilities.

In his new book, “Reprogramming the American Dream,” Kevin Scott, Microsoft’s chief technology officer, looks at how he went from a childhood in rural Virginia to being a leader in the field of AI – and why he thinks there is ample opportunity for people from all walks of life to take advantage of AI to achieve the American dream.

We recently had the opportunity to talk to him about his life, book and career.

You’ve written a new book. What’s it about?

The book is essentially about how we should all think about artificial intelligence as this incredibly powerful tool that we can choose to use to build a better future for all of us and how, in particular, I think artificial intelligence can be really beneficial for folks who live and work in rural and middle America.

How did your upbringing in rural America inform your perspective about the technology industry?

I think I’ve had a lot of good luck over the course of my life. The first bit of good luck was being born to a family and a community in rural, central Virginia, in this little town called Gladys, where I had all of these role models around me who were inventive and creative and tinkerers and entrepreneurs and folks with tons of grit.

I had not just parents but an entire family structure that was super supportive. We didn’t have much. We were sort of a paycheck-to-paycheck family and had moments of true financial hardship throughout my childhood, but my brother and I never even thought that we were lacking anything. And I had this gigantic curiosity that my parents, in a whole bunch of different ways, tried to support.

I remember one of the things that my mom did really early on — I was such a voracious reader, and I don’t know whether folks remember this, but we used to have door-to-door encyclopedia salespeople, and so the World Book Encyclopedia salesperson came to our house one day, and my mom, even though we didn’t have much money, put the World Book Encyclopedias on a payment plan. And I would go into the living room by myself as a little kid and pull these books off of the shelf one by one and just read the encyclopedia. And it was just an incredible thing, given our circumstances, that my mom and dad would’ve done that for me.

How did your dad influence some of the choices that you made later in life?

My dad was maybe the most important role model in my life. He was an awesome, awesome dad, and some of the most important things I learned from him by example. He experienced a bunch of failure, but every time he would just dust himself off, stand back up and go back at it. And that resilience and grit is just such an important thing to have if you are attempting to do something hard or something that’s right outside of the boundaries of your experience. You’re going to fail a lot, and he just taught me that it’s not the worst thing in the world to fail as long as you’re able to pick yourself up and start moving forward again.

But one of the funniest stories about my dad is he was just super determined that I was not going to go into the family business. My great-grandfather, my grandfather and my dad were all in construction, and I went to work for him when I was a teenager. And he would give me the most miserable jobs in the world, like carrying sheaves of shingles up and down a ladder onto hot roofs all day long or running jackhammers to break up basement floors or pushing wheelbarrows full of bricks up hills. He just wanted to show me how hard that life was.

The interesting thing was it actually taught me how much beauty and dignity there was in all of that work. And my hobbies, funny enough, are all very close to this stuff that he did. I love woodworking, I love building things, I love working with my hands.

The really hilarious thing, as he was giving me all of this miserable work, is that I had already decided that I was really, really interested in computers and programming, and I knew that I wanted to go to college. I kept telling him that and he still kept giving me this crap work.

Kevin Scott’s book, Reprogramming the American Dream, will be available Tuesday, April 7.

Do you feel like you achieved the American dream?

Yeah, I think so. I think a big part of the American dream is that you come into society as a child and you are equipped with an education and a set of experiences that prepare you to go do something interesting and valuable in the world, and that you don’t have a set of systemic barriers standing in your way of achieving those goals.

I got a really good education. I went to a really good science and technology Governor’s School in central Virginia. I wish there were more kids who had that opportunity, because it just gave me the conviction to go on to actually earn a set of computer science degrees. And I never felt like I had enormous impediments in my way.

In your book, you raise the idea that technology such as AI can help people in rural America achieve the American dream. How?

When I left academia and took my first job in industry, I did this machine learning project where I had to sit down with a stack of research papers and a bunch of textbooks filled with not necessarily accessible mathematics, and I spent six months coding to build the system that, at the time, did a very useful thing with machine learning.

The machine learning tools are so powerful now that a motivated high school kid could do that same project in maybe a weekend. And that’s an amazing realization to have because it basically means that anybody can pick up these tools and use them to do interesting things.

When I think about the people that I grew up with, these are some of the most ingenious people that I know. I mean, this community is just full of scrappy people who are using all of the tools that are available to them to make a better future for themselves.

And now, they have this new tool which may be the most powerful tool that we’ve ever built. And it’s so exciting to think about what people will do with these tools who are in different contexts and come at problem solving from different angles than those of us who are in the technology industry.

What do you think needs to happen structurally in order for folks in this country who aren’t in the technology industry to see those benefits?

We should do a better job teaching kids the basic concepts of computer science and engineering and machine learning when they’re in middle and high school.

Machine learning makes it so much easier to do sophisticated things with computers than the traditional tools of programming. We have this tool that we are developing internally right now that allows anyone to build computer vision models, and it’s easy enough that my nine-year-old or 11-year-old can use it to easily train a computer vision model to perform a vision task.

So, I think the argument that AI is too complicated for people to get ramped up on is actually not true. I think, in a way, AI is going to turn the task of getting computers to do things for you from a programming task into a teaching task. And we all know how to teach someone how to do a thing. It’s an innate part of our human set of capabilities. And so I think we should definitely be teaching more of these concepts in high school.

And if you want people to be able to participate in the digital economy, you have to, in these rural communities, have broadband.

That’s why things like Microsoft’s Airband program, that’s using some of the white space spectrum that is no longer being used by broadcast television to carry data, is a really fantastic thing. For kids and businesses and workers to be digitally fluent, they have to have network connectivity. You just can’t expect them to fully participate in this new emerging economy without this very basic bit of infrastructure.

AI is going to turn the task of getting computers to do things for you from a programming task into a teaching task. And we all know how to teach someone how to do a thing.

You also acknowledged in the book that change is hard and scary for people. What needs to happen in order to get people to make that leap to embracing something like AI?

I think it’s really difficult, especially when you’re a kid, to imagine yourself doing something that’s abstract. You look at the people around you and you look at what they’re doing and there’s almost this momentum in the career choices that you make. A huge number of people choose to do the same things that their parents or members of their family or the members of their close community do.

They have to have role models, and one of the things that I wanted to say with the book is, “Hey, I came from exactly where you all did. Being born and raised in rural and middle America, it is a perfectly acceptable and reasonable and possible path for you to go have a job in tech.”

And you can have a job in tech, I think, now more so than when I was growing up, staying exactly where you are.

Tell me a little bit more about that.

For example, there are a bunch of really great tech jobs near where I grew up. There’s a Microsoft data center in Boydton, Virginia, hours away from my hometown, where there are hundreds of high-tech jobs that are well-paying and extremely interesting. That didn’t exist in the 90s when I was a kid. Even in Lynchburg, which is the nearest big town to Gladys, there’s a bunch of industry there now that wasn’t there when I was a kid.

I ended my book chatting with this young man, Hunter Bass, who’s the son of one of my friends from school. And he got a degree in computer engineering and decided to stay in Lynchburg and he’s got a job that he loves.

I think more and more of those opportunities exist all the time because it’s easier than ever to do your work in the distributed fashion where the physical place of where you’re doing a thing is less important than your ability to have access to infrastructure that you can use to connect yourself to people doing the things that you want to do.

One of the things that I wanted to say with the book is, ‘Hey, I came from exactly where you all did. Being born and raised in rural and middle America, it is a perfectly acceptable and reasonable and possible path for you to go have a job in tech.’

You said in your book that you wanted to explore the future of technology in a way that is neither dystopian nor utopian. Can you talk about some of the challenges that you see as we move toward this more AI-centric world?

I think we have the same set of challenges with AI that you have with any very powerful new technology. My favorite analogy is the development of the steam engine in the late 18th century. It’s the first large-scale substitute for human labor – a single machine could do work that lots and lots of human beings would have had to do by hand before.

In the beginning of the development of the steam engine, the people to whom value accrued to immediately were folks who had capital and folks who had expertise. If you had money you could build a factory around one of these steam engines and build a business that was way more efficient than the business making a similar set of things completely manually.

And then you had this big disruption that moved through the workforce. The very nature of work was changed by the onset of this new technology, and it took a while for things to settle out.

Now, you look at engines and they’re a ubiquitous tool that everybody has in their arsenal for making things, and eventually that is what we will have with artificial intelligence. And the question is, what does the transition period look like?

My argument – the reason that I wrote the book, the reason that I do the job that I do at Microsoft – is that I think we need to collectively be doing everything in our power to democratize access to these tools, so that my friends and family and the people that I admire in these small communities have just as much access to these tools as I do. Because I have infinite amounts of faith in their ability to go do amazing things once they have the access.

I think that is ultimately the thing that really does make sure that we have fair and inclusive decision-making about what the trajectory of the future looks like, powered by more and more AI over time. And it is certainly the way that you get more equitable distribution of the benefits of AI.

Last question. I’m curious what you learned while writing this book.

It forced me to look at AI and its potential impacts in a different way. I was very much in the same opinion pool as many of my colleagues and peers and friends in the tech industry about what the trajectory of AI looked like and what its impact was going to be on the future of work. The book gave me an opportunity to go do some research, and more importantly to go talk to a whole bunch of people and remind myself how awesomely creative and inventive people are, no matter where they live.

Top image: In his new book, Kevin Scott discusses how AI can benefit Americans in areas such as rural Virginia, shown above. Photo by Walter Arnold Photography/Getty Images.

Related:"
Microsoft_News,https://news.microsoft.com/source/features/ai/microsoft-365-ai-tools/,,"New AI tools help writers be more clear, concise and inclusive in Office and across the web","Susan Hendrich was talking with a friend who mentioned how hard a co-worker with dyslexia worked to ensure that meeting notes he was responsible for writing were error free.

Because he worried about making mistakes, he routinely brought meeting recordings home with him and labored over the summaries for hours at night.

That led Hendrich, a Microsoft group program manager and expert on natural language and AI for Microsoft Office, to wonder how her team might improve those stressful writing experiences for people whose brains process letters and words differently.

A new feature now being rolled out in Editor in Word can use more sophisticated AI to offer suggestions for rewriting full sentences rather than offering spelling or grammar fixes one at a time. In internal evaluations, it was nearly 15 percent more effective than previous approaches in catching mistakes commonly made by people who have dyslexia, Microsoft says.

That’s largely because the deep learning algorithms that can offer those rewrites were trained on large and diverse datasets, including documents written in the real world by people with dyslexia, rather than a narrow and finite set of linguistic rules.

“It was actually something that we did not expect,” Hendrich said. “But then we started doing some benchmarking and realized this can be a huge benefit to people.”

Microsoft engineers have steadily been incorporating more AI advances into its Microsoft 365 suite of products over the past several years. They now help over 200 million Office 365 users have more productive meetings, stay on top of their to-do lists, deliver more powerful presentations, preserve focus time and help people find ways to write more clearly.

Now, Microsoft is making its AI-powered writing assistance tools more widely available to enterprise and consumer customers around the world. With new features that begin rolling out today and will continue over the coming months, Microsoft Editor will give writers the option to use intelligent tools to craft more polished prose in documents, emails and posts across the web on sites such as LinkedIn, Gmail, Facebook, Twitter and more.

The new tools are available through Editor in Word, Editor in Outlook and a new Editor in the browser extension, which will allow users to catch mistakes and write more confidently when crafting social media posts or communicating elsewhere on the web.

Editor’s spelling and basic grammar checks will be available to everyone, and Microsoft 365 subscribers — including the new Microsoft 365 Personal and Family productivity subscriptions announced today — can opt to use more advanced AI features that offer intelligent suggestions for making writing more concise, clear, formal and more.

The releases expand Microsoft’s advanced AI-powered writing suggestions to Outlook.com, Outlook for the web and the new browser extension, currently available for Microsoft Edge and Google Chrome, in more than 20 languages. Basic spelling checks in the browser extension will be available in 89 languages.

Starting with Editor in Word and coming soon to other platforms, Microsoft 365 subscribers can also opt to see inclusive language suggestions — such as the word firefighter instead of fireman — that seek to eliminate biases based on gender, age, ability and more. In Word for the web in English, those users who want more feedback can now access whole sentence rewrite suggestions to improve fluency, conciseness and readability.

Other new AI-powered Word features, which will be expanded to other Editor offerings, can offer intelligent suggestions for spelling out acronyms, putting numbers in real-world perspective and even flagging potentially unoriginal language and allowing writers to properly cite reference material.

Massive scale and opportunity for impact

As Microsoft has incorporated more AI technology into its products, company executives say they’ve been keenly aware of their duty to help ensure that AI is used in ways that are responsible and thoughtful, that anticipate unintended consequences and that help meet real customer needs.

“If you think about the number of people who use Office in their daily lives, what’s unique about us is the massive scale and opportunity for impact,” said Sumit Chauhan, Microsoft corporate vice president for engineering in Office. “The burden is really on us to get this right.”

For instance, Editor in Word’s AI-powered rewrite suggestions tool has the potential to benefit many authors — from people learning English whose omissions of “a,” “an,” or “the” aren’t always caught by traditional language checkers to busy professionals who get hundreds of emails an hour and don’t have time to labor over each response.

At the same time, AI has the potential to reinforce harmful biases that exist in society, and in the data that algorithms learn from. To address this unintended consequence, Microsoft researchers have developed a block list of words that are at greater risk of causing offense, and Word doesn’t show rewrite suggestions with those phrases.

For those who choose to use it, Editor’s inclusive language critique offers suggestions to replace language that may perpetuate biases around age, ability, gender, sexual orientation, religion, ethnic or racial slurs, as well as outdated or sensitive geopolitical references.

The goal isn’t to correct all of society’s issues, Chauhan said, but to highlight potential blind spots and offer some general suggestions to consider.

If you think about the number of people who use Office in their daily lives, what’s unique about us is the massive scale and opportunity for impact. The burden is really on us to get this right.

“In our products, we want to be thoughtful about stereotypes in the world and to make sure our AI is not reinforcing or amplifying those,” Chauhan said.

Of course, those sensitivities vary widely by country and culture. That’s why Microsoft hires native speakers and linguistic experts in 20 languages to write the rules that guide grammar, clarity and conciseness checking — and to advise which inclusiveness critiques don’t have comparable solutions in that language or might be unwelcome in certain markets.

Considering users’ needs can be as simple as recognizing that people who are colorblind can’t distinguish between words written in red or blue and may also need dashed lines or squiggles to flag words or phrases.

Or it can be as complicated as figuring out how to handle gender-neutral pronouns in spelling and grammar critiques — something the team is experimenting with. The cultural shift to use pronouns such as “they/them” to refer to people whose gender identities are nonbinary is recent enough that there’s little data that can teach algorithms their proper usage.

For now, Editor in Word and Outlook will not flag the use of “they” in a singular context as incorrect — such as “they are taking their final exams tomorrow” rather than “she is taking her final exam tomorrow” — which Hendrich believes is a good first step toward including a wider spectrum of gender identities. But she also worries about the person who might use “they” by mistake in a cover letter and doesn’t land a job because Word’s grammar checker failed to flag it.

“We have a goal of empowering our customers to write confidently and feel like their writing reflects positively on them,” she said. “And we also have a goal to properly represent and celebrate people for their uniqueness. So, to be perfectly honest, these are the questions that I grapple with as a product creator. And I don’t always have the answer.”

Putting people at the center of AI design

Mira Lane, the lead of Microsoft’s Ethics & Society team, is charged with ensuring that the principles articulated at the highest levels of the company to guide the responsible use of AI find their way into the heads of researchers conducting user testing and the hands of engineers writing code. It starts with asking the right questions, she said.

Her team of philosophers, engineers, security experts, designers and trainers works closely with product teams to consider what data or models should be used, who might be directly or indirectly affected by a new technology, what kinds of people should be interviewed to identify unintentional harms and how those insights can be folded into product design.

“The thing that we’re trying to do is help people design technology in a really intentional way, so you really understand what the effects of the tech are and can look around the corner to how it might be used or misused,” Lane said.

For teams that incorporate AI into productivity tools, one of the most important principles is to keep people at the center of the process.

“We bring a lot of focus to making sure the experiences we’re delivering are actually valuable,” said Penny Collisson, principal design research manager for Office. “We have lots of conversations with customers where we never even mention AI. We’re talking about understanding the expressed or latent needs or pain points that people have and then we go back and try to think about how AI could fit in.”

Microsoft has developed 18 best practices that researchers and product designers use to guide their work. But a lot of that work involves listening to people with different levels of tech adoption, socioeconomic backgrounds, geography, physical abilities or attitudes about AI and privacy.

If you talk to people with learning disabilities, for instance, some have a fear of starting with a blank page. That insight helped guide improved dictation offerings in Word for the web, which makes it easier to create content with one’s voice and use speech-to-text to get thoughts down on paper.

Creating good user experiences with AI is more complicated than asking people for feedback on whether they prefer one type of control over another, or which interface is easier to navigate, said Jon Friedman, Microsoft corporate vice president for design and research.

“The kicker and power of AI is that everyone’s experience is unique. Before, we were designing for the mean because solutions were closer to one size fits all. And now we are designing each thing to be a special size to fit each individual,” Friedman said.

“So making sure we’re talking to a much broader set of people and hearing everyone’s voice is really important to give people what they truly need,” he said.

In one example, Microsoft designers and engineers who were interested in building a better screen reader for people who are blind or with low vision built a relationship with the Washington State School for the Blind and began interviewing and observing how those students consume information and approach tasks for the day. That work led to Play My Emails in Outlook mobile, which turned out to also be useful for anyone who wants a jump on their day but can’t safely look at a screen while commuting or cooking breakfast for kids.

Through interviews and equipment that simulated the experience of having macular degeneration, the design team began to understand the massive cognitive load that’s required to listen for pertinent information among a sea of extraneous details like dates and time stamps and even punctuation marks that screen readers include as they scan from left to right.

“It was like listening for a needle in a haystack, and the fatigue level was really high,” Friedman said.

So the team used AI to offer the most important information upfront and in a much more conversational way. Having Cortana, Microsoft 365’s personal productivity assistant, tell you that someone sent you an email in the past hour about scheduling a meeting this afternoon is more useful than knowing the precise time stamp, Friedman said.

Play My Emails also provides summary information like how many unread emails are in your inbox and how long it would take to listen to them. That helps people decide if they have enough commute time or brain space while they’re rushing to get out of the house to focus on the task.

“We started on this path because we thought inclusive design was an important philosophy that we needed to start living and breathing in product,” Friedman said. “But the team quickly realized that there’s a lot of instances where people are situationally blind or looking at screens when it’s not safe, and that’s when they realized this is something that could be useful for people in a lot of different contexts.”

Keeping users in control

Microsoft also wanted users to have control over its new AI-powered tools. Some of the new Editor features, like inclusive language critiques, aren’t automatically turned on but allow people to opt into using them.

Researchers also heard loud and clear from some users whose unique writing style is an important part of their brand or professional success. They didn’t want AI algorithms rewriting their prose. That’s, in part, why the Editor in Word rewrite suggestion tool includes three options that can serve as inspiration or jumping-off points for an author to build on.

“In some ways this is just exposing the idea that there are different ways to say the same thing,” Friedman said. “We believe that’s going to help with both the concept of teaching people and letting them have their own voice.”

Designers of the Editor tools regularly talk to teachers about how their students prefer to receive editing feedback and how the tools can help build students’ skills rather than simply doing tasks for them.

“Teachers don’t just want us to fix their students’ work,” Hendrich said. “They want them to be able to learn in the process. That’s why Word offers explanations, to help people write more confidently while also providing these teachable moments.”

That was one of the drivers behind the new similarity checker function in Word for the web, which can help flag unoriginal content that may have made its way into a document from the abundant reference material available online. The similarity checker also helps teach people how to properly cite others’ words or ideas, which is an important skill for students to learn and one for which teachers have said they would welcome extra help.

As Microsoft looks to the future, teams are exploring other new features made possible by advances in natural language processing, computer vision and other types of AI. That includes Presenter Coach features in PowerPoint that can tell people how often they slouch or make eye contact during a presentation. Tools in Office that help people accomplish more of their routine tasks on the go through voice interaction can free up time for more focused work.

“When you’re using our products, you’re trying to get your job done right,” Chauhan said. “Our job is to amplify that human ingenuity. So whether you’re writing a document or designing a beautiful presentation or analyzing a spreadsheet, we’re always thinking about how can we help you in that task. That’s really been the arc of AI in Office.”

Top image: Teams led by Sumit Chauhan, Microsoft corporate vice president for engineering in Office (left), and Mira Lane, who heads Microsoft’s Ethics & Society team (right), collaborate to ensure that AI-powered productivity tools are designed with the company’s values in mind. Photo by Dan DeLong.

Related:

Jennifer Langston writes about Microsoft research and innovation. Follow her on Twitter."
Microsoft_News,https://news.microsoft.com/source/features/sustainability/artificial-intelligence-makes-a-splash-in-efforts-to-protect-alaskas-ice-seals-and-beluga-whales-2/,,Artificial intelligence makes a splash in efforts to protect Alaska’s ice seals and beluga whales,"When Erin Moreland set out to become a research zoologist, she envisioned days spent sitting on cliffs, drawing seals and other animals to record their lives for efforts to understand their activities and protect their habitats.

Instead, Moreland found herself stuck in front of a computer screen, clicking through thousands of aerial photographs of sea ice as she scanned for signs of life in Alaskan waters. It took her team so long to sort through each survey — akin to looking for lone grains of rice on vast mounds of sand — that the information was outdated by the time it was published.

“There’s got to be a better way to do this,” she recalls thinking. “Scientists should be freed up to contribute more to the study of animals and better understand what challenges they might be facing. Having to do something this time-consuming holds them back from what they could be accomplishing.”

That better way is now here — an idea that began, unusually enough, with the view from Moreland’s Seattle office window and her fortuitous summons to jury duty. She and her fellow National Oceanic and Atmospheric Administration scientists now will use artificial intelligence this spring to help monitor endangered beluga whales, threatened ice seals, polar bears and more, shaving years off the time it takes to get data into the right hands to protect the animals.

The teams are training AI tools to distinguish a seal from a rock and a whale’s whistle from a dredging machine’s squeak as they seek to understand the marine mammals’ behavior and help them survive amid melting ice and increasing human activity.

Moreland’s project combines AI technology with improved cameras on a NOAA turboprop airplane that will fly over the Beaufort Sea north of Alaska this April and May, scanning and classifying the imagery to produce a population count of ice seals and polar bears that will be ready in hours instead of months. Her colleague Manuel Castellote, a NOAA affiliate scientist, will apply a similar algorithm to the recordings he’ll pick up from equipment scattered across the bottom of Alaska’s Cook Inlet, helping him quickly decipher how the shrinking population of endangered belugas spent its winter.

The data will be confirmed by scientists, analyzed by statisticians and then reported to people such as Jon Kurland, NOAA’s assistant regional administrator for protected resources in Alaska.

Kurland’s office in Juneau is charged with overseeing conservation and recovery programs for marine mammals around the state and its waters and helping guide all the federal agencies that issue permits or carry out actions that could affect those that are threatened or endangered.

Of the four types of ice seals in the Bering Sea — bearded, ringed, spotted and ribbon — the first two are classified as threatened, meaning they are likely to become in danger of extinction within the foreseeable future. The Cook Inlet beluga whales are already endangered, having steadily declined to a population of only 279 in last year’s survey, from an estimate of about a thousand 30 years ago.

Individual groups of beluga whales are isolated and don’t breed with others or leave their home, “so if this population goes extinct, no one else will come in; they’re gone forever,” says Castellote. “Other belugas wouldn’t survive there because they don’t know the environment. So you’d lose that biodiversity forever.”

Yet recommendations by Kurland’s office to help mitigate the impact of human activities such as construction and transportation, in part by avoiding prime breeding and feeding periods and places, are hampered by a lack of timely data.

“There’s basic information that we just don’t have now, so getting it will give us a much clearer picture of the types of responses that may be needed to protect these populations,” Kurland says. “In both cases, for the whales and seals, this kind of data analysis is cutting-edge science, filling in gaps we don’t have another way to fill.”

The AI project was born years ago, when Moreland would sit at her computer in NOAA’s Marine Mammal Laboratory in Seattle and look across Lake Washington toward Microsoft’s headquarters in Redmond, Washington. She felt sure there was a technological solution to her frustration, but she didn’t know anyone with the right skills to figure it out.

She hit the jackpot one week while serving on a jury in 2018. She overheard two fellow jurors discussing AI during a break in the trial, so she began talking with them about her work. One of them connected her with Dan Morris from Microsoft’s AI for Earth program, who suggested they pitch the problem as a challenge that summer at the company’s Hackathon, a week-long competition when software developers, programmers, engineers and others collaborate on projects. Fourteen Microsoft engineers signed up to work on the problem.

“Across the wildlife conservation universe, there are tons of scientists doing boring things, reviewing images and audio,” Morris says. “Remote equipment lets us collect all kinds of data, but scientists have to figure out how to use that data. Spending a year annotating images is not only a bad use of their time, but the questions get answered way later than they should.”

Moreland’s idea wasn’t as simple as it may sound, though. While there are plenty of models to recognize people in images, there were none — until now — that could find seals, especially real-time in aerial photography. But the hundreds of thousands of examples NOAA scientists had classified in previous surveys helped technologists, who are using them to train the AI models to recognize which photographs and recordings contained mammals and which didn’t.

“Part of the challenge was that there were 20 terabytes of data of pictures of ice, and working on your laptop with that much data isn’t practical,” says Morris. “We had daily handovers of hard drives between Seattle and Redmond to get this done. But the cloud makes it possible to work with all that data and train AI models, so that’s how we’re able to do this work, with Azure.”

Moreland’s first ice seal survey was in 2007, flying in a helicopter based on an icebreaker. Scientists collected 90,000 images and spent months scanning them but only found 200 seals. It was a tedious, imprecise process.

Ice seals live largely solitary lives, making them harder to spot than animals that live in groups. Surveys are also complicated because the aircraft have to fly high enough to keep seals from getting scared and diving, but low enough to get high-resolution photos that enable scientists to differentiate a ring seal from a spotted seal, for example. The weather in Alaska — often rainy and cloudy — further complicates efforts.

Subsequent surveys improved by pairing thermal and color cameras and using modified planes that had a greater range to study more area and could fly higher up to be quieter. Even so, thermal interference from dirty ice and reflections off jumbled ice made it difficult to determine what was an animal and what wasn’t.

And then there was the problem of manpower to go along with all the new data. The 2016 survey produced a million pairs of thermal and color images, which a previous software system narrowed down to 316,000 hot spots that the scientists had to manually sort through and classify. It took three people six months.

When Moreland told colleagues about the AI project, she discovered that Castellote faced a similar obstacle.

Each spring and fall, Castellote flies from Seattle to Anchorage, takes a boat out, retrieves microphones from 15 spots around the bottom of Cook Inlet, downloads the data and puts the equipment back. He and his team spend the rest of the year trying to classify each sound from the previous six months, determining which whistles and calls are from beluga, humpback or killer whales, which roars are from a plane or a ship, and which thumps are from construction or cracking ice.

That doesn’t leave him with much time for analysis, such as trying to interpret how the whales are communicating.

Whales operate on sound, using echo location to get around, especially in Cook Inlet, where sediment from melting glaciers makes the water murky and where it’s too dark most of the year for eyes to be useful. That means noise — which is amplified under water — can disorient the mammals, leaving them unable to find the ocean floor or surface, follow their pod, catch prey or be alerted to the presence of a predator such as a killer whale.

If calves can’t hear their mothers’ clicks and whistles, for example, they can get separated and die.

“Human noise could be masking key signals the whales use to find food and each other, which could affect reproduction, and if you can’t eat, mate or reproduce, then you can’t increase the population,” says Castellote. “So we think noise is a big issue, and we’re focusing on that.”

The problem is that Anchorage is an important hub for cargo ships and for military and commercial flights. The port is expanding, which requires piles to be driven down for new docks. There are 17 oil rigs with accompanying pipelines in Cook Inlet, he says, and the deposits from glaciers require continual dredging to keep shipping channels open. Each of those activities creates noise that drowns out the whales’ whistles and calls. So Castellote aims to give Kurland’s group data on how the whales’ habitat use overlaps with human noise, helping guide mitigation measures to make human activity less detrimental to the endangered animals. The agency might work to minimize vessel activity near prime feeding areas or to reduce construction noise in certain spots during breeding season, for example.

Working with Microsoft, Castellote had a robust set of algorithms by last fall that showed a 99 percent match to the logs his team had previously classified manually. And the group is developing new technology that will make the process even more efficient.

As climate change allows human activity to move further north, Castellote’s work will help guide protective measures for other populations of whales that could be introduced to the same types of noise in the next decade or two, he says.

“The Cook Inlet belugas are a very small population that’s concentrated near the biggest human population in Alaska, so that development-related activity can be a threat,” Kurland says. “The seals are more broadly distributed over a larger area with less human activity, and are mainly threatened by climate change,” which is harder to mitigate.

Click below to listen to the calls of beluga whales against the whir of a passing ship in the Cook Inlet near Anchorage. Any sounds the belugas make below 1 kHz are masked by the ship’s noise. (Audio clip provided by Manuel Castellote.) https://news.microsoft.com/wp-content/uploads/prod/2020/01/Ship-and-beluga.mp3

The seals being surveyed rely on ice floes to breed, nurse their pups and go through their annual molt, a process that replaces their coats each spring. Ribbon seals rarely ever go ashore — when the ice melts each summer, they just swim around in the Arctic Ocean until the floes form again in the fall. So there’s nowhere that global warming is having a more pronounced impact than the Arctic and sub-Arctic regions, Morris says.

Studying the population data and distribution of the seals over time will provide a first step in understanding how they’re coping with a changing environment and what they need, Moreland says.

“We’re living in a changing time, and we need all the players we can get to protect our resources,” says Tom Gray, a tribal representative who hunts Eastern Bering Sea belugas with nets and has used his knowledge to help Castellote’s team catch the endangered Cook Inlet whales briefly to attach sensors with suction cups.

When Gray was growing up in Nome, Alaska, “there were no ships going past us toward the Northwest Passage. Now there are hundreds a year and it’s projected that before long there will be a thousand,” he says.

“Alaska has beluga whales, moose, caribou, all these unique animals, and it’s like a mystique, something we talk about and love, and we’re right in the middle of it,” he says.

But amid the increased development and the whales’ persistent struggles, and despite scientists’ efforts over the past few decades, “I don’t think our people have the tools to keep these populations healthy. We’re losing the battle, and once they’re gone, it’s over. We need scientists and innovators to protect these animals so we don’t lose them.”"
Microsoft_News,https://news.microsoft.com/source/features/digital-transformation/vintage-inspired-lucky-brand-embraces-fresh-innovation-to-deliver-better-customer-service/,,Vintage-inspired Lucky Brand embraces fresh innovation to deliver better customer service,"Click here to load media

In the market for retail apparel, Lucky Brand stands out from competitors. Headquartered in Los Angeles, the retailer draws upon the city’s history through its catalog of vintage-inspired jeans and T-shirts alongside other Bohemian-styled clothing.

Facing increased competition from online and brick-and-mortar retailers, Lucky Brand wanted to improve in-store shopping experiences and further integrate analytics into its everyday operations to enhance every customer interaction. However, its legacy IT architecture limited the company’s ability to achieve its goals.

“Retail traditionally looked to manage its own technology in-house,” says Kevin Nehring, chief technology officer at Lucky Brand. “And while that might have been effective years ago, we now see more advantages to tapping into new innovation in the cloud.”

Lucky Brand previously powered its IT environment with a mix of cloud platforms and co-located facilities that had limited scalability, inefficient administration and sizable licensing costs. “We spent a lot of time figuring out how to connect data spread across different locations,” explains Nehring. “We knew our corporate and in-store teams needed to be able to make more timely decisions using accurate, centralized data.”

While Lucky Brand had looked into updating its IT infrastructure in-house, the retailer’s scalability and delivery timeline challenges would be difficult to accomplish without additional support. By working with Microsoft and VMware Cloud Verified partner CloudSimple, and leveraging Microsoft Azure VMware Solutions, Lucky Brand now has a foundation that offers agile IT to support higher sales and enhanced customer services.

Visit the VMware site to learn how Lucky Brand found the perfect fit for better customer insights, and read the article on CIO Dive."
Microsoft_News,https://news.microsoft.com/source/features/innovation/people-who-inspired-us-in-2019/,,People who inspired us in 2019,"People all over the world are doing incredible things with technology. Akiyoshi Shinobu, a waitress in Japan, learned Power BI and Azure Machine Learning to improve her restaurant’s dining experience. Dr. Raymond Campbell of South Africa created a mobile health clinic that screens preventable diseases with an Azure-powered backpack. Chelsey Potts, an employee at PACCAR in Ohio, is learning new skills with mixed reality. Here are the stories of some of the people who have inspired us this year.

Dr. Raymond Campbell

South Africa

This doctor started a mobile health clinic to help people in rural communities get needed medical care.

Watch the video

Akiyoshi Shinobu

Japan

She went from waiting tables to teaching herself machine learning and data visualization to digitally transform the restaurant where she worked.

Watch the video

Gerardo

Mexico

This young boy is getting cancer treatment at Casa de la Amistad, which is using Power BI and Dynamics 365 to be accountable to donors and monitor treatment effectiveness.

Watch the video

Residents of Kiruna Stad

Sweden

People here are using HoloLens to plan the relocation of their entire city, which was built on top of an iron mine.

Watch the video

Chelsey Potts

Ohio, U.S.

This employee and other firstline workers at PACCAR are using the power of mixed reality to learn valuable new skills.

Watch the video

Martin Lee

United Kingdom

He started as a dispatcher but is now a software developer at Autoglass, where he used Power Apps to save money and make technicians’ jobs far easier.

Watch the video

Red Cross volunteers

U.S.

They respond where they are needed, and they use Microsoft Teams, Power Platform and other tech to focus on their core mission of alleviating human suffering.

Watch the video

Dr. David Kellermann

Australia

This university teacher in Sydney, Australia, uses Microsoft’s platforms to connect all his students, including those in his classroom and watching online.

Watch the video

Connie Sales

North Carolina, U.S.

This visual artist brings her creativity, words and “paint” to life with the help of her Microsoft Surface.

Watch the video

Michael Monthervil

Florida, U.S.

This U.S. Army veteran in Tampa Bay, Florida, uses the Xbox Adaptive Controller to speed his rehabilitation and connect with friends over video games.

Watch the video"
Microsoft_News,https://news.microsoft.com/source/features/ai/mona-lisa-translation-research-products/,,"From search to translation, AI research is improving Microsoft products","Until recently, a multinational company looking to help customers around the world book international travel would have had to build separate chatbots from scratch to converse in French, Hindi, Japanese or other languages.

But thanks to artificial intelligence research breakthroughs that have enabled algorithms to more accurately parse nuances in the way different languages express concepts or structure sentences, it is now possible to build a single bot and use Microsoft Translator to translate questions and answers accurately enough for use in multiple countries.

Over the past few years, Microsoft deep learning researchers were the first to achieve human parity milestones in developing algorithms that could perform about as well as a person on research benchmarks testing conversational speech recognition, reading comprehension, translation of news articles and other challenging language understanding tasks. Now, the benefits of those AI research breakthroughs are making their way into products from Azure to Bing.

Search engineers are borrowing lessons from Microsoft AI researchers who developed a new deep neural network model that can learn from multiple natural language understanding tasks at once. They’ve applied those lessons to improve answers to questions and captions in Bing search results and question answering in corporate SharePoint sites. A new AI model that performed well on a recent speaker recognition challenge to recognize speakers from real life speech is being incorporated into Azure’s Speaker Recognition Cognitive Service.

“It’s really only been the recent introduction of new deep learning models that has allowed language understanding to dramatically improve,” said Eric Boyd, Microsoft corporate vice president, Azure AI. “The types of things we’re now able to do in our products because of these research breakthroughs are things that previously didn’t work as well or that we just generally couldn’t do.”

Across the company, he can point to examples of Azure AI products that grew from researchers solving challenges that also turned out to be useful for customers ­— like Azure’s automated machine learning capabilities that vastly simplify the model building process or Azure’s Personalizer Cognitive Service that easily delivers relevant content to users. The latter reinforcement learning model was initially developed by researchers, proved out internally and eventually built into a product for Azure cloud customers, he said.

“This space moves so quickly that you really need to tap into the latest thinking, and it’s a very privileged position to have Microsoft Research’s vast army of super talented people pushing the envelope in all these different ways,” Boyd said. “So our work is really to figure out the most interesting places where we can apply that to our products and, on the other side, to also give them guidance on what would really make the biggest differences to us.”

In the translation field, for instance, Microsoft researchers in 2018 were the first to demonstrate that AI could match human performance in translating news articles from Chinese to English on a commonly used test set. As soon as the team achieved that historic research milestone, they began adapting the model to work in Microsoft Translator, which powers an Azure Cognitive Service that has to work instantaneously and translate a wide variety of texts ranging from historical research documents to travel websites and production manuals.

The resulting product improvements were rolled out in the first nine language pairs in June, for translation to and from English, and in eight new languages in November. For example, English to French translations have improved by 9 percent, English to Hindi by 9 percent, Bengali to English by 11 percent, Urdu to English by 15 percent and English to Korean by 22 percent. Even previously strong models such as Portuguese and Swedish have seen significant quality gains.

In one example, the improved machine translation model accurately translates a sentence from French as: “Arsenal manager Arsene Wenger believes ‘the signs are promising’ for his three injured midfielders who are due to recover for Sunday’s game against Chelsea.” The previous model translated it this way: “Arsenal’s Director Arsene Wenger thinks ‘signs are promising’ for his three wounded terrain backgrounds that need to be plumb for the game against Chelsea on Sunday.”

With these kinds of improvements, it’s much more feasible to take, for example, a human resource document that’s written in one language, use machine translation to convert it to another and simply post the document without additional editing, said Microsoft distinguished engineer Arul Menezes, founder of Microsoft Translator. Or for an engineer working in a factory with a broken piece of equipment to communicate with an expert in the home office who speaks a different language.

“We are really getting to the point where automatic translation just works, and a lot of customers are using it for new applications they never thought were possible before,” Menezes said.

Original Sentence Human Translation Previous Machine Translation Improved Machine Translation with New AI Model Le directeur d’Arsenal Arsene Wenger pense que ‘les signes sont prometteurs’ pour ses trois milieux de terrains blessés qui doivent être remis d’aplomb pour le match contre Chelsea dimanche. Arsenal manager Arsene Wenger believes the ‘signs look quite good’ for his three injured midfielders as they face a race to be fit for the Chelsea game on Sunday. Arsenal’s Director Arsene Wenger thinks ‘signs are promising’ for his three wounded terrain backgrounds that need to be plumb for the game against Chelsea on Sunday. Arsenal manager Arsene Wenger believes ‘the signs are promising’ for his three injured midfielders who are due to recover for Sunday’s game against Chelsea. Geld könnten Verbraucher unter anderem durch Frühbucherrabatte oder All-Inclusive-Angebote sparen, erklärte Laepple. Consumers could save money through early-bird or all-inclusive discounts, among others, Laepple said. Money could save consumers through early bird discounts or all-inclusive deals, among other things, Laepple explained. Consumers could save money through early booking discounts or all-inclusive deals, Laepple said. Microsoft researchers developed a new AI model that has boosted the accuracy of Microsoft Translator, which powers an Azure Cognitive Service, as shown in these before-and-after examples.

The evolution from research to product

It’s one thing for a Microsoft researcher to use all the available bells and whistles, plus Azure’s powerful computing infrastructure, to develop an AI-based machine translation model that can perform as well as a person on a narrow research benchmark with lots of data. It’s quite another to make that model work in a commercial product.

To tackle the human parity challenge, three research teams used deep neural networks and applied other cutting-edge training techniques that mimic the way people might approach a problem to provide more fluent and accurate translations. Those included translating sentences back and forth between English and Chinese and comparing results, as well as repeating the same translation over and over until its quality improves.

“In the beginning, we were not taking into account whether this technology was shippable as a product. We were just asking ourselves if we took everything in the kitchen sink and threw it at the problem, how good could it get?” Menezes said. “So we came up with this research system that was very big, very slow and very expensive just to push the limits of achieving human parity.”

“Since then, our goal has been to figure out how we can bring this level of quality — or as close to this level of quality as possible — into our production API,” Menezes said.

Someone using Microsoft Translator types in a sentence and expects a translation in milliseconds, Menezes said. So the team needed to figure out how to make its big, complicated research model much leaner and faster. But as they were working to shrink the research system algorithmically, they also had to broaden its reach exponentially — not just training it on news articles but on anything from handbooks and recipes to encyclopedia entries.

To accomplish this, the team employed a technique called knowledge distillation, which involves creating a lightweight “student” model that learns from translations generated by the “teacher” model with all the bells and whistles, rather than the massive amounts of raw parallel data that machine translation systems are generally trained on. The goal is to engineer the student model to be much faster and less complex than its teacher, while still retaining most of the quality.

In one example, the team found that the student model could use a simplified decoding algorithm to select the best translated word at each step, rather than the usual method of searching through a huge space of possible translations.

The researchers also developed a different approach to dual learning, which takes advantage of “round trip” translation checks. For example, if a person learning Japanese wants to check and see if a letter she wrote to an overseas friend is accurate, she might run the letter back through an English translator to see if it makes sense. Machine learning algorithms can also learn from this approach.

In the research model, the team used dual learning to improve the model’s output. In the production model, the team used dual learning to clean the data that the student learned from, essentially throwing out sentence pairs that represented inaccurate or confusing translations, Menezes said. That preserved a lot of the technique’s benefit without requiring as much computing.

With lots of trial and error and engineering, the team developed a recipe that allowed the machine translation student model — which is simple enough to operate in a cloud API — to deliver real-time results that are nearly as accurate as the more complex teacher, Menezes said.

Arul Menezes, Microsoft distinguished engineer and founder of Microsoft Translator. Photo by Dan DeLong.

Improving search with multi-task learning

In the rapidly evolving AI landscape, where new language understanding models are constantly introduced and improved upon by others in the research community, Bing’s search experts are always on the hunt for new and promising techniques. Unlike the old days, in which people might type in a keyword and click through a list of links to get to the information they’re looking for, users today increasingly search by asking a question — “How much would the Mona Lisa cost?” or “Which spider bites are dangerous?” — and expect the answer to bubble up to the top.

“This is really about giving the customers the right information and saving them time,” said Rangan Majumder, partner group program manager of search and AI in Bing. “We are expected to do the work on their behalf by picking the most authoritative websites and extracting the parts of the website that actually shows the answer to their question.”

To do this, not only does an AI model have to pick the most trustworthy documents, but it also has to develop an understanding of the content within each document, which requires proficiency in any number of language understanding tasks.

Last June, Microsoft researchers were the first to develop a machine learning model that surpassed the estimate for human performance on the General Language Understanding Evaluation (GLUE) benchmark, which measures mastery of nine different language understanding tasks ranging from sentiment analysis to text similarity and question answering. Their Multi-Task Deep Neural Network (MT-DNN) solution employed both knowledge distillation and multi-task learning, which allows the same model to train on and learn from multiple tasks at once and to apply knowledge gained in one area to others.

Bing’s experts this fall incorporated core principles from that research into their own machine learning model, which they estimate has improved answers in up to 26 percent of all questions sent to Bing in English markets. It also improved caption generation — or the links and descriptions lower down on the page — in 20 percent of those queries. Multi-task deep learning led to some of the largest improvements in Bing question answering and captions, which have traditionally been done independently, by using a single model to perform both.

For instance, the new model can answer the question “How much does the Mona Lisa cost?” with a bolded numerical estimate: $830 million. In the answer below, it first has to know that the word cost is looking for a number, but it also has to understand the context within the answer to pick today’s estimate over the older value of $100 million in 1962. Through multi-task training, the Bing team built a single model that selects the best answer, whether it should trigger and which exact words to bold.

This screenshot of Bing search results illustrates how natural language understanding research is improving the way Bing answers questions like “How much does the Mona Lisa cost?” A new AI model released this fall understands the language and context of the question well enough to distinguish between the two values in the answer — $100 million in 1962 and $830 million in 2018 — and highlight the more recent value in bold. Image by Microsoft.

Earlier this year, Bing engineers open sourced their code to pretrain large language representations on Azure. Building on that same code, Bing engineers working on Project Turing developed their own neural language representation, a general language understanding model that is pretrained to understand key principles of language and is reusable for other downstream tasks. It masters these by learning how to fill in the blanks when words are removed from sentences, similar to the popular children’s game Mad Libs.

You take a Wikipedia document, remove a phrase and the model has to learn to predict what phrase should go in the gap only by the words around it,” Majumder said. “And by doing that it’s learning about syntax, semantics and sometimes even knowledge. This approach blows other things out of the water because when you fine tune it for a specific task, it’s already learned a lot of the basic nuances about language.”

To teach the pretrained model how to tackle question answering and caption generation, the Bing team applied the multi-task learning approach developed by Microsoft Research to fine tune the model on multiple tasks at once. When a model learns something useful from one task, it can apply those learnings to the other areas, said Jianfeng Gao, partner research manager in the Deep Learning Group at Microsoft Research.

For example, he said, when a person learns to ride a bike, she has to master balance, which is also a useful skill in skiing. Relying on those lessons from bicycling can make it easier and faster to learn how to ski, as compared with someone who hasn’t had that experience, he said.

“In some sense, we’re borrowing from the way human beings work. As you accumulate more and more experience in life, when you face a new task you can draw from all the information you’ve learned in other situations and apply them,” Gao said.

Like the Microsoft Translator team, the Bing team also used knowledge distillation to convert their large and complex model into a leaner model that is fast and cost-effective enough to work in a commercial product.

And now, that same AI model working in Microsoft Search in Bing is being used to improve question answering when people search for information within their own company. If an employee types a question like “Can I bring a dog to work”? into the company’s intranet, the new model can recognize that a dog is a pet and pull up the company’s pet policy for that employee — even if the word dog never appears in that text. And it can surface a direct answer to the question.

“Just like we can get answers for Bing searches from the public web, we can use that same model to understand a question you might have sitting at your desk at work and read through your enterprise documents and give you the answer,” Majumder said.

Top image: Microsoft investments in natural language understanding research are improving the way Bing answers search questions like “How much does the Mona Lisa cost?” Image by Musée du Louvre/Wikimedia Commons.

Related:

Jennifer Langston writes about Microsoft research and innovation. Follow her on Twitter."
Microsoft_News,https://news.microsoft.com/source/features/ai/car10-azure-car-repair-app/,,"Less stress, less time: How a Brazilian startup is using Azure AI to make car repairs easier","SÃO PAOLO, Brazil – For most people, the worst part of getting into a minor car accident is figuring out how to get your car repaired.

There’s the trouble of figuring out who to call, the hassle of driving around to get estimates and the constant worry that whoever you work with will end up taking advantage of you.

That’s where Car10 comes in. The Brazilian startup has created an app that allows customers to take a picture of the damage, submit the photo and get three to five estimates from nearby car repair shops that Car10 has pre-screened for quality and reliability. The startup even guarantees it will make the repair for free if you aren’t satisfied.

“We take the fear out of the process, the worry that you’ll be taken advantage of,” said Jose Tafner, Car10’s chief financial officer.

Now, the São Paolo-based company is using artificial intelligence to make the process faster. The startup announced that it is using Microsoft’s Azure Cognitive Services Custom Vision Service to almost immediately give the user a rough sense of what they expect the repair to cost.

With the current system, users who submit a photo will get a quote within 30 minutes to an hour. With the new AI tools, Tafner said they can get a general sense of how much the repair will cost within about 30 seconds.

“It goes back to the customer need. When you have a small accident or crash, the thing you want to know is how much it’s going to cost,” Tafner said. “The first need is speed and some level of accuracy.”

The AI system uses a machine learning model to compare the damage to the customer’s car with other examples of similar damage to come up with a reasonably close estimate. Then, the company works with car repair shops to get firmer bids.

The AI system may speed up the quote process, but it doesn’t replace the hands-on involvement that Car10 has in ensuring customers feel comfortable throughout the process of getting their car repaired.

Tafner said Car10 works with customers on everything from providing the estimate to scheduling the visit and even paying through Car10’s digital platform. The customer then has the opportunity to rate the experience and the shop where the repair was made.

“The digital part of the journey is small. The largest part is analog,” Tafner said.

Focus on quality

Car10 has about 100,000 customers and works with about 4,000 auto body shops throughout Brazil, ranging from big businesses to small mom-and-pop shops. Tafner said the company initially focused only on larger shops, thinking that was what the customer would prefer. But they found that customers didn’t care whether the shop was being run out of someone’s garage or a fancy office.

“They care about the quality of the service,” he said.

Car10 was started in 2014 by three brothers who had previously worked for their father’s insurance adjustment business. When that business was sold, they decided to use their experience in the car repair industry to plunge into the startup world. Tafner joined a couple of years later, after decades of global experience in the corporate world. The service is designed for people who are paying for repairs themselves, instead of relying on insurance.

From the beginning, the four-person leadership team has been highly reliant on technology and data. They run on Microsoft’s Azure cloud service, use Power BI dashboards and built the app on the .NET framework.

“The four of us are data freaks. We’re constantly using it to improve the business,” Tafner said.

Still, Tafner said that like many businesses swimming in data, it can be challenging to figure out which pieces of data are useful.

One clear winner: The photos of car repairs. Car10 was able to use that data to train the machine learning model to automatically detect what kind of repair a person needs and what it would generally cost. Car10 doesn’t sell customer data, and it protects people’s personal information using Azure security protections.

Car10, which has received startup investment funds from Microsoft, first started building the AI solution when the company participated in an industry hackfest. Although it has an IT staff, none of the people who work for Car10 have a particular expertise in AI. Azure Cognitive Services are designed so that even people without any formal AI training can use them.

Future plans

Car10 is about five years old now, and it expects to break even within a quarter. Now, Tafner said the company is seeking more funding so that it can expand into other areas of business, and potentially other markets outside of Brazil.

“What we can do for car crashes we can do for a number of things,” he said.

For Tafner, the small team and fast pace is both invigorating and enlightening. Like any startup, he notes, the company is constantly trying new things, making mistakes and adjusting – all while trying to run the core business. He likens it to race car driving.

“We’re changing the tires while the car is running,” Tafner said. “There are no pit stops for us.”

Related:

Allison Linn writes about AI and innovation. Follow her on Twitter."
Microsoft_News,https://news.microsoft.com/source/features/ai/ignite-2019-autonomous-systems/,,How autonomous systems use AI that learns from the world around it,"If a mine collapses or an earthquake strands people underground in a subway car, first responders can’t rush into that unknown subterranean environment without potentially endangering themselves.

A rescue team must ensure an area is structurally sound and air is breathable before pushing forward — ­­which sometimes means help moves slower than anyone would like.

In a competition sponsored by DARPA, teams are designing autonomous robots that can explore and map these potentially dangerous underground landscapes and also identify objects of interest to first responders like survivors, backpacks, cell phones or fire extinguishers.

“With a robot, you’re able to take much more risk and potentially move much faster in a rescue,” said Sebastian Scherer, Carnegie Mellon University associate research professor and co-leader of Team Explorer, which took first place in the initial leg of that Subterranean Challenge using Microsoft’s AirSim technology to train its robots to recognize objects in a simulated mine.

“It’s really difficult to design a system to operate in an environment where you really have no idea what’s coming next. It has to be very robust and be able to make decisions on its own to get itself out of trouble,” Scherer said.

It’s exactly the kind of hard problem that Microsoft’s autonomous systems platform is designed to make easier — along with a growing list of other industrial and manufacturing applications in which AI can be used to teach machines to learn from and respond to the physical world.

At its Ignite conference in Orlando, Florida, this week, Microsoft announced that it is expanding a limited preview program of its autonomous systems platform, which will offer more opportunities for developers, engineers and enterprise customers to test its first components.

Autonomous systems are part of a new class of systems that go beyond basic automation. Instead of performing a specific task repeatedly without variation, they are capable of sensing and dynamically responding to changing environments to accomplish a desired goal. Microsoft’s platform uses a unique combination of machine teaching, reinforcement learning and simulation to help companies create these systems.

At Ignite this week, Microsoft also announced that it is launching new partnerships with companies such as MathWorks, a leading developer of mathematical computing software and maker of the MATLAB and Simulink products that are used by millions of engineers and scientists worldwide to design complex embedded and multidomain systems. The partnership will allow engineers to create autonomous systems using Microsoft AI and Azure with the widely used modeling and simulation tools already at their fingertips.

New partners also include Fresh Consulting, a Bellevue, Washington-based consulting team of designers, developers and engineers who are helping customers build new systems such as tractors that autonomously deliver materials to outdoor solar farms or construction sites.

Microsoft says these new partnerships reflect the company’s commitment to building an entire ecosystem of partners — with expertise ranging from simulation to drone software and systems integration — that will support customers interested in taking the leap from automated to autonomous systems.

In some cases, those pioneering companies are using autonomous systems to perform work that’s either too dangerous or tedious for people to want to do. In others, they are helping people who work with physical systems — someone tweaking chemical reactions to make an optimal batch of plastics or adjusting automotive components to ensure a smooth ride — make smarter decisions by processing greater volumes of information than people can comprehend.

Microsoft’s unique machine teaching approach allows employees who might know a lot about keeping large buildings at a comfortable temperature without wasting energy or how material needs to move around a construction site but who aren’t data science experts to more intuitively “teach” AI systems. By using their subject matter expertise to break complicated tasks into smaller parts, they help the AI hit on solutions faster. This approach also results in AI with explainable behavior, giving people a clearer understanding of how it makes decisions and confidence that the solution is sound.

Deep reinforcement learning algorithms — which the Microsoft autonomous systems platform selects and manages — learn by testing out a series of actions and seeing how close they get to a desired goal. But because no one wants to crash real robots or take critical pieces of equipment offline while the algorithms figure out what works, the training happens in simulated environments.

With the MathWorks partnership announced today, customers can now use MATLAB and Simulink models with Microsoft’s machine teaching tools for training autonomous systems on the cloud. This enables them to use a wider range of simulation models to instantly spin up scenarios that mimic all the different conditions that an autonomous system might encounter. Whether those represent the many potential hazards inside a collapsed mine or a jet engine flying in different weather conditions, this allows the AI to learn from many simulated situations at once.

The journey from automated to autonomous systems is a spectrum of solutions, and very few of the engagements we’re seeing are in that fully autonomous with no humans in the loop zone. The vast majority are assistive technologies that work with people.

Millions of engineers across industries such as automotive, aerospace, industrial machinery and medical devices have already built models of the systems they work on using MATLAB or Simulink. This new partnership allows users to bring simulation models built using MATLAB and Simulink to Microsoft’s Azure cloud computing platform, enabling unprecedented scalability and making it easier for developers and engineers building autonomous systems.

“Our core interest really comes down to engineering productivity — the ability to succeed at a task in the least amount of time possible,” said Loren Dean, MathWorks senior director of engineering for MATLAB products. “This partnership allows engineers to stay in a familiar workflow to learn and apply AI without having to do the things that are non-traditional for them, like setting up the infrastructure to run a bunch of simulations at once. They’re shielded from all that.”

By running hundreds or thousands of simulations in parallel in Azure and learning from massive amounts of data at once, deep reinforcement learning algorithms can find optimal solutions to chaotic, real-world control problems that other types of AI still struggle to solve.

It turns out these problems are everywhere, said Gurdeep Pall, Microsoft’s corporate vice president for Business AI. Microsoft received three times more interest than it expected after opening its autonomous systems limited preview program in May.

The companies who have applied to work with Microsoft’s autonomous systems team and partners are looking to develop control systems to intelligently stitch fabric, optimize chemical engineering processes, manufacture durable consumer goods and even process food. The potential goes far beyond robotics or autonomous vehicles, Microsoft says.

“These are the kinds of diverse use cases for autonomous systems that we’re starting to see emerge,” Pall said. “As customers learn about the capabilities of our toolchain, we’re seeing them apply it in really interesting ways because these control problems exist almost everywhere you look.”

Most customer use cases Microsoft has seen so far involve helping existing employees do their jobs more efficiently, safely or with higher quality, said Mark Hammond, Microsoft general manager for Business AI and the former CEO of the startup Bonsai, which Microsoft acquired last year. As sensors in modern workplaces collect ever more data, it can become difficult for any one operator — such as someone who is guiding a drill bit or calibrating expensive equipment — to track it all. AI tools can process that data and bring the most relevant patterns to that operator’s attention, enabling them to make more informed decisions.

“The journey from automated to autonomous systems is a spectrum of solutions, and very few of the engagements we’re seeing are in that fully autonomous with no humans in the loop zone,” Hammond said. “The vast majority are assistive technologies that work with people.”

Training AI systems in virtual worlds

Traditionally, AI models have often relied on labor-intensive labeled data for training, which works well for many problems but not for those that lack real-world data. Now, Microsoft and partners like MathWorks are expanding the use of AI into more areas such as those that require learning from the three-dimensional physical world around them — through the power of reinforcement learning and simulation.

Engineers have long used simulations to mathematically model the systems they work with in the real world. This allows them to estimate how a particular change in a chemical, manufacturing or industrial process may affect performance, without having to worry about slowing production or putting people or equipment at risk.

Now, those same simulations can be used to train reinforcement learning algorithms to find optimal solutions, Dean said.

“The AI is really augmenting how these traditional systems have worked — it just gives you greater confidence in your design and gives you additional capabilities that either had to be done manually before or were difficult to solve,” Dean said.

Imagine a building engineer whose job is to calibrate all the heating and cooling systems in a large commercial building to keep each room at a comfortable temperature as people stream in and out for meetings and outside weather fluctuates — while using as little energy as possible. That could involve tuning dozens of different parameters and might take many cycles of modeling and measuring changes for that engineer to find the best balance of controls.

With the new Microsoft and MathWorks partnership, that engineering expert could use machine teaching tools to help an AI system focus on the most important dimensions of the problem, set safety limits and figure out how to reward success as the algorithms learn. This allows for greater transparency and trust in how the AI system is making decisions and also helps it work more efficiently than randomly exploring all possibilities.

The engineer could train the AI using models that he or she already developed in MATLAB or Simulink. The simulations can be automatically scaled up in the Azure cloud — which means the engineer doesn’t have to worry about learning how to host and manage computing clusters.

The end result is the building engineer uses AI to zero in on promising solutions much faster — but still uses his or her judgment to decide what works best.

“This partnership really marries the best of MathWorks’ capabilities for modeling and simulation with the best of Microsoft’s capabilities for cloud computing and AI,” Microsoft’s Hammond said.

Our core interest really comes down to engineering productivity — the ability to succeed at a task in the least amount of time possible.

But simulation needs vary widely. Some engineers execute equations in pure math to model fluid dynamics while others want to test a drone’s detection capabilities in photorealistic scenes. That’s why the autonomous systems toolchain also includes AirSim, an open source technology developed by Microsoft to simulate vehicles, drones and other equipment operating in three-dimensional virtual environments.

In the DARPA Subterranean Challenge, for instance, researchers and students from CMU and Oregon State University used AirSim to train perception models to detect objects such as people, backpacks or phones from three-dimensional LIDAR data. In its two best runs, Team Explorer’s robots were able to detect and map 25 artifacts — more than twice as many as any other team.

Artists used reference material from real-world mines to create an intricate maze of virtual manmade tunnels in AirSim. The simulations also included the team’s robotic vehicles and sensor data that reflected obstacles and objects they might encounter.

Others have used AirSim to train drones to spot elephant poachers and autonomously inspect wind turbines.

“I can create one scenario with the wind turbine operating in cloudy skies with windy conditions and another in sunlight and hot temperatures and all the permutations in between,” said Microsoft Senior Principal Researcher Ashish Kapoor. “There are thousands of different worlds we can create instantly and in parallel that the AI can learn from.”

The ability to generate data on such a massive scale allows reinforcement learning algorithms to pinpoint exactly which actions or series of steps mattered most in reaching a goal, which is critical to solving dynamic real-world problems.

AirSim is also well-suited to modeling situations where people’s unpredictable behavior comes into play, Kapoor said. In those cases, there are no immutable laws of motion or physics on which to rely.

“We can’t use our existing control techniques, so you need something to create a world that mimics all this unstructured behavior. And that’s what AirSim does very well — it allows you to create data that represents the chaos of human life,” Kapoor said.

Building an ecosystem of partners

Helping customers transition from automated to autonomous systems — a shift that Microsoft says is foundational to the fourth industrial revolution — will require more than one company acting alone.

In addition to its strong portfolio of Internet of Things services, Microsoft’s partnerships with companies like Fresh Consulting will help customers who see the benefits that AI-powered autonomous systems could offer but who may need conceptual or technical help in building them.

Other collaboration and partnership announcements include simulation software makers AnyLogic, CGTech, solution providers Neal Analytics and enterprise drone software maker 3DR.

In a warehouse of today, said Fresh Consulting CEO Jeff Dance, companies have to build a lot of infrastructure around an automated robot arm that can only pick up an object of a certain size or in a certain orientation. They may create special shelving or pallets that need to be redesigned if the process or product changes. By contrast, autonomous systems are designed to adapt to the world around them.

“When you can create an autonomous machine that can deal with new situations it’s never seen before, you don’t have to create that infrastructure, and that’s a huge benefit,” Dance said.

Fresh Consulting is also developing a fleet of autonomous tractors that can deliver panels and other materials to workers assembling outdoor solar farms ­— as they’re needed in the field. With persistent labor shortages in the construction industry, that allows installations to go quicker and employees to focus on more interesting parts of the job, Dance said.

Microsoft is partnering with systems integrators like Fresh Consulting to help customers that are interested in autonomous systems but don’t have core expertise in hardware or software design, Pall said.

It’s still an emerging industry, and Microsoft is still in the process of listening to early customers to refine its autonomous systems toolchain and help put all the puzzle pieces together, he said.

“Eventually we will get to a platform that becomes absolutely accessible to everyone, and that will be the tipping point in how we build things the old way and how we build things in entirely new ways,” Pall said.

“But what we’ve seen through history is that it’s the folks who embrace these big leaps early, not the ones who move slowly until their comfort levels are hit, who emerge as leaders in the new paradigm. And you can definitely tell from talking to customers who is really leaping.”

Top image: Microsoft partner Fresh Consulting, based in Bellevue, Washington, helps customers build autonomous systems such as these tractors that can autonomously deliver materials to workers assembling solar farms. Photo courtesy of Fresh Consulting.

Related:

Jennifer Langston writes about Microsoft research and innovation. Follow her on Twitter."
Microsoft_News,https://news.microsoft.com/source/features/innovation/how-a-new-ai-powered-service-is-helping-one-global-company-transform-employee-knowledge-sharing/,,How a new AI-powered service is helping one global company transform employee knowledge sharing,"Developing a master plan to transform John F. Kennedy International Airport in New York. Replacing a double-deck road with a massive tunnel in Seattle. Keeping beachgoers safe from polluted waters in New Zealand with advanced analytics.

Those are just a few of the thousands of complex projects delivered each year by Mott MacDonald, a global engineering, management and development consulting firm headquartered in London. With 180 principal offices in 50 countries, the company helps solve some of the world’s most urgent social, environmental and economic challenges.

Because Mott MacDonald doesn’t create physical products, its success relies on the knowledge and expertise of its 16,000 employees. To help them share and learn more easily, the company uses Project Cortex, a new service in Microsoft 365 that is part of Microsoft’s vision to transform knowledge and help people learn and grow their skills and expertise.

Announced this week at Microsoft Ignite, Project Cortex uses artificial intelligence to create a knowledge network that automatically connects and organizes organizations’ content into topics and generates topic cards, wiki-like “topic pages” and other new experiences in Microsoft 365.

The experiences will appear seamlessly in familiar tools like Office, Outlook and Microsoft Teams to help people find information, learn quickly and get up to speed faster within the apps they use every day. When employees see an unfamiliar acronym or project in email or chat, for example, they’ll be able to hover on the word and pop out a topic card with a description and related experts, documents and videos. A click on the card will call up a topic page, curated by AI and experts, with richer information like diagrams that link related and adjacent topics.

These capabilities “are going to further enhance our ability to reach our business goals with quicker access and connection to colleagues and their expertise — what we call our connected thinking,” says Simon Denton, Mott MacDonald productivity applications architect. “They’re going to help us build an even stronger knowledge network so people can have the right knowledge at the right time to deliver more excellent project outcomes for our clients. It’s going to be brilliant.”

The company already organizes its many experts and vast business knowledge into 47 communities that cover aviation, bridges and other practice areas. It began building its initial knowledge management system a few years ago to classify content in SharePoint and add people to Yammer groups based on interest.

Project Cortex, currently in private preview, will give Mott MacDonald even more advanced capabilities. Already secure and compliant, the product will allow automated policies based on precise document tags for added security. Its knowledge experiences, which build on an organization’s existing SharePoint content services, will permeate everyday work tools in Microsoft 365 and could one day include learning content from such platforms as LinkedIn Learning.

The solution will have powerful capture technology to make ingested content smarter. Powered by AI, it can extract information from structured content like forms, receipts and invoices. With machine teaching – having experts teach the AI how to respond – Project Cortex can also pull information from unstructured content like legal contracts and employee agreements.

It then adds metadata and classifies the documents into topics, automatically doing tasks that are traditionally manual and slow.

“We’re really excited about that,” says Denton. “We’re already talking about processing 30 years’ worth of drawings with good information on how something was built and how it needs to be maintained for the future. It’s going to unlock a lot of latent knowledge.”

Click here to load media

The knowledge vision

Scheduled for general availability in the first half of 2020, Project Cortex is the first new product to emerge from Microsoft’s knowledge vision, which includes new capabilities in other Microsoft 365 services such as Yammer, for communities of practice; Microsoft Stream, for intelligent video creation and sharing; and Workplace Analytics, for organizational insights.

As a longtime concept for organizing and re-using information, knowledge management has never fully solved the challenges it seeks to address due to disconnected information silos, technical limits and clunky end-user experiences, says Seth Patton, general manager of Microsoft 365 marketing.

But demand for knowledge has become particularly timely due to sweeping changes in the workplace. Automation, gig economies, flex work, skills shortages and retiring baby boomers have heightened the need for organizations to retain knowledge, share it with employees and help them learn new skills and expertise faster, Patton says.

“Business leaders and CEOs are recognizing the importance of their people’s skills and talent in their organizations’ ability to succeed,” he says. “It’s a recognition that upskilling and learning are the new workplace competitive advantage.”

Microsoft’s advances in AI and machine learning, SharePoint’s massive cloud content repository, the intelligence of the Microsoft Graph and integration with Office 365 apps have helped overcome previous challenges in knowledge management to help customers solve unmet needs.

“All of us have had the experience of joining a new project, team or company,” Patton says. “It takes a long time to understand the language before you can contribute and participate. With Project Cortex you can get up to speed quickly and start contributing right away.”

Microsoft Search will also integrate Project Cortex, so people will be able to find topic cards and knowledge pages when they search. Microsoft Search is an important component in the company’s knowledge vision, bringing a unified, intelligent search experience across Microsoft 365 and Bing. It also extends to externally connected content, such as file shares. As content is crawled, it’s added to the knowledge network.

As video becomes an increasingly powerful way to capture and share knowledge, Microsoft Stream applies AI to provide automatic transcription for things like recorded meetings. AI-powered voice enhancement helps reduce background noise so people can better focus on what was discussed, and they can also now create short videos from mobile devices to share in Teams and Yammer.

More than a decade after it was created, Yammer has been completely redesigned with dozens of new capabilities, as well as new integrations with Teams, SharePoint and Outlook. These new features allow people to connect and share knowledge across teams and geographic locations.

Mott MacDonald connects people in Yammer communities that span 47 practice areas so they can share knowledge, ask questions and get answers.

As another way Microsoft 365 helps people share knowledge, Workplace Analytics provides business leaders insights into how people collaborate and spend their time with new self-service dashboards. These insights provide the context of industry benchmarks, as well as AI-driven analyses of business processes and networks of people.

This information can help identify high-performance trends such as close relationships between effective salespeople and engineers, or correlations between good onboarding experiences and more managerial one-on-ones. Leaders can then encourage and replicate similar patterns elsewhere.

The solutions are designed to be easy-to-use, customizable solutions. For the new Project Cortex, AI does the behind-the-scenes “heavy lifting” of mining and collecting useful, internal information, says Naomi Moneypenny, Microsoft director of content services and insights. Then experts can edit, update and add content to make sure knowledge pages are current and relevant.

“Our goal is to put intelligent content and knowledge services into the flow of the work you do every day to help you find the information you need, discover what you want and make your business processes more efficient,” says Moneypenny, who leads the Project Cortex product team. “All while enhancing and enforcing your security and compliance policies.”

At Mott MacDonald, Project Cortex will help build stronger connections across the company’s large, global communities and deliver timely information that helps employees create solutions to many complex challenges, build expertise and save time, all while enhancing service to customers, Denton says.

“I’m really excited by Microsoft’s vision for creating Project Cortex,” he says. “It fits completely with our strategy for knowledge networks. The idea of connecting people to content and content to people and building this network out, powered by Microsoft 365 — it’s going to be a game-changer for us.”

Lead image: From left to right, civil engineer James Balla, project principal Jonathan Hine and civil engineer Cleopatra Meade work together at Mott MacDonald offices in Birmingham. (Photos by Mark Mercer)"
Microsoft_News,https://news.microsoft.com/source/features/ai/nuance-exam-room-of-the-future/,,Microsoft and Nuance join forces in quest to help doctors turn their focus back to patients,"Imagine a visit to your doctor’s office in which your physician asks you how you’ve been feeling, whether your medication is working or if the shoulder pain from an old fall is still bothering you — and his or her focus is entirely on you and that conversation.

The doctor is looking at you, not at a computer screen. He or she isn’t moving a mouse around hunting for an old record or pecking on the keyboard to enter a diagnosis code.

This sounds like an ideal scenario, but as most people know from their own visits to the doctor, it’s far from the norm today.

But experts say that in an exam room of the future enhanced by artificial intelligence, the doctor would be able to call up a lab result or prescribe a new medicine with a simple voice command. She or he wouldn’t be distracted by entering symptoms into your electronic health record (EHR). And at the end of the visit, the essential elements of the conversation would have been securely captured and distilled into concise documentation that can be shared with nurses, specialists, insurance companies or anyone else you’ve entrusted with your care.

A new strategic partnership between Microsoft and Nuance Communications Inc. announced today will work to accelerate and deliver this level of ambient clinical intelligence to exam rooms, allowing ambient sensing and conversational AI to take care of some of the more burdensome administrative tasks and to provide clinical documentation that writes itself. That, in turn, will allow doctors to turn their attention fully to taking care of patients.

Of course, there are still immense technical challenges to getting to that ideal scenario of the future. But the companies say they believe that they already have a strong foundation in features from Nuance’s ambient clinical intelligence (ACI) technology unveiled earlier this year and Microsoft’s Project EmpowerMD Intelligent Scribe Service. Both are using AI technologies to learn how to convert doctor-patient conversations into useful clinical documentation, potentially reducing errors, saving doctors’ time and improving the overall physician experience.

“Physicians got into medicine because they wanted to help and heal people, but they are spending a lot of their time today outside of the care process,” said Joe Petro, Nuance executive vice president and chief technology officer. “They’re entering in data to make sure the appropriate bill can be generated. They’re capturing insights for population health and quality measures. And although this data is all important, it’s really outside a physician’s core focus on treating that patient.”

Click here to load media

Primary care doctors spend two hours on administrative tasks for every hour they’re involved in direct patient care, studies have shown. If they don’t capture a patient’s complaint or treatment plan during or shortly after an exam, that documentation burden will snowball as the day goes on. In another recent study, physicians reported one to two hours of after-hours work each night, mostly related to administrative tasks.

This shift to digital medical record keeping and so-called ‘meaningful use’ regulations is well-intentioned and has provided some important benefits, said Dr. Ranjani Ramamurthy, senior director at Microsoft Healthcare who leads the company’s EmpowerMD research.

People no longer have to worry about not being able to read a doctor’s handwriting or information that never makes it into the right paper file. But the unintended consequence has been that doctors are sometimes forced to focus on their computers and administrative tasks instead of their patients, she said.

After starting her career in computer science, Ramamurthy went back to school to get a medical degree and pursue cancer research. But as she walked the halls of the hospital every day, she couldn’t help thinking that she was missing an opportunity to use her background to create tech solutions that could reinvigorate the doctor-patient relationship.

Ramamurthy noted that most physicians got into healthcare because they want to use their skills and expertise to treat patients, not to feel tethered to their keyboards.

“We need to work on building frictionless systems that take care of the doctors so they can do what they do best, which is take care of patients,” she said.

Built on Microsoft Azure — and working in tandem with the EHR — this new technology will marry the two companies’ strengths in developing ambient sensing and conversational AI solutions. Those include ambient listening with patient consent, wake-up word, voice biometrics, signal enhancement, document summarization, natural language understanding, clinical intelligence and text-to-speech.

Nuance is a leading provider of AI-powered clinical documentation and decision-making support for physicians. Leveraging deep strategic partnerships with the major providers of EHRs, the company has spent decades developing medically relevant speech recognition and processing solutions such as its Dragon Medical One platform, which allows doctors to easily and naturally enter a patient’s story and relevant information into an EHR using dictation. Nuance conversational AI technologies are already used by more than 500,000 physicians worldwide, as well as in 90 percent of U.S. hospitals.

Microsoft brings deep research investments in AI and partner-driven healthcare technologies, commercial relationships with nearly 170,000 healthcare organizations, and enterprise-focused cloud and AI services that accelerate and enable scalable commercial solutions. Earlier this month, for instance, Microsoft announced a strategic collaboration to combine its AI technology with Novartis’ deep life sciences expertise to address challenges in developing new drugs.

In other areas, Azure Cognitive Services offers easy-to-deploy AI tools for speech recognition, computer vision and language understanding, and trusted Azure cloud services can support the user’s compliance with privacy and regulatory requirements for healthcare organizations.

As part of the agreement, Nuance will migrate the majority of its current on-site internal infrastructure and hosted products to Microsoft Azure. Nuance already is a Microsoft Office 365 customer for its more than 8,500 employees worldwide, empowering them with the latest in collaboration and communications tools, including Microsoft Teams.

We need to work on building frictionless systems that take care of the doctors so they can do what they do best, which is take care of patients.

“Just capturing a conversation between two people has been a thorny technical problem for a long time, and a lot of companies have attempted to crack it,” Petro said. “This partnership brings two trusted healthcare superpowers together to solve some of the most difficult challenges and also to leverage the most innovative advances we’ve made in AI, speech and natural language processing.”

The companies will expand upon Nuance’s early success with ACI and expect the technology to be introduced to an initial set of physician specialties in early 2020, and then it will be expanded to numerous other medical specialties over the next few years, Petro said. Initially, the ACI output may be checked by a remote reviewer with medical expertise to provide an important quality check and produce additional training data for the AI models. Once the system has proven its accuracy for a given physician, the ACI documentation will go directly to that physician, who can review it, make any necessary revisions and sign off on a treatment plan all in real-time, Petro said.

With a patient’s consent, ACI is designed to securely ingest and synthesize patient-doctor conversations, integrate that data with information from an EHR, populate a patient’s chart and also help the EHR deliver intelligent recommendations to the doctor.

With innovations in multi-party speech recognition, language understanding and computer vision, these tools can listen to the encounter between the doctor and a patient who grants consent, sense whether they’re pointing to a left knee or right knee when verbally describing a particular pain, extract medically relevant details and translate what just occurred in the exam room into actionable clinical documentation and care suggestions.

“Moving forward, we recognize that reducing the burden of clinical documentation is just the beginning,” said Dr. Greg Moore, Microsoft’s corporate vice president for health technology and alliances. “As the core AI improves and becomes more capable, it will be able to understand much more deeply what is going on by observing doctors and nurses in their day to day work. Ambient clinical intelligence will be able to work in tandem with the EHR to help convert those observations into supportive, augmenting actions.”

For instance, an AI-enabled system can learn to recognize when a doctor is talking to a patient about a new medication, and it can automatically review past conversations as well as the patient’s history to reduce the risk of a drug interaction or allergic reaction. Or it can mine a patient’s complicated medical history with new reported symptoms and offer suggestions for potential diagnoses for the doctor to consider.

In addition, the two companies will open up the ACI platform to an ecosystem of partners than can bring other highly valuable AI innovations to the exam room or at the bedside where the ambient sensing device will be present.

“We want ambient clinical intelligence to assist the EHR in delivering recommendations at the time when it matters — not three days later on your patient portal or when a nurse follows up, but when the doctor and patient are face to face and when that information can actually inform care,” Ramamurthy said.

Related:"
Microsoft_News,https://news.microsoft.com/source/features/work-life/ideas-from-the-heart-could-help-make-employment-more-attainable-for-people-with-disabilities/,,Ideas from the heart could help make employment more attainable for people with disabilities,"Kim Charlson was 11 when she started losing her eyesight because of glaucoma. An operation a year and a half later not only didn’t help, it resulted in complications that hastened her blindness.

Her pragmatic parents insisted she learn Braille, a key to literacy for people who are blind or have low vision. Without that literacy, Charlson likely wouldn’t have gone on to college or a career. Only 13 percent of blind students in the United States know Braille, and roughly 70 percent of adults who are blind or have low vision are unemployed.

Those troubling statistics are one reason Charlson is excited about an app that will help increase the amount of time students can spend learning and practicing Braille. ObjectiveEd, the company that’s developing the Braille AI Tutor app, is a new recipient of Microsoft’s AI for Accessibility grants to people using AI-powered technology to make the world a more inclusive place. Ten other recipients joining the program in conjunction with National Disability Awareness Month include City University of London, inABLE, iMerciv and The Open University

“We have a huge opportunity and a responsibility to be making technology smarter and more useful for people with disabilities,” says Mary Bellard, Microsoft senior architect lead for accessibility. The aim of the AI for Accessibility program, which began in 2018 and now has 32 grantees, is to help people “build something really useful at the intersection of AI, accessibility and disability.”

The Braille AI Tutor app is the latest project for ObjectiveEd’s president, Marty Schultz, a longtime software developer and volunteer teacher who created an iPhone game five years ago called “Blindfold Racer” for children who are blind. It led to more than 80 games for the iPhone and iPad that have together been downloaded more than a half-million times.

If you only get an hour a week with the teacher — I mean, how many kids would learn how to read print if they only had an hour a week of instruction?

Charlson, former president of the American Council of the Blind, is a big fan of Schultz’s work. So is Judy Dixon, consumer relations officer for the National Library Service for the Blind and Physically Handicapped, and the two women often talked with him about the importance of Braille education for literacy and employment. Schultz took it to heart — and to the drawing board.

Some students who are blind or have low vision attend schools that are geared to their needs, and where Braille is taught and used daily. But many attend public schools and learn Braille from teachers who visit their schools once a week, spending about an hour with each student.

“If you only get an hour a week with the teacher — I mean, how many kids would learn how to read print if they only had an hour a week of instruction?” says Charlson. “It’s just not enough. You have to immerse yourself in it at that developmental stage, or you’re not going to be as fluent in it as you need to be as an adult.”

The Braille AI Tutor app will incorporate AI-based speech recognition, using Microsoft’s Azure Speech API, to help students practice reading Braille with personalized, gamified learning plans. The app will send a word or a sentence to a refreshable Braille display, one of the types of hardware used for reading Braille. The student will feel the word in Braille, say the word or sentence out loud, and then the app will process the audio feedback and let the student know immediately if they are correct or not.

Teachers will be able to monitor students’ progress, with results sent to a web dashboard.

“We see our role as not teaching the student but giving the student the ability to practice when that teacher’s not around,” Schultz says. “The teacher teaches, and we make practicing fun and engaging and something that can be done without the teacher being there. So the next time the student meets with the teacher, the student has made some real progress.”

Schultz says the extra practice will help students “accelerate more quickly through school, which will lead to college, and to much better employment opportunities in the future.”

Two longtime friends who watched their loved ones go through vision loss found another way to help: using technology to help people get to work or otherwise navigate their cities.

Bin Liu and Arjun Mali are from different parts of the world, but their lives took parallel paths. Liu, born in China, moved at age 9 with his family to Gaborone, Botswana, for several years because of his father’s work as a civil engineer. Mali spent parts of his childhood in India and the United Arab Emirates, where his father worked for a while in sales of fiber optic networks.

About 10 years ago, Liu’s father was diagnosed with inoperable glaucoma. Mali’s grandmother in India had partial sight, and he sometimes accompanied her to a local school for the blind, where she volunteered, to read and teach English to the children.

The two were in university when they met in Toronto and became friends playing poker. They often talked about some of the frustrations and indignities faced by people who are blind or have low vision, as well as ways to improve mobility for those with vision impairment.

“Vision loss affected our families, and we saw an opportunity to create a technological solution that would impact that community,” says Mali, who graduated with an economics degree from McMaster University in Ontario.

Liu, who has a civil engineering degree from the University of Toronto, had been searching for devices that could help his dad navigate obstacles more precisely with his cane, and says he didn’t find much. Liu and Mali developed their first product together, the BuzzClip.

It’s a 2-ounce, clip-on wearable device that uses ultrasound to detect obstacles in a person’s path, then alerts the user with different vibrations and frequencies.

Vision loss affected our families, and we saw an opportunity to create a technological solution that would impact that community.

Early on, the duo received support from the Impact Centre, the University of Toronto’s accelerator for startup tech companies, and in 2014 they formed their company, iMerciv, Inc.

Now among AI for Accessibility’s latest grantees, iMerciv is developing a navigation app called MapinHood for pedestrians who are blind or have low vision, and who want to choose the routes they take if they’re walking to work, or to any destination.

The app will audibly alert a person to hazards — from construction to high-crime areas — to avoid while walking, as well as let them know about things they might need, like water fountains, benches or ramps. It’s all based on machine learning, crowdsourced data and open source information from local law enforcement.

Current navigation systems, in general, are optimized to generate routes that are the fastest or shortest for getting to a destination, but Liu says, “that’s not always the best route for pedestrians with disabilities” trying to find the best walking route to work, shops or parks, for example.

The app is in now in the alpha stages of being tested with help from the nonprofit Canadian National Institute for the Blind, which also worked with iMerciv on the BuzzClip. The app uses iMerciv’s custom routing engine, and with the AI for Accessibility grant, will use Azure machine learning, storage and virtual machines.

MapinHood in Toronto will also be a template for the app in other cities.

“Our focus is on personalization — making the app as flexible and as customizable as it can be,” Liu says. “Because with navigation for pedestrians in general — and especially for people with disabilities — you cannot have a single solution that fits all needs.”

For people with autism, sometimes the biggest hurdle to employment is the interview. That’s the focus of Nilanjan Sarkar. A family member – a cousin’s son – has autism, and in doing research later, Sarkar learned that people on the autism spectrum sometimes respond better when they deal with intelligent systems, such as chatbots, instead of people.

Sarkar, director of the Robotics and Autonomous Systems Lab at Vanderbilt University in Tennessee, is now leading a project aimed at helping people with autism perform well in job interviews using intelligent systems. Career Interview Readiness in Virtual Reality (CIRVR) is being developed in conjunction with Vanderbilt University’s Frist Center for Autism & Innovation, having joined the AI for Accessibility program earlier this year.

In the U.S., there are approximately 2.5 million adults on the autistism spectrum, Sarkar says. “Sixty percent or more of them can do some work. However, 85 percent of those able to work are either underemployed or unemployed.”

This system aims to help people be better prepared when they actually go out for an interview.

CIRVR is a virtual reality job interview platform that uses Azure AI and incorporates a computer avatar that acts as the interviewer, a wearable device that tracks interviewees’ physiological measures such as heart rate and skin sweating to infer their anxiety using machine learning techniques, and an eye tracker to gauge attention.

“This system will quantitively, objectively gather lots of data regarding their anxiety, where they’re looking, eye contact, how they’re responding, what should they have done — and we believe we can create a feedback system so that by repeated practice, they will improve their interviewing skills,” Sarkar says.

“People with autism sometimes like to interact with things that respond in a routine way, in a predictable way,” Sarkar says. “Human response, human interactions are not predictable, and that can be confusing.”

Many times, he says, open-ended interview questions such as “Can you tell me about an instance where you resolved a conflict?” or “How did you help a teammate?” might create anxiety. So can tests with urgency, such as being asked to solve a programming problem quickly.

Sarkar says CIRVR testing has begun and will provide feedback to the interviewees so they can practice improving how they handle interviews. Overall results will also be evaluated for trends to possibly share with hiring managers at interested companies, so they can learn how to modify their interview structure, or how to ask questions differently, if needed, Sarkar says.

“We assume the interview protocol structure will not change overnight,” he says. “So, this system aims to help people be better prepared when they actually go out for an interview.”

All AI for Accessibility grantees “have so much passion and expertise in the area of accessible technology,” says Bellard of Microsoft.

“The amount of potential that there is for software or hardware to better meet the needs of people with disabilities, and to raise the bar of what customers can come to expect of the role technology could play in their lives, is just an amazing opportunity.”

Learn more about AI for Accessibility grants, and about Microsoft’s Autism Hiring Program.

Lead image: Vision rehabilitation therapist Ashley Colburn shows 11-year-old Steven DeAngelis refreshable Braille devices at the Carroll Center for the Blind. The Newton, Massachusetts, center helped ObjectiveEd test the games it developed for people who are blind. (Photo by Dan DeLong)"
Microsoft_News,https://news.microsoft.com/source/features/ai/ada-artist-in-residence/,,Smiles beam and walls blush: Architecture meets AI at Microsoft,"Redmond, Washington and Ithaca, New York – Jenny Sabin is perched high on a scissor lift, her head poking through an opening of the porous fabric structure that she’s struggling to stretch onto the exoskeleton of her installation piece, which is suspended in the airy atrium of building 99 on Microsoft’s Redmond, Washington, campus.

Momentarily defeated, she pauses and looks up.

“It’s going to be gorgeous,” she says.

“It” is a glowing, translucent and ethereal pavilion that Sabin and her Microsoft collaborators describe as both a research tool and a glimpse into a future in which architecture and artificial intelligence merge.

“To my knowledge, this installation is the first architectural structure to be driven by artificial intelligence in real time,” said Sabin, principal designer at Jenny Sabin Studio in Ithaca, New York, who designed and built the pavilion as part of Microsoft’s Artist in Residence program.

The two-story structure, made of 3D printed nodes, fiberglass rods and fabric digitally knit with photoluminescent yarn, uses AI to translate anonymized data about facial expressions, noise, voice tones and language into a choreographed dance of color and light.

By using art and architecture to visualize information collected by microphones and cameras placed at different locations in the building, Microsoft designers and researchers hope to stimulate thinking about AI in our lives through interactive architecture.

“Artistry, creativity and humanity play an important role in technical innovation,” said Eric Horvitz, director of Microsoft’s research organization and chair of the company’s Aether Committee, which focuses on the responsible development and deployment of AI technologies, including issues around sensitive uses of AI, biases and fairness of AI systems, and human-AI interaction and collaboration.

The Artist in Residence program, he explained, was set up to invite artists to explore ideas at the intersection of art and computer science with Microsoft’s researchers and engineers and, more generally, “to stimulate joyful creation and out-of-the-box thinking across our organization.”

“Jenny’s creation,” he added, “is an embodiment of possibilities, expectations and anxieties about the rising influences of machine learning and pattern recognition technologies that are permeating the world in interesting, beautiful – and at the same time potentially invasive and concerning – ways.”"
Microsoft_News,https://news.microsoft.com/source/features/sustainability/feed-the-world-how-the-usda-is-using-data-and-ai-to-address-a-critical-need/,,Feed the world: How the USDA is using data and AI to address a critical need,"Farmers around the world are facing the urgent question of how to sustainably feed a global population expected to reach 9.7 billion by 2050 — and the answer, in part, might be found nestled among the cornstalks and soybeans on a farm a short distance from Washington, D.C.

The fields are outfitted with a network of high-tech sensors that could revolutionize how food is grown across the globe by putting data in the hands of farmers and scientists in ways unimaginable a few years ago.

The sensors are part of a groundbreaking new partnership between Microsoft and the U.S. Department of Agriculture (USDA). The 7,000-acre farm at the USDA’s Beltsville Agricultural Research Center in Maryland is using FarmBeats, a project that aims to harness data and artificial intelligence to help farmers cut costs, increase yields and sustainably grow crops that are more resilient to climate change.

“We can’t simply double our acreage to produce this food,” says Dan Roberts, research leader at the Sustainable Agricultural Systems Research Laboratory, located at the Beltsville center. “There’s a lot of competition for arable land with urbanization. What we need to do is develop more environmentally benign crop production systems — the new green revolution, if you will.”

FarmBeats collects data from multiple sources, such as sensors, drones, satellites and tractors and feeds it into cloud-based artificial intelligence models that provide a detailed picture of conditions on the farm. Since most farms have little or no internet access, FarmBeats transmits data via TV white spaces, the unused broadcasting frequencies between television channels, to an edge device at the farm and onto the Microsoft cloud.

The USDA pilot is testing out FarmBeats technology on two crop systems experiments at the Beltsville farm. If all goes as planned, the functionality will be rolled out to 200-plus farms in a nationwide research network, from mom-and-pop operations to large commercial farms. The farmers will be able to see the data generated by FarmBeats in real time; the USDA researchers will use that data to inform their own work and provide web-based tools and site-specific insights to farmers to help them better allocate resources and refine their methods.

The pilot is focused on cover crops, grown during the off-season to limit weeds, manage pests, prevent erosion and improve soil for the main crops. At the Beltsville farm, sensors are measuring soil temperature, humidity and acidity. The sensors also track water levels in the soil, which help determine how much water is retained after increasingly common heavy rainfalls and in turn, inform water budgets for a growing season. A weather station tracks air temperature, precipitation and wind speed, and a tractor with an array of sensors will assess crop heights, biomass and greenness — an indicator of plant health.

The project is using geographic information system mapping software from California-based company Esri. Microsoft and Esri joined forces to provide the USDA with a platform designed to feed the world’s growing population in an environmentally sustainable way, Esri President Jack Dangermond says.

“As a result, farmers will have a quicker and more innovative way to implement practices that directly benefit the climate, and the partnership will also provide an avenue for them to cost-effectively bring new agriculture products to market based on good science,” he says.

Almost 90 miles east of Beltsville, Trey Hill squints against the afternoon sun as he looks out at the land his family has been farming for more than a century. Harborview Farms is headquartered in Rock Hall, Maryland, a charming seaside village on the eastern shore of the Chesapeake Bay, and encompasses 13,000 acres and more than 80 farms over three counties.

The farm mainly grows corn, soybeans and winter wheat, and solar panels power everything but the farm’s grain storage and drying containers. Hill and his father began using cover crops on the farm about 20 years ago to help improve the ecology of the bay and promote biodiversity. Now they plant cover crops over 100% of their fields.

Harborview is part of the Beltsville pilot and has several sensors that are measuring temperature, water and nitrate leaching in the soil. Hill gets satellite images every day that help him see how his crops are doing. Holding up his phone, he points to an image displaying yellow lines that show where one of his crops is suffering.

But the images don’t tell him why, or what’s happening in the soil. Hill thinks his cover crops are helping keep the soil cooler, an important benefit as summers get hotter and drier, but he needs data to verify that claim. And with large rainfalls becoming more frequent, he needs to know if areas with cover crops retain more water, allowing him to use less fertilizer, and whether a particular combination of cover crops increases retention.

“As we’ve been doing cover crops, we’ve seen a lot of different things change in the soil as the soil health grows. The problem is, we’re not able to quantify any of that,” Hill says. “A lot of it’s just things that we see, but we don’t have the science behind it and we don’t have the numbers behind it.”

That’s where FarmBeats comes in. Steven Mirsky, a research ecologist in the Beltsville Sustainable Agricultural Systems Laboratory, will be collecting data from Hill’s crops and helping him analyze it to allocate resources and make crop-management decisions. The farm is currently using three different programs to store and manage data, and Hill hopes to merge the information into a single, user-friendly, cloud-based dataset that is easier to manage.

“We’re getting a ton of data, and we are struggling to figure out how to utilize it all. We’ve got soil data; we’ve got electroconductivity data; we’ve got planting data; we’ve got data from the satellite imagery that we get every day. We’ve got data from the combines that’s giving us yield and moisture of the field as we harvest it,” Hill says. “Somehow, we need to get it consolidated into a common language. Right now, it’s very fragmented for me as a farmer.”

Combining sensor data with imagery from drones and satellites will help the USDA researchers better understand how soil conditions, weather and management intersect to drive crop performance and long-term conservation of water and soil. Armed with that detailed information, they can analyze conditions and pinpoint decision-making down to sections of a field.

“There’s so much spatial variability in a field, from soil, topography and climate perspectives, that we need the data that help us provide site-specific solutions,” says Mirsky, who is spearheading the USDA pilot.

“The only way we can do that is by collecting data across broad climate, soil and management regimes,” he says. “That requires extensive amounts of data, AI and machine learning applications so we can put that all together and make site-specific solutions for farmers.”

Click here to load media

Just a decade ago, collecting that data typically meant sending scientists into the field to write information in a notebook. Then the data would be entered into spreadsheets back at the lab and disseminated, a process that was time-consuming, prone to error and arguably not the best use of highly trained scientists’ abilities.

The USDA previously developed its own systems for collecting and analyzing data, Mirsky says, but FarmBeats eliminates that need by providing a standardized platform that allows researchers to fuse data and build machine learning models across datasets. While wireless technologies have made it easier to collect data, they have led to a different issue that FarmBeats also addresses.

“As a research scientist with lots of different hardware and sensing technology at my fingertips, the challenge these days in agriculture is not getting data,” Mirsky says. “It used to be, ‘How do you get data?’ Now it’s all about, ‘What do you do with all of this data?’ FarmBeats is providing us with a mechanism for data aggregation, visualization and analytics in the cloud.”

With more than 90 research stations and some 2,000 researchers and scientists around the country, the USDA has struggled with what Michael Buser, the department’s national program leader for engineering, calls “siloes within siloes” — large amounts of data that sit on employees’ hard drives and in filing cabinets that are not accessible to other USDA staff.

“The way we’re structured, we’re not capturing all the value from the data. It’s a huge loss for the agency,” Buser says.

Migrating that data into a centralized, secure Microsoft Azure repository will allow the USDA to capture historical and future data that can be helpful to researchers, Buser says. He also sees potential for FarmBeats to be used for continuous monitoring operations at USDA weather stations, animal research sites and other locations to reduce staff time and cut costs.

“We see FarmBeats as providing us the opportunity to bring that information back into the cloud more quickly and with less human interaction, less data touches,” Buser says.

“When we think about big data, we have challenges beyond just how do we get all this information into a system. We also have the economic piece. When you think about having 90-plus research locations, 2,000 scientists and post-docs and how much that costs, that’s a consideration. I think FarmBeats could be that economic piece that we’re looking for.”

FarmBeats’ use of TV white spaces is key. The technology will allow the USDA to involve more farms in its research network and provide the bandwidth needed to transmit images. For example, if a crop is stressed, an image showing the plants can be sent to the farmer’s computer or cell phone to help with assessing the situation.

“That speaks volumes, and we just couldn’t do that previously,” says Chris Reberg-Horton, a crop and soil sciences professor at NC State University who launched the farm research network with Mirsky four years ago.

“The reality is that farmers don’t see any of their fields very often. An average row crop farm in America is around 5,000 acres, but a lot are north of 10,000 acres, and those fields can be spread out over multiple counties,” Reberg-Horton says.

“As farm sizes have increased, the need for some type of monitoring system for all those fields has increased.”"
Microsoft_News,https://news.microsoft.com/source/features/innovation/how-ai-and-teams-are-benefitting-the-littlest-of-patients/,,How AI and Teams are benefitting the littlest of patients,"Last December in Germany, beautiful twins Amelia and Bianca were born. The two share the same lively eyes and sweet smiles. But, unlike her sister, Bianca’s health is perilous. She was born with heart problems, is missing ribs and vertebrae and has only one kidney. She cannot breathe without the help of special medical equipment.

The place Bianca calls home for now, Kinderhaus AtemReich in Munich, is the only one of its kind in the country. More typically, hospitals’ intensive care units (ICUs) are long-term destinations for children with critical breathing issues. At the nonprofit Kinderhaus AtemReich, based in a setting that looks more like a real home than a medical facility, 127 staffers care for 18 children who receive full-time medical attention, affection, have play time, and when appropriate, sit outside in the garden to get fresh air.

Bianca’s mother, Tamara Schaper, says when doctors recommended that at age 6 months, Bianca be moved from an ICU to Kinderhaus AtemReich, she was both “skeptical” and “afraid” she “couldn’t see Bianca and that she could never go home again.”

Now, she is “glad” Bianca is there and sees her two to three times a week, more if she can, making the four-hour round trip from where she lives.

“The AtemReich staff are doing a great job.” They attend to Bianca’s medical issues, but they see her first as a person, not a patient, Schaper says. “They give the kids the feeling that they are normal children.”

That is the gift and the goal of Kinderhaus AtemReich, which translated loosely into English means “Children’s house full of breath.” In time, some of the children may go home; others are terminally ill. All of them require ventilators to breathe. Most cannot speak.

The most important thing for us is that the children today, here and now, have a good day with as much quality of life as possible.

Felicitas Hanne, Kinderhaus AtemReich director since it opened in 2006, is often lauded for her can-do attitude, big heart and passion about the facility’s mission – “The most important thing for us is that the children today, here and now, have a good day with as much quality of life as possible.”

But, as both the facility’s main administrator and director, Hanne is constantly faced with a non-stop avalanche of forms, paperwork and staffing issues.

In the past, communication among the staff was mainly done using paper and email. Caregivers were using handwritten notes for daily updates on the children. To keep track of each child’s medical information and other records, Hanne was using Microsoft Access, an older database program only she and one other administrator had the authority to use.

Recruiting and retaining employees was another challenge – nonprofit organizations like Kinderhaus AtemReich have difficulty competing with hospitals when it comes to pay and benefits. And because the staff is on a 24/7 cycle, if one person was out sick, and another stepped in, some duties could get missed like the wrong medications being requested.

Although there was a lot of love and compassion in this house, there was not enough order.

So last summer, when Hanne attended Microsoft Germany’s #Hackfest2018 in Munich, a two-day Microsoft employee hackathon to help customers, partners and nonprofit organizations, she wasn’t sure what to expect.

At that time, “It was my great hope that Microsoft would help me to expand and improve my work with Microsoft Access database,” she says.

But as Hanne spoke to the Microsoft employees about Kinderhaus AtemReich, “We listened really carefully to what she was saying about the children, and I think half of our colleagues had tears in their eyes,” says Volker Strasser, a Microsoft digital adviser who normally works with large companies. Moved by the children’s challenges and those faced by Kinderhaus AtemReich, he became the project lead for the effort.

Andre Kiehne, executive sponsor of the project and a member of the Microsoft Germany leadership team, also remembers talking to Hanne that first time. It was an “emotional moment,” he says. His twin daughters were born 13 years ago in the same children’s hospital where the idea for Kinderhaus AtemReich was raised, and around the same time. His girls were premature babies and faced some medical problems in their first weeks – “they are completely healthy now,” he says – but the worry he faced remains a fresh memory.

The night the hackfest ended, Strasser remembers being unable to sleep “as thoughts circled my mind as to how we’d help Kinderhaus succeed, how we could bring these ideas to life, and how we’d scale those ideas more broadly” for other potential and much-needed Kinderhaus AtemReichs in his country.

At 3 a.m., he got out of bed and started drafting a plan that would ultimately include bringing machine learning, artificial intelligence (AI), Microsoft Teams and a modern recruiting strategy to Kinderhaus AtemReich.

For the next year, the team met for a project call every Monday at 8 a.m. – “We put that meeting on Monday at that time because we wanted to start the week with the most important thing, Kinderhaus AtemReich,” Strasser says.

Hanne had no idea she would wind up with a dedicated army of 50 Microsoft volunteers and partners who, over the past year, have not only provided Kinderhaus AtemReich with a digital transformation, but who also spend their own time at the facility, about 5 miles from Microsoft’s Munich office, doing everything from helping clean out the cellar to tending the garden.

The technology solutions being put into place fit “the needs of AtemReich to get closer to the goal of more staff time with the children,” and less on paperwork, says Hanne. “That is what touches me most of all. This incredible combination of Microsoft and partner team members’ empathy, passion, know-how and time for our children can hardly be put into words because it is so great.”

Among the changes that have come to Kinderhaus AtemReich: shifting from a laborious, often manual, medical record-keeping system that only kept track of a child’s vital signs to a system that compiles information – such as heart rate, oxygen, breathing rhythm, blood pressure – from the children’s medical devices and uses machine learning, AI, IoT and Azure tools to produce data and analysis to see if there are safety or medically related problems or trends that should be addressed.

“Before, we just copied the data from the monitors onto paper. But we were not able to evaluate or compare the incredible amounts of data provided by our devices,” Hanne says. “Now we can evaluate and analyze data. This allows us to discover patterns in children and makes it possible to react faster than we could before.”

That proved to be crucial for Maxi, a 13-year-old who has lived at Kinderhaus AtemReich since he was a baby. Maxi, who is on a ventilator, also cannot see or hear. “He is totally restricted in his communication and interaction,” Hanne said.

Maxi was becoming increasingly agitated, physically hurting himself, and sometimes disconnecting himself from his ventilator out of frustration, a threat to his safety. It was “terrible,” Hanne said. “We could hardly hold him; we could not reach him anymore.”

Trying to figure out what was wrong was frustrating. But once the data from Maxi’s medical devices were collected and analyzed, his doctors discovered he was receiving slightly too much of one of his medications and reduced the dosage.

“Since then, Maxi has not had any more aggressive phases,” Hanne says. “The fact that it is suddenly possible to recognize things and patterns through the evaluation of data and thus achieve a positive change for a child is unbelievable.”

Now we can evaluate and analyze data. This allows us to discover patterns in children and makes it possible to react faster than we could before.

Kinderhaus AtemReich is also incorporating Microsoft Teams into its daily rhythms. The chat-based workspace is alleviating a lot of stress and miscommunication, as well as missed communication among the staff, and can be accessed anytime and anywhere because it’s also available via mobile. Soon, there will also be individual Teams channels created for every child, so the staff can communicate with those outside the facility – parents, doctors, physical therapists and others – who are crucial to each child’s care.

“It is a single go-to point for everyone,” says Strasser. “If I’m a caretaker, and I want to know something about a child, I go to Teams and say, ‘If I’m going from morning shift to evening shift, do I have to shift something?’ Or, ‘This information is important for today.’ And the doctors and therapists can put their documentation in Teams, all the special documents for the kids. It’s all in one place, it’s all up to date.”

Hanne says her daily “email flood” has been significantly reduced because of Teams, and the interaction between staff is friendlier and more fun thanks to smiley face emojis and GIFs. It also gives Hanne more time to do her job, which includes visiting with the children, something that is vitally important to her.

“When I go to the children and one of them sees me and comes running toward me, this makes me happy,” she says. “To experience the children, whose life expectancy was originally not even their first birthday, enjoy the sun and make trips, is a wonderful feeling of happiness for me. That I succeed in giving these very special children quality of life, joy and a positive everyday life – I can’t imagine anything more beautiful.”

Kinderhaus AtemReich also received a marketing makeover to help draw in more prospective employees, including recruiting videos on social media focused on the children and the staff. The effort has filled almost half of the facility’s 20 vacancies, says Strasser.

It doesn’t matter if you see tubes or medical devices at first. Every child can be a happy child.

Xbox games, especially created for the children at Kinderhaus AtemReich, are also in the works now, something some of the children will be able to play using the Xbox Adaptive Controller.

Because most games are mentally and physically too challenging for the children, the Microsoft Xbox team in Munich met with Kinderhaus AtemReich staff to figure out what the children could and couldn’t do, and plan to develop games to help with cognitive abilities, and a set-up with the Xbox Adaptive Controller adapted to the specific needs of the children.

Meanwhile, Tamara Schaper hopes to be able to bring Bianca home at some point. At Kinderhaus AtemReich, she recently introduced Bianca and Amelia to each other for the first time since birth.

“Both children looked at each other, cried and were very happy. You can’t describe it, but it was a very touching, emotional experience. Amelia and Bianca held hands, smiled. It was a wonderful day for both of them and also for me.”

When Bianca was born, “I was very desperate and didn’t know how to deal with my daughter’s illness,” Schaper says. “The AtemReich helped me see what a happy little girl I have – despite her illness. It doesn’t matter if you see tubes or medical devices at first. Every child can be a happy child.”

Lead image: Jason plays as nurse Sabrina Leick looks on at Kinderhaus AtemReich. Photo courtesy of Kinderhaus AtemReich."
Microsoft_News,https://news.microsoft.com/source/features/digital-transformation/technicolor-and-microsoft-team-up-to-produce-a-bright-future-for-content-creators/,,Technicolor and Microsoft team up to produce a bright future for content creators,"As the media and entertainment industry continues to transition to the cloud, Technicolor and Microsoft have joined forces to empower creatives in new ways. In a post on the Technicolor Press and News Center, Bob Eicholz, chief technical officer of Technicolor Production Services, and Bob De Haven, general manager of communications and media for Microsoft, share their views on this industry shift and the potential for their companies to transform the industry together.

“Until today, the technology hasn’t been good enough for us to be able to do our work in the cloud. So, instead we have had to build big, expensive buildings housing costly infrastructure,” says Eicholz. “As we move into the future, our facilities will not go anywhere, but will become more interesting places. The changes will give us more freedom to make our facilities into interesting architectural spaces and community spaces. But we will also … be able to work on content from anywhere, anytime.”

Adds De Haven, “Having these two brands come together, in particular – Technicolor, with its legacy of over a century of leadership in the movie industry, with Azure, with its level of safety and investment – brings a level of credibility to this area of the market that the industry has not seen before. Both companies are truly platform companies – what we offer is a way to allow great content creators to use their intelligence and skill to do their thing without competing with them or getting in their way.”

Visit the Technicolor Press and News Center to read the full interview with Eicholz and De Haven."
Microsoft_News,https://news.microsoft.com/source/features/innovation/a-way-to-bring-peace-of-mind-and-sleep-to-parents-whose-children-suffer-seizures-wins-microsoft-hackathon/,,A way to bring peace of mind — and sleep — to parents whose children suffer seizures wins Microsoft Hackathon,"For most parents, sleep is a sacrifice they accept during the earliest part of their child’s life. But for Francesca Fedeli and Roberto D’Angelo, sleep deprivation has been a constant for five years as they’ve taken turns in overnight co-sleeping vigils for their 8-year-old son, Mario, who has suffered potentially life-threatening seizures since he was 3.

Just recently, they’ve finally been able to sleep through the night.

“For about a month, we’ve regained that peace of mind that we had lost,” says Fedeli.

The much-needed breakthrough came from what D’Angelo, a 21-year Microsoft employee, and colleagues around the world worked to finish building in July at the company’s annual Global Hackathon, produced by The Garage. Their project, MirrorHR – Epilepsy Research Kit for Kids, was just named this year’s grand prize winner for the event.

Mario’s parents are using the new system — a mobile app connected to a wearable device that sends alerts when anomalous activity might indicate a seizure — so they no longer have to hover over their son. It helps allay the biggest fear that a seizure could lead to what is called SUDEP, or sudden unexpected death in epilepsy.

“I see an amazing opportunity to make real what we’re trying to achieve,” says D’Angelo, who’s currently a director of program management on the Commercial Software Engineering team, based in Milan. “We have the ambition to make it real, to impact parents like me and kids like my son. This is the beginning of the journey.”

The 29-person hackathon team spanned the globe, with participants at Microsoft headquarters in Redmond, Washington, as well as in Washington, D.C., Canada, India and Italy, and was structured like a startup – with a mission. Members had expertise in many different areas including research and development, business, design and marketing, and they often worked in 24-hour cycles because of the various time zones.

The team worked together over about three months to develop the end-to-end, scalable proof of concept that is currently being tested by Mario.

If a seizure is about to happen, parents can catch it at the onset and take immediate actions, such as preventing falls or other trauma and making sure the child doesn’t swallow vomit. It means there’s less likelihood the parents will have to rush to the emergency room or miss the seizure entirely. The biometric data and daily videologs are stored in a Microsoft Azure-powered FHIR Server. Machine learning and data visualization techniques are applied to this information to offer parents and doctors easy-to-read visuals and insights using Power BI tools.

“I believe that there’s so much potential to use tech for positive social impact, as long as we can truly engage with the people whose lives we want to improve,” says Pritika Mehra, the Redmond-based lead for the hackathon team, who just celebrated her one-year anniversary with Microsoft. “I’ve never seen so many different skills, personalities and nationalities come together so beautifully to create something.”

Mehra, a software engineer working on operating system biometric security in her daily job, says the project really showed her “the breadth of diversity and expertise that exist in this company.”

“What I value about this team so much is that I don’t feel like it’s just technologists solving a problem. So much of our team has lived this problem, through having autism, being stroke survivors or other personal connections,” she says. “The high level of empathy and learning, and the perspective that’s come from that, has really shifted the way that we think.”

Everyone on the team appreciated what others brought to the table — and the potential for their solution to help others.

“If we think about ways to help and include people with disabilities in our society, this is not just the right thing to do to bring everyone along, we can also get insights that are going to help everyone,” says Ricardo Wagner, Microsoft’s accessibility lead for Canada based in Toronto, who worked to share the team’s story.

Epilepsy is one of the most common neurological diseases. It’s marked by susceptibility to repeated, unprovoked seizures and affects more than 50 million people around the world, especially children. Many children with cerebral palsy have epilepsy.

“We are dealing with something huge, something that can really change lives,” Wagner says.

Mario’s diagnosis of cerebral palsy was established 10 days after he was born. His parents found out he’d suffered a perinatal stroke, which severely injured the right half of his brain, making him unable to control the left side of his body. But because they found out so early, D’Angelo says, they were able to begin rehabilitation immediately, engaging Mario in stimulating games and other therapies to help him regain his motor skills.

In their research early on, D’Angelo and Fedeli were hampered by a lack of information on childhood strokes like the one their son suffered. But since then, they’ve been continuously learning from other families going through what they were experiencing, as well as from medical professionals.

They founded FightTheStroke back in 2014. Both were driven by the conviction that in order to help their son, they had to “help every kid in the world like him.” The foundation is working toward a new ecosystem that includes independent living for kids who have cerebral palsy, a group of disorders that affect muscle coordination and balance, usually caused by damage to the brain before or at birth.

Over the years FightTheStroke has helped establish a pediatric Neonatal Stroke Center at the Children’s Hospital Gaslini in Genoa, Italy; created rehabilitation camps for kids; and promoted scientific dissemination and platforms to spread awareness.

As Mario got older, his epilepsy became harder to control. Fedeli and D’Angelo tried solutions claiming to detect seizures, but none worked for him. It took a toll on the family.

“Mario looked to his parents as mirrors. So when Francesca and Roberto realized they were reflecting their sadness to Mario, they wanted him to see the best from them instead,” Wagner says. That idea led to the name MirrorHR for this project, and also an earlier project called Mirrorable, which focused on an interactive platform geared to rehabilitative therapy at home.

“We were so uncertain of Mario’s future. When he was 3 and he had the first seizure, we went to the ER, his life was at risk. From that point we began to know the burden of epilepsy,” says Fedeli, who had suffered earlier miscarriages and had to spend months bed-bound before giving birth to Mario. “Apart from the risk, it’s the fear and fact that you lose your peace of mind. You can’t sleep anymore because you’re always checking if your son is breathing.”

Fedeli and D’Angelo took turns monitoring their child all night long. They’ve gone to the emergency room 24 times in the past five years.

“A couple of years of no sleep, I can guarantee is no good,” D’Angelo says. “But we can reframe this. We know this problem so well, we can do something. It’s worth trying. The probability of failure is probably 99%. But the 1% chance is worth my life.”

So the reframing focused on a solution that would allow parents to get some sleep and wake them up when a potential seizure was detected. By identifying tell-tale patterns and triggers, the team has helped parents contain seizures and avoid traumatic rushes to the hospital.

For Mario, routines matter. Going to sleep at the same time each night and reducing stress also help reduce the potential for seizures.

“We practice continuous mirroring in our family. Once we feel safe, secure and confident, Mario can keep trying,” Fedeli says. “Our son has regained confidence and is enjoying every day of his life.”

The family won’t be alone as they face future obstacles — and they’re grateful for the jumpstart they have on this problem.

“We couldn’t have had enough resources to do this in such a short time,” Fedeli says. “The fact that we can count on the right professionals has been crucial in these developments.”

The team wants to use machine learning as they get more data, so they can generate more intelligent insights to help parents and doctors better nail down what may be triggering these seizures. Then, they could adapt accordingly, by calming down patients, improving the environment or staying close when there are indicators for a seizure.

“I truly loved working on this project,” Mehra says. “I’ve learned so much about how you can bring people and skills together through a central mission to create something against all obstacles. All this is very much possible because Microsoft is supportive about giving employees resources to work on projects like these. More than that, they have incredible channels to help to find these people, and foster, support and encourage you.”

Wagner, who’s been with the company 12 years longer than Mehra, couldn’t agree more.

“My personal mission in life is to help people with disabilities. That’s the reason I work for Microsoft, to empower every person on the planet,” he says. “It’s a privilege to work on this. This one was very special. Everyone was committed to make it happen.”

Like other kids his age, Mario is back in school. While he still faces many challenges, he’s been able to enjoy the benefits of rehabilitation and neuroplasticity.

“As a couple they have a limited time on the planet,” Wagner says of D’Angelo and Fedeli. “Every day is an opportunity to empower Mario.”

“My son is my coach. He’s helping us every single day to look at things through his eyes,” D’Angelo says. “Disability can be a strength. Now I have the proof, it’s true. What we have is a gift and what we miss is just an opportunity for improvement. We maximize the strength of each person, mix it and balance each other in order to be stronger together.”

Lead image: Francesca Fedeli, Roberto D’Angelo and their son Mario (Photo by Andrea Ruggeri)"
Microsoft_News,https://news.microsoft.com/source/features/digital-transformation/from-farm-to-cloud-to-table-butcherbox-serves-up-a-new-approach-to-meat-delivery/,,"From farm to cloud to table, ButcherBox serves up a new approach to meat delivery","The path to a future of mining cloud-based data started in a decidedly low-tech way for Boston company ButcherBox after its founder, Mike Salguero, found himself in a Massachusetts parking lot buying garbage bags of beef from a local farmer.

Salguero’s wife, Karlene, has a thyroid condition, and the couple wanted to switch to an anti-inflammatory diet including lean, grass-fed meat. But they found little beyond ground beef and the occasional grass-fed steak at their local grocery stores — hence the parking-lot purchase. That was too much meat for the couple to eat, so Salguero gave some to a friend, who remarked how convenient it would be to have high-quality meat delivered at home.

“That was the initial spark of the idea for ButcherBox,” Salguero says.

The company launched in 2015, delivering boxes of frozen grass-fed beef, free-range organic chicken and heritage breed pork to subscribers, or “members,” around the United States. ButcherBox sells only meats raised without antibiotics or added hormones, ships them in 100 percent curbside-recyclable boxes made of 95 percent recycled materials, and prides itself on partnering with vendors that use sustainable, humane approaches and fair labor practices.

The company offers 21 cuts of meat and subscription boxes ranging from $129 to $270 monthly, depending how many pounds of meat are included.

ButcherBox tapped into a trio of hot retail trends: a demand for sustainable products, consumers’ interest in knowing more about what they’re buying, and an explosion in subscription box companies selling everything from dog toys to fitness gear, even house plants and hygge kits.

ButcherBox doesn’t release sales figures, but Salguero says the company has grown exponentially since its launch, even without seeking venture capital. Collecting and analyzing data became increasingly important as ButcherBox expanded, but the limited data the company had was mainly in Excel spreadsheets and didn’t provide the depth of information employees needed.

Customer service agents, for example, didn’t have access to warehouse data and couldn’t check to see if a member’s box had been filled or where it was. Teams in various departments were pulling data together in ad hoc ways, leading to inconsistent and imprecise insights.

“Depending on which department it was and where they got the data, everyone had their own truths about what was going on in the business,” says Kevin Hall, ButcherBox’s head of technology. “People began to realize there was a need for a single source of truth.”

Salguero puts it another way: “People became entrepreneurial and enterprising in finding ways to answer questions, but as an organization that’s pretty risky, because we don’t even know if it’s right.”

So the company turned to Microsoft, adopting Azure as its cloud platform about a year ago. It developed a “demand plan” that uses members’ purchasing data to determine how much meat must be ordered and replenished in fulfillment centers. It enabled its approximately 70 employees to create and read dashboards using Microsoft’s Power BI data visualization tool. It interviewed more than 100 ButcherBox subscribers, then used Azure’s Databricks service to analyze their feedback and organize it into easily understandable reports in Power BI.

The interviews revealed a key insight — that the number one reason people were canceling their subscriptions wasn’t lack of freezer space, as previously thought, but value. Based on that finding, the company implemented an “add-on” program offering members perks (free bacon!) and specials on certain products, often undercutting grocery store prices on those promotional items.

More robust data also enabled the company to better determine how much dry ice is needed for each shipped box based on geographic location — a crucial calculation, since too much ice can cause leaks and too little can mean a thawed shipment.

“If someone doesn’t get his or her box or it shows up late, it’s ruined,” Salguero says. “So really understanding our data — what’s shipping, where the boxes are — became the rallying cry of the company in a big way to understand our members and build out our data infrastructure.”

But even the most sophisticated data can’t necessarily provide the type of information gleaned from talking with people face-to-face. Last year, Salguero embarked on what employees jokingly refer to as his “freezer road show,” visiting members’ homes, asking them about their cooking and eating habits and yes, peering into their freezers.

The exercise provided useful insights about the degree to which members rely on ButcherBox meats to feed their families, Salguero says, and showed that subscribers who most often use the food in their freezers tend to plan out their meals. That finding could help with tackling one of the biggest challenges facing a company that sells frozen meat — which is, ironically, to get members to stop using their freezers so much.

“A lot of people think of a freezer as a savings account,” Salguero says. “It’s there for a rainy day, not necessarily the place you go if you want to eat dinner tonight.”

The company is exploring how technology might be used to get more information about what customers are eating, whether through a meal-planning app or other tool, with the goal of prompting them to move food out of the deep freeze and onto the dinner table.

“All of that is a data problem at its core,” Salguero says. “We should know what members are eating and in what order. If we do our job well, we’ll know that member A is eating through X and they have a pork shoulder left over, so if we’re going to send a recipe, we should be sending one for pork shoulder.”

ButcherBox is now focusing on using data science and analytics to provide more personalized service, starting with identifying “clusters” of members who have similar likes and buying habits to determine which products and services to market to them.

“It doesn’t make sense to show someone beef if they’re really a chicken or salmon member,” Hall says. “We’re really looking to understand the data so we can serve members in a much more personalized way.”

Since data showed that members who buy certain types of boxes are more likely to leave, the company began proactively suggesting different options to those members and introduced new subscription plans with varying delivery schedules.

“We’re giving people more flexibility to switch to a plan that comes less often,” says Reba Hatcher, ButcherBox’s chief of staff. “Giving people those options has been really helpful.”

The company’s approach suits Ismael Santos, who lives in Youngsville, a small city in south-central Louisiana. Santos tried various approaches to get high-quality, sustainably raised meat free of antibiotics and added hormones — driving to a grocery store more than 50 miles away, buying at local farmers markets, splitting a quarter- or half-cow with friends. None of the options was ideal, so Santos signed up for ButcherBox almost a year ago.

“It’s hard to get that quality at a good price, and conveniently and reliably here,” he says. “You can go out and buy beef, but you’re either going to pay a ton or you’re not going to get what you’re looking for sometimes. The cost (of ButcherBox) is good compared with going to a store and buying the same quality and quantity.”

Santos also tried several meal-kit subscription services but didn’t consider them a good value and didn’t like being restricted to cooking a particular meal. With ButcherBox, he gets the main part of his meal and builds around it, picking up other ingredients at his local market as needed and sometimes adding items to his box, like ribs or breakfast sausage.

“I like that you can change it up,” he says.

ButcherBox is still in the early stages of using Azure, but Salguero says the move has already radically changed how employees think and operate.

“It’s pretty amazing to see the cultural change because of what we’re doing with Microsoft,” he says. “It’s a totally different conversation. People used to sit around a table and say, ‘I don’t really know what’s happening.’ Now it’s like, ‘Did you pull the data for that?’ or, ‘Let’s look at this dashboard and make a decision based on what we see.’

“The culture has really moved to a reliance on the data that we have,” Salguero says. “People trust the data, and it’s only getting better and better.”

Top photo: ButcherBox CEO and founder Mike Salguero. (All photos courtesy of ButcherBox)"
Microsoft_News,https://news.microsoft.com/source/features/digital-transformation/the-internet-of-things-is-going-mainstream-microsoft-survey-finds/,,"The Internet of Things is going mainstream, Microsoft survey finds","Over 80% of large companies around the world are adopting IoT solutions, stoking an “invisible revolution” that will reach 94% of enterprises in two years, according to a new Microsoft survey, IoT Signals.

But that widening commercial embrace of the Internet of Things is occurring even as 97% of business and tech leaders acknowledge they have security concerns about their IoT implementations, Microsoft’s research found.

“IoT is often a gateway for businesses going through digital transformation – it’s not the end but rather just the beginning,” says Sam George, director of Azure IoT at Microsoft. “IoT is becoming mainstream.”

The survey spanned nearly 2,500 business and IT decision makers – as well as 737 developers – working at companies of 1,000 employees or larger in the U.S., Germany, Japan, China, France and U.K.

Consumers increasingly rely on IoT-enabled products to simplify their lives and smarten their homes, from lighting and temperature to security, cooking and cleaning.

Similarly, as more businesses connect their machines and equipment to the cloud, they are creating new data sources that drive astute, real-time decisions. And IoT is helping many of those same companies evolve as they add solutions built with artificial intelligence, edge computing and, soon, 5G, George says.

“IoT is having a profound impact on things that I think of as invisible IoT – things like elevators becoming more reliable, water pumps that never break down, agriculture that uses 30 to 50 percent less energy and water,” George says.

“Manufacturing also is becoming orders of magnitude more efficient and profitable while using less energy in the process, again due to IoT. There are just thousands of examples – all invisible to consumers day to day – that are having GDP-impacting results across the world,” he says.

The survey also showed:

Companies that deployed an IoT solution have had, on average, a 25% return on investment – and those respondents expect their ROI to grow to 30% in two years.

Among IoT adopters, 38% cite complexity and technical challenges to using IoT as a barrier to further their IoT adoption.

Lack of available IT talent and training present challenges for half of IoT adopters, with 47% responding that there are not enough available skilled tech workers.

The potential for IoT to reshape industries is significant, says George, who is seeing evidence of this change across retail, energy, agriculture, manufacturing and more. Below are some examples George cited of businesses taking advantage of catalytic innovations in IoT.

thyssenkrupp built its “Innovation Test Tower” in Rottweil, Germany. More than 800 feet tall, the laboratory is where the company can try new technologies and showcase them to potential customers and to the public. It’s both a test lab and an active commercial building, with nearly 200,000 square feet of occupied office space and IoT sensors that transmit data of all kinds 24 hours a day.

At its test tower in 2017, thyssenkrupp Elevator unveiled MULTI, a groundbreaking, rope-less and sideways-moving elevator.

Click here to load media

“We wanted to find new ways to use IoT sensor technology to make a building interact with the facility manager and the owner,” says Michael Cesarz, chief executive officer for MULTI at thyssenkrupp Elevator. “thyssenkrupp is uniquely positioned to do that, because an elevator is the nervous system of a building, and the shafts are like the backbone – they are a crucial structural element and they touch every single floor and serve every single tenant.”

To help develop new solutions in the Innovation Test Tower, thyssenkrupp partnered with Willow, a member of the Microsoft Partner Network. thyssenkrupp uses the company’s Willow Twin platform powered by Azure IoT which provides a “digital twin” of the tower that delivers actionable insights to the building managers.

Each Starbucks store has more than a dozen pieces of equipment, from coffee machines to grinders and blenders, that must be operational around 16 hours a day. A glitch in any of those devices can mean service calls that rack up repair costs. More significantly, equipment problems can potentially interfere with Starbucks’ primary goal of providing a consistently high-quality customer experience.

“Any time we can create additional moments of connection between our partners and customers, we want to explore and activate,” says Natarajan “Venkat” Venkatakrishnan, vice president of global equipment for Starbucks. “Our machines are what allow our partners to create that special beverage, and ensuring they are working properly is critical.”

To reduce disruptions to that experience and securely connect its devices in the cloud, Starbucks is partnering with Microsoft to deploy Azure Sphere, designed to secure the coming wave of connected IoT devices across its store equipment.

The IoT-enabled machines collect more than a dozen data points for every shot of espresso pulled, from the type of beans used to the coffee’s temperature and water quality, generating more than 5 megabytes of data in an eight-hour shift. Microsoft worked with Starbucks to develop an external device called a guardian module to connect the company’s various pieces of equipment to Azure Sphere in order to securely aggregate data and proactively identify problems with the machines.

The solution will also enable Starbucks to send new coffee recipes directly to machines, which it has previously done by manually delivering the recipes to stores via thumb drive multiple times a year. Now the recipes can be delivered securely from the cloud to Azure Sphere-enabled devices at the click of a button.

“Think about the complexity — we have to get to 30,000 stores in nearly 80 markets to update those recipes,” says Jeff Wile, senior vice president of retail and core technology services for Starbucks Technology. “That recipe push is a huge part of the cost savings and the justification for doing this.”

Just one grain of corn infected with a highly carcinogenic mold called aflatoxin can be all it takes to poison the whole harvest and sicken or even kill people and animals, not to mention the waste of having to throw out the lot when contamination isn’t found in time. Aflatoxin often can’t be seen, smelled or tasted, and it’s not destroyed by heat – so cooking contaminated food doesn’t make it safe.

Ingestion of high levels of aflatoxin can be fatal, and chronic exposure can result in serious health problems, according to the International Food Policy Research Institute. There are about 155,000 new cases a year of cancer caused by aflatoxin – it’s the leading cause of liver cancer in developing countries.

Since consumers can’t tell if their food is infected, the onus is entirely on growers, harvesters and processors – more of whom are having to fight the mold as it expands north amid climate change that stresses crops and makes them more susceptible. So the stakes are high for the new corn processing system Bühler engineers developed as part of an innovation challenge.

With the LumoVision optical sorter, corn gets fed from a truck into a hopper above the 6-foot-tall machine, and a vibratory feeder sends it into a chute where it accelerates to 3.5 meters (11.5 feet) a second as it flows in a single layer. UV lights illuminate the corn. A camera on each side of the chute monitors the lighted grains, looking for the telltale fluorescence of aflatoxin infection.

High-speed valves operating compressed air jets – which can open or close in a thousandth of a second – simply shoot any contaminated kernels into the rejects bin, letting the rest of the healthy corn pass through into storage or shipping containers.

Weather patterns at the time of harvest, the health of other lots harvested in the area and other relevant data points can be uploaded to the Bühler Insights platform hosted on the Microsoft cloud to augment the machine data. This can then be combined with information from the cameras as they watch the grains pass by, monitored and analyzed using IoT and edge computing to provide a real-time risk assessment on the crop and guide the system’s processes. If the risk is minimal, sorting can be paused while monitoring continues. If the risk rises, sorting automatically restarts.

“This came at exactly the right time for us, because we were just starting our digital journey toward data analytics and the Internet of Things,” says Stuart Bashford, Bühler’s digital officer. “The general concept for something like this had been around for years, but the technology never existed before to make it commercially viable. But now it’s all come together in this incredibly rewarding project.”

Deep within a Chevron fuel refinery, one key machine is now talking – and revealing secrets about its own health.

That chatty piece of equipment, called a heat exchanger, removes the heat from fluids flowing through it as part of the plant’s fuel processing.

In a pilot program, Chevron affixed some exchangers with wireless, Industrial Internet of Things (IIoT) sensors that collect and send real-time data from the heat exchanger to the cloud – supplementing information already gathered by the safety and control system.

Data scientists then analyze that fresh data to check the equipment’s health status now, and to predict its condition in the future.

“Understanding the health of these exchangers can prevent unscheduled outages as well as optimize when we clean these units,” says Deon Rae, a Chevron fellow and lead of Chevron’s IIoT Center of Excellence. “That has the potential to save the company millions of dollars a year when scaled across our whole inventory of heat exchangers.”

The company plans to expand that same IoT technology to other pieces of equipment at facilities around the world to similarly monitor their health and forecast their performance, Rae says. Chevron has more than 5,000 heat exchangers in active operations in more than 100 countries. Deploying health monitoring across different pieces of equipment has the potential to provide significant savings.

Toyota Material Handling Group is the largest forklift manufacturer in the world, but its customers require much more than warehouse trucks and equipment. To better serve them, the global business is expanding and enriching its logistics solutions with digital innovation and Toyota’s renowned principles in lean and efficient manufacturing.

By providing solutions with artificial intelligence, mixed reality and IoT, Toyota Material Handling Group is helping customers meet the global rise in e-commerce and move goods quickly, frequently, accurately and safely.

With Microsoft technologies, the solutions range from connected forklift and field service systems available today to AI-powered concepts that pave the way for intelligent automation and logistics simulation – all designed with Toyota’s standards for optimizing efficiency, operation assistance and kaizen, or continuous improvement.

“Our direction is going to more systemizing and logistics solutions, services in digital automation, AI analytics and IoT,” says Toshihide Itoh, associate director and CIO of Toyota Material Handling Group, an Aichi, Japan-based division of Toyota Industries Corporation. “We also continue to improve our forklift trucks, because this is our origin. But customers need more and more efficient logistics and we need digital innovation to accelerate and expand our business.”

Toyota has presented its vision for a future warehouse with lean logistics and pre-trained, intelligent forklifts. Enabled with machine learning and IoT services in Microsoft Azure, the vehicles can quickly learn navigation in a virtual model of a customer’s warehouse, a so-called “digital twin.” Customers can experience the trucks interacting with their physical and virtual environment.

The ability to simulate and visualize a physical environment will help solve one of the biggest challenges in the industry: the long deployment time for customized IoT solutions. Installations can normally take six months to a year, but using machine learning and digital twins can significantly shorten the time.

Numerous studies have shown that bad air outside affects air quality inside homes and offices, entering through ventilation systems.

Even worse, pollutants generated inside from cleaning supplies, cooking and fireplaces can be even harder on your health than what you breathe out on the street, according to the Environmental Protection Agency.

The Pure A9 – an IoT-connected air purifier built with Microsoft Azure – removes ultra-fine dust particles, pollutants, bacteria, allergens and bad odors from indoor rooms. It launched March 1 in four Nordic countries plus Switzerland and, previously, in Korea.

By linking the purifier and its associated app to the cloud, Electrolux can show the product’s users real-time data about their air quality – inside and outside – while tracking interior air improvement over time. In addition, the Pure A9 continuously monitors its filter usage, alerting users when it’s time to order a replacement filter.

And as a connected appliance, the Pure A9 eventually may have the ability to learn the daily patterns of when household occupants are typically away, enabling the device to run itself on a smart schedule, Larsson says.

“If we can predict when the house is empty, we make sure not to waste filter by cleaning air that nobody is going to breathe,” says Andreas Larsson, engineering director at Electrolux. “Then we can start the purification, so the air is clean when you come home.”

Visit the Official Microsoft Blog to read more from the survey’s breakdown of IoT trends.

Top photo: Starbucks partners are able to spend more time hand-crafting the perfect beverage and less time on machine maintenance thanks to cloud-connected devices. (Photo courtesy of Starbucks)"
Microsoft_News,https://news.microsoft.com/source/features/digital-transformation/norwegian-air-shuttle-chooses-surface-pro-to-connect-pilots-and-airports-around-the-world/,,Norwegian Air Shuttle chooses Surface Pro to connect pilots and airports around the world,"There was a time, not too long ago, when pilots around the world carried flight bags with them for each flight. Filled with documents such as operating manuals, navigational charts and weather information, each bag could easily weigh more than 80kg (176 pounds) – about the same as two fully grown German shepherds. Thankfully for pilots, times have changed.

Electronic Flight Bags (EFBs) in the form of tablet devices have replaced the antiquated stacks of paper. Lighter, smaller and easily updatable, the reduced weight over long-haul flights adds up to enormous fuel savings and improved environmental impact.

Based in Oslo, Norwegian Air Shuttle, Europe’s principle low-cost carrier and the largest airline in Scandinavia, has fully embraced the transformation. As a global airline, Norwegian requires uninterrupted communications between the EFB devices and airports in countries that have varying telecommunications standards.

When it needed to update its EFB devices with one best-suited to changeable cockpit environments and telecommunication needs, the airline turned to the Surface Pro with LTE Advanced.

“We need to be sure that our crews have connectivity wherever they are,” says Klaus Olsen, Norwegian Air Shuttle EFB administrator. “Most countries in the EU follow one standard, the United States another. These are easy to deal with, but as we branch out to more and more destinations all over the world, there are more variations to deal with.”

Visit Microsoft News Centre Europe to learn how Norwegian Air Shuttle is empowering its pilots."
Microsoft_News,https://news.microsoft.com/source/features/digital-transformation/now-its-personal-unilevers-digital-journey-leads-to-real-results-for-consumers-and-employees/,,Now it’s personal: Unilever’s digital journey leads to real results for consumers and employees,"What does “digital transformation” mean for an established global manufacturing enterprise like Unilever, maker of iconic brands such as Dove, Vaseline and Ben & Jerry’s?

For Unilever CIO Jane Moran, it means empowering employees to carry out the company’s mission of meeting consumers’ rising expectations.

“What’s transformative is the way we’re connecting people, making data accessible to a broader employee base and giving them the skills to analyze the data to make better informed decisions,” Moran says. “That can have obvious benefits, like increasing efficiency, but also an impact on topics that are central to our business, such as sustainability.”

From project to platform

One of Unilever’s major goals in its digital journey is to become driven by data insights to predict the future — no mean feat for a global giant worth $55 billion, operating in 190 countries.

To realize this change, Unilever shifted from a project-based approach to a platform strategy, supported by Microsoft technology and hands-on support. Azure, Microsoft’s cloud computing service, provides the architectural backbone for the company’s digital transformation.

“That has allowed us to be much more agile and much more scalable,” says Moran. “We can’t deliver unless we have a platform-based approach and it’s very powerful. We’re really exploiting that now at Unilever.”

Click here to load media

Digitally rewiring the supply chain

For Unilever, the capabilities of digital technology offer an opportunity to transform its supply chain to meet the needs of customers who “expect customization, on-demand products and brands with purpose,” Moran says.

“We are digitally rewiring our supply chain, focusing on generating real-time, democratized information, artificial intelligence planning, capitalizing on robotics and building digitally connected factories. All this will allow us to readily predict and respond to whatever the future throws at us,” adds Dave Penrith, Unilever chief engineer.

Unilever is using IoT (Internet of Things) and intelligent edge services in the Azure IoT platform to enable its digital twin, which is a next-generation digital model of a physical environment — in this case, a Unilever factory. The machines and equipment in the factory are connected so that they can send a mass of data — everything from temperatures to production cycle times — into the model.

This creates a representation of every machine and process, offering visibility across all levels of the plant. The collected data is mined for insights and patterns using advanced analytics and machine learning algorithms, which can predict outcomes based on historical data.

“The more data it gets, the more it learns. The more it learns, the faster it learns, and it starts to learn at an increasingly exponential rate,” Penrith says.

The algorithm can reach a level of accuracy where it can be allowed to directly control part of a machine or process. This allows operators to make better-informed decisions and frees them up from repetitive manual tasks for more value-added functions.

The digital twin has already had an impact on operations. Once Unilever switched control of moisture levels in a soap-making machine to the digital twin algorithm, operators did not want it switched off because it gave them so much control over consistency.

In another instance, the digital twin has used data on how long it takes to produce one batch of liquid, such as shampoo or detergent, to predict the correct order of processes in order to get the most efficient batch time. The less time each batch takes, the higher the production capacity of the plant, fully utilizing the asset and avoiding having to invest in capability elsewhere.

The digital twin solution was custom-built by Unilever’s engineering team in partnership with The Marsden Group, a Microsoft partner, and is hosted on Microsoft’s Azure platform.

Right now, Unilever is operating eight digital twins across North America, South America, Europe and Asia. The company is streaming data from 15 of its 300 global plants, with plans to connect 70 factories by the end of the year and another 100 or so in 2020 – “everything from soap to soup,” Penrith says.

Diving into data

In its mission to become data-insights driven, Unilever is using Power BI, a business analytics tool, to help employees access the data they need. Employees can use Power BI to visualize data in whatever way works for them to solve the problem they’re facing, and it also allows them to create their own reports, rather than relying on a technology team.

Being able to uncover data and visualize it in Power BI has allowed Unilever to increase productivity by eliminating false or unimportant alerts on production lines. Previously, operators were responding to 3,000 alerts every day in this complex site, each of which took a few minutes to assess, acknowledge and clear. This put operators into constant reactive mode and slowed down production lines. Unilever has been able to reduce the number of alerts requiring action by 90% per day, ensuring far fewer interruptions and more timely interventions.

Power BI is just one tool in an interconnected system that cultivates the “democratization of data,” says Penrith. “With Power BI connected to all our historical data, live data, analytics and models, our people get real-time intelligence, all sitting in Microsoft Teams, with conversation happening all the time so our employees and factories can support and collaborate with each other.”

Empowering with PowerApps

A big part of that interconnected system is finding ways to help people fix their own issues. One tool the company is using to achieve this is Microsoft PowerApps, which allows employees to build custom apps themselves, without a developer.

For example, one Unilever factory quality assurance employee saw a demo for PowerApps — and then created a quality assurance PowerApp herself.

The app is now available in all of Unilever’s factories, a vast upgrade from the manual process that was previous used for quality checks. The app enables real-time adjustment to the manufacturing process and saves time, freeing up employees for more valuable tasks. It also saves paper, contributing to Unilever’s sustainability mission.

Connecting a global team

Unilever also wanted to offer its people — nearly 155,000 employees worldwide — the tools to further connect with one another and share lessons and ideas. Unilever uses Microsoft 365, a bundle of services that includes Windows 10, as well as productivity apps such as SharePoint, Outlook, Word, PowerPoint and Excel, and collaboration and communication tools such as Teams and Yammer.

This suite of tools has made a big impact on productivity and collaboration, according to Moran.

“Using digital tools like Teams and Yammer have really helped our organization to collaborate and share, and you can’t appreciate how great that is,” she says. “It’s taken off at the top of our company, and now everyone is using this to share wonderful stories about what they’re doing every day. It has allowed everyone to have a voice.”

For Penrith, Microsoft Teams has had a major impact on communication. The company created a global Teams environment for all Unilever engineers that allows them to connect and share knowledge.

“That’s been a real game changer,” he says. “Overnight, we connected 2,000 engineers, most of whom may never really have spoken to each other before … it takes away any false boundaries that people may have, and it links colleagues from around the whole world.”

Penrith has a blog area within Teams where everyone can reply to everyone else, and they can also contact him directly on the platform. Penrith now spends more time on Teams than on email and has seen a 60% to 70% drop in the number of emails arriving to his inbox.

Digital enables sustainability, too

Unilever’s digital conversion has also helped to support the company’s commitment to sustainability, particularly in terms of energy efficiency.

One example is the amount of energy used at factories that make Dove soap. Unilever has used Teams to set up a community for Dove factories where they can access energy usage data for all factories, as well as share best practices for conserving energy. Everyone in the community can see how much energy each factory uses per batch of Dove soap and work together on reducing that usage.

Data-driven decisions

Unilever’s technological transformation has already resulted in substantial success across the organization, from the supply chain to research and development, human resources, sales, finance, logistics and more, supporting the company’s ultimate goal of serving consumers.

“We are creating a culture and organization which is data-intelligent across our end-to-end supply chain, supported with the data, analytics and insights to make smarter, faster decisions to understand, anticipate and exceed consumer expectations,” says Penrith.

At the Microsoft Inspire 2019 conference, Microsoft’s executive vice-president of Worldwide Commercial Business, Judson Althoff, spoke to Unilever executives about how Microsoft technology is fueling Unilever’s digital transformation. Above, Althoff greets employees at a Unilever factory in Valinhos, Brazil ."
Microsoft_News,https://news.microsoft.com/source/features/digital-transformation/machine-learning-unlocking-secrets-human-movement-reshaping-pro-sports/,,How machine learning is unlocking the secrets of human movement – and reshaping pro sports,"It’s another busy morning in the lab. Twelve of the best basketball players on the planet are each a blur of action and a bundle of hope.

As hip-hop beats fill the lab, the group trains without touching a single basketball, individually bouncing side to side on an indoor track, soaring over a three-foot-tall box, and slinging weighted balls against a wall. One athlete, however, is producing both sweat and data – jumping, lifting and sprinting as cloud-connected cameras record his every movement at Peak Performance Project (P3) in Santa Barbara, California.

All 12 of these college athletes expect to enjoy a long NBA career. And far away from P3, many sports analysts are equally certain they already know which of these NBA Draft hopefuls will become a legend, a valuable starter or a key contributor off the bench.

But according to thousands of biomechanical data points captured by the lab’s special cameras, many of those outside forecasts will be air balls. Some of the athletes will retire after a few forgettable seasons, some will suffer injuries that end their hoop dreams, and some lesser-ranked prospects will stun experts and reach NBA stardom, the data reveals.

None of this is news to the one man who is standing still inside the bustling lab. Dr. Marcus Elliott, a Harvard-trained physician and founder of P3, has seen the data and – he believes – the future.

“We understand these athletes and how they’re going to perform on an NBA court before they set foot on an NBA court,” Elliott says.

“All of these kids going through this NBA Draft – including Zion Williamson and R.J. Barrett from Duke (University) – have been coming to see us since they were 16, 17 years old. With our data, we can give them injury-risk models and performance models to help guide their career development,” Elliott says. “Nobody has this biomechanical information on them. We have years of it.

“It’s an amazing view.”

Click here to load media

Launched in 2006, P3 is the first facility to apply a more data-driven approach to understanding how elite competitors move. It uses advanced sports-science strategies to assess and train athletes in ways that will revolutionize pro sports – and, eventually, the bodies and abilities of weekend warriors, Elliott says.

“We are challenging them and measuring them. But we’re not interested in how high they jump or how fast they accelerate,” Elliott says. “We’re interested in the mechanics of how they jump, how they accelerate and decelerate. It’s helping us unlock the secrets of human movement.”

Working directly with players and their agents or families, P3 has evaluated members of the past six NBA draft classes, amassing a database of more than 600 current and former NBA athletes.

Some of P3’s clients include NBA stars Luka Doncic and Zach LaVine plus athletes from the NFL, Major League Baseball, international soccer, track and field and more.

Many of those NBA clients, like Philadelphia 76ers guard Josh Richardson, return to P3 each summer for re-testing to pinpoint whether their movement patterns have gained asymmetries that could cause injury, or to reconfirm the health of physical systems they use to leap, land, stop and start, fueling their on-court edge.

“This is my fifth off-season now at P3,” Richardson says. “When I started with them during my NBA draft preparation, I immediately saw that their approach was different and that it could help me have the best chance to improve my athleticism. Every off-season I get to see exactly where I am physically compared to where I was before – and compared to other NBA players.

“They are able to help me identify where I might be at risk of injury and where I can improve physically. It’s important for me to know that the training I am doing is specific to my unique needs,” Richardson says.

To collect all that granular data, P3 outfitted its lab with a high-speed camera system manufactured by Simi Reality Motion Systems GmbH, a German company from the ZF Group and a Microsoft partner.

Simi offers markerless, motion-capture software that removes the need for athletes to wear tracking sensors while they play or train. Simi also works with seven Major League Baseball clubs, deploying high-speed camera systems to those stadiums to record every pitch during every game since the 2017 season.

Simi’s software digitizes the pitchers’ arm angles and related body movements, spanning 42 different joint centers across 24,000 pitches thrown per team per season. That produces hundreds of billions of data points that are uploaded and processed on Microsoft Azure, enabling teams to create in-depth biomechanical analyses for the players, says Pascal Russ, Simi’s CEO.

“The first team that deploys this effectively on the field to pick lineups or to see which pitch angles worked well against which batters is going to see a huge separation between them and the other teams not using this,” Russ says.

“It’s freakishly accurate.”

While Russ foresees this technology eventually remaking baseball, such seismic shifts already are occurring in the NBA through P3’s player assessments, says Benedikt Jocham, Simi’s U.S. chief operations officer.

“We provide the software solution that can quantify the movement and analyze, for example, how much pressure and torque a person is putting on various body parts,” Jocham says. “P3 adds the magic sauce. They are wizards at figuring out what it all means and making sense out of it for athletes.”

After the cameras record a player’s movements in the P3 lab, those datasets are loaded into Azure where machine-learning algorithms reveal how that player’s physical systems are most related to other NBA players who were similarly assessed. The algorithm then assigns that player into one of several clusters or branches that predict how their basketball career may unfold, Elliott says.

One branch, for example, contains athletes who had a brief NBA experience and never became significant players. Another branch encompasses players who were impactful during their first three or four seasons then sustained serious injuries that depleted their skills. In still another branch, players share rare combinations of length, power and force that fed elite careers – and they remained healthy.

“The human eye is good at measuring size and maybe estimating weight, and very bad at comparing athletes’ physical systems and movement symmetries to one another,” Elliot says. “But we can measure those things in the lab and the machine tells us how young athletes are most alike.

“It’s a solid foothold into an area of sports science that has been out of sight until now,” he says.

The data is also helping to shatter long-held theories that successful NBA players who, at first glance, lack the size, jumping ability or quickness of traditional stars are merely compensating by tapping unmeasurable intangibles such as “intuition” or “IQ” or “heart.”

“That’s how people once would have defined (2017-18 NBA most valuable player) James Harden, as somebody who just has this super-high basketball IQ,” Elliott says. “Maybe he does. But he also has a better stopping or braking system than anybody we’ve ever assessed in the NBA.

“That creates competitive advantages,” he adds. “There’s Newtonian physics behind these advantages.”

Case in point: Dallas Mavericks rookie Luka Doncic. In its pre-draft assessment of Doncic one year ago, P3 identified that same hidden performance metric – the elite ability to stop quickly. P3 knew, before his NBA Draft, that Doncic and Harden were in the same player branch. Doncic posted a stunning first pro season.

The insights also help athletes avoid injuries by adopting new training techniques to change unhealthy movement patterns revealed in the data, says Elliott, who previously served as the first director of sports science in MLB (for the Seattle Mariners) and as the first director of sports science in the NFL (for the New England Patriots).

Every NBA player or draft prospect assessed by P3 receives a report that highlights their injury risks and compares them to league peers based on performance.

“Athletes come to us because they trust us to take better care of their bodies than would happen anywhere else,” Elliott says. “Traditionally, and still today, when these bad things happen to players, everyone says, ‘Oh, that was a freak injury.’ I’m just telling you that the machine learning models predict a whole lot of these.

“I can’t imagine a world where out of nowhere you suffer, say, a right tibial stress fracture – not your left one, not your femur, it’s your tibia, out of nowhere,” he adds. “Without a doubt, these are not random events. Sports science just has not been very good about identifying them.”

Eventually, this same information may become available to amateur athletes and everyone else, Elliott says. The same technologies could predict, for example, that a weekend warrior has too much force going through the left leg while jumping or landing plus a tiny but unhealthy rotation of the left knee and femur, causing too much friction, and, eventually, an erosion of the left knee cartilage.

“What if you identified that when you were 30 or 20, instead of learning when you’re 50 that your cartilage is gone? That really is the future,” Elliott says.

“The power of machine learning and (Microsoft) Artificial Intelligence are going to help us unlock these secrets in ways that have never existed. We’re already doing it but it’s only in the early days of what I think is going to be a revolution in this space,” he says. “It’s coming. It’s definitely coming.

Top photo: Stanley Johnson, a forward with the NBA’s New Orleans Pelicans, moves laterally inside an exercise band at the P3 lab. (All photos courtesy of P3.)"
Microsoft_News,https://news.microsoft.com/source/features/digital-transformation/icertis-narrows-the-gap-between-ai-expectations-and-reality/,,Icertis narrows the gap between AI expectations and reality,"Transform recently sat down with several Microsoft customers at an event highlighting emerging trends in data and artificial intelligence. We talked with Vivek Bharti, general manager of product management at Icertis, which provides contract management services to enterprise customers.

TRANSFORM: Describe how your company uses AI to serve customers.

VIVEK BHARTI: We strive to solve the hardest contract management problems, using technology, and making it easy for the customers to use it.

All a company’s commitments and obligations are in that contract document. The problem is that those are in natural languages, not very amenable to the traditional systems. We take their (contract) repository, which is usually a set of folders of PDFs, etc., convert them into intelligent documents and help them manage their publications for life.

In the process, we save them money or help them garner more revenue.

TRANSFORM: What are the biggest challenges you see with AI?

BHARTI: One challenge is that the technology seems to be ahead of the business. The pace of innovation is so fast that technologies are producing possibilities, left, right and center. But it’s not necessarily true that the business use cases have been found. It’s resulting in very hyped-up speculation from the customers. There’s a gap between expectations and reality.

Another challenge is creating pools of people who understand both the customer and the technology, to create the intersection of technology and what the business problems are. At a tactical level, that’s solved by having a pool of domain experts who sensitize the engineers about what the business problem is.

Conversely, every single person who joins the company, they go through product training. So we set a foundation where everyone is aligned on what the company vision is and what is it that we’re building for. That starts sensitizing people who are more business oriented, sales folks, business analysts or whatever, to what is the technology capability.

TRANSFORM: How does that intersection of technology and business know-how help you serve customers better?

BHARTI: If you look at the size of our company, and the kind of customers we are acquiring, some of them have 400,000 suppliers. And they’ve trusted our system to manage (their contracts). It’s not because we are a big company. They saw that everyone that they interacted with from our company was actually talking about their problems, not about their product. So that’s how we’re making a difference."
Microsoft_News,https://news.microsoft.com/source/features/work-life/microsofts-ai-for-accessibility-grant-winners-you-want-to-be-seen-as-the-person-you-are/,,Microsoft’s AI for Accessibility grant winners: ‘You want to be seen as the person you are’,"John Robinson was born without the extensions of his arms or legs. As a child, and an adult, he rejected wearing prostheses. They worked, but they were uncomfortable, and he never felt like himself with them on. And that’s all Robinson really wanted to be, just himself.

It’s why he understands the frustrations many other people with disabilities face in trying to get people to see who they really are – especially when it comes to looking for employment. And why his organization, Our Ability, is among seven new recipients of Microsoft’s AI for Accessibility grants to people using AI-powered technology to make the world a more inclusive place.

In 2018, when the $25 million program was announced, nine organizations were given grants to work on a variety of projects, some from scratch, some already underway.

The new grantees, announced in conjunction with Global Accessibility Awareness Day May 16, are: University of California, Berkeley; Massachusetts Eye and Ear, a teaching hospital of Harvard Medical School; Voiceitt in Israel; Birmingham City University in the United Kingdom; University of Sydney in Australia; Pison Technology of Boston; and Our Ability, of Glenmont, New York.

Their projects may differ, but the people behind them share a passion for how technology can improve the lives of their fellow human beings.

“What stands out the most about this round of grantees is how so many of them are taking standard AI capabilities, like a chatbot or data collection, and truly revolutionizing the value of technology in typical scenarios for a person with a disability like finding a job, being able to use a computer mouse or anticipating a seizure,” says Mary Bellard, Microsoft senior accessibility architect.

The one-year grants provide use of the Azure AI platform through Azure compute credits and can also include Azure compute credits plus engineering-related costs. AI for Accessibility has three focus areas: communication and connection; employment; and daily life.

Robinson of Our Ability knows about all of those. But it was his employment journey after college that always remained with him. He went through a discouraging, 4-1/2-year search to find a job – the right job. During those years, he sent out hundreds of resumes, and had 20 to 25 interviews for work in ad sales at TV stations. He also married and started a family.

“If I were really going to give up, I would have given up after the first 10 or 20 interviews,” he says. “That’s not who I am.”

He vowed, someday, to find a way to improve the process for others who have disabilities. “You want to be seen as the person you are, in total, not just the shell that you are on the outside,” he says.

After working at TV stations for many years, Robinson founded Our Ability in 2011 to bring businesses with employment opportunities together with people with disabilities looking for jobs.

Now, with the AI for Accessibility grant, and working with students from Syracuse University, Our Ability wants to create an accessible and intuitive AI-powered chatbot to help businesses find workers, and to help people with disabilities find employment that’s meaningful to them.

“So many of them are taking standard AI capabilities, like a chatbot or data collection, and truly revolutionizing the value of technology in typical scenarios for a person with a disability.”

And with good reason: The unemployment rate among people with disabilities is about twice as high – 7.9 percent – as for those without disabilities, according to the U.S. Department of Labor’s Office of Disability Employment Policy (ODEP). Robinson says the rate is actually closer to 65 percent when you factor in another significant number: Only one out of every five people with disabilities is in the labor force, according to ODEP.

Of course, human job coaches are helpful, Robinson says, but even some of them still tend to look at the disability first, and not the person.

“The internet is a more level playing field” that way, he says. “The individual with a disability will talk to the chatbot about who they really are, and maybe more importantly, who they want to be.”

Our Ability has 20,000 unique users that visit its website every year, but not all of them go through the manual process of filling out the forms on the site; the chatbot will help with that, Robinson says. It will also help individuals “find the skills they need for the jobs that they want.”

The Our Ability website now includes an area where individuals can build their profile, companies can search the database, and individuals can search job openings, and “they can find each other organically that way, or they can reach out to us and we can make an email introduction as best we can for opportunities that we know about,” he says. That’s not ideal, though.

The chatbot, he says, “will provide a much more rapid way of getting more people to connect with one another. By creating a place where we assess real-life skills, train real-life skills and match them with employment – that’s every disability job coach’s goal in the last 50 years,” he says.

“We’re going to be able to do it with technology a lot faster and a lot better.”

Every day, Dexter Ang was growing more frustrated as he watched his mother deal with the indignities of ALS, amyotrophic lateral sclerosis. She was diagnosed with it in 2014.

The progressive disease attacks nerve cells that control muscles throughout the body. Over time – for many, anywhere from a year to decades – it robs people of their ability to walk, to use their arms and hands, to talk and ultimately, to breathe independently.

Ang had been working in Chicago in the financial world of high-frequency trading before his mother was diagnosed. He decided to move to Boston to help take care of her. Over the course of a year, there were fewer activities she could do with her hands. Eventually, she couldn’t use utensils to eat. She couldn’t dress herself. And she couldn’t maneuver the mouse to use her laptop, which she relied on for reading e-books from the library.

“I asked her when the last time was that she had read a book, and she said six weeks — because she couldn’t click a mouse,” Ang says. “That just made me tremendously sad, because that was one of the only things that she could still enjoy, and that was just gone.”

Ang, a graduate of Massachusetts Institute of Technology (MIT) with a degree in mechanical engineering, spent months meeting with experts and poring over information about existing technologies to see if there were any that could help his mother.

“Ultimately, a lot of it was not useful — it was complicated and not well-designed,” he says. He credits his mother for inspiring him with a question she asked: What if a person could use their nerve signals to help control a mouse?

Ang wanted to learn more, returned to MIT as a graduate student and co-founded Pison Technology. The company, one of the AI for Accessibility grantees, is developing a nerve-sensing wearable, similar in appearance to a watch, to control digital devices using small, micro-movements of the hands and arms.

“Our proprietary technology can sense nerve signals on the surface of the skin,” Ang says. “Our machine-learning algorithms can classify those voltage signals into discernable actions,” such as simulating a mouse click to help interact with a computer.

In 2016, the ALS Association awarded an ALS Assistive Technology prize to Ang and Pison co-founder David Cipoletta.

“People are looking for products or services to make things easier, and AI might be able to help.”

“They blew the judges away with their easy-to-use, self-contained communication system,” the ALS Association said on its blog. “People living with ALS are able to learn and use the system to communicate in minutes. We observed first hand as participants (and) were thrilled with its comfort and usability while testing out their technology.”

The device, which is now undergoing testing, can help improve communication for people with other neuromuscular disabilities, including multiple sclerosis, Ang says. He wants it to be made widely available, around the world, at a low cost, and easy to purchase online. He believes his mother, who died in 2015, would be proud of the work he and his team have done.

When a person’s “physical world shrinks” because of a disease like ALS, for many “the digital world is the only world that is still out there for people to express themselves, and to connect with others,” Ang says. “To be able to maintain and increase access to that digital world is exceptionally important for people with disabilities.”

For people with epilepsy, one of the biggest dangers is having a seizure while driving. In some places, patients need to prove they’ve been seizure-free for a year in order to be allowed behind the wheel, which can create psychological and economic stress of its own.

It’s a problem that got Omid Kavehei thinking: What if there was a way to warn drivers who have epilepsy that a seizure could be coming, so that they have time to safely pull off the road?

Kavehei, a senior lecturer at the Faculty of Engineering and Information Technologies, and his colleagues at the University of Sydney – also a new AI for Accessibility grantee – are working on a potential way to help. They have been using deep learning to develop an analytical tool that can read a person’s electroencephalogram (EEG) data via a wearable cap, then communicate that data back and forth to the cloud to provide seizure monitoring and alerts.

It’s a very new approach to a very old disorder. Awareness and writings about epilepsy date back to ancient times, but so do myths and social stigma about it that continue to persist.

“Some people think epilepsy is contagious — it’s not — and we hear stories of misbelief and misguidance on social media almost every day,” says Kavehei. “I’ve read it in tweets — ‘My child can’t be enrolled in such-and-such primary school because there’s a student there with epilepsy.’ We are living in 2019, but still, you can’t believe some of the stories you hear.”

More than 50 million people worldwide live with epilepsy, making it one of the most common neurological disorders globally, according to the World Health Organization.

“Some people think epilepsy is contagious — it’s not — and we hear stories of misbelief and misguidance on social media.”

“To have a non-surgical device available for those living with epilepsy will make a significant difference to many, including family members, friends, and of course those impacted by epilepsy,” says Carol Ireland, CEO of Epilepsy Action Australia, which is among the groups working with the university on the project.

“Such a device would take away the fear element of when and if a seizure may occur, ensuring that the person living with epilepsy can get into a safe place quickly.”

Kavehei and his colleagues want to first test a wearable cap on epilepsy patients using driving simulations. They will leverage Azure Machine Learning to attempt to predict seizures from human signals.

The research being done by all of the AI for Accessibility grantees “is an important step in scaling accessible technology across the globe,” says Bellard of Microsoft. “People are looking for products or services to make things easier and AI might be able to help.”

Lead image: Leanne Strong talks with John Robinson at a recent job fair hosted by CDPHP and Living Resources in Albany, New York. (Photo by Scott Eklund/Red Box Pictures)"
Microsoft_News,https://news.microsoft.com/source/features/ai/bing-vector-search/,,"As search needs evolve, Microsoft makes AI tools for better search available to researchers and developers","Only a few years ago, web search was simple. Users typed a few words and waded through pages of results.

Today, those same users may instead snap a picture on a phone and drop it into a search box or use an intelligent assistant to ask a question without physically touching a device at all. They may also type a question and expect an actual reply, not a list of pages with likely answers.

These tasks challenge traditional search engines, which are based around an inverted index system that relies on keyword matches to produce results.

“Keyword search algorithms just fail when people ask a question or take a picture and ask the search engine, ‘What is this?’” said Rangan Majumder, group program manager on Microsoft’s Bing search and AI team.

Of course, keeping up with users’ search preferences isn’t new — it’s been a struggle since web search’s inception. But now, it’s becoming easier to meet those evolving needs, thanks to advancements in artificial intelligence, including those pioneered by Bing’s search team and researchers at Microsoft’s Asia research lab.

“The AI is making the products we work with more natural,” said Majumder. “Before, people had to think, ‘I’m using a computer, so how do I type in my input in a way that won’t break the search?’”

Microsoft has made one of the most advanced AI tools it uses to better meet people’s evolving search needs available to anyone as an open source project on GitHub. On Wednesday, it also released user example techniques and an accompanying video for those tools via Microsoft’s AI lab.

The algorithm, called Space Partition Tree And Graph (SPTAG), allows users to take advantage of the intelligence from deep learning models to search through billions of pieces of information, called vectors, in milliseconds. That, in turn, means they can more quickly deliver more relevant results to users.

Vector search makes it easier to search by concept rather than keyword. For example, if a user types in “How tall is the tower in Paris?” Bing can return a natural language result telling the user the Eiffel Tower is 1,063 feet, even though the word “Eiffel” never appeared in the search query and the word “tall” never appears in the result.

Microsoft uses vector search for its own Bing search engine, and the technology is helping Bing better understand the intent behind billions of web searches and find the most relevant result among billions of web pages.

Click here to load media

Using vectors for better search

Essentially a numerical representation of a word, image pixel or other data point, a vector helps capture what a piece of data actually means. Thanks to advances in a branch of AI called deep learning, Microsoft said it can begin to understand and represent search intent using these vectors.

Once the numerical point has been assigned to a piece of data, vectors can be arranged, or mapped, with close numbers placed in proximity to one another to represent similarity. These proximal results get displayed to users, improving search outcomes.

The technology behind the vector search Bing uses got its start when company engineers began noticing unusual trends in users’ search patterns.

“In analyzing our logs, the team found that search queries were getting longer and longer,” said Majumder. This suggested that users were asking more questions, over-explaining because of past, poor experiences with keyword search, or were “trying to act like computers” when describing abstract things — all unnatural and inconvenient for users.

With Bing search, the vectorizing effort has extended to over 150 billion pieces of data indexed by the search engine to bring improvement over traditional keyword matching. These include single words, characters, web page snippets, full queries and other media. Once a user searches, Bing can scan the indexed vectors and deliver the best match.

Vector assignment is also trained using deep learning technology for ongoing improvement. The models consider inputs like end-user clicks after a search to get better at understanding the meaning of that search.

While the idea of vectorizing media and search data isn’t new, it’s only recently been possible to use it on the scale of a massive search engine such as Bing, Microsoft experts said.

“Bing processes billions of documents every day, and the idea now is that we can represent these entries as vectors and search through this giant index of 100 billion-plus vectors to find the most related results in 5 milliseconds,” said Jeffrey Zhu, program manager on Microsoft’s Bing team.

To put that in perspective, Majumder said, consider this: A stack of 150 billion business cards would stretch from here to the moon. Within a blink of an eye, Bing’s search using SPTAG can find 10 different business cards one after another within that stack of cards.

The Bing team said they expect the open source offering could be used for enterprise or consumer-facing applications to identify a language being spoken based on an audio snippet, or for image-heavy services such as an app that lets people take pictures of flowers and identify what type of flower it is. For those types of applications, a slow or irrelevant search experience is frustrating.

Uses for visual, audio search

“Even a couple seconds for a search can make an app unusable,” noted Majumder.

The team also is hoping that researchers and academics will use it to explore other areas of search breakthroughs.

“We’ve only started to explore what’s really possible around vector search at this depth,” he said.

Related:

Main photo by Getty Images."
Microsoft_News,https://news.microsoft.com/source/features/work-life/artist-uses-ai-trained-to-create-an-ever-changing-musical-score-shaped-by-the-skies-above-a-nyc-hotel/,,Artist uses AI to create an ever-changing musical score shaped by the skies above an NYC hotel,"People can’t yet be in two places at the same time. But Los Angeles-based musician Julianna Barwick is getting around that little problem to treat guests at a new hotel in New York City to a never-ending, ever-changing, live performance that funnels the sound and mood of the skies above Manhattan down into the lobby.

A generative music program created with artificial intelligence (AI) has been trained to keep a constant watch skyward through a camera on the Sister City hotel rooftop, which boasts a sweeping view from the Empire State Building down to the Statue of Liberty. It will take the live inputs it sees — maybe a sudden sunburst, a passing airplane, a full moon or a flock of pigeons — and spontaneously create a musical score, drawn from Barwick’s corresponding compositions, that will play all day and night and never repeat.

“It will be a magical, delightful thing to experience that will pique your sense of wonder,” Barwick says. “But the most exciting thing, to me, is that I’ll be going home to LA and the AI will still be there helping me perform in New York.”

Barwick, an experimental musician, has been working on the project with Sister City and Microsoft for the past year, but in an unusual twist for a musician, she won’t hear the composition she created until the public does, when the hotel officially opens on May 16.

Once the AI performance starts that day, it won’t stop.

Barwick composed five movements within an overall soundscape that reflect the constantly changing nature of the sky throughout the day, each with its own background of bass, synthesizer and vocal lines that weave in and out. For each “event,” identified by Microsoft AI, she then created six synthesized and six vocal sounds for the generative audio program to choose from – for example, 60 different musical options a day for every time an airplane passes above. The sounds are an expression of Barwick’s emotions in response to each stimulus.

“I didn’t want it to be too literal,” she says. “I could have made it sound ‘raindroppy,’ but it’s more about the attitude of the event. An airplane is a lot different than the moon, so it has more of a metallic sound than a warm sun sound or a quiet ‘moony’ kind of feeling. I wanted people who listen to it to be curious and wonder what that sound meant, what’s going across the sky right now.”

Barwick has never been afraid of technology, even if she didn’t have access to it. She recorded her first album in 2007 using a guitar pedal to form vocal loops on a cassette tape. “I didn’t even have a computer then,” she remembers. “I took my bag of tapes in somewhere to get mastered to produce the CD.”

Now she relies on technology to compose, record and perform her multilayered, ambient music. She uses effects on everything, including her voice. There’s no such thing as an unplugged Julianna Barwick set. Still, she says, “Before I was approached to do this project, the only thing I knew about artificial intelligence was from the movies. I’d never seen an application of it in my daily life.”

So as she began exploring sounds, Barwick grappled not only with what AI was and could do, but also with what her role would be in comparison to its. Who was the actual composer – she or the program? Was AI a partner or a tool?

“I contemplated how the project would play out in my absence and realized that I can make all the sounds, but I’m not going to be there to detect all the events — you have to rely on the AI to do that,” Barwick says. “And that’s such an important part of the score; it’s almost like it’s a 50-50 deal. And that’s what makes this project interesting. It almost brings in another collaborator, and the possibilities are endless. It’s opened up a new world of thinking and approaching future compositions and scores.”

Barwick’s wordless music features her own ethereal vocals and synthesized sounds. She composes spontaneously as she performs or records her pieces, never knowing just what the end result will sound like. And the AI program’s adaptability mirrors her own.

“My music is very abstract and interpretive, and I’m a filter for stimuli,” she says. “Whether I’m in a different country or it’s raining or something really sad just happened, that comes out in the music. And this is kind of like the AI is the filter for the stimuli now, because I can’t sit there and watch the sky and perform 24/7 like it can.”

Barwick relied on a team of Microsoft AI technologists, to train the AI in how to respond to events in the sky, and to help organize the tracks and create a generative program. The camera sends live images to a Microsoft Azure computer vision tool, which assigns tags such as “clouds” or “sun.” Those are fed into the system technologists programmed after analyzing Barwick’s compositions and distilling them into an algorithm, which then chooses which tracks to play together, depending on what types of events are happening.

“The only thing I knew about artificial intelligence was from the movies. I’d never seen an application of it in my daily life.”

All the sounds for each of the five sets throughout the day are harmonious, even though the key changes for each. Barwick says she chose chord progressions that made sense to her for the time of day, such as calm but energetic in the morning and “starting to chill out a little bit” by nighttime. She dubbed the project “Circumstance Synthesis.”

“Creating something that will change from bar to bar, from minute to minute, hour to hour, from morning to afternoon and then evening, and different seasons, too – it’s been both challenging and fascinating,” says Luisa Pereira, a technologist working with the Microsoft team. “It has to work within all of these different types of constraints.”

Music is steeped in the background of Atelier Ace, the creative agency and management company behind Sister City and Ace Hotels — the company got its start in the late ‘90s as a concert promotion firm. Ryan Bukstein, vice president of brand for Atelier Ace, remembers when he was an intern for the company in 2000 and first heard Brian Eno’s “Music for Airports,” an album of ambient music that Barwick’s work is reminiscent of. “We’ve had this idea to do an audio score like this for many years, but haven’t had the right place to do it,” Bukstein says. “But Sister City is different than any of our other hotels, and it’s a place where we wanted to be experimental and try new things that we’ve never done anywhere else.”

The 14-story, 200-room boutique hotel on Bowery, a wide avenue on the Lower East Side, has a minimalist aesthetic drawing from Japanese and Scandinavian influences to offer a clean and calm ambiance.

“I picture people who want to enjoy the serenity and aesthetic of Sister City, because it’s very sparse, clean, pretty, light woods, white walls, very airy and light,” Barwick says. “So I want to give them a peaceful, serene feeling.”

Sister City guests can have as much or as little human interaction as they want; if they’re overwhelmed by the crush of humanity in Manhattan and crave solitude, they can check in via a self-serve kiosk, tap their room key to get in and out of the building and use the hotel’s app to request services, without having to speak to anyone.

“We’re including technology in a smooth, intuitive and additive way so it will create more space for us to enjoy life,” Bukstein says. “So we wanted to take music and tie it to AI in a way that could create something special and filter what’s going on outside into Sister City. Julianna’s music is unique, and even though it’s created with technology, it comes out sounding very organic and very human.”

“(AI) almost brings in another collaborator, and the possibilities are endless.”

Although Barwick lived in New York City for 16 years before moving to LA, she was born in Louisiana and grew up in Missouri and Oklahoma. Her album “The Magic Place” was named after a tree on her family’s farm with a canopy that was big enough to crawl into. Her lifelong love of nature influenced her compositions as she focused on bringing the skies above Manhattan down into the lobby of the hotel.

“This is almost like a living score, because it’s interacting with nature and what’s going on outside at the moment,” Barwick says. “It’s like a live synthesis. And I love creating something that will live in New York, since I don’t anymore.

“I can’t wait to hear it in the space and see what people think about it. Maybe AI will seem more tangible and not this far-off sci-fi thing that people only see in movies, but rather something they can use in their own compositions and projects.”

All images by Jay Carroll."
Microsoft_News,https://news.microsoft.com/source/features/ai/microsoft-build-future-of-natural-language/,,What’s Microsoft’s vision for conversational AI? Computers that understand you,"Today’s intelligent assistants are full of skills. They can check the weather, traffic and sports scores. They can play music, translate words and send text messages. They can even do math, tell jokes and read stories. But, when it comes to conversations that lead somewhere grander, the wheels fall off.

“You have to poke around for magic combinations of words to get various things to happen, and you find out that a lot of the functions that you expect the thing to do, it actually just can’t handle,” said Dan Roth, corporate vice president and former CEO of Semantic Machines, which Microsoft acquired in May 2018.

For example, he explained, systems today can add a new appointment to your calendar but not engage in a back-and-forth dialogue with you about how to juggle a high-priority meeting request. They are also unable to use contextual information from one skill to assist you in making decisions from another, such as checking the weather before scheduling an afternoon meeting on the patio of a nearby coffee shop.

The next generation of intelligent assistant technologies from Microsoft will be able to do this by leveraging breakthroughs in conversational artificial intelligence and machine learning pioneered by Semantic Machines.

The team unveiled its vision for the next leap in natural language interface technology today at Microsoft Build, an annual conference for developers, in Seattle, and announced plans to incorporate this technology into all of its conversational AI products and tools, including Cortana.

Teaching context and concepts

Natural language interfaces are technologies that aim to allow us to communicate with computers in the same way we talk with each other. When natural language interfaces work as Roth and his team envision, our computers will understand us, converse with us and do what we want them to do, much like most people can understand a complex request that requires a few actions.

“Being able to express ourselves in the way we have evolved to communicate and to be able to tie that into all of these really complicated systems without having to know how they work is the promise and vision of natural language interfaces,” said Roth.

The natural language technology in today’s intelligent assistants such as Cortana leverages machine learning to understand the intent of a user’s command. Once that intent is determined, a handwritten program – a skill – is triggered that follows a predetermined set of actions.

For example, the question, “Who won today’s football match between Liverpool and Barcelona?” prompts a sports skill that follows the rules of a pre-coded script to fill in slots for the type of sport, information requested, date and teams. “Will it rain this weekend?” prompts a weather skill and follows pre-scripted rules to get the weekend forecast.

Since the rules for these exchanges are handwritten, developers must anticipate all the ways the skill could be used and write a script to cover each scenario. The inability of humans to script every possible scenario limits the scope and functionality of skills, explained Roth.

The Semantic Machines technology extends the role of the machine learning beyond intents all the way through to enabling what the system does. Instead of a programmer trying to write a skill that plans for every context, the Semantic Machines system learns the functionality for itself from data.

In other words, the Semantic Machines technology learns how to map people’s words to the computational steps needed to carry out requested tasks.

For example, instead of executing a hand-coded program to get the score of the football match, the Semantic Machines approach starts with people who show the system how to get sports scores across a range of example contexts so that the system can learn to fetch sports scores itself.

What’s more, machine learning methods then enable the system to generalize from contexts it has seen to new contexts, learning to do more things in more ways. If it learns how to get sports scores, for example, it can also get weather forecasts and traffic reports. That’s because the system has learned not just a skill, but the concept of how to gather data from a service and present it back to the user.

That’s missing in today’s intelligent assistants, which are programmed to do a list of isolated things that a programmer anticipated. The machine learning in these systems primarily focuses on words that trigger a skill, explained Microsoft technical fellow Dan Klein, a recognized leader in the field of natural language processing and a professor of computer science at the University of California at Berkeley.

“They aren’t focused on learning how to do new things, or mixing and matching the things they already know in order to support new contexts,” said Klein, who was also a co-founder and chief scientist at Semantic Machines.

Click here to load media

Dynamic conversation

Since the Semantic Machines system can learn how to do new things, it can more easily engage in a dynamic conversation with a person, accessing and stitching together relevant content, context and concepts from disparate sources to provide answers, present options and produce results.

The Semantic Machines system also has a memory to keep track of the context in a conversation and so-called full duplex capability to talk and listen at the same time in order to keep the dialogue flowing.

“Everything you say is contextualized by what has come before so you can do more complicated things: you can change your mind, you can explore,” said Klein. “Moreover, once things get contextual enough, the notion of a skill begins to dissolve.”

That’s because the notion of skills confines interactions to silos of data whereas true conversation relies on connecting data from all over the place. The Semantic Machines technology orchestrates gathering data and accomplishing tasks on the backend while maintaining a fluid, natural dialogue with the user on the frontend.

Reshuffling your schedule to accommodate a high-priority meeting, for example, requires calendar data and directory data to determine who is free, when, as well as contextually relevant data such as the weather, nearby coffee shops and traffic to figure out where to meet and sit, and when to leave to get there on time.

“Once you start letting things evolve and connect contextually, the notion of a skill is way too limiting,” said Klein. “Getting things done involves mixing and matching.”

Building with natural language

At Build, Microsoft showcased a calendaring application using Semantic Machines technology that can make organizing your day with an intelligent assistant a more fluid, natural and powerful experience. The same technology can be applied to any conversational experience and will eventually power conversations across all of Microsoft’s products and services.

That will build on Cortana’s existing capabilities such as providing answers to questions, offering previews of your day and helping you across your devices from phone to laptop and smart speaker.

Once the technology is incorporated into Cortana, for example, it could make getting things done in Office more about what you need to do and less about accomplishing tasks in certain applications.

“We want it to be less cognitive load, less feeling like I have to go to PowerPoint for this or Word for that, or Outlook for this and Teams for that, and more about personal preferences and intents,” said Andrew Shuman, Microsoft’s corporate vice president for Cortana.

What’s more, added Roth, the technology will be made available through the Microsoft Bot Framework. His team is currently engineering a way for developers working in the framework today to migrate their existing data to the Semantic Machines-powered conversational engine when it is ready.

“As a developer you can start building these experiences yourself,” he said. “We can collectively move, on the basis of this technology, past this notion of skills and silos and simple handwritten programs into the kind of fluid Star Trek-like natural language interfaces we all want.”

Related:

John Roach writes about Microsoft research and innovation. Follow him on Twitter."
Microsoft_News,https://news.microsoft.com/source/features/ai/microsoft-365-intelligent-workday-productivity/,,Microsoft 365: Making the workday more productive with AI,"Writing requires a dash of uniquely human creativity. Artificial intelligence alone cannot do it for us, at least not very well. But AI can – and already is – helping us do things like make sure we spell words correctly and use correct grammar, through the myriad ways it is infused across the suite of Microsoft 365 products. Some of them were even used to craft this story.

As the AI in these products is becoming more sophisticated, they are helping us do more than spot a misspelled word.

That includes new intelligent features in Microsoft Word that help us design our documents for maximum readability, along with other features in Microsoft Search and Microsoft Edge that aim to make everybody’s workday more productive. Microsoft showcased these intelligent features today at Microsoft Build, an annual conference for developers, in Seattle.

“Microsoft AI is all about amplifying human ingenuity with intelligent technologies,” said Malavika Rewari, a senior product marketing manager for Microsoft 365.

Microsoft 365 uses AI to help employees overcome some of the realities of modern work, including increasing time demands, overwhelming amounts of data and growing security threats, she noted.

Gathering knowledge

One modern reality of work is age old: a need for knowledge. The difference is that today’s workers turn to the internet to learn, and more than half start with a search engine.

Beginning on May 28, Microsoft Search will move to general availability, the company announced at Build. The technology brings access to the web and work into a single search experience.

Microsoft Search leverages the AI capabilities of Bing and Microsoft Graph, one of the largest collections of data about how people work ever created, enabling workers to find, command, navigate and discover items across their organization’s network of data.

Microsoft Graph includes data from the public internet as well as data available only to employees within an organization such as directories and policy manuals. What’s more, every employee’s graph is distinctive since it contains data that is available only to their specific team, such as documents, and data from their email and calendar.

“We are able to deliver a cohesive search experience that works across any endpoint in Microsoft 365,” said Bill Baer, a senior product marketing manager on the Microsoft Search team. “Whether you are searching in Bing or searching in the Windows 10 search bar, you’ll get a set of contextually relevant results.”

New intelligence in Microsoft Search includes a machine reading comprehension capability that can extract a paragraph from documents explicitly related to your question. For example, if an employee asks, “Can I bring my dog to work?” Microsoft Search will extract the relevant paragraph from the human resources manual and present it as a search result.

“It understands the question you are asking, and then it can find the answer within millions of words of text and give it to you in context,” said Baer.

Another new intelligent feature allows people within a company to conduct people searches with incomplete information. For example, consider being told, “Talk to Pat on the third floor,” and not knowing who Pat is. A search on “Pat, floor 3” uses intelligence from Microsoft Graph such as your immediate team and location to return the most likely Pat, including an office number and picture.

Click here to load media

Working on Microsoft Edge

Microsoft, which recently announced plans to adopt the Chromium open source project in the development of Microsoft Edge on the desktop, also is working on ways to make the Edge browser a more natural extension of the Microsoft Search experience, noted Baer. That means users who are signed in to a Microsoft 365 account will be able to see related results within the Edge browser.

The Microsoft Edge team is also experimenting with a feature called Collections that allows users to compile and organize content as they browse the internet in their open browser window and intelligently share the compiled content via email or export it to Excel or Word.

For example, a person shopping for a new camera could visit several product websites and save each page in the Collections pane on the side of the browser. The underlying machine learning in Collections would intelligently display an image of each model along with relevant metadata such as price, user rating and the website where the data originated.

From there, a user could email the list to a friend, or copy and paste the collection elsewhere, maintaining the clean format of the content. Another option is to export to Excel, where the machine learning automatically populates a table organized with columns for brand, model, price, rating and so on based on the collected metadata.

“You can easily, at a glance, get the value and make your decision more quickly,” said Divya Kumar, group product marketing manager for Microsoft Edge. She added that the team is experimenting with similar functionality for exporting to Word, including the ability to compile a document with information such as images and text collected from several websites, citations included.

Better Word documents

Beginning this fall, people working in Word Online who are in search of inspiration and insights on how to make their document better will be able to receive intelligent suggestions with Ideas – a feature that is already making people more productive in PowerPoint and Excel.

The Ideas in Word feature uses machine learning and intelligence from Microsoft Graph to help users write polished prose, create more professional documents and efficiently navigate documents created by others.

For example, feedback and signals from Microsoft Graph indicate that workers generally ignore tools available in Word to structure their documents, such as section heads, but rather manually make some words bold and bigger to indicate a new section.

“Here’s something where we say, ‘Hey, we understand the structure of your document. We can make it navigable, or we could create a table of contents on your behalf,’” explained Kirk Gregersen, a partner director of program management in Microsoft’s Experiences and Devices group.

Other intelligent suggestions include recommended acronyms based on their usage in Microsoft Graph, calculated average time to read the document, highlight extraction, as well as familiar fixes for spelling and grammatical errors and advice on more concise and inclusive language such as “police officer” instead of “policeman.”

Neural rewrites

A recently available intelligent feature in Word is rewrite suggestions, which brings the power of deep learning to offer suggestions on different ways to write a phrase.

The technology builds on enhancements to the popular synonyms feature in Word that use machine learning to understand the context of the sentence the word appears in to offer alternative word choices that are more relevant.

“You don’t need to search online to find an alternative way to express a phrase,” said Zhang Li, a senior program manager in the Microsoft Office team, explaining that the intelligence service will surface suggestions within the document.

His team used similar technology to improve synonym ranking earlier this year, leading the synonym suggestion acceptance rate to double.

“We want to augment your skills,” said Rewari, the senior product marketing manager for Microsoft 365. “We want to help you communicate more efficiently, effectively and inclusively.”

Top video: The Ideas in Word feature uses machine learning and intelligence from Microsoft Graph to help a user style a table for a professional document.

Related:

John Roach writes about Microsoft research and innovation. Follow him on Twitter."
Microsoft_News,https://news.microsoft.com/source/features/ai/microsoft-build-autonomous-systems/,,Microsoft Build 2019: Accelerating towards autonomous systems,"In the aftermath of an earthquake, a snakelike robot that can crawl through rubble and tight air pockets is able to access places that no person could — or should — be able to go.

The Sarcos Guardian S, a small robotic visual inspection platform, is designed for exactly those scenarios: searching for cracks in industrial pipelines, finding people trapped in unstable buildings, sensing whether hazardous gases at an accident site could pose a safety risk to first responders.

Today, the robot is controlled by someone working at a safe distance, who sees the scene through its cameras and guides it with the equivalent of a video game joystick. Now, Microsoft and Sarcos are collaborating to add intelligent capabilities to the Guardian S that would allow it to navigate more autonomously — freeing the operator to focus on more important decisions.

The idea of automated industrial applications and using robots isn’t new. Robot arms now move products along an assembly line, machines turn hunks of metal into parts, a car shifts gears without your input.

But that’s a far cry from systems that are actually autonomous — ones that are capable of sensing their surroundings and knowing what to do when confronted with unfamiliar situations. Instead of performing specific tasks repeatedly without variation, these autonomous systems can dynamically respond to changing environments to solve a difficult problem. They also have vast potential to augment how people do their jobs or to perform work that is unsafe or cost-prohibitive for people to do.

Microsoft is building an end-to-end toolchain to help make it easier for every developer and every organization to create autonomous systems for their own scenarios — whether that’s a robot that can help in life-threatening situations, a drone that can inspect remote equipment or systems that help reduce downtime in a factory by autonomously calibrating equipment.

“Machines have been progressing on a path from being completely manual to having a fixed automated function to becoming intelligent where they can actually deal with real-world situations themselves,” said Gurdeep Pall, Microsoft vice president for Business AI. “We want to help accelerate that journey, without requiring our customers to have an army of AI experts.”

Today at the Microsoft Build developers conference, the company is announcing the platform’s first component: a limited preview program for developers to work with its experts to build intelligent agents using Microsoft AI and Azure tools that can autonomously run physical systems. That team includes longtime Microsoft researchers and engineers and experts from Bonsai, which Microsoft acquired last year.

Microsoft’s platform to help developers create autonomous systems employs:

Unique machine teaching tools that enable domain experts to use their knowledge to create AI systems without data science skills

Simulation technologies, such as Microsoft’s AirSim or industry simulators, that allow machines to learn in safe yet highly realistic environment

It will also draw from Microsoft’s diverse portfolio of Internet of Things services, an easy-to-use deep reinforcement learning platform and other AI solutions, and tools like ROS for Windows that allow developers to build intelligent robotic systems — all running on a trusted and secure platform, whether it’s on a device or in the cloud.

Early customers who participate in the limited preview program will learn how to use the same autonomous systems tools as companies like Toyota Material Handling, which is working with Microsoft to develop intelligent and autonomous forklifts.

Sarcos, for instance, was looking for an autonomous systems solution that would combine the best of what machines have to offer with human intellect and intuition, said Kristi Martindale, executive vice president and chief marketing officer for Sarcos.

Today, the person controlling a commercial Guardian S robot has to direct some of his or her attention to pushing buttons and levers on a joystick to guide it through tight spaces and over varied terrain. It can take several steps to appropriately manipulate each segment of the snake over a common landscape feature like stairs.

Using elements of Microsoft’s toolchain, engineers were able to develop an autonomous control system that enables the snakelike robot to avoid obstacles, navigate stairs and climb a metallic wall on its own.

In a real-world scenario, the operator would still play a role in guiding the robot. But if the Guardian S can sense its surroundings and perform all the intermediate motions to traverse stairs on its own, the operator can focus on assessing the scene and making more critical judgement calls, Martindale said.

“We are looking to offload the tasks that can be automated — how does the robot climb a stair? How does it move around obstacle? — so the operator can focus on the more important parts of the job,” she said. “The human is still there to say, ‘No you actually want to go to that obstacle over there because maybe that obstacle is a person who is hurt.’”

A journey from automated to autonomous systems

When people think of autonomous systems, many go straight to the vision of the fully autonomous car that drives itself while you sit in the back seat and read a book, said Mark Hammond, former Bonsai CEO and Microsoft general manager for Business AI.

But car manufacturers have been integrating autonomous features into cars for years, like cruise control or anti-lock braking systems that sense what a driver is trying to do when they encounter a hazard on a wet, slippery road. If that person slams on the brakes in a way that might lock the wheels, that control system takes over and prevents the car from losing traction.

Microsoft’s vision is to help other types of companies — from smart building and energy companies to industrial manufacturers — achieve these incremental steps towards autonomy in their own industries. As the Sarcos robot example shows, many will find the greatest value with humans still in the loop, Hammond said.

“In any sort of operation where you have a mechanical system that interacts with the physical world, you can probably make it smarter and more autonomous,” Hammond said. “But keeping people in the loop is still very desirable, and the goal is really to increase the capabilities of what those humans can do.”

Reinforcement learning is a branch of AI in which algorithms learn by executing a series of decisions and are rewarded or penalized based on which actions get them closer to an end goal. It’s well suited to help machines learn how to do autonomous control tasks, like deciding how to steer an underground drill or angle a tractor blade depending on whether the earth is lumpy or sandy or rocky.

But while deep reinforcement learning algorithms have successfully beat people in video games, mastering real world tasks has been more challenging. In the physical world, the dynamic environments that an autonomous system might encounter — with people and objects moving in unpredictable ways or minute-by-minute changes in temperature or weather — can be far more complicated. Pinpointing exactly where the system went wrong in a long sequence of steps is a difficult computational task.

Machines have been progressing on a path from being completely manual to having a fixed automated function to becoming intelligent where they can actually deal with real-world situations themselves. We want to help accelerate that journey, without requiring our customers to have an army of AI experts.

Microsoft’s autonomous systems platform overcomes some of these challenges by using a unique approach called machine teaching. It relies on a developer’s or subject matter expert’s knowledge — someone who may not have a background in AI but understands how to steer a drill or keep the airflow in an office building at safe levels — to break a large problem into smaller chunks.

Instead of having reinforcement learning algorithms explore how to solve a problem randomly or naively, which could take forever, that person uses a programming language called Inkling to show the system how to solve simpler problems first and provide clues about what’s important. This shortcuts the learning process and enables the algorithms to hit on a solution much faster.

Microsoft’s platform also enables non AI-experts to establish and tweak the reward system, which is key to arriving at a solution that truly works. And it selects and configures the algorithms to tackle the task, eliminating the need for machine learning experts to custom build solutions.

For instance, team members worked with Schneider Electric, a global company working to digitally transform energy management in homes, buildings and industries, to test whether AI could help reduce the carbon footprint of HVAC systems that are used to heat and cool large commercial buildings.

“Schneider is very focused on sustainability, and large buildings are a top contributor to carbon pollution. So there’s a really important mandate to make HVAC systems more energy efficient,” said Barry Coflan, senior vice president and chief technology officer for Schneider Electric’s EcoBuildings Division.

Centered on a longstanding relationship, a proof-of-concept test was conducted using the Microsoft toolchain and Schneider supplied simulation to train an AI system to autonomously run the HVAC systems that controlled airflow and heating in a conference room. It had to balance saving energy with other goals, such as keeping the temperature comfortable for people inside and making sure there’s enough fresh air to keep carbon dioxide levels from building up.

Optimizing for all those factors — which are controlled by different physical systems — requires far more intelligence than a simple thermostat, says Microsoft’s Hammond. The system has to account for environmental variables that are constantly changing: energy costs that fluctuate throughout the day, people coming and going from the room, what the outside weather is doing, the physics of how air flows.

Using a machine teaching approach, Schneider and Microsoft experts first taught the reinforcement learning system to control temperature well. Then the AI system learned how to control air flows to keep air quality at healthy levels. Then it learned to consider how room occupancy affected those outcomes.

Taking all those factors into account, Microsoft’s AI system was able to reduce energy consumption in the room by about 20 percent, while preserving comfort and high air quality when it mattered. The teams are now embarking on a second phase of collaboration to scale the simulation across different types of rooms and further boost energy savings.

Coflan said the laddered approach to teaching and the ability to layer in different rewards enabled Schneider Electric to understand how the AI system was learning and track which factors contributed to the biggest gains.

“A lot of what we do has safety ramifications so we really need to understand how the AI system is making decisions,” Coflan said. “This approach lets you see how the system is getting smarter and gives you an audit trail that is essential for safety and reproducibility. Our customers would want that too — you can’t just put a system out there and say ‘Trust us.’”

Click here to load media

Running simulation at scale in Azure

Because no company can afford to let a robot or an intelligent control system make millions of mistakes in a real-world factory or wind farm or highway as it is learning, reinforcement learning algorithms need to practice in a simulated environment that can replicate the thousands or millions of different real-world scenarios they might encounter.

The Microsoft toolchain also includes AirSim, an open source simulation platform originally developed by Microsoft researchers to use AI to teach drones, self-driving cars or robots to learn in high fidelity simulated environments. Or, the team can work with customers to train autonomous systems using existing industry-specific simulators.

In either case, running these data-hungry simulations in the Azure cloud enables the system to test thousands of different decision-making sequences in parallel, which allows the AI models to learn what does and doesn’t work much faster.

“If I have the ability to spawn thousands of simulations at once and in each one the pedestrian crossing the street is different and the curve of the road is different, suddenly the AI system is able to gather much more diverse experience in a short amount of time ,” said Ashish Kapoor, Microsoft principal research manager. “Azure gives us the ability to run these simulations at scale, which is really important.”

AirSim also allows developers to train different AI and control tools to solve different parts of more complex problems. In helping develop autonomous forklifts for Toyota Material Handling, for instance, researchers broke the task down into sub-concepts that are simpler to learn and debug: navigating to the load, aligning with the pallet, picking it up, detecting other people and forklifts, delivering the pallet, returning to the charging station.

In these complex scenarios, Kapoor said, it may make sense to use reinforcement learning to train a forklift on basic control tasks, like picking up a pallet. Machine teaching helps the system learn in progressively more difficult steps, such as aligning the lift horizontally and then finding the proper angles.

But other parts of the problem might be better solved by entirely different tools like obstacle detection and avoidance algorithms, robotics path planning or classical control techniques. Decomposing the larger task into smaller ones allows developers to select and deploy the best tool for that particular job.

“We are working to provide a comprehensive platform for customers who want to build intelligent autonomous systems, covering development, operation and end-to-end lifecycle management,” Hammond said.

Top image: An experimental version of the Sarcos Guardian S, a visual inspection robot that can be used in disaster recovery or for industrial inspections, has learned to avoid obstacles and climb stairs on its own using Microsoft’s autonomous systems platform. Photo by Dan DeLong for Microsoft.

Microsoft Build 2019 — related autonomous systems links:

Jennifer Langston writes about Microsoft research and innovation. Follow her on Twitter"
Microsoft_News,https://news.microsoft.com/source/features/digital-transformation/starbucks-turns-to-technology-to-brew-up-a-more-personal-connection-with-its-customers/,,Starbucks turns to technology to brew up a more personal connection with its customers,"Walk into a Starbucks store anywhere in the world and you’ll encounter a similar sight: coffee beans grinding, espresso shots being pulled and customers talking to baristas while their coffee order is hand-crafted.

The process may look like a simple everyday scene, but it is carefully orchestrated to serve Starbucks’ more than 100 million weekly customers. With the help of Microsoft, Starbucks is creating an even more personal, seamless customer experience in its stores by implementing advanced technologies, ranging from cloud computing to blockchain.

“We have a world-class team of technologists engaging in groundbreaking innovation each day. Their inventiveness and intellectual curiosity are matched by their dedication to enabling the Starbucks experience, and this is increasingly critical to how technology has to show up for us,” says Gerri Martin-Flickinger, Starbucks executive vice president and chief technology officer.

“Everything we do in technology is centered around the customer connection in the store, the human connection, one person, one cup, one neighborhood at a time.”

At the Microsoft Build 2019 conference, Microsoft CEO Satya Nadella recently demonstrated how Starbucks delivers its signature customer experience with new technologies.

Making recommendations more relevant with reinforcement learning

Starbucks has been using reinforcement learning technology — a type of machine learning in which a system learns to make decisions in complex, unpredictable environments based upon external feedback — to provide a more personalized experience for customers who use the Starbucks® mobile app.

Within the app, customers receive tailor-made order suggestions generated via a reinforcement learning platform that is built and hosted in Microsoft Azure. Through this technology and the work of Starbucks data scientists, 16 million active Starbucks® Rewards members now receive thoughtful recommendations from the app for food and drinks based on local store inventory, popular selections, weather, time of day, community preferences and previous orders.

“Just like their relationship with a barista, customers receive the same care and personalized recommendations when it comes from our digital platforms,” says Jon Francis, senior vice president, Starbucks Analytics and Market Research.

This personalization means that customers are more likely to get suggestions for items they will enjoy. For example, if a customer consistently orders dairy-free beverages, the platform can infer a non-dairy preference, steer clear of recommending items containing dairy, and suggest dairy-free food and drinks.

In essence, reinforcement learning allows the app to get to know each customer better. And while the recommendations are driven by a machine, the end goal is personal interaction.

“Starbucks is an experience,” says Martin-Flickinger. “And it’s centered around that customer connection in the store, the human connection, one person, one cup, one neighborhood at a time. I think that mission is so critical to how technology has to show up for us.”

Now, Starbucks is looking to expand this technology to the drive-thru experience.

“As an engineering and technology organization, one of the areas we are incredibly excited to be pursuing is using data to continuously improve the experience for our customers and partners,” says Martin-Flickinger. “Using data for personalization is vital to our mobile app, and now we are leveraging data to improve our drive-thru experience.”

Because the technology does not have the individual order histories for drive-thru customers that are available for mobile app customers, it will generate relevant drive-thru recommendations based on store transaction histories and more than 400 other store-level criteria. These recommendations will be offered proactively on a digital menu display from which customers can order. Eventually, customers will be able to explicitly opt in to recommendations that are even more personalized.

Starbucks is currently testing this technology in its Tryer Center innovation hub in Seattle, with plans to roll it out soon. And according to Francis, reinforcement learning will continue to have an important role at Starbucks in many other applications going forward.

“We’re meeting our customers where they are — whether in-store, in their car or on the go through the app — using machine learning and artificial intelligence to understand and anticipate their personal preferences,” he says. “Machine learning also plays a role in how we think about store design, engage with our partners, optimize inventory and create barista schedules. This capability will eventually touch all facets of how we run our business.”

Implementing IoT to deliver a smooth coffee experience

Each Starbucks store has more than a dozen pieces of equipment, from coffee machines to grinders and blenders, that must be operational around 16 hours a day. A glitch in any of those devices can mean service calls that rack up repair costs. More significantly, equipment problems can potentially interfere with Starbucks’ primary goal of providing a consistently high-quality customer experience.

“Any time we can create additional moments of connection between our partners and customers, we want to explore and activate,” says Natarajan “Venkat” Venkatakrishnan, vice president of global equipment for Starbucks. “Our machines are what allow our partners to create that special beverage, and ensuring they are working properly is critical.”

To reduce disruptions to that experience and securely connect its devices in the cloud, Starbucks is partnering with Microsoft to deploy Azure Sphere, designed to secure the coming wave of connected internet of things (IoT) devices across its store equipment.

The IoT-enabled machines collect more than a dozen data points for every shot of espresso pulled, from the type of beans used to the coffee’s temperature and water quality, generating more than 5 megabytes of data in an eight-hour shift. Microsoft worked with Starbucks to develop an external device called a guardian module to connect the company’s various pieces of equipment to Azure Sphere in order to securely aggregate data and proactively identify problems with the machines.

The solution will also enable Starbucks to send new coffee recipes directly to machines, which it has previously done by manually delivering the recipes to stores via thumb drive multiple times a year. Now the recipes can be delivered securely from the cloud to Azure Sphere-enabled devices at the click of a button.

“Think about the complexity — we have to get to 30,000 stores in nearly 80 markets to update those recipes,” says Jeff Wile, senior vice president of retail and core technology services for Starbucks Technology. “That recipe push is a huge part of the cost savings and the justification for doing this.”

The overarching goal with Azure Sphere, Wile says, is to shift from reactive maintenance to a predictive approach that heads off issues before they happen. Longer term, the company envisions leveraging Azure Sphere for additional uses such as managing inventory and ordering supplies, and will encourage suppliers of its devices to build the solution into future versions of their products.

Using blockchain to share coffee’s journey with customers

Starbucks is also innovating ways to trace the journey that its coffee makes from farm to cup — and to connect the people who drink it with the people who grow it.

The company is developing a feature for its mobile app that shows customers information about where their packaged coffee comes from, from where it was grown and what Starbucks is doing to support farmers in those locations, to where and when it was roasted, tasting notes and more.

For Starbucks, which has long been committed to ethical sourcing, knowing where its coffee comes from is not new. Last year alone, Starbucks worked with more than 380,000 coffee farms. However, digital, real-time traceability will allow customers to know more about their coffee beans. Perhaps even more important and differentiating are the potential benefits for coffee farmers to know where their beans go after they sell them.

This new transparency is powered by Microsoft’s Azure Blockchain Service, which allows supply chain participants to trace both the movement of their coffee and its transformation from bean to final bag. Each state change is recorded to a shared, immutable ledger providing all parties a more complete view of their products’ journey.

This can not only empower farmers with more information and visibility once the beans leave their farms, but also allows customers to see the impact their coffee purchase has on the real people they’re supporting.

“While high-quality, handcrafted beverages are so important, it’s the stories, the people, the connections, the humanity behind that coffee that inspires everything we do,” says Michelle Burns, Starbucks senior vice president of Global Coffee & Tea. “This kind of transparency offers customers the chance to see that the coffee they enjoy from us is the result of many people caring deeply.”

Starbucks previewed digital traceability for shareholders at its annual meeting in March. Eventually, customers will be able to use the Starbucks mobile app to trace the journey of their Starbucks packaged coffee.

“What we’re still working on is interviewing coffee farmers in Costa Rica, Colombia and Rwanda, learning more about their stories, their knowledge and their needs in order to determine how digital traceability can best benefit them,” says Burns. “We’re forging new ground here, so we’re excited to report more in the coming months.”

Click here to load media

Learn about the latest innovations and imagine new ways to create solutions at Build 2019.

Top photo: At the Starbucks store at 81st and Broadway in New York City, and at every store around the world, cutting-edge innovation powers a deceptively simple everyday scene. All photos courtesy of Starbucks. Additional reporting by Deborah Bach."
Microsoft_News,https://news.microsoft.com/source/features/ai/microsoft-build-2019/,,Microsoft Build 2019: Making AI adoption as simple as possible,"Just a few years ago, artificial intelligence was largely relegated to universities and research labs, a charming computer science concept with little use in mainstream business. Today, AI is being integrated into everything from your refrigerator to your favorite workout app.

Lance Olson, director of program management for applied AI at Microsoft. Photo by Microsoft.

“It’s really exciting, because there’s a new breakthrough every month, or every week,” said Lance Olson, director of program management for applied AI at Microsoft. “Increasingly, the conversations are switching from discussing the art of the possible to getting to the next level of implementation on a specific project.”

Still, many companies are struggling to achieve their AI goals, as the supply of data scientists and AI experts has failed to keep up with surging demand. Creating AI models is difficult work. And then comes a struggle to get them into production – and keep them running. Data ages, much more quickly than code, making models less accurate as the world changes around us.

At its 2019 Microsoft Build conference, the company says it’s focused on helping all developers – even those without an AI or data science background – use its tools and services to deliver the big benefits that more and more customers expect.

“AI and machine learning can turn developers into heroes, for their ability to deliver really personalized, super-immersive experiences to customers,” said Wisam Hirzalla, director of operational databases and Blockchain product marketing at Microsoft. “We want to make it easy for any company to use the technology.”

Simplified and automated machine learning

Toward that end, Microsoft is announcing new capabilities for its cloud-based Azure Machine Learning service, with a goal of enabling developers and data professionals of any skill level to build advanced machine learning models.

We can think of AI practitioners in three categories, according to Bharat Sandhu, director of artificial intelligence at Microsoft. First, we have developers and data scientists who like to write code. They want to build machine learning models using tools and processes they already know. For them, Azure Machine Learning offers a “code first model,” where they can use the development tools they like.

A second group, including business domain experts, may know a lot about data, but they don’t know much about machine learning or code. For those customers, Azure Machine Learning’s automated machine learning experience is a “no code” option, accessible without having to write any code.

“A third category of people, who are learning machine learning concepts, they want to make their own models, but they are not coders. This could be IT professionals, or folks with background in statistics or mathematics,” Sandhu said. “For those customers, we’re offering a drag-and-drop experience to make models visually.” Sandhu noted that no matter which way the machine learning models are created, they all use the same back end, meaning all the models can easily be integrated together.

Bharat Sandhu, director of product marketing for Microsoft Azure, at Microsoft’s office in Bellevue, Washington. Photo by Dan DeLong for Microsoft.

Interoperability

Of course, developers and data scientists have a number of platforms to choose from when they build AI models. To make sure companies can adopt AI advances as quickly as possible, Microsoft says it’s important to overcome platform mismatches, which can delay the rollout of those models into production.

One way Microsoft promotes interoperability among the various AI frameworks is a standard called ONNX Runtime, or Open Neural Network Exchange. This joint effort with other tech companies creates deployment models that work across multiple platforms.

That frees up developers and data scientists to use whatever framework and hardware target is best for them. And it frees up the operational team to focus on deploying and getting results, instead of having to translate as they move from one to the other.

At Build, Microsoft is announcing support for ONNX integration with leading hardware accelerators.

The company also is announcing that it is now an active contributor to the MLflow project, an open source platform for managing the machine learning lifecycle.

Azure Cognitive Services updates

More than 1.3 million developers, many without specific AI or data science skills, currently use Azure Cognitive Services to build intelligent apps that can see, hear, speak, understand and even begin to reason.

At Build, Microsoft is announcing a new category of Azure Cognitive Services called Decision, which gives specific recommendations to help people make decisions. This new category includes Personalizer, which uses a branch of AI called reinforcement learning to help technology glean knowledge from its own experiences and then offer informed recommendations.

“We are able to take reinforcement learning and ship it in a way that’s accessible to developers and doesn’t require a data scientist,” Olson said. “That will be very impactful for customers.”

At Build, the company is announcing many other updates to Azure Cognitive Services, including Ink Recognizer, which can learn to read handwriting, Form Recognizer, which identifies forms, and other new conversation transcription capabilities and other speech, vision and language advances.

Click here to load media

Just getting started

To date, Microsoft’s customers have created almost 400,000 digital agents through its Azure bot service, and more than 3,000 come on line each week. Companies of all sizes are looking to AI to give them a competitive edge.

That includes Cheetah Mobile, a leading mobile app maker building AI-enhanced hardware, including the hand-held CM Translator. Rather than developing the entire speech system from scratch, the company used Azure Cognitive Services, leveraging its text-to-speech API to provide rapid, high quality translations.

MediaValet chief technology officer Jean Lozano. The digital asset management company relies on the security and privacy safeguards within Azure to reassure customers that the images it processes will be handled properly. Photo by MediaValet.

The development cost savings helped keep the device affordable, with no compromise in the natural speech flow.

Other companies say one of the chief benefits of using Azure data and AI tools is that they can take advantage of other attributes built into the tools. For example, the digital asset management company MediaValet relies on the security and privacy safeguards Azure provides to reassure customers that the images it processes will be handled properly.

“We’re not a big company, but we can actually play ball with big enterprise players, because we can leverage the information security and privacy attributes, the trust-ability of Azure,” said MediaValet chief technology officer Jean Lozano.

In the coming months and years, Microsoft expects more and more customers to start using AI, both because they see the business benefits and because the tools are more accessible.

“AI opens up so many possibilities. And the limits are very few, generally limited only by your imagination,” Olson said. “It doesn’t need to be overwhelming for people. We are getting to the point where we can now make AI accessible to a much broader set of customers.”

Related:

Top image: Wisam Hirzalla, director of product marketing for Microsoft Azure, at Microsoft’s Redmond, Washington campus. Photo by Dan DeLong for Microsoft."
Microsoft_News,https://news.microsoft.com/source/features/ai/machine-teaching/,,How people’s expertise makes AI more powerful,"Most people wouldn’t think to teach five-year-olds how to hit a baseball by handing them a bat and ball, telling them to toss the objects into the air in a zillion different combinations and hoping they figure out how the two things connect.

And yet, this is in some ways how we approach machine learning today — by showing machines a lot of data and expecting them to learn associations or find patterns on their own.

For many of the most common applications of AI technologies today, such as simple text or image recognition, this works extremely well.

But as the desire to use AI for more scenarios has grown, Microsoft scientists and product developers have pioneered a complementary approach called machine teaching. This relies on people’s expertise to break a problem into easier tasks and give machine learning models important clues about how to find a solution faster. It’s like teaching a child to hit a home run by first putting the ball on the tee, then tossing an underhand pitch and eventually moving on to fastballs.

“This feels very natural and intuitive when we talk about this in human terms but when we switch to machine learning, everybody’s mindset, whether they realize it or not, is ‘let’s just throw fastballs at the system,’” said Mark Hammond, Microsoft general manager for Business AI. “Machine teaching is a set of tools that helps you stop doing that.”

Machine teaching seeks to gain knowledge from people rather than extracting knowledge from data alone. A person who understands the task at hand — whether how to decide which department in a company should receive an incoming email or how to automatically position wind turbines to generate more energy — would first decompose that problem into smaller parts. Then they would provide a limited number of examples, or the equivalent of lesson plans, to help the machine learning algorithms solve it.

In supervised learning scenarios, machine teaching is particularly useful when little or no labeled training data exists for the machine learning algorithms because an industry or company’s needs are so specific.

Click here to load media

In difficult and ambiguous reinforcement learning scenarios — where algorithms have trouble figuring out which of millions of possible actions it should take to master tasks in the physical world — machine teaching can dramatically shortcut the time it takes an intelligent agent to find the solution.

It’s also part of larger goal to enable a broader swath of people to use AI in more sophisticated ways. Machine teaching allows developers or subject matter experts with little AI expertise, such as lawyers, accountants, engineers, nurses or forklift operators, to impart important abstract concepts to an intelligent system, which then performs the machine learning mechanics in the background.

Microsoft researchers began exploring machine teaching principles nearly a decade ago, and those concepts are now working their way into products that help companies build everything from intelligent customer service bots to autonomous systems.

“Even the smartest AI will struggle by itself to learn how to do some of the deeply complex tasks that are common in the real world. So you need an approach like this, with people guiding AI systems to learn the things that we already know,” said Gurdeep Pall, Microsoft corporate vice president for Business AI. “Taking this turnkey AI and having non-experts use it to do much more complex tasks is really the sweet spot for machine teaching.”

Today, if we are trying to teach a machine learning algorithm to learn what a table is, we could easily find a dataset with pictures of tables, chairs and lamps that have been meticulously labeled. After exposing the algorithm to countless labeled examples, it learns to recognize a table’s characteristics.

But if you had to teach a person how to recognize a table, you’d probably start by explaining that it has four legs and a flat top. If you saw the person also putting chairs in that category, you’d further explain that a chair has a back and a table doesn’t. These abstractions and feedback loops are key to how people learn, and they can also augment traditional approaches to machine learning.

“If you can teach something to another person, you should be able to teach it to a machine using language that is very close to how humans learn,” said Patrice Simard, Microsoft distinguished engineer who pioneered the company’s machine teaching work for Microsoft Research. This month, his team moves to the Experiences and Devices group to continue this work and further integrate machine teaching with conversational AI offerings.

Millions of potential AI users

Simard first started thinking about a new paradigm for building AI systems when he noticed that nearly all the papers at machine learning conferences focused on improving the performance of algorithms on carefully curated benchmarks. But in the real world, he realized, teaching is an equally or arguably more important component to learning, especially for simple tasks where limited data is available.

If you wanted to teach an AI system how to pick the best car but only had a few examples that were labeled “good” and “bad,” it might infer from that limited information that a defining characteristic of a good car is that the fourth number of its license plate is a “2.” But pointing the AI system to the same characteristics that you would tell your teenager to consider — gas mileage, safety ratings, crash test results, price — enables the algorithms to recognize good and bad cars correctly, despite the limited availability of labeled examples.

In supervised learning scenarios, machine teaching improves models by identifying these high-level meaningful features. As in programming, the art of machine teaching also involves the decomposition of tasks into simpler tasks. If the necessary features do not exist, they can be created using sub-models that use lower level features and are simple enough to be learned from a few examples. If the system consistently makes the same mistake, errors can be eliminated by adding features or examples.

One of the first Microsoft products to employ machine teaching concepts is Language Understanding, a tool in Azure Cognitive Services that identifies intent and key concepts from short text. It’s been used by companies ranging from UPS and Progressive Insurance to Telefonica to develop intelligent customer service bots.

“To know whether a customer has a question about billing or a service plan, you don’t have to give us every example of the question. You can provide four or five, along with the features and the keywords that are important in that domain, and Language Understanding takes care of the machinery in the background,” said Riham Mansour, principal software engineering manager responsible for Language Understanding.

Microsoft researchers are exploring how to apply machine teaching concepts to more complicated problems, like classifying longer documents, email and even images. They’re also working to make the teaching process more intuitive, such as suggesting to users which features might be important to solving the task.

Imagine a company wants to use AI to scan through all its documents and emails from the last year to find out how many quotes were sent out and how many of those resulted in a sale, said Alicia Edelman Pelton, principal program manager for the Microsoft Machine Teaching Group.

As a first step, the system has to know how to identify a quote from a contract or an invoice. Oftentimes, no labeled training data exists for that kind of task, particularly if each salesperson in the company handles it a little differently.

If the system was using traditional machine learning techniques, the company would need to outsource that process, sending thousands of sample documents and detailed instructions so an army of people can attempt to label them correctly — a process that can take months of back and forth to eliminate error and find all the relevant examples. They’ll also need a machine learning expert, who will be in high demand, to build the machine learning model. And if new salespeople start using different formats that the system wasn’t trained on, the model gets confused and stops working well.

By contrast, Pelton said, Microsoft’s machine teaching approach would use a person inside the company to identify the defining features and structures commonly found in a quote: something sent from a salesperson, an external customer’s name, words like “quotation” or “delivery date,” “product,” “quantity,” or “payment terms.”

It would translate that person’s expertise into language that a machine can understand and use a machine learning algorithm that’s been preselected to perform that task. That can help customers build customized AI solutions in a fraction of the time using the expertise that already exists within their organization, Pelton said.

Pelton noted that there are countless people in the world “who understand their businesses and can describe the important concepts — a lawyer who says, ‘oh, I know what a contract looks like and I know what a summons looks like and I can give you the clues to tell the difference.’”

Making hard problems truly solvable

More than a decade ago, Hammond was working as a systems programmer in a Yale neuroscience lab and noticed how scientists used a step-by-step approach to train animals to perform tasks for their studies. He had a similar epiphany about borrowing those lessons to teach machines.

That ultimately led him to found Bonsai, which was acquired by Microsoft last year. It combines machine teaching with deep reinforcement learning and simulation to help companies develop “brains” that run autonomous systems in applications ranging from robotics and manufacturing to energy and building management. The platform uses a programming language called Inkling to help developers and even subject matter experts decompose problems and write AI programs.

Deep reinforcement learning, a branch of AI in which algorithms learn by trial and error based on a system of rewards, has successfully outperformed people in video games. But those models have struggled to master more complicated real-world industrial tasks, Hammond said.

Adding a machine teaching layer — or infusing an organization’s unique subject matter expertise directly into a deep reinforcement learning model — can dramatically reduce the time it takes to find solutions to these deeply complex real-world problems, Hammond said.

For instance, imagine a manufacturing company wants to train an AI agent to autonomously calibrate a critical piece of equipment that can be thrown out of whack as temperature or humidity fluctuates or after it’s been in use for some time. A person would use the Inkling language to create a “lesson plan” that outlines relevant information to perform the task and to monitor whether the system is performing well.

Armed with that information from its machine teaching component, the Bonsai system would select the best reinforcement learning model and create an AI “brain” to reduce expensive downtime by autonomously calibrating the equipment. It would test different actions in a simulated environment and be rewarded or penalized depending on how quickly and precisely it performs the calibration.

Telling that AI brain what’s important to focus on at the outset can short circuit a lot of fruitless and time-consuming exploration as it tries to learn in simulation what does and doesn’t work, Hammond said.

“The reason machine teaching proves critical is because if you just use reinforcement learning naively and don’t give it any information on how to solve the problem, it’s going to explore randomly and will maybe hopefully — but frequently not ever — hit on a solution that works,” Hammond said. “It makes problems truly solvable whereas without machine teaching they aren’t.”

Related:

Jennifer Langston writes about Microsoft research and innovation. Follow her on Twitter.

Top image: Mark Hammond, Microsoft general manager for Business AI and former Bonsai CEO, developed a platform that uses machine teaching to help deep reinforcement learning algorithms tackle real-world problems. Photo by Dan DeLong for Microsoft."
Microsoft_News,https://news.microsoft.com/source/features/innovation/she-wanted-to-take-photos-he-wanted-to-understand-movies-in-english-heres-how-ai-helped-them-both/,,She wanted to take photos. He wanted to understand movies in English. Here’s how AI helped them both.,"The last time she could see her family, her animals or her beloved flowers was when she was 11. Monique Van den Abbeel, born with congenital glaucoma that resulted in optic nerve damage, was blind in her right eye by age 4 and lost sight in her left eye seven years later. Several operations over the years had not changed anything for the girl from Bruges, Belgium.

The visual memories of her favorite people and things remained with her, but they were starting to fade. Now 43, and as spunky, defiant and independent as she was as a child, she yearned to use her smartphone by herself to photograph all those things that gave – and still give – her joy as a way “to help me trigger my memories, and hold them all,” she says.

In the town of Lokeren, about an hour’s drive from Bruges, a feisty 17-year-old boy likes swimming, listening to audio books and watching TV and streaming movies and programs with his family on the weekends when he is home from school.

In Belgium, many of the streamed movies and TV shows are in Dutch English, with Dutch subtitles. While Wouter De Brandt speaks Dutch, he has difficulty reading it because of Cerebral Visual Impairment, a result of a brain injury before and during his birth. When he tries to read, he gets nauseous, dizzy and disoriented. He wanted a way to hear the movies in Dutch that his family was watching.

Van den Abbeel and De Brandt don’t know each other, although Belgians like to say almost everyone knows everyone in the small country that is about 90 miles wide and 175 miles long.

But their hopes – Van den Abbeel’s to be able to take photographs, and De Brandt’s to understand the dialogue as his family watched movies – would be realized by the same small team of people who not only understood their frustrations but were determined to help them.

Among them was Katrien De Graeve, a largely self-taught programmer and web developer who is comfortable with technology, but not necessarily with attention. Born in France, De Graeve settled in Belgium, working for companies creating e-commerce sites and web applications.

In 2008, she was hired by Microsoft in Belgium, where for the last 11 years she has had a variety of roles, from developer evangelist to now as an Internet of Things specialist with the Azure Global Black Belt team of cloud architects that works with customers.

A year ago, De Graeve was asked to be one of eight participants on a new show, “Team Scheire,” a Belgian TV program similar to the BBC documentary series “The Big Life Fix,” where inventors create tech solutions for people who have special needs. (Featured in the BBC series was work by Microsoft researcher Haiyan Zhang, who developed a watch that can temporarily short-circuit the hand tremors of graphic designer Emma Lawton, who has Parkinson’s disease.)

De Graeve was on board, although not entirely at ease with the prospects of the TV show filming her brainstorming sessions with Microsoft colleagues, her meetings with Van den Abbeel and De Brandt as the projects progressed and her own late-night ramblings as she worked through problems by herself, often on weekends. It was not in her “comfort zone” – in part why she agreed to do it.

“I never thought about anything like this happening,” she says.

♦♦♦♦♦

Of the hundreds of requests for help that flooded into “Team Scheire” from the public ahead of the show’s first season last year, the host, technology and science journalist Lieven Scheire, and his team had to choose 16 people, with each inventor tasked with figuring out ways to help two people each.

Of all the problems, Van den Abbeel’s was “our moonshot case,” Scheire says.

He remembers an early session when the show’s staff met to talk about it. “We have a person who is blind who wants to take her own photographs without the help of anyone else,” he says. “Everybody looked at each other and thought like, ‘OK, we understand the need, but we don’t even see the beginning of the solution. How do you help a person who is blind to take photographs?’”

With the help of her colleagues, De Graeve thought there was a way. She also was resolute about helping De Brandt. In him, she saw a young man who wanted to not only enjoy entertainment time with his family, but also be able to talk about the latest shows and movies with friends at school, part of the currency of teen chatter.

♦♦♦♦♦

You know instantly – instantly – when talking to Monique Van den Abbeel that she is gregarious and spirited, with her deep laugh and excitement in her voice as she talks. She is a social media diva, with a presence on Instagram, Facebook and YouTube. She has her own website which she started in part to promote her 2016 autobiography, “Like to See! Blind Mama, Strong Woman.” She is the single mother of a 17-year-old son and hopes to be the first person in Belgium to have a guide horse (yes, that’s right, a guide horse).

Her son, Robin, is asked: Do any of your friends’ moms do as much online as your mom? “No! None of them!” he says, marveling at her energy and persistence, her drive to stay connected to the world around her. Van den Abbeel gives public lectures about living as a blind person and likes to entertain through shows that feature her comedy, singing and dancing.

Van den Abbeel has been taking photos of Robin all his life, figuring out how and where to photograph him based on his physical proximity and his voice. She has continued to take photos using a smartphone in much the same way. Robin helps his mom choose the photos that turn out best, and then posts them online for her.

But she wanted to do more than snap a shutter. She wanted to really know what she was capturing, and if it was in focus, or centered. And she knew she would have even more to photograph when a miniature horse named Dinky, about 2 feet high, becomes her guide animal in the next year.

Guide horses are unusual, but not unheard of, and Van den Abbeel already has had several meetings with Dinky, who is being trained now to work with her.

To help Van den Abbeel, De Graeve reached out to the Microsoft team behind the smartphone app Seeing AI, released in 2017 and designed to help people who are blind or have low vision by describing people, objects and text around them.

“Together with Saqib Shaikh, one of the people behind Seeing AI, we got talking about our ideas for Monique and how they saw an opportunity to leverage the groundwork of Seeing AI to create a special ‘for Monique’ prototype,” De Graeve wrote in a LinkedIn article. “Without this ground layer nothing would have been possible!”

Additional assistance came from De Graeve’s colleagues who took part in a Microsoft hackathon on the Redmond, Washington campus in April 2018. Among them was Wesley Backelant, a cloud solution architect with expertise in advanced analytics and AI.

“When I first heard about the project, I immediately felt that AI would be an important building block if we wanted to change people’s lives,” Backelant says. “Knowing that what we build would really impact the day-to-day life” of Van den Abbeel “immediately convinced me to join the team.”

What the team built incorporated additional machine learning so the camera can do real-time, offline recognition of 1,500 objects – even distinguishing vehicles such as “car” or “mini-van,” and then speak what those objects are to help Van den Abbeel choose her own photographs later on.

Also, when Van den Abbeel takes horizontal photos, if the shot isn’t straight, the phone will vibrate to let her know that, and it will alert her if someone’s eyes were closed in a photo so she can re-take it if she wants. These solutions, created for Van den Abbeel, are not publicly available yet.

Using a machine learning model, the team also added to Seeing AI’s facial recognition features to provide real-time recognition of Dinky.

On a day of testing the app, as Monique aimed her smartphone camera toward Dinky, she heard: “Dinky is to the left” in the frame.

Another sound, already incorporated into Seeing AI, lets her know if there is enough light in the frame to take the photo.

“My eyes will never see again, but it’s like this has given me a new way to see,” Van den Abbeel says.

♦♦♦♦♦

Wouter De Brandt is the son of two electrical engineers. Like his parents, he’s smart and he loves to learn. But Cerebral Visual Impairment makes reading letters and words literally painful. It’s a little easier for him with numbers, explains his mother, Sofie Huys.

With numbers, “You only have 1 to 9, and it’s no big deal if you have to read 1,2,3 separately or you see immediately 123,” she says. However if you have to read each character, one at a time, “it takes a lot of time and effort for longer words, and once you’re at the end, you forgot how it started.”

His limited range of vision also makes it a challenge for him to ride a bike, or go for a walk on his own.

During the week, De Brandt attends a school far from his family’s home. He comes back on weekends, when Huys, dad Pascal De Brandt and brother Arno enjoy watching those mainly-in-English movies and TV shows with Dutch subtitles. A staple of their entertainment diet has been “The Big Bang Theory,” a much-loved, long-running American comedy series about young physicists and their friends.

But De Brandt doesn’t know English and he can’t read the Dutch subtitles because of his disability. When they heard about “Team Scheire,” his parents immediately applied “as we are constantly looking for tools that can make Wouter’s life easier,” Huys says.

De Graeve incorporated AI by combining optical character recognition for the Dutch subtitles and text-to-speech to speak the subtitles. De Brandt uses a Surface laptop equipped with this solution and wears a bone-conducting headset (versus an acoustic headset) so he can hear the dialogue, without missing the music and sound effects emanating from the screen.

The teen was less than impressed with an early prototype that didn’t quite do the trick. He shrugged it off, much in the way teenagers often say they don’t really care when they really do. “He was hopeful but realized it wouldn’t be easy” to come up with a solution, “and to protect himself from disappointment, he did set his expectations rather low,” says Huys.

For De Graeve, it was frustrating as well. “I was pretty stressed, and I was not sure how to solve it,” she says, not wanting to let down the teen.

After months of work, including help from colleagues, De Graeve developed a more polished app for De Brandt (the software for the app is published as sample code, available to anyone, on GitHub).

De Brandt “was surprised and happy,” his mother says. “It worked much better than he expected it to.”

He spent a lot of time catching up on episodes of “The Big Bang Theory.” His take? Meh.

“We are all fond of ‘The Big Bang Theory,’ so we assumed that Wouter would like this too,” Huys says. “But unfortunately, it’s not his cup of tea. However, at least now he knows he doesn’t like it, and before he thought he was missing a lot by not being able to understand what it was about.”

The family “doesn’t feel guilty anymore watching an English film, because now he has the choice” of whether he wants to watch it or not, she says. “He does not join always, but he can decide for himself now, where before there was no choice.”

“Now he can talk with his friends at school, and say, ‘Yeah, I watched that.’ ‘No, I don’t like that.’ Or ‘Yes, that was good,’” says De Graeve. “Before, he felt when they started talking about a movie or something, he said, ‘No, I didn’t watch it, I don’t know what you’re talking about,’ so he felt left out. But now he just – he just wants to be normal like everyone else, and I think I helped him with some small step in that, so that is really special.”

♦♦♦♦♦

Nick Trogh, a Microsoft software engineer in Belgium, was among the team members who worked on both De Brandt and Van den Abbeel’s projects.

He developed the object detection functionality of the app for Van den Abbeel, which “allowed her in real-time to hear which objects were in the camera frame, and where they were located,” such as “top left,” or “center, bottom right.”

Because he has been working with AI and computer vision technology, he also provided insights to De Graeve “on how to optimize the process of recognizing subtitles on a TV set” for De Brandt.

“It was truly an honor to be able to participate in these projects, knowing that a few lines of code can make such a big difference in a person’s life,” Trogh says.

The first season of “Team Scheire” is over, but the work for De Graeve isn’t. She’s following up with De Brandt, refining his app so it’s easier to use at movie theaters. And she and Van den Abbeel have become good friends and sometimes go to the theater together. “I’m so inspired by her,” De Graeve says.

The technical expert, the one comfortable with technology, but not necessarily with attention, estimated a lot of things right with both projects. What she underestimated, she says, is the impact both De Brandt and Van den Abbeel had on her life.

“It has been an evolution as well for me,” De Graeve says. “I still get emotional when I start thinking about both of them. I really want them to feel part of a community, and not feel left out.”

Top image: Monique Van den Abbeel practices taking photos using her smartphone."
Microsoft_News,https://news.microsoft.com/source/features/ai/ai-business-school/,,"Strategy, culture & responsibility: Microsoft launches AI Business School","In recent years, some of the world’s fastest growing companies have deployed artificial intelligence to solve specific business problems. In fact, according to new market research from Microsoft on how AI will change leadership, these high-growth companies are more than twice as likely to be actively implementing AI as lower-growth companies.

What’s more, high-growth companies are further along in their AI deployments, with about half planning to use more AI in the coming year to improve decision making compared to about a third of lower growth companies. Still, less than two in 10 of even high-growth companies are integrating AI across their operations, the research found.

“There is a gap between what people want to do and the reality of what is going on in their organizations today, and the reality of whether their organization is ready,” said Mitra Azizirad, corporate vice president for AI marketing at Microsoft in Redmond, Washington.

“Developing a strategy for AI extends beyond the business issues,” she explained. “It goes all the way to the leadership, behaviors and capabilities required to instill an AI-ready culture in your organization.”

On the road to developing a strategy, executives and other business leaders are often stalled by questions about how and where to begin implementing AI across their companies; the cultural changes that AI requires companies to make; and how to build and use AI in ways that are responsible, protect privacy and security, and comply with government rules and regulations.

Today, Azizirad and her team are launching Microsoft’s AI Business School to help business leaders navigate these questions. The free, online course is a master class series that aims to empower business leaders to lead with confidence in the age of AI.

Click here to load media

Focus on strategy, culture and responsibility

AI Business School course materials include brief written case studies and guides, plus videos of lectures, perspectives and talks that busy executives can access in small doses when they have time. A series of short introductory videos provide an overview of the AI technologies driving change across industries, but the bulk of the content focuses on managing the impact of AI on company strategy, culture and responsibility.

“This school is a deep dive into how you develop a strategy and identify blockers before they happen in the implementation of AI in your organization,” said Azizirad.

The business school complements other AI learning initiatives across Microsoft, including the developer-focused AI School and the Microsoft Professional Program for Artificial Intelligence, which provides job-ready skills and real-world experience to engineers and others looking to improve their skills in AI and data science.

Unlike these other initiatives, AI Business School is non-technical and designed to get executives ready to lead their organizations on a journey of AI transformation, according to Azizirad.

Nick McQuire, an analyst who covers artificial intelligence for CCS Insight, said more than 50 percent of the companies his firm has surveyed are already either researching, trialing or implementing specific projects with AI and machine learning, but very few are using AI across their organization and identifying business opportunities and problems that AI can address.

“That’s because there’s limited understanding in the business community about what AI is, what it can do and, ultimately, what are the applications,” he said. “Microsoft is trying to fill that gap.”

Mitra Azizirad, corporate vice president for AI marketing. Photo by Microsoft.

Teaching by example

INSEAD, a graduate business school with campuses in Europe, Asia and the Middle East, partnered with Microsoft to build the AI Business School’s strategy module, which includes case studies about companies across many industries that have successfully transformed their businesses with AI.

For example, a case study on Jabil describes how one of the world’s largest manufacturing solutions providers was able to reduce overhead costs and increase production line quality by using AI to check electronic parts as they are manufactured, freeing up employees to focus on value added activities that machines are unable to do.

“There is still a lot of work that has got to have the human capital piece in it, especially if it is not something that lends itself to standardized processes,” explained Gary Cantrell, senior vice president and chief information officer for Jabil.

A key to implementing AI, Cantrell added, was the leadership team’s focus on clearly communicating to employees the company’s strategy around AI – to eliminate routine, repetitive activities in order to free them up to focus on activities that cannot be automated.

“If they are guessing or they are speculating, it is undoubtedly going to become counterproductive at some point,” he said. “So, the better job you do at keeping the team glued together with where you are going, the better the adoption will be and the faster it will be.”

Prepping an AI-ready culture

The culture and responsibility modules of AI Business School also place a core focus on data. After all, companies that successfully embrace AI need to openly share data across departments and business functions, explained Azizirad, and make sure all employees can participate in the development and implementation of data-driven AI applications.

“You need to start out with an open approach to how the data of an organization is going to be used, which is the foundation of AI, to get the results that you are banking on,” she said, adding that successful leaders foster an inclusive approach to AI that brings different roles together and breaks down data silos.

To illustrate the point, the Microsoft AI Business School surfaces a case study from Microsoft’s marketing team, which wanted to use AI to better score leads for the sales team to pursue. To build the solution, marketing employees partnered with data scientists to create machine learning models that weigh thousands of variables to score leads. The collaboration brought together marketing employees’ knowledge on lead quality with the machine learning expertise of data scientists.

“In the case of AI and in the case of culture, the people closest to the business problem you are trying to solve really need to be involved,” said Azizirad, adding that the sales team is embracing the lead-scoring model because they trust it will produce high-quality leads.

AI and responsibility

Building trust also comes from developing and deploying AI systems in a responsible manner, an area that Microsoft’s market research has found resonates with business leaders. Among high-growth companies, the research found, the more leaders know about AI, the more they recognize that they need to make sure the AI is deployed responsibly.

The AI Business School module on the implications of responsible AI showcases Microsoft’s own work in this area. Course materials include real-world examples in which leaders at Microsoft learned lessons such as the need to safeguard AI systems against malicious attacks and the need for systems to detect bias in datasets used to train models.

“Over time, as companies become operationally dependent on these machine learning algorithms and models that they built, there’s going to be much more focus on governance,” said McQuire, the CCS Insight analyst.

Related:

John Roach writes about Microsoft research and innovation. Follow him on Twitter.

Top image: A key to implementing AI at Jabil, one of the world’s largest manufacturing solutions providers, was the leadership team’s focus on clearly communicating to employees the company’s strategy around AI. Photo by Microsoft."
Microsoft_News,https://news.microsoft.com/source/features/innovation/station-b/,,Station B: A platform that could help boost production of lifesaving biological therapies,"CAMBRIDGE, United Kingdom – In recent years, companies have figured out how to engineer bacteria to make cement, helping reduce the pollution involved in traditional manufacturing. Using more advanced techniques, scientists have even programmed patients’ immune cells to recognize and kill leukemia cells, giving children who had virtually no chance of survival years of prolonged life.

That’s all possible because introducing a manufactured sequence of DNA into a living cell can make it behave in new and transformative ways.

Researchers believe that this ability to program biology has enormous potential to transform how we produce everything from medicines and chemicals to food and fuel. But predicting which out of the millions of combinations of genetic and environmental factors will unlock a desired result is still an expensive, arduous and largely artisanal endeavor. It’s certainly many steps beyond blind luck, but each success can take months or even years of failed experimentation before it works.

“Imagine you’re trying to land a rocket on the moon, but you don’t sufficiently understand the laws of physics or have the means to precisely control it. You’d be lucky to even get close,” said Andrew Phillips, who leads the Biological Computation Group at Microsoft’s research lab in Cambridge, United Kingdom. “But if you understand the equations that govern how the rocket will behave and are able control it, you can determine where it is going to go.”

For thousands of years, people have been taking advantage of biological processes to make things we cannot make ourselves, such as using brewer’s yeast to ferment beer. The instructions that tell the yeast what proteins to make and how to perform the complex operations that turn raw ingredients into a frothy beverage are encoded in the yeast’s DNA. But if we insert new DNA into the yeast, we can program it with new instructions to make all sorts of other things.

Microsoft researchers have spent years studying those underlying processes and learning how to influence them. Now they are launching collaborations with Princeton University and UK-based companies Oxford Biomedica and Synthace to develop and test an integrated platform that’s designed to help other companies and research teams perform that work more reliably. The goal: To reduce the amount of trial and error required to make beneficial scientific breakthroughs and enable companies and academic researchers already established in the field to operate more efficiently and cost-effectively.

The project, called Station B, aims to develop an end-to-end platform — including a software stack, a means to automate lab experiments and machine learning methods that run in the cloud on Microsoft Azure — to help scientists more efficiently and predictably channel the power of life’s ultimate information processing machines: living cells.

The first academic collaboration to pilot the Station B platform, with microbiologists and physicists from Princeton University, will investigate the formation of biofilms — thin, slimy layers of bacteria that build up on surfaces and contribute to processes ranging from medical infections to industrial fouling. The team plans to rapidly assemble and test genetic constructs to help researchers understand and, ultimately, learn to disrupt these bacterial communities that are believed to kill as many people as cancer and are a leading cause of infection worldwide.

Microsoft is also launching a collaboration with Oxford Biomedica, a company that develops and manufactures gene therapies that enable a patient’s cells to combat debilitating and fatal diseases. By working with Station B researchers to identify which genetic and environmental combinations will help make its manufacturing processes more productive, Oxford Biomedica hopes to “dramatically lower the costs of those life-changing treatments and put them within reach of more patients,” said Jason Slingsby, the company’s chief business officer.

“If we are going to tackle diseases that are more common, we need to go from making hundreds of doses of targeted therapies per batch to thousands of doses per batch with the same effort,” Slingsby said.

The platform also relies on software developed by Synthace, a London-based company that uses Microsoft Azure to automate biological experiments instead of relying on scientists to do them by hand. This allows scientists or drug manufacturers to test more complicated scenarios and, crucially, to reproduce the same experiment in different settings.

Microsoft’s Azure cloud infrastructure and machine learning tools can quickly analyze experimental data and improve models that predict how cells will react when a particular sequence of DNA is introduced. That could help users zero in on the best conditions for engineering a lifesaving drug, or bacteria that fix dyes onto textiles through a non-toxic process.

Ultimately, a shared knowledge base could let people predict how genetic devices — essentially, segments of fabricated DNA introduced into a cell — will work in new situations, cutting down on the amount of trial and error in developing new products or processes.

By modeling those biological processes in silico, much like meteorologists use computer models to predict tomorrow’s weather or where hurricanes may land, the Station B tools could help scientists obtain promising results or speed up production processes without having to laboriously test every scenario in the lab.

Turning cells into superfactories for lifesaving drugs

Oxford Biomedica’s headquarters are configured in the shape of an antibody, a holdover from the pharmaceutical company that designed the building and used those proteins to elicit helpful behaviors in cells.

These days, drug manufacturers are seeking out personalized treatments. That’s driven up the costs to discover and bring new drugs to market. One of the fastest growing areas of drug development is gene therapy, which uses biological delivery tools that are often made by genetically engineered cells in culture.

Oxford Biomedica, established more than two decades ago as a spinout from Oxford University, has many of these cutting-edge gene and cell therapies in development and also helps strategic partners develop and manufacture their own. It specializes in making the delivery system that gets engineered genes into a cell — essentially a virus particle that’s been stripped of its ability to cause disease or grow but uses its clever cell entry mechanisms to deliver a therapeutic payload of helpful genes.

For instance, a single delivery into the brain of Parkinson’s disease patients introduces three genes that induce target cells to produce a missing neurotransmitter called dopamine. Early clinical trials show promise for helping reverse the illness’ debilitating symptoms.

The company also is helping a partner develop a drug that fixes a gene mutation in the stem cells of children with severe combined immune deficiency (SCID) syndrome — sometimes known as the “Bubble Boy Disease.” The treatment has restored immune function to all the children who have been treated to date, transforming their lives and often allowing them to attend school for the first time.

Oxford Biomedica also secured a deal with Novartis to produce the first treatment approved in the U.S. and the E.U. that reprograms a patient’s own immune cells to recognize and kill cancer cells in patients with leukemia and lymphoma. The drug must be specially made for each individual and costs nearly half a million dollars to treat a child with acute lymphoblastic leukemia.

Before the treatment, those children typically had weeks or months to live. After receiving the cell therapy, 81 percent of the children in clinical trials went into remission, and the first patient to receive the treatment is still alive six years later.

“There’s a lot of excitement around what gene therapies can achieve. Being able to save or significantly prolong the life of a child for whom nothing else has worked is incredible,” said James Miskin, Oxford Biomedica’s chief technical officer. “But there’s also been a lot of desire to reduce manufacturing costs to make these transformative therapies more accessible to patients suffering from more common diseases.

Oxford Biomedica’s current challenge is ensuring that it can make enough doses from its LentiVector® platform — the system that delivers engineered genes into human cells — for its own products and for those of its partners. The larger goal is to lower the cost of existing therapies and meet ballooning demand for new ones, including therapies that target larger organs or diseases which affect millions of patients.

“To get democratic and widespread adoption of gene therapy products, we need to drive the economics downward so the cost is reasonable for patients and so that healthcare systems will adopt them,” Slingsby said. “This new collaboration with Microsoft should allow us to discover new insights into how best to configure our systems to further ramp up our production and move in that direction.”

Oxford Biomedica is investing in new facilities and has already managed to improve its output by a factor of ten. To make the next big leap in productivity, it’s looking to the Station B collaboration to better understand, and ultimately engineer, optimal producer cells for its LentiVector platform.

The company is able to meticulously test thousands of combinations of cell lines, genetic material and environmental conditions and pick a winner. But its scientists still can’t say why that one performed better than all the others.

“These screening methods commonly used by pharmaceutical companies get you a result, but they don’t get you understanding,” said Paul Grant, a synthetic biologist who runs the experiments at the Station B lab in Cambridge. “You can’t build on those successes to make the next thing because you don’t really know how you did it. We are building the infrastructure to change that.”

Oxford Biomedica collects many thousands of data points from experimentation and each manufacturing run — from movements of liquid handling robots to conditions inside industrial bioreactors and machines that mix production systems like a cocktail bartender shakes a martini.

The Station B team will first apply its modeling and machine learning expertise to that data to better understand and predict what experimental conditions will produce more of the gene therapy vector. Boosting that manufacturing productivity, producing more doses more reliably with less effort, should help reduce the overall cost of the therapies.

In a second phase, the teams will work to systematically engineer genetic devices — the biological equivalent of computer programs — to enhance helpful interactions and tweak behaviors that can turn the company’s cell lines from reliable performers into superfactories.

Building the Station B platform

Microsoft’s Biological Computation Group has been assembling the Station B platform’s building blocks for years.

Nearly a decade ago, Phillips and colleague Michael Pedersen developed a programming language that compiles biological algorithms to DNA instead of binary code, to influence how a cell behaves. Building on this initial work, Microsoft scientist Boyan Yordanov, who specializes in computer science and biochemistry, worked with the team to develop a prototype platform for designing, implementing and analyzing biological algorithms in cells. It also incorporates the ability to predict behaviors based on training simulation models with data, using a machine learning system developed by Neil Dalchau, a mathematician with a history of exploring diverse biological applications. Grant, a biologist who once studied how zebrafish cells organize to make stripes, uses this prototype to engineer and test genetic constructs to learn how cells make decisions.

Sara-Jane Dunn, a Microsoft scientist and mathematician, also develops computational models to understand how stem cells maintain their ability and readiness to transform into other types of cells: brain, pancreatic, skin, nerve, blood. By reverse engineering that process, scientists in this domain hope to create stem cell therapies to treat a host of illnesses, from regenerating healthy organs to replacing missing neurons that contribute to Alzheimer’s disease.

But influencing biological systems isn’t like programming an operating system or video game. It’s less like writing a recipe — which involves following a logical sequence of steps — than trying to unravel the many interactions and parallel processes that occur in a noisy molecular soup.

“When your cells are trying to decide between something that’s healthy or foreign or deciding when to divide or how to grow, this is essentially information processing at a molecular level,” Dunn said. “We’ve had to come up with new methods to understand this biological computation and how to make the system do what we want it to do.

These screening methods commonly used by pharmaceutical companies get you a result, but they don’t get you understanding. You can’t build on those successes to make the next thing because you don’t really know how you did it. We are building the infrastructure to change that.

The power of the Station B platform lies in pulling all those pieces of the puzzle together in one integrated system, Phillips said. Both initial deployments will occur in labs that are overseen by health, safety, ethical and medical regulators.

“It marries Microsoft’s deep expertise in programming languages, modeling capabilities and machine learning with lab automation and the power of the cloud and intelligent edge — that combination of tools doesn’t exist anywhere in this industry today,” Phillips said.

To solve one key challenge, the platform uses Synthace’s lab automation system to allow users to run experiments from the cloud and precisely replicate each step in complicated scientific protocols.

Synthace’s Antha software allows the user to replace subjective instructions like “shake a test tube vigorously” with digital language that isn’t open to misinterpretation and that lab robots can execute. Building on top of Azure IoT, Antha is a high-level language for describing biological experiments that allows an array of lab machines made by different manufacturers to run them, much like printer drivers allow any make or model of printer to print PDF documents.

That ability to run experiments exactly the same way each time gives users confidence that the results they’re seeing are meaningful, and not just a fluke in the way the experiment happened to be set up that day.

Synthace’s system — which can handle experiments that simultaneously test dozens of different parameters or genetic constructs rather than one or two at a time — speeds up the research process exponentially. Combined with machine learning capabilities, it also gives customers the ability to pose and learn from much more sophisticated lines of inquiry.

“The near infinite power of biology can only be unlocked by bringing software abstraction and automation to biological R&D and manufacturing, and by enabling biologists to build atop their collective work. That is what the Antha platform does successfully,” said Tim Fell, Synthace chief executive officer.

’This could have huge reach’

The Station B platform will be tested first in the lab of Bonnie Bassler, chair of Princeton’s Department of Molecular Biology, a Howard Hughes Medical Institute Investigator and recipient of a MacArthur genius grant, who studies how bacteria wield outsized power by acting as collectives. The Princeton team includes Bassler’s longtime collaborator Ned Wingreen, a physicist and professor in Princeton’s Lewis-Sigler Institute for Integrative Genomics.

“Historically we’ve thought of bacteria as only having harmful behaviors, like infecting us and causing disease, but more recently scientists have discovered the microbiome, a rather magical bacterial community that lives in and on us and that keeps us alive,” Bassler said. “What my lab has always wondered about is how do bacteria manage to either kill us or keep us alive? They’re so tiny.”

Bassler discovered the widespread use of a phenomenon called quorum sensing in the bacterial world. It’s a form of molecular communication that bacteria use to determine when their numbers have reached a critical mass. When they reach the “quorum,” together they trigger behaviors that are only successful when bacteria act as a coordinated group — such as unleashing virulent diseases.

In a proof-of-concept pilot, the team will deploy the Station B platform to investigate how cholera bacteria use quorum sensing to form biofilms, thin layers of bacteria that grow on almost all surfaces. Bacteria living in biofilm communities can be 1000 times more resistant to antibiotics than non-biofilm bacteria.

Princeton researchers will use the Station B platform and Synthace’s lab automation tools to construct and test different versions of two proteins that are key to biofilm formation — which are also genetically programmed to light up. The light allows the scientists to see and measure how much of each protein is produced under many different conditions and in different regions of the biofilm.

Bassler compares the working microbiologists in her lab to master craftspeople, creating elegant and complicated genetic constructs to produce a desired result. But that artisanal process yields only a few prospects at a time and doesn’t allow the team to massively attack the problem.

The Station B platform will be able to build and test dozens of engineered proteins at once — in whatever combinations a researcher can dream up and type into the system for a liquid handling robot to produce. The platform will then help the scientists learn which of the protein constructs behave most like the natural proteins and yield an accurate picture of how biofilm cells organize, Bassler said.

The goal is to build on that basic understanding and find an Achilles heel that might weaken virulent biofilms or increase their sensitivity to antibiotics.

“The platform will allow us to ask more questions, get more results and do more experiments than a graduate student or postdoc, no matter how clever, can do today. So, it gets us to the winning genetic constructs faster,” Bassler said.

Equally important, the platform will also collect and help analyze data from every single lab experiment — including ones that fail, Bassler said. By necessity, scientists have to pursue their most fruitful lines of inquiry, but that can leave an untapped trove of information about why something didn’t succeed.

“If this extra information can help us discover the underlying patterns in what works and what doesn’t work and why, that would be a transformative leap for us,” she said.

The value of deploying the Station B platform in Bassler’s lab is that those researchers have already built an extensive inventory of genetic components, chemical mixtures and models in the years that they’ve been studying bacteria like cholera.

If the team can begin to uncover the rules and principles that govern those systems, Wingreen said, they may be able to program them in transferrable ways. That could potentially enable a doctor who studies cancer or an engineer working on low-carbon fuels to imagine a genetic construct that they’d love to test and get an exact blueprint for assembling it — without spending years at a lab bench.

“From my perspective, this could have a huge reach,” Wingreen said. “Just as the tech sector was democratized by software that lets you ask for what you want in a microchip design and have someone make it, we need that same revolution in biology.”

Top image: Breech Odu works in an Oxford Biomedica lab, where the Station B platform will be deployed to accelerate discovery and manufacturing of gene and cell therapies. Photo by Jonathan Banks.

Related:

Jennifer Langston writes about Microsoft research and innovation. Follow her on Twitter."
Microsoft_News,https://news.microsoft.com/source/features/ai/ai-subseasonal-weather-forecast/,,Researchers turn to AI in a bid to improve weather forecasts,"As winter drags on, some people wonder whether to pack shorts for a late-March escape to Florida, while others eye April temperature trends in anticipation of sowing crops. Water managers in the western U.S. check for the possibility of early-spring storms to top off mountain snowpack that is crucial for irrigation, hydropower and salmon in the summer months.

Unfortunately, forecasts for this timeframe — roughly two to six weeks out — are a crapshoot, noted Lester Mackey, a statistical machine learning researcher at Microsoft’s New England research lab in Cambridge, Massachusetts. Mackey is bringing his expertise in artificial intelligence to the table in a bid to increase the odds of accurate and reliable forecasts.

“The subseasonal regime is where forecasts could use the most help,” he said.

Mackey knew little about weather and climate forecasting until Judah Cohen, a climatologist at Atmospheric and Environmental Research, a Verisk business that consults about climate risk in Lexington, Massachusetts, reached out to him for help using machine learning techniques to tease out repeating weather and climate patterns from mountains of historical data as a way to improve subseasonal and seasonal forecast models.

The preliminary machine learning based forecast models that Mackey, Cohen and their colleagues developed outperformed the standard models used by U.S. government agencies to generate subseasonal forecasts of temperature and precipitation two to four weeks out and four to six weeks out in a competition sponsored by the U.S. Bureau of Reclamation.

Mackey’s team recently secured funding from Microsoft’s AI for Earth initiative to improve and refine its technique with an eye toward advancing the technology for the social good.

“Lester is working on this because it is a hard problem in machine learning, not because it is a hard problem in weather forecasting,” noted Lucas Joppa, Microsoft’s chief environmental officer who runs the AI for Earth program, as he explained why his group is helping fund the research. “It just so happens that the techniques he is interested in exploring have huge applicability in weather forecasting, which happens to have huge applicability in broader societal and economic domains.”

Photo by Getty Images.

AI on the brain

Mackey said current weather models perform well up to about seven days in advance, and climate forecast models get more reliable as the time horizon extends from seasons to decades. Subseasonal forecasts are a middle ground, relying on a mix of variables that impact short-term weather such as daily temperature and wind and seasonal factors such as the state of El Niño and the extent of sea ice in the Arctic.

Cohen contacted Mackey out of a belief that machine learning, the arm of AI that encompasses recognizing patterns in statistical data to make predictions, could help improve his method of generating subseasonal forecasts by gleaning insights from troves of historical weather and climate data.

“I am basically doing something like machine learned pattern recognition in my head,” explained Cohen, noting that weather patterns repeat throughout the seasons and from year to year and that therefore pattern recognition can and should inform longer-term forecasts. “I thought maybe I can improve on what I am doing in my head with some of the machine learning techniques that are out there.”

Using patterns in historical weather data to predict the future was standard practice in weather and climate forecast generation until the 1980s. That’s when physical models of how the atmosphere and oceans evolve began to dominate the industry. These models have grown in popularity and sophistication with the exponential rise in computing power.

“Today, all of the major climate centers employ massive supercomputers to simulate the atmosphere and oceans,” said Mackey. “The forecasts have improved substantially over time, but they make relatively little use of historical data. Instead, they ingest today’s weather conditions and then push forward their differential equations.”

Photo by Getty Images.

Forecast competition

As Mackey and Cohen were discussing a research collaboration, Cohen received notice of a competition sponsored by the U.S. Bureau of Reclamation to improve subseasonal forecasts of temperature and precipitation in the western U.S. The government agency is interested in improved subseasonal forecasts to better prepare water managers for shifts in hydrologic regimes, including the onset of drought and wet weather extremes.

“I said, ‘Hey, what do you think about trying to enter this competition as a way to motivate us, to make some progress,’” recalled Cohen.

Mackey, who was an assistant professor of statistics at Stanford University in California prior to joining Microsoft’s research organization and remains an adjunct professor at the university, invited two graduate students to participate on the project. “None of us had experience doing work in this area and we thought this would be a great way to get our feet wet,” he said.

Over the course of the 13-month competition, the researchers experimented with two types of machine learning approaches. One combed through a kitchen sink of data containing everything from historical temperature and precipitation records to data on sea ice concentration and the state of El Niño as well as an ensemble of physical forecast models. The other approach focused only on historical data for temperature when forecasting temperature or precipitation when forecasting precipitation.

“We were making forecasts every two weeks and between those forecasts we were acquiring new data, processing it, building some of the infrastructure for testing out new methods, developing methods and evaluating them,” Mackey explained. “And then every two weeks we had to stop what we were doing and just make a forecast and repeat.”

Toward the end of the competition, Mackey’s team discovered that an ensemble of both machine learning approaches performed better than either alone.

Final results of the competition were announced today. Mackey, Cohen and their colleagues captured first place in forecasting average temperature three to four weeks in advance and second place in forecasting total precipitation five and six weeks out.

Photo by Getty Images.

Forecast for the future

After the competition, the collaborators combined their ensemble of machine learning approaches with the standard models used by U.S. government agencies to generate subseasonal forecasts and found that the combined models improved the accuracy of the operational forecast by between 37 and 53 percent for temperature and 128 and 154 percent for precipitation. These results are reported in a paper the team posted on arXiv.org.

“I think we will continue to see these types of approaches be further refined and increase in the breadth of their use within the field of forecasting,” said Kenneth Nowak, water availability research coordinator with the U.S. Bureau of Reclamation, who organized the forecast rodeo. He added that government agencies will “look for opportunities to leverage” machine learning in future generations of operational forecast models.

Microsoft’s AI for Earth program is providing funding to Mackey and colleagues to hire an intern to expand and refine their machine learning based forecasting technique. The collaborators also hope that other machine learning researchers will be drawn to the challenge of cracking the code to accurate and reliable subseasonal forecasts. To encourage these efforts, they have made available to the public the dataset they created to train their models.

Cohen, who kicked off the collaboration with Mackey out of a curiosity about the potential impact of AI on subseasonal to seasonal climate forecasts, said, “I see the benefit of machine learning, absolutely. This is not the end; more like the beginning. There is a lot more that we can do to increase its applicability.”

Related:

John Roach writes about Microsoft research and innovation. Follow him on Twitter.

Top image: Photo by Getty Images."
Microsoft_News,https://news.microsoft.com/source/features/innovation/empathy-innovation-accessibility/,,Empathy and innovation: How Microsoft’s cultural shift is leading to new product development,"The young Microsoft software engineer had just moved to the U.S. and was trying her best to stay in close touch with her parents back home, calling them on Skype every week.

But their internet connection in India was poor, and Swetha Machanavajhala, deaf since birth, struggled to read their lips over the glitchy video. She always had to ask her parents to turn off the lights in the background to help her focus better on their faces.

“I kept thinking, ‘Why can’t we build technology that can do this for us instead?’” Machanavajhala recalled. “So I did.”

It turned out her background-blurring feature was good for privacy reasons as well, helping to hide messy offices during video conference calls or curious café customers during job interviews. So Machanavajhala was one of the people who influenced the decision to develop similar features for Microsoft Teams and Skype, and she soon found herself catapulted into the spotlight at Microsoft – as well as into the company’s work on inclusion, a joy to experience after having been excluded at a previous job where her deafness made it hard to fully participate.

Microsoft employees say those twists and turns of innovation – aiming for A and ending up with a much broader B – have become more common at Microsoft in the five years since Satya Nadella was appointed chief executive officer.

Nadella’s immediate push to embolden employees to be more creative has been exemplified by the company’s annual hackathon. Machanavajhala and others say the event has helped spark a revival where employees feel energized to innovate year-round and to seek support from their managers for their ideas – even if those have nothing to do with their day jobs.

“The company has changed culturally,” Michael A. Cusumano, a professor at the Massachusetts Institute of Technology’s Sloan School of Management who wrote a book about Microsoft 20 years ago, recently told The New York Times. “Microsoft is an exciting place to work again.”

Chris Kauffman, a marketing manager in product licensing who has worked for Microsoft for 13 years, said Nadella’s focus on fostering collaboration was a turning point for her, as she noticed silos being torn down. Kauffman also realized the advent of artificial intelligence (AI) could help business people like her broach the realm of engineers and IT specialists. She and her team capitalized on both of those developments to create a chatbot and virtual colleague, answering thousands of licensing questions from around the world and helping to handle the accelerated pace of Azure cloud computing service updates.

“I went to my first hackathon three years ago and fell back in love with Microsoft,” Kauffman said. “I realized that I now have permission to talk to anyone I want to. I’m no longer limited by my job function or level. And my experience with the chatbot is a great example of how technology can be democratized and used by everybody.”

That new openness has led to an explosion in new products or fine-tuned improvements across Microsoft, for customers as well as for internal use. Employees say the resurgence is showing up both in product improvements and internal events such as TechFest, an annual showcase of Microsoft research that takes place in a few weeks.

Nadella, only the third chief executive in Microsoft’s four decades, made his innovation intentions clear from the first email he sent to employees on his first day as CEO in February 2014. In short order, he had clarified his vision for the company to “empower every person and every organization on the planet to achieve more.” His book “Hit Refresh,” published in 2017, emphasized empathy as the way to accomplish that goal.

The message: Empathy leads to understanding and collaboration, which helps innovation push its way through the often-messy journey toward helpful products.

“My personal philosophy and my passion … is to connect new ideas with a growing sense of empathy for other people,” Nadella wrote. And later, “My approach is to lead with a sense of purpose and pride in what we do, not envy or combativeness.”

That’s something Rene Brandel experienced firsthand.

Brandel joined Microsoft two years ago on the Skype team in Prague and was impressed to find that employees there were encouraged to take a couple days off every quarter to work on new ideas or interesting concepts that previously lacked support.

A project from one such hackathon quickly gained traction, and Brandel and his colleagues soon launched an all-in-one service for job interviews for developers, by combining Skype and Visual Studio. Skype Interviews allows recruiters to observe coding skills during interviews with just one click, getting rid of the awkwardness of downloading separate programs and messing with logistics. The team then developed a scheduling tool that proved even more popular and is now being used by mentoring programs, consulting services, small businesses and others looking for an easier way to set up meetings, without the back-and-forth hassle of email calendaring.

Brandel said the product’s quick launch – from hackathon to shipment in only one month – was a direct result of Nadella’s emphasis on collaboration. The CEO led the way after he saw a description of the project by sending an email connecting Brandel’s team with others who could help – and they did, smoothing out wrinkles within hours.

“There’s this feeling of empathy among teams now to try to make each other successful, instead of so much internal competition,” Brandel said. “I’ve never talked with Satya in person. But he fosters this culture of learning and of respectfully questioning each other, to try to understand the other perspectives. The whole emphasis on empathy is really shining through in situations where there’s a dire need to innovate and create something individuals need and want.

Success always hinges on passionate people who care about something greater than themselves and can motivate and attract like-minded collaborators with unique skill sets.

The mantra of empowering everyone to do more prompted a flood of innovative solutions that use AI for people with disabilities – Seeing AI, Soundscape, Immersive Reader, Eye Control and live captions for Skype and PowerPoint, to name just a few. Support for those projects is rooted not only in the desire to help people achieve more, but also to help Microsoft achieve its business objectives.

“People with disabilities are the ultimate early adopters and in many ways are ahead of the curve in terms of tech,” said Saqib Shaikh, a software engineer in London who leads Microsoft’s Seeing AI research project. “They have a lot more to gain so are willing to try things out a lot earlier on, when things aren’t quite ready yet, and then they help that technology mature into something for mainstream use.”

Until 2014, Shaikh had tried to hide his blindness as much as possible at work, saying he “just wanted to be a regular developer.” But then he noticed “a buzz” around the new CEO and Nadella’s talk of culture change. That encouraged him to see his disability as his strength and to experiment with a dream he’d had since his university days, of eyeglasses that could see for him and tell him what was happening around him. A collaborative effort with colleagues resulted in a smartphone app called Seeing AI that can read menus and documents, identify currency, recognize people – along with their facial expressions and emotions – and more.

When the app launched in 2017, the team was swamped with messages from the blind community as well as from sighted people and people with learning disabilities who all appreciated its usefulness in different ways.

A teacher who is blind taught Seeing AI to recognize his students and then put his smartphone on a stand pointing toward the door, where it calls out the names of the kids as they arrive; a sighted system administrator started using the app to read the serial numbers on the backs of computers, rather than having to crawl under desks; and a blind man in Puerto Rico used it to help him navigate after a hurricane – if Seeing AI recognized the space in front of him as a pathway, then he knew it was clear of debris. The technology behind the app is being used to improve other AI projects at Microsoft as well.

“Disability is a driver for innovation, not a charity case,” Shaikh said. “It’s a field worth watching for what comes next.

Amos Miller had a similar experience with his Soundscape app, which provides a map in 3D sound. Miller, a product strategist with Microsoft Research, envisioned his app helping people with vision loss to participate more fully in their surroundings as they navigate through cities, with non-textual audio cues that guide without intruding. But when a group of sighted Tennessee high-schoolers got their hands on it for an audio scavenger hunt earlier this year, they surprised him with ideas for how it could help them and their friends with challenges such as reading difficulties, attention deficit disorder, post-traumatic stress disorder and anxiety.

Innovation often blooms from personal experiences, highlighting the importance of diversity in the workforce as well as getting out of “the bubble” of company headquarters.

Miller, who lost his sight to a genetic disease that left him blind by the time he’d finished his computer science degree, made sure his team of developers and engineers designed Soundscape out in the field, away from their computer screens. That helped them better understand and meet the needs of their customers – such as building the app to work hands-free so a user can hold an umbrella and a guide dog’s harness, for example.

“Diversity of thought and creativity will be imperative to designing the technology of the future,” said Jill Bender, a software engineer for Azure IoT who worked on a hackathon project to create a tool that evaluates job descriptions to help weed out language that would only appeal to limited groups. The company’s Dynamics 365 for Talent product team has been looking at how that work could be incorporated into recruiting products.

Finding time to get out and pursue one’s passions and turn them into helpful tools isn’t always easy, and the paths of innovation are often crooked. But many at Microsoft now say they’re heartened by the efforts they see to smooth out the process.

Click here to load media

“There’s a good culture now around empowering individuals to come up with new ideas, so that’s the first step, but everyone is fighting their own battle to figure out how to go beyond that,” said Shaikh, whose boss gave him two months off his job developing features for Bing and Cortana in order to work on a presentation that eventually became Seeing AI. “It hasn’t always been rosy, and that’s the reality of innovation. But it’s becoming easier for people to change jobs and find ways to work on the projects they care about.”

The unexpected zigzags inherent in innovation mean it flourishes under leaders who are flexible and are comfortable with uncertainty and change, and who aren’t looking for an immediate financial payoff.

“Innovation is a non-linear process,” Miller said. “You can’t say to innovation, ‘Start over there when I tell you to.’ And there’s a risk of killing innovation by over-systematizing it.”

When Harish Kulkarni joined Microsoft Research’s NeXT Enable team, the explicit job definition was to create a wheelchair that could be controlled by tracking the user’s eye movements. It had been a challenge given to Microsoft by former NFL player Steve Gleason, who is paralyzed by amyotrophic lateral sclerosis, or ALS. An outgrowth of that project was an eye-tracking app to help people with ALS to better communicate with their loved ones, since the disease eventually robs them of their ability to talk.

The team began spending more time with various groups of people living with ALS, and they began to understand “a long trail of problems” that tech wasn’t addressing, Kulkarni said. Ultimately, people with motor and speech impairments wanted to use Windows the same way others do – to compose documents, manage their finances, play games, create music, make Skype calls with loved ones and more. But Kulkarni’s team wasn’t big enough to write all the apps necessary to meet those needs, and matters were complicated because each company making eye-tracking hardware had its own software.

[Satya Nadella] fosters this culture of learning and of respectfully questioning each other, to try to understand the other perspectives. The whole emphasis on empathy is really shining through in situations where there’s a dire need to innovate and create something individuals need and want.

Much of Kulkarni’s 18-year tenure with Microsoft had been spent in operating systems, however, so he understood how hardware gets integrated and knew the right people to reach out to. He also took advantage of Nadella’s “positive and very refreshing” emphasis on accessibility and the emerging value of “grass-roots innovation” to bring multiple parties together.

He and Eric Badger, who heads up the Windows Text Input development team, partnered on a prototype to introduce the feature to Windows leadership. Once the hardware manufacturers saw the close collaboration among Microsoft teams, they agreed to standardize their products, and this “little side project” by Kulkarni’s group was added to Windows last year for a whole new feature called Eye Control that works with any software operating within that system.

It’s not only bringing people with disabilities back into everyday communication with loved ones and business partners but could also help anyone who needs to access information or connect electronically without the use of their hands – such as cooks who are elbow–deep in dough yet need to look up a recipe online. And researchers from different teams are exploring ways the feature could help people conquer reading difficulties, boost productivity and more.

“This cross-pollination of ideas is happening more now, and the important thing is fostering a culture that actually supports that,” said Ann Paradiso, who’s in charge of user experience for the Enable team and has been with Microsoft for 17 years. “There’s a shift that’s been happening where leadership sees that the amount of problem-solving that goes into designing for the most constrained situations actually leads to all sorts of innovation that benefits a broader audience.

“Gnarly, impossible problems require creativity, resourcefulness, grit and resolve to work through,” she said. “And success always hinges on passionate people who care about something greater than themselves and can motivate and attract like-minded collaborators with unique skill sets.”

Paradiso and her team have made plenty of prototypes that failed and have seen lots of closets in the homes of people with disabilities that were filled with devices that didn’t end up being helpful. But none of that experience is wasted when different groups collaborate and end up making a huge impact, Paradiso said. Failures are never thrown away, she said, but instead the lessons are absorbed and projects are adapted to solve different problems in other contexts.

“Eye Control was just this accidental twist that the hackathon wheelchair project took,” Kulkarni said, “but what we have now makes everything else possible.”

Top image: Microsoft software engineer Swetha Machanavajhala demonstrates the background-blurring feature on Microsoft Teams on Microsoft’s Redmond, Washington, campus. Photo by Scott Eklund/Red Box Pictures.

Related:"
Microsoft_News,https://news.microsoft.com/source/features/digital-transformation/irel8-partners-veterans-artists-reduce-mental-illness-stigma/,,iRel8 partners with groups like veterans and artists to help reduce the stigma of mental illness,"For years, the soldier lived in pain from combat injuries in Iraq. His need for painkillers developed into an addiction, which made him feel ashamed, particularly because he was an active-duty member of the elite U.S. Army Special Forces. He shunned treatment, hid his condition from his commander and became so despondent that he considered suicide.

But last year, the soldier began confiding to an anonymous chat group through the mobile app iRel8. Composed of fellow, unnamed Green Berets, the group understood the soldier’s anguish and encouraged him to get help. He’s now seven months sober.

“We convinced him to go to his commander and come clean,” says Ignacio Garza, executive director of the Special Forces Foundation, a Colorado-based nonprofit that supports Special Forces members and their families. The organization connected the soldier with a Green Beret version of iRel8, a digital social network designed for mental wellness.

Veteran suicide prevention and mental health support have become top public health priorities for many military support groups and the U.S. Department of Veterans Affairs. A 2018 study by the agency found that the suicide rate of veterans is 1.5 times higher than that of non-veteran adults, with more than 6,000 veteran suicides a year between 2008 and 2016.

“The No. 1 motto for special operations forces is: ‘Humans are more important than hardware,’” says Garza. “Tools like iRel8 help guys get the help they need, so they can serve at a high level. It gets them to open up. Once they start talking about their problems, they see they’re not alone. They can get past the stigma and get professional help.”

Launched last year, iRel8 connects people in an anonymous, peer-to-peer forum similar in philosophy to in-person recovery groups. The app enables users to access secure chat rooms from their phones to help each other with anxiety, depression and other mental health issues without fear of judgement.

Anyone can use iRel8 for a small subscription fee. But the app is largely growing due to partnerships with the Special Forces Foundation and other organizations that provide, or want to provide, mental health support.

iRel8 partners can create a customized, exclusive app experience for their members; they include groups that work with first responders, youths of color, athletes, artists and inmates transitioning out of prison.

Based in the Denver area, Jeff Dorchester and Dion Gonzales co-founded iRel8 after struggling alone with personal and family mental health issues. Dorchester had major depression after a heart condition diagnosis and Gonzales was coping with the suicide attempt of a family member. When the longtime friends and tech collaborators finally confided in one another, they were inspired to create something to help others.

“Jeff and I talk about this a lot: Suicide was one of the reasons we built this app. We believe it will save and improve lives. We also see the need to help people on a global scale,” says Gonzales, citing a World Economic Forum statistic that one in six people have experienced a mental health or substance abuse disorder. In the United States, suicide is the 10th leading cause of death and the second leading cause of death among people 10 to 34 years old, according to the National Institute of Mental Health.

iRel8 recently migrated the app to Microsoft Azure to reach more people globally and grow with innovation. Built with Visual Studio Code, the app is now live in 54 languages through the Microsoft Translator API in Azure Cognitive Services. The co-founders also want to use artificial intelligence (AI) to weed out inappropriate comments, if they become a problem as the social network grows. (Such comments are currently not a problem, as the app’s monthly fee wards off trolls).

Gonzales and Dorchester also want to train a model with AI to recognize key phrases in mental health crises and escalate a response from a psychologist and potentially 911, or other emergency services.

“We know crisis doesn’t have an appointment and will not wait for your Thursday support group,” says Gonzales. “So if someone says, ‘I’m out of here, I’m going to kill myself,’ a bot is listening all the time and can notify a human to jump in and respond.”

Ultimately, iRel8 views phones, modern software and AI as a bridge to – not a replacement of – human connection and professional care.

“With the advancement of technology and the massive stack that Microsoft offers, we can use it to change people’s lives,” says Dorchester. “Peers go in the app, help each other, heal each other and relate with folks who have ‘been there, done that.’”

For Dave Bellevue, a New York City musician often on the road, the app has been a valuable outlet for coping with the anxieties of touring. The anonymity allows him to be open and honest, without jeopardizing his career as a well-known artist.

“It’s extremely helpful, because sometimes you feel isolated,” says Bellevue, a lead singer with the alt-hip hop band Oxymorrons. “As a musician, I’m always in and out of situations I would consider mentally unstable, so it’s good to talk to people who can give you a line into reality.”

Bellevue learned of the app at an event hosted by i Live For…, a Washington, D.C.-based nonprofit that partners with iRel8. The organization produces films, events and social media campaigns that reduce mental illness stigma for millennials of color around the world.

Nikki Webber Allen founded the organization after the suicide of her nephew, Paul R. Webber V, a bright, young, African-American college student, in 2013. She wanted to help other young people of color, who are more likely to experience major depression than white people, but less likely to get help.

“When you are from a population that’s already marginalized, you don’t want to add another reason to be discriminated against. And if you’re struggling to pay the bills or put food on the table, taking the time and money to deal with your mental health is seen as a luxury,” says Webber Allen. An African-American multimedia producer, she has shared her own struggle with depression and anxiety in a TED talk viewed more than 1.9 million times.

The financial cost of professional therapy is another barrier to getting help in many communities of color. i Live For… gives members free subscriptions to iRel8, which Webber Allen says is a safe, affordable and always accessible tool.

“People can get help and support, and no one has to know who they are,” she says.

Call the National Suicide Prevention Lifeline, a free, 24/7 confidential service, at 1-800-273-8255 if you or a loved one is in a suicidal crisis or emotional distress.

Top photo: A Special Forces Foundation board member, center, with other Green Berets in Afghanistan in 2019. (Photo courtesy of the Special Forces Foundation)"
Microsoft_News,https://news.microsoft.com/source/features/ai/this-week-in-machine-learning-podcast/,,Podcast series explores how AI can help solve society’s toughest challenges,"Click here to load media

A podcast series sponsored by Microsoft on how artificial intelligence is helping people solve previously intractable societal challenges launches Monday, Feb. 4, on This Week in Machine Learning and AI. The six-episode “AI For the Benefit of Society with Microsoft” series highlights how AI breakthroughs are advancing work in environmental sustainability, precision medicine, accessibility and life-saving humanitarian assistance.

Hosted by Sam Charrington, the podcast episodes cover technologies and people using AI to pinpoint communities that are at risk of famine before it strikes, help children with autism get additional communication tools, fight climate change through sustainable forest management and develop chatbots to efficiently connect refugees with legal services. They also explore cross-cutting themes around AI and ethics, including how to account for bias in data, ensure new technologies work for the broadest range of users and build a culture of responsible innovation.

Episodes will be available on the following dates at the This Week in Machine Learning and AI website and on Spotify, iTunes and Google Play.

Feb. 4: AI for Humanitarian Action (podcast, transcript)

With Justin Spelhaug, Microsoft general manager for Technology for Social Impact

(podcast, transcript) With Justin Spelhaug, Microsoft general manager for Technology for Social Impact Feb. 6: AI for Accessibility (podcast, transcript)

With Wendy Chisholm, Microsoft principal accessibility architect, and AI for Accessibility grantee InnerVoice

(podcast, transcript) With Wendy Chisholm, Microsoft principal accessibility architect, and AI for Accessibility grantee InnerVoice Feb. 8: AI for Earth (podcast, transcript)

With Lucas Joppa, Microsoft chief environmental officer, and AI for Earth grantee SilviaTerra

(podcast, transcript) With Lucas Joppa, Microsoft chief environmental officer, and AI for Earth grantee SilviaTerra Feb. 18: AI in Healthcare (podcast, transcript)

With Peter Lee, corporate vice president, Microsoft Healthcare

(podcast, transcript) With Peter Lee, corporate vice president, Microsoft Healthcare Feb. 20: Fairness in Machine Learning (podcast, transcript)

With Hanna Wallach, principal researcher at Microsoft Research

(podcast, transcript) With Hanna Wallach, principal researcher at Microsoft Research Feb. 22: Human-Centered Design (podcast, transcript)

With Mira Lane, Microsoft partner director–ethics and society

Related:

Jennifer Langston writes about Microsoft research and innovation. Follow her on Twitter."
