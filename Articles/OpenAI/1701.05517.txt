7
1
0
2

n
a
J

9
1

]

G
L
.
s
c
[

1
v
7
1
5
5
0
.
1
0
7
1
:
v
i
X
r
a

UnderreviewasaconferencepaperatICLR2017PIXELCNN++:IMPROVINGTHEPIXELCNNWITHDISCRETIZEDLOGISTICMIXTURELIKELIHOODANDOTHERMODIFICATIONSTimSalimans,AndrejKarpathy,XiChen,DiederikP.Kingma{tim,karpathy,peter,dpkingma}@openai.comABSTRACTPixelCNNsarearecentlyproposedclassofpowerfulgenerativemodelswithtractablelikelihood.HerewediscussourimplementationofPixelCNNswhichwemakeavailableathttps://github.com/openai/pixel-cnn.Ourimplementationcontainsanumberofmodiﬁcationstotheoriginalmodelthatbothsimplifyitsstructureandimproveitsperformance.1)Weuseadiscretizedlogisticmixturelikelihoodonthepixels,ratherthana256-waysoftmax,whichweﬁndtospeeduptraining.2)Weconditiononwholepixels,ratherthanR/G/Bsub-pixels,simplifyingthemodelstructure.3)Weusedownsamplingtoefﬁcientlycapturestructureatmultipleresolutions.4)Weintroduceadditionalshort-cutconnec-tionstofurtherspeedupoptimization.5)Weregularizethemodelusingdropout.Finally,wepresentstate-of-the-artloglikelihoodresultsonCIFAR-10todemon-stratetheusefulnessofthesemodiﬁcations.1INTRODUCTIONThePixelCNN,introducedbyvandenOordetal.(2016b),isagenerativemodelofimageswithatractablelikelihood.Themodelfullyfactorizestheprobabilitydensityfunctiononanimagexoverallitssub-pixels(colorchannelsinapixel)asp(x)=Qip(xi|x<i).Theconditionaldistributionsp(xi|x<i)areparameterizedbyconvolutionalneuralnetworksandallshareparameters.ThePixel-CNNisapowerfulmodelasthefunctionalformoftheseconditionalsisveryﬂexible.InadditionitiscomputationallyefﬁcientasallconditionalscanbeevaluatedinparallelonaGPUforanob-servedimagex.Thankstotheseproperties,thePixelCNNrepresentsthecurrentstate-of-the-artingenerativemodelingwhenevaluatedintermsoflog-likelihood.Besidesbeingusedformodelingimages,thePixelCNNmodelwasrecentlyextendedtomodelaudio(vandenOordetal.,2016a),video(Kalchbrenneretal.,2016b)andtext(Kalchbrenneretal.,2016a).Foruseinourresearch,wedevelopedourowninternalimplementationofPixelCNNandmadeanumberofmodiﬁcationstothebasemodeltosimplifyitsstructureandimproveitsperformance.Wenowreleaseourimplementationathttps://github.com/openai/pixel-cnn,hopingthatitwillbeusefultothebroadercommunity.OurmodiﬁcationsarediscussedinSection2,andevaluatedexperimentallyinSection3.State-of-the-artlog-likelihoodresultsconﬁrmtheiruseful-ness.2MODIFICATIONSTOPIXELCNNWenowdescribethemostimportantmodiﬁcationswehavemadetothePixelCNNmodelarchite-cureasdescribedbyvandenOordetal.(2016c).Forcompletedetailsseeourcodereleaseathttps://github.com/openai/pixel-cnn.2.1DISCRETIZEDLOGISTICMIXTURELIKELIHOODThestandardPixelCNNmodelspeciﬁestheconditionaldistributionofasub-pixel,orcolorchannelofapixel,asafull256-waysoftmax.Thisgivesthemodelalotofﬂexibility,butitisalsoverycostlyintermsofmemory.Moreover,itcanmakethegradientswithrespecttothenetworkparameters1 
 
 
 
 
 
UnderreviewasaconferencepaperatICLR2017verysparse,especiallyearlyintraining.Withthestandardparameterization,themodeldoesnotknowthatavalueof128isclosetoavalueof127or129,andthisrelationshipﬁrsthastobelearnedbeforethemodelcanmoveontohigherlevelstructures.Intheextremecasewhereaparticularsub-pixelvalueisneverobserved,themodelwilllearntoassignitzeroprobability.Thiswouldbeespeciallyproblematicfordatawithhigheraccuracyontheobservedpixelsthantheusual8bits:Intheextremecasewhereveryhighprecisionvaluesareobserved,thePixelCNN,initscurrentform,wouldrequireaprohibitiveamountofmemoryandcomputation,whilelearningveryslowly.Wethereforeproposeadifferentmechanismforcomputingtheconditionalprobabilityoftheobserveddiscretizedpixelvalues.Inourmodel,likeintheVAEofKingmaetal.(2016),weassumethereisalatentcolorintensityνwithacontinuousdistribution,whichisthenroundedtoitsnearest8-bitrepresentationtogivetheobservedsub-pixelvaluex.Bychoosingasimplecontinuousdistributionformodelingν(likethelogisticdistributionasdonebyKingmaetal.(2016))weobtainasmoothandmemoryefﬁcientpredictivedistributionforx.Here,wetakethiscontinuousunivariatedistributiontobeamixtureoflogisticdistributionswhichallowsustoeasilycalculatetheprobabilityontheobserveddiscretizedvaluex,asshowninequation(2).Forallsub-pixelvaluesxexceptingtheedgecases0and255wehave:ν∼KXi=1πilogistic(µi,si)(1)P(x|π,µ,s)=KXi=1πi[σ((x+0.5−µi)/si)−σ((x−0.5−µi)/si)],(2)whereσ()isthelogisticsigmoidfunction.Fortheedgecaseof0,replacex−0.5by−∞,andfor255replacex+0.5by+∞.Ourprovidedcodecontainsanumericallystableimplementationforcalculatingthelogoftheprobabilityinequation2.Ourapproachfollowsearlierworkusingcontinuousmixturemodels(Domkeetal.,2008;Theisetal.,2012;Uriaetal.,2013;Theis&Bethge,2015),butavoidsallocatingprobabilitymasstovaluesoutsidethevalidrangeof[0,255]byexplicitlymodelingtheroundingofνtox.Inaddi-tion,wenaturallyassignhigherprobabilitytotheedgevalues0and255thantotheirneighboringvalues,whichcorrespondswellwiththeobserveddatadistributionasshowninFigure1.Experi-mentally,weﬁndthatonlyarelativelysmallnumberofmixturecomponents,say5,isneededtoaccuratelymodeltheconditionaldistributionsofthepixels.Theoutputofournetworkisthusofmuchlowerdimension,yieldingmuchdensergradientsofthelosswithrespecttoourparameters.Inourexperimentsthisgreatlyspedupconvergenceduringoptimization,especiallyearlyonintrain-ing.However,duetotheotherchangesinourarchitecturecomparedtothatofvandenOordetal.(2016c)wecannotsaywithcertaintythatthiswouldalsoapplytotheoriginalPixelCNNmodel.Figure1:Marginaldistributionofallsub-pixelvaluesinCIFAR-10.Theedgevalueof255ismuchmorefrequentthanitsneighbouringvalues:Thisiseasytomodelusingourroundingbasedapproach,butharderusingcontinuousortruncateddistributions.2UnderreviewasaconferencepaperatICLR20172.2CONDITIONINGONWHOLEPIXELSThepixelsinacolorimageconsistofthreerealnumbers,givingtheintensitiesofthered,blueandgreencolors.TheoriginalPixelCNNfactorizesthegenerativemodeloverthese3sub-pixels.Thisallowsforverygeneraldependencystructure,butitalsocomplicatesthemodel:besideskeepingtrackofthespatiallocationoffeaturemaps,wenowhavetoseparateoutallfeaturemapsin3groupsdependingonwhetherornottheycanseetheR/G/Bsub-pixelofthecurrentlocation.Thisaddedcomplexityseemstobeunnecessaryasthedependenciesbetweenthecolorchannelsofapixelarelikelytoberelativelysimpleanddonotrequireadeepnetworktomodel.Therefore,weinsteadconditiononlyonwholepixelsupandtotheleftinanimage,andoutputjointpredictivedistributionsoverall3channelsofapredictedpixel.Thepredictivedistributiononapixelitselfcanbeinterpretedasasimplefactorizedmodel:Weﬁrstpredicttheredchannelusingadiscretizedmixtureoflogisticsasdescribedinsection2.1.Next,wepredictthegreenchannelusingapredictivedistributionofthesameform.Hereweallowthemeansofthemixturecomponentstolinearlydependonthevalueoftheredsub-pixel.Finally,wemodelthebluechannelinthesameway,whereweagainonlyallowlineardependencyontheredandgreenchannels.Forthepixel(ri,j,gi,j,bi,j)atlocation(i,j)inourimage,thedistributionconditionalonthecontextCi,j,consistingofthemixtureindicatorandthepreviouspixels,isthusp(ri,j,gi,j,bi,j|Ci,j)=P(ri,j|µr(Ci,j),sr(Ci,j))×P(gi,j|µg(Ci,j,ri,j),sg(Ci,j))×P(bi,j|µb(Ci,j,ri,j,gi,j),sb(Ci,j))µg(Ci,j,ri,j)=µg(Ci,j)+α(Ci,j)ri,jµb(Ci,j,ri,j,gi,j)=µb(Ci,j)+β(Ci,j)ri,j+γ(Ci,j)bi,j,(3)withα,β,γscalarcoefﬁcientsdependingonthemixturecomponentandpreviouspixels.Themixtureindicatorissharedacrossall3channels;i.e.ourgenerativemodelﬁrstsamplesamix-tureindicatorforapixel,andthensamplesthecolorchannelsone-by-onefromthecorrespondingmixturecomponent.HadweusedadiscretizedmixtureofunivariateGaussiansforthesub-pixels,insteadoflogistics,thiswouldhavebeenexactlyequivalenttopredictingthecompletepixelusinga(discretized)mixtureof3-dimensionalGaussianswithfullcovariance.ThelogisticandGaus-siandistributionsareverysimilar,sothisisindeedveryclosetowhatweendupdoing.Forfullimplementationdetailswerefertoourcodeathttps://github.com/openai/pixel-cnn.2.3DOWNSAMPLINGVERSUSDILATEDCONVOLUTIONTheoriginalPixelCNNonlyusesconvolutionswithsmallreceptiveﬁeld.Suchconvolutionsaregoodatcapturinglocaldependencies,butnotnecessarilyatmodelinglongrangestructure.Al-thoughweﬁndthatcapturingtheseshortrangedependenciesisoftenenoughforobtainingverygoodlog-likelihoodscores(seeTable2),explicitlyencouragingthemodeltocapturelongrangedependenciescanimprovetheperceptualqualityofgeneratedimages(compareFigure3andFig-ure5).Onewayofallowingthenetworktomodelstructureatmultipleresolutionsistointroducedilatedconvolutionsintothemodel,asproposedbyvandenOordetal.(2016a)andKalchbren-neretal.(2016b).Here,weinsteadproposetousedownsamplingbyusingconvolutionsofstride2.Downsamplingaccomplishesthesamemulti-resolutionprocessingaffordedbydilatedconvo-lutions,butatareducedcomputationalcost:wheredilatedconvolutionsoperateoninputofeverincreasingsize(duetozeropadding),downsamplingreducestheinputsizebyafactorof4(forstrideof2in2dimensions)ateverydownsampling.Thedownsideofusingdownsamplingisthatitlosesinformation,butwecancompensateforthisbyintroducingadditionalshort-cutconnectionsintothenetworkasexplainedinthenextsection.Withtheseadditionalshort-cutconnections,wefoundtheperformanceofdownsamplingtobethesameasfordilatedconvolution.2.4ADDINGSHORT-CUTCONNECTIONSForinputofsize32×32oursuggestedmodelconsistsof6blocksof5ResNetlayers.Inbetweentheﬁrstandsecondblock,aswellasthesecondandthirdblock,weperformsubsamplingbystridedconvolution.Inbetweenthefourthandﬁfthblock,aswellastheﬁfthandsixthblock,weperformupsamplingbytransposedstridedconvolution.Thissubsamplingandupsamplingprocesslosesinformation,andwethereforeintroduceadditionalshort-cutconnectionsintothemodeltorecover3UnderreviewasaconferencepaperatICLR2017thisinformationfromlowerlayersinthemodel.Theshort-cutconnectionsrunfromtheResNetlayersintheﬁrstblocktothecorrespondinglayersinthesixthblock,andsimilarlybetweenblockstwoandﬁve,andblocksthreeandfour.ThisstructureresemblestheVAEmodelwithtopdowninferenceusedbyKingmaetal.(2016),aswellastheU-netusedbyRonnebergeretal.(2015)forimagesegmentation.Figure2showsourmodelstructuregraphically.= Identity (skip)       connectionx32x3216x168x88x8x= Sequence of 6     layers16x1632x32= Convolutional     connection= Downward stream= Downward and        rightward streamFigure2:LikevandenOordetal.(2016c),ourmodelfollowsatwo-stream(downward,anddownward+rightward)convolutionalarchitecturewithresidualconnections;however,therearetwosigniﬁcantdifferencesinconnectivity.First,ourarchitectureincorporatesdownsamplingandup-sampling,suchthattheinnerpartsofthenetworkoperateoverlargerspatialscale,increasingcom-putationalefﬁciency.Second,weemploylong-rangeskip-connections,suchthateachk-thlayerprovidesadirectinputtothe(K−k)-thlayer,whereKisthetotalnumberoflayersinthenet-work.Thenetworkisgroupedintosequencesofsixlayers,wheremostsequencesareseparatedbydownsamplingorupsampling.2.5REGULARIZATIONUSINGDROPOUTThePixelCNNmodelispowerfulenoughtooverﬁtontrainingdata.Moreover,ratherthanjustreproducingthetrainingimages,weﬁndthatoverﬁttedmodelsgenerateimagesoflowperceptualquality,asshowninFigure8.Oneeffectivewayofregularizingneuralnetworksisdropout(Srivas-tavaetal.,2014).Forourmodel,weapplystandardbinarydropoutontheresidualpathaftertheﬁrstconvolution.ThisissimilartohowdropoutisappliedinthewideresidualnetworksofZagoruyko&Komodakis(2016).Usingdropoutallowsustosuccessfullytrainhighcapacitymodelswhileavoidingoverﬁttingandproducinghighqualitygenerations(compareﬁgure8andﬁgure3).3EXPERIMENTSWeapplyourmodeltomodelingnaturalimagesintheCIFAR-10dataset.Weachievestate-of-the-artresultsintermsoflog-likelihood,andgenerateimageswithcoherentglobalstructure.3.1UNCONDITIONALGENERATIONONCIFAR-10WeapplyourPixelCNNmodel,withthemodiﬁcationsasdescribedabove,togenerativemodelingoftheimagesintheCIFAR-10dataset.FortheencodingpartofthePixelCNN,themodeluses3Resnetblocksconsistingof5residuallayers,with2×2downsamplinginbetween.Thesamearchitectureisusedforthedecodingpartofthemodel,butwithupsamplinginsteadofdownsamplinginbetweenblocks.Allresiduallayersuse192featuremapsandadropoutrateof0.5.Table1showsthestate-of-the-arttestlog-likelihoodobtainedbyourmodel.Figure3showssomesamplesgeneratedbythemodel.4UnderreviewasaconferencepaperatICLR2017Figure3:SamplesfromourPixelCNNmodeltrainedonCIFAR-10.ModelBitspersub-pixelDeepDiffusion(Sohl-Dicksteinetal.,2015)5.40NICE(Dinhetal.,2014)4.48DRAW(Gregoretal.,2015)4.13DeepGMMs(vandenOord&Dambre,2015)4.00ConvDRAW(Gregoretal.,2016)3.58RealNVP(Dinhetal.,2016)3.49PixelCNN(vandenOordetal.,2016b)3.14VAEwithIAF(Kingmaetal.,2016)3.11GatedPixelCNN(vandenOordetal.,2016c)3.03PixelRNN(vandenOordetal.,2016b)3.00PixelCNN++2.92Table1:Negativelog-likelihoodforgenerativemodelsonCIFAR-10expressedasbitspersub-pixel.3.2CLASS-CONDITIONALGENERATIONNext,wefollowvandenOordetal.(2016c)inmakingourgenerativemodelconditionalontheclass-labeloftheCIFAR-10images.Thisisdonebylinearlyprojectingaone-hotencodingoftheclass-labelintoaseparateclass-dependentbiasvectorforeachconvolutionalunitinournetwork.Weﬁndthatmakingthemodelclass-conditionalmakesithardertoavoidoverﬁttingonthetrainingdata:ourbesttestlog-likelihoodis2.94inthiscase.Figure4showssamplesfromtheclass-conditionalmodel,withcolumns1-10correspondingthe10classesinCIFAR-10.Theimagesclearlylookqualitativelydifferentacrossthecolumnsandforanumberofthemwecanclearlyidentifytheirclasslabel.5UnderreviewasaconferencepaperatICLR2017Figure4:Class-conditionalsamplesfromourPixelCNNforCIFAR-10(left)andrealCIFAR-10imagesforcomparison(right).3.3EXAMININGNETWORKDEPTHANDFIELDOFVIEWSIZEItishypothesizedthatthesizeofthereceptiveﬁeldandadditionallytheremovalofblindspotsinthereceptiveﬁeldareimportantforPixelCNN’sperformance(vandenOordetal.,2016b).IndeedvandenOordetal.(2016c)speciﬁcallyintroducedanimprovementoverthepreviousPixelCNNmodeltoremovetheblindspotinthereceptiveﬁeldthatwaspresentintheirearliermodel.HerewepresentthesurprisingﬁndingthatinfactaPixelCNNwithrathersmallreceptiveﬁeldcanattaincompetitivegenerativemodellingperformanceonCIFAR-10aslongasithasenoughcapacity.Speciﬁcally,weexperimentedwithourproposedPixelCNN++modelwithoutdownsamplingblocksandreducethenumberoflayerstolimitthereceptiveﬁeldsize.Weinvestigatetworeceptiveﬁeldsizes:11x5and15x8,andareceptiveﬁeldsizeof11x5,forexample,meansthattheconditionaldistributionofapixelcandependsonarectangleabovethepixelofsize11x5aswellas11−12=5x1blocktotheleftofthepixel.Aswelimitthesizeofthereceptiveﬁeld,thecapacityofthenetworkalsodropssigniﬁcantlysinceitcontainsmanyfewerlayersthananormalPixelCNN.WecallthetypeofPixelCNNthat’ssimplylimitedindepth“Plain”SmallPixelCNN.Interestingly,thismodelalreadyhasbetterperformancethantheoriginalPixelCNNinvandenOordetal.(2016b)whichhadablindspot.Toincreasecapacity,weintroducedtwosimplevariantsthatmakeSmallPixelCNNmoreexpressivewithoutgrowingthereceptiveﬁeld:•NIN(NetworkinNetwork):insertadditionalgatedResNetblockswith1x1convolutionbe-tweenregularconvolutionblocksthatgrowreceptiveﬁeld.Inthisexperiment,weinserted3NINblocksbetweeneveryotherlayer.•AutoregressiveChannel:skipconnectionsbetweensetsofchannelsvia1x1convolutiongatedResNetblock.Bothmodiﬁcationsincreasethecapacityofthenetwork,resultinginimprovedlog-likelihoodasshowninTable2.Althoughthemodelwithsmallreceptiveﬁeldalreadyachievesanimpressivelikelihoodscore,itssamplesdolackglobalstructure,asseeninFigure5.6UnderreviewasaconferencepaperatICLR2017Table2:CIFAR-10bitspersub-pixelforSmallPixelCNNModelBitspersub-pixelField=11x5,Plain3.11Field=11x5,NIN3.09Field=11x5,AutoregressiveChannel3.07Field=15x8,Plain3.07Field=15x8,NIN3.04Field=15x8,AutoregressiveChannel3.03Figure5:Samplesfrom3.03bits/dimSmallPixelCNN3.4ABLATIONEXPERIMENTSInordertotesttheeffectofourmodiﬁcationstoPixelCNN,werunanumberofablationexperimentswhereforeachexperimentweremoveaspeciﬁcmodiﬁcation.3.4.1SOFTMAXLIKELIHOODINSTEADOFDISCRETIZEDLOGISTICMIXTUREInordertotestthecontributionofourlogisticmixturelikelihood,were-runourCIFAR-10experi-mentwiththe256-waysoftmaxastheoutputdistributioninstead.Weallowthe256logitsforeachsub-pixeltolinearlydependontheobservedvalueofprevioussub-pixels,withcoefﬁcientsthataregivenasoutputbythemodel.Ourmodelwithsoftmaxlikelihoodisthusstrictlymoreﬂexiblethanourmodelwithlogisticmixturelikelihood,althoughtheparameterizationisquitedifferentfromthatusedbyvandenOordetal.(2016c).Themodelnowoutputs1536numbersperpixel,describingthelogitsonthe256potentialvaluesforeachsub-pixel,aswellasthecoefﬁcientsforthedependenciesbetweenthesub-pixels.Figure6showsthatthismodeltrainsmoreslowlythanouroriginalmodel.Inaddition,therunningtimeperepochissigniﬁcantlylongerforourtensorﬂowimplementation.Forourarchitecture,thelogisticmixturemodelthusclearlyperformsbetter.SinceourarchitecturediffersfromthatofvandenOordetal.(2016c)inotherwaysaswell,wecannotsaywhetherthiswouldalsoapplytotheirmodel.3.4.2CONTINUOUSMIXTURELIKELIHOODINSTEADOFDISCRETIZATIONInsteadofdirectlymodelingthediscretepixelvaluesinanimage,itisalsopossibletode-quantizethembyaddingnoisefromthestandarduniformdistribution,asusedbyUriaetal.(2013)andothers,andmodelingthedataasbeingcontinuous.Theresultingmodelcanbeinterpretedasavariationalautoencoder(Kingma&Welling,2013;Rezendeetal.,2014),wherethedequantizedpixelszformalatentcodewhosepriordistributioniscapturedbyourmodel.Sincetheoriginaldiscretepixelsxcanbeperfectlyreconstructedfromzunderthismodel,theusualreconstructiontermvanishesfrom7UnderreviewasaconferencepaperatICLR2017Figure6:Trainingcurvesforourmodelwithlogisticmixturelikelihoodversusourmodelwithsoftmaxlikelihood.thevariationallowerbound.Theentropyofthestandarduniformdistributioniszero,sothetermthatremainsistheloglikelihoodofthedequantizedpixels,whichthusgivesusavariationallowerboundontheloglikelihoodofouroriginaldata.Were-runourmodelforCIFAR-10usingthesamemodelsettingsasthoseusedforthe2.92bitsperdimensionresultinTable1,butnowweremovethediscretizationinourlikelihoodmodelandinsteadaddstandarduniformnoisetotheimagedata.TheresultingmodelisacontinuousmixturemodelinthesameclassasthatusedbyTheisetal.(2012);Uriaetal.(2013);Theis&Bethge(2015)andothers.Afteroptimization,thismodelgivesavariationallowerboundonthedataloglikelihoodof3.11bitsperdimension.Thedifferencewiththereported2.92bitsperdimensionshowsthebeneﬁtofusingdiscretizationinthelikelihoodmodel.3.4.3NOSHORT-CUTCONNECTIONSNext,wetesttheimportanceoftheadditionalparallelshort-cutconnectionsinourmodel,indicatedbythedottedlinesinFigure2.Were-runourunconditionalCIFAR-10experiment,butremovetheshort-cutconnectionsfromthemodel.AsseeninFigure7,themodelfailstotrainwithouttheseconnections.Thereasonforneedingtheseextrashort-cutsislikelytobeouruseofsub-sampling,whichdiscardsinformationthatotherwisecannoteasilyberecovered,Figure7:Trainingcurvesforourmodelwithandwithoutshort-cutconnections.3.4.4NODROPOUTWere-runourCIFAR-10modelwithoutdropoutregularization.Thelog-likelihoodweachieveonthetrainingsetisbelow2.0bitspersub-pixel,buttheﬁnaltestlog-likelihoodisabove6.0bitsper8UnderreviewasaconferencepaperatICLR2017sub-pixel.Atnopointduringtrainingdoestheunregularizedmodelgetatest-setlog-likelihoodbelow3.0bitspersub-pixel.Contrarytowhatwemightnaivelyexpect,theperceptualqualityofthegeneratedimagesbytheoverﬁttedmodelisnotgreat,asshowninFigure8.Figure8:SamplesfromintentionallyoverﬁttedPixelCNNmodeltrainedonCIFAR-10,withtrainlog-likelihoodof2.0bitsperdimension:Overﬁttingdoesnotresultingreatperceptualquality.4CONCLUSIONWepresentedPixelCNN++,amodiﬁcationofPixelCNNusingadiscretizedlogisticmixturelike-lihoodonthepixelsamongothermodiﬁcations.Wedemonstratedtheusefulnessofthesemod-iﬁcationswithstate-of-the-artresultsonCIFAR-10.Ourcodeismadeavailableathttps://github.com/openai/pixel-cnnandcaneasilybeadaptedforuseonotherdatasets.REFERENCESLaurentDinh,DavidKrueger,andYoshuaBengio.Nice:Non-linearindependentcomponentsesti-mation.arXivpreprintarXiv:1410.8516,2014.LaurentDinh,JaschaSohl-Dickstein,andSamyBengio.Densityestimationusingrealnvp.arXivpreprintarXiv:1605.08803,2016.JustinDomke,AlapKarapurkar,andYiannisAloimonos.Whokilledthedirectedmodel?InComputerVisionandPatternRecognition,2008.CVPR2008.IEEEConferenceon,pp.1–8.IEEE,2008.KarolGregor,IvoDanihelka,AlexGraves,andDaanWierstra.Draw:Arecurrentneuralnetworkforimagegeneration.InProceedingsofthe32ndInternationalConferenceonMachineLearning,2015.KarolGregor,FredericBesse,DaniloJimenezRezende,IvoDanihelka,andDaanWierstra.Towardsconceptualcompression.arXivpreprintarXiv:1604.08772,2016.NalKalchbrenner,LasseEspeholt,KarenSimonyan,AaronvandenOord,AlexGraves,andKorayKavukcuoglu.Neuralmachinetranslationinlineartime.arXivpreprintarXiv:1610.10099,2016a.NalKalchbrenner,AaronvandenOord,KarenSimonyan,IvoDanihelka,OriolVinyals,AlexGraves,andKorayKavukcuoglu.Videopixelnetworks.arXivpreprintarXiv:1610.00527,2016b.DiederikPKingmaandMaxWelling.Auto-EncodingVariationalBayes.Proceedingsofthe2ndInternationalConferenceonLearningRepresentations,2013.9UnderreviewasaconferencepaperatICLR2017DiederikP.Kingma,TimSalimans,RafalJozefowicz,XiChen,IlyaSutskever,andMaxWelling.Improvingvariationalinferencewithinverseautoregressiveﬂow.InAdvancesinNeuralInforma-tionProcessingSystems,2016.DaniloJRezende,ShakirMohamed,andDaanWierstra.Stochasticbackpropagationandapproxi-mateinferenceindeepgenerativemodels.InICML,pp.1278–1286,2014.OlafRonneberger,PhilippFischer,andThomasBrox.U-net:Convolutionalnetworksforbiomed-icalimagesegmentation.InInternationalConferenceonMedicalImageComputingandComputer-AssistedIntervention,pp.234–241.Springer,2015.JaschaSohl-Dickstein,EricA.Weiss,NiruMaheswaranathan,andSuryaGanguli.Deepunsuper-visedlearningusingnonequilibriumthermodynamics.InProceedingsofthe32ndInternationalConferenceonMachineLearning,2015.NitishSrivastava,GeoffreyEHinton,AlexKrizhevsky,IlyaSutskever,andRuslanSalakhutdinov.Dropout:asimplewaytopreventneuralnetworksfromoverﬁtting.JournalofMachineLearningResearch,15(1):1929–1958,2014.LucasTheisandMatthiasBethge.Generativeimagemodelingusingspatiallstms.InAdvancesinNeuralInformationProcessingSystems,pp.1927–1935,2015.LucasTheis,ReshadHosseini,andMatthiasBethge.Mixturesofconditionalgaussianscalemix-turesappliedtomultiscaleimagerepresentations.PloSone,7(7):e39857,2012.BenignoUria,IainMurray,andHugoLarochelle.Rnade:Thereal-valuedneuralautoregressivedensity-estimator.InAdvancesinNeuralInformationProcessingSystems,pp.2175–2183,2013.AaronvandenOordandJoniDambre.Locally-connectedtransformationsfordeepgmms.InInternationalConferenceonMachineLearning(ICML):DeeplearningWorkshop,2015.AaronvandenOord,SanderDieleman,HeigaZen,KarenSimonyan,OriolVinyals,AlexGraves,NalKalchbrenner,AndrewSenior,andKorayKavukcuoglu.Wavenet:Agenerativemodelforrawaudio.arXivpreprintarXiv:1609.03499,2016a.AaronvandenOord,NalKalchbrenner,andKorayKavukcuoglu.Pixelrecurrentneuralnetworks.InInternationalConferenceonMachineLearning(ICML),2016b.AaronvandenOord,NalKalchbrenner,OriolVinyals,LasseEspeholt,AlexGraves,andKo-rayKavukcuoglu.Conditionalimagegenerationwithpixelcnndecoders.arXivpreprintarXiv:1606.05328,2016c.SergeyZagoruykoandNikosKomodakis.Wideresidualnetworks.arXivpreprintarXiv:1605.07146,2016.10